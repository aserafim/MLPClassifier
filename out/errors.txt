Iteration 1, loss = 1.93407755
Iteration 2, loss = 1.91553556
Iteration 3, loss = 1.89723563
Iteration 4, loss = 1.87918141
Iteration 5, loss = 1.86137487
Iteration 6, loss = 1.84381377
Iteration 7, loss = 1.82649231
Iteration 8, loss = 1.80940230
Iteration 9, loss = 1.79253419
Iteration 10, loss = 1.77587738
Iteration 11, loss = 1.75942034
Iteration 12, loss = 1.74315076
Iteration 13, loss = 1.72705578
Iteration 14, loss = 1.71112230
Iteration 15, loss = 1.69533743
Iteration 16, loss = 1.67968871
Iteration 17, loss = 1.66416440
Iteration 18, loss = 1.64875363
Iteration 19, loss = 1.63344648
Iteration 20, loss = 1.61823412
Iteration 21, loss = 1.60310879
Iteration 22, loss = 1.58806374
Iteration 23, loss = 1.57309321
Iteration 24, loss = 1.55819228
Iteration 25, loss = 1.54335685
Iteration 26, loss = 1.52858351
Iteration 27, loss = 1.51386943
Iteration 28, loss = 1.49921236
Iteration 29, loss = 1.48461047
Iteration 30, loss = 1.47006233
Iteration 31, loss = 1.45556685
Iteration 32, loss = 1.44112323
Iteration 33, loss = 1.42673091
Iteration 34, loss = 1.41238957
Iteration 35, loss = 1.39809908
Iteration 36, loss = 1.38385949
Iteration 37, loss = 1.36967100
Iteration 38, loss = 1.35553397
Iteration 39, loss = 1.34144889
Iteration 40, loss = 1.32741638
Iteration 41, loss = 1.31343717
Iteration 42, loss = 1.29951209
Iteration 43, loss = 1.28564209
Iteration 44, loss = 1.27182817
Iteration 45, loss = 1.25807141
Iteration 46, loss = 1.24437293
Iteration 47, loss = 1.23073392
Iteration 48, loss = 1.21715559
Iteration 49, loss = 1.20363917
Iteration 50, loss = 1.19018591
Iteration 51, loss = 1.17679707
Iteration 52, loss = 1.16347390
Iteration 53, loss = 1.15021768
Iteration 54, loss = 1.13702967
Iteration 55, loss = 1.12391111
Iteration 56, loss = 1.11086326
Iteration 57, loss = 1.09788737
Iteration 58, loss = 1.08498467
Iteration 59, loss = 1.07215639
Iteration 60, loss = 1.05940376
Iteration 61, loss = 1.04672801
Iteration 62, loss = 1.03413035
Iteration 63, loss = 1.02161199
Iteration 64, loss = 1.00917413
Iteration 65, loss = 0.99681797
Iteration 66, loss = 0.98454469
Iteration 67, loss = 0.97235547
Iteration 68, loss = 0.96025147
Iteration 69, loss = 0.94823383
Iteration 70, loss = 0.93630369
Iteration 71, loss = 0.92446217
Iteration 72, loss = 0.91271036
Iteration 73, loss = 0.90104933
Iteration 74, loss = 0.88948016
Iteration 75, loss = 0.87800386
Iteration 76, loss = 0.86662145
Iteration 77, loss = 0.85533392
Iteration 78, loss = 0.84414223
Iteration 79, loss = 0.83304732
Iteration 80, loss = 0.82205009
Iteration 81, loss = 0.81115143
Iteration 82, loss = 0.80035220
Iteration 83, loss = 0.78965321
Iteration 84, loss = 0.77905526
Iteration 85, loss = 0.76855912
Iteration 86, loss = 0.75816552
Iteration 87, loss = 0.74787517
Iteration 88, loss = 0.73768872
Iteration 89, loss = 0.72760681
Iteration 90, loss = 0.71763005
Iteration 91, loss = 0.70775899
Iteration 92, loss = 0.69799416
Iteration 93, loss = 0.68833604
Iteration 94, loss = 0.67878508
Iteration 95, loss = 0.66934167
Iteration 96, loss = 0.66000619
Iteration 97, loss = 0.65077894
Iteration 98, loss = 0.64166021
Iteration 99, loss = 0.63265020
Iteration 100, loss = 0.62374912
Iteration 101, loss = 0.61495708
Iteration 102, loss = 0.60627417
Iteration 103, loss = 0.59770042
Iteration 104, loss = 0.58923583
Iteration 105, loss = 0.58088032
Iteration 106, loss = 0.57263378
Iteration 107, loss = 0.56449604
Iteration 108, loss = 0.55646690
Iteration 109, loss = 0.54854609
Iteration 110, loss = 0.54073330
Iteration 111, loss = 0.53302817
Iteration 112, loss = 0.52543029
Iteration 113, loss = 0.51793921
Iteration 114, loss = 0.51055443
Iteration 115, loss = 0.50327540
Iteration 116, loss = 0.49610155
Iteration 117, loss = 0.48903225
Iteration 118, loss = 0.48206682
Iteration 119, loss = 0.47520457
Iteration 120, loss = 0.46844475
Iteration 121, loss = 0.46178659
Iteration 122, loss = 0.45522927
Iteration 123, loss = 0.44877195
Iteration 124, loss = 0.44241377
Iteration 125, loss = 0.43615382
Iteration 126, loss = 0.42999117
Iteration 127, loss = 0.42392487
Iteration 128, loss = 0.41795395
Iteration 129, loss = 0.41207741
Iteration 130, loss = 0.40629423
Iteration 131, loss = 0.40060338
Iteration 132, loss = 0.39500380
Iteration 133, loss = 0.38949444
Iteration 134, loss = 0.38407420
Iteration 135, loss = 0.37874201
Iteration 136, loss = 0.37349674
Iteration 137, loss = 0.36833730
Iteration 138, loss = 0.36326255
Iteration 139, loss = 0.35827137
Iteration 140, loss = 0.35336264
Iteration 141, loss = 0.34853520
Iteration 142, loss = 0.34378792
Iteration 143, loss = 0.33911966
Iteration 144, loss = 0.33452927
Iteration 145, loss = 0.33001561
Iteration 146, loss = 0.32557754
Iteration 147, loss = 0.32121390
Iteration 148, loss = 0.31692358
Iteration 149, loss = 0.31270542
Iteration 150, loss = 0.30855831
Iteration 151, loss = 0.30448111
Iteration 152, loss = 0.30047270
Iteration 153, loss = 0.29653199
Iteration 154, loss = 0.29265784
Iteration 155, loss = 0.28884919
Iteration 156, loss = 0.28510492
Iteration 157, loss = 0.28142396
Iteration 158, loss = 0.27780525
Iteration 159, loss = 0.27424772
Iteration 160, loss = 0.27075032
Iteration 161, loss = 0.26731202
Iteration 162, loss = 0.26393177
Iteration 163, loss = 0.26060858
Iteration 164, loss = 0.25734142
Iteration 165, loss = 0.25412932
Iteration 166, loss = 0.25097129
Iteration 167, loss = 0.24786635
Iteration 168, loss = 0.24481357
Iteration 169, loss = 0.24181199
Iteration 170, loss = 0.23886068
Iteration 171, loss = 0.23595873
Iteration 172, loss = 0.23310524
Iteration 173, loss = 0.23029931
Iteration 174, loss = 0.22754008
Iteration 175, loss = 0.22482667
Iteration 176, loss = 0.22215825
Iteration 177, loss = 0.21953397
Iteration 178, loss = 0.21695302
Iteration 179, loss = 0.21441458
Iteration 180, loss = 0.21191786
Iteration 181, loss = 0.20946209
Iteration 182, loss = 0.20704649
Iteration 183, loss = 0.20467030
Iteration 184, loss = 0.20233280
Iteration 185, loss = 0.20003325
Iteration 186, loss = 0.19777093
Iteration 187, loss = 0.19554515
Iteration 188, loss = 0.19335522
Iteration 189, loss = 0.19120046
Iteration 190, loss = 0.18908021
Iteration 191, loss = 0.18699382
Iteration 192, loss = 0.18494064
Iteration 193, loss = 0.18292006
Iteration 194, loss = 0.18093146
Iteration 195, loss = 0.17897424
Iteration 196, loss = 0.17704780
Iteration 197, loss = 0.17515158
Iteration 198, loss = 0.17328499
Iteration 199, loss = 0.17144750
Iteration 200, loss = 0.16963854
Iteration 201, loss = 0.16785759
Iteration 202, loss = 0.16610411
Iteration 203, loss = 0.16437761
Iteration 204, loss = 0.16267758
Iteration 205, loss = 0.16100352
Iteration 206, loss = 0.15935494
Iteration 207, loss = 0.15773139
Iteration 208, loss = 0.15613239
Iteration 209, loss = 0.15455748
Iteration 210, loss = 0.15300623
Iteration 211, loss = 0.15147820
Iteration 212, loss = 0.14997296
Iteration 213, loss = 0.14849009
Iteration 214, loss = 0.14702918
Iteration 215, loss = 0.14558982
Iteration 216, loss = 0.14417163
Iteration 217, loss = 0.14277422
Iteration 218, loss = 0.14139721
Iteration 219, loss = 0.14004023
Iteration 220, loss = 0.13870291
Iteration 221, loss = 0.13738490
Iteration 222, loss = 0.13608585
Iteration 223, loss = 0.13480542
Iteration 224, loss = 0.13354327
Iteration 225, loss = 0.13229908
Iteration 226, loss = 0.13107252
Iteration 227, loss = 0.12986327
Iteration 228, loss = 0.12867103
Iteration 229, loss = 0.12749550
Iteration 230, loss = 0.12633638
Iteration 231, loss = 0.12519337
Iteration 232, loss = 0.12406619
Iteration 233, loss = 0.12295457
Iteration 234, loss = 0.12185822
Iteration 235, loss = 0.12077688
Iteration 236, loss = 0.11971028
Iteration 237, loss = 0.11865818
Iteration 238, loss = 0.11762031
Iteration 239, loss = 0.11659642
Iteration 240, loss = 0.11558628
Iteration 241, loss = 0.11458965
Iteration 242, loss = 0.11360629
Iteration 243, loss = 0.11263597
Iteration 244, loss = 0.11167847
Iteration 245, loss = 0.11073357
Iteration 246, loss = 0.10980105
Iteration 247, loss = 0.10888071
Iteration 248, loss = 0.10797234
Iteration 249, loss = 0.10707573
Iteration 250, loss = 0.10619068
Iteration 251, loss = 0.10531700
Iteration 252, loss = 0.10445450
Iteration 253, loss = 0.10360299
Iteration 254, loss = 0.10276229
Iteration 255, loss = 0.10193222
Iteration 256, loss = 0.10111260
Iteration 257, loss = 0.10030326
Iteration 258, loss = 0.09950403
Iteration 259, loss = 0.09871474
Iteration 260, loss = 0.09793522
Iteration 261, loss = 0.09716533
Iteration 262, loss = 0.09640491
Iteration 263, loss = 0.09565379
Iteration 264, loss = 0.09491183
Iteration 265, loss = 0.09417888
Iteration 266, loss = 0.09345480
Iteration 267, loss = 0.09273944
Iteration 268, loss = 0.09203267
Iteration 269, loss = 0.09133434
Iteration 270, loss = 0.09064433
Iteration 271, loss = 0.08996251
Iteration 272, loss = 0.08928873
Iteration 273, loss = 0.08862289
Iteration 274, loss = 0.08796484
Iteration 275, loss = 0.08731448
Iteration 276, loss = 0.08667168
Iteration 277, loss = 0.08603633
Iteration 278, loss = 0.08540831
Iteration 279, loss = 0.08478750
Iteration 280, loss = 0.08417380
Iteration 281, loss = 0.08356710
Iteration 282, loss = 0.08296729
Iteration 283, loss = 0.08237427
Iteration 284, loss = 0.08178793
Iteration 285, loss = 0.08120817
Iteration 286, loss = 0.08063490
Iteration 287, loss = 0.08006802
Iteration 288, loss = 0.07950743
Iteration 289, loss = 0.07895304
Iteration 290, loss = 0.07840475
Iteration 291, loss = 0.07786249
Iteration 292, loss = 0.07732615
Iteration 293, loss = 0.07679565
Iteration 294, loss = 0.07627091
Iteration 295, loss = 0.07575184
Iteration 296, loss = 0.07523836
Iteration 297, loss = 0.07473038
Iteration 298, loss = 0.07422784
Iteration 299, loss = 0.07373065
Iteration 300, loss = 0.07323874
Iteration 301, loss = 0.07275202
Iteration 302, loss = 0.07227044
Iteration 303, loss = 0.07179390
Iteration 304, loss = 0.07132235
Iteration 305, loss = 0.07085570
Iteration 306, loss = 0.07039390
Iteration 307, loss = 0.06993688
Iteration 308, loss = 0.06948457
Iteration 309, loss = 0.06903689
Iteration 310, loss = 0.06859380
Iteration 311, loss = 0.06815522
Iteration 312, loss = 0.06772110
Iteration 313, loss = 0.06729137
Iteration 314, loss = 0.06686597
Iteration 315, loss = 0.06644485
Iteration 316, loss = 0.06602794
Iteration 317, loss = 0.06561519
Iteration 318, loss = 0.06520655
Iteration 319, loss = 0.06480195
Iteration 320, loss = 0.06440134
Iteration 321, loss = 0.06400468
Iteration 322, loss = 0.06361190
Iteration 323, loss = 0.06322296
Iteration 324, loss = 0.06283781
Iteration 325, loss = 0.06245639
Iteration 326, loss = 0.06207866
Iteration 327, loss = 0.06170457
Iteration 328, loss = 0.06133407
Iteration 329, loss = 0.06096712
Iteration 330, loss = 0.06060366
Iteration 331, loss = 0.06024365
Iteration 332, loss = 0.05988706
Iteration 333, loss = 0.05953383
Iteration 334, loss = 0.05918393
Iteration 335, loss = 0.05883730
Iteration 336, loss = 0.05849391
Iteration 337, loss = 0.05815372
Iteration 338, loss = 0.05781669
Iteration 339, loss = 0.05748277
Iteration 340, loss = 0.05715194
Iteration 341, loss = 0.05682414
Iteration 342, loss = 0.05649934
Iteration 343, loss = 0.05617751
Iteration 344, loss = 0.05585861
Iteration 345, loss = 0.05554260
Iteration 346, loss = 0.05522944
Iteration 347, loss = 0.05491911
Iteration 348, loss = 0.05461156
Iteration 349, loss = 0.05430677
Iteration 350, loss = 0.05400469
Iteration 351, loss = 0.05370530
Iteration 352, loss = 0.05340856
Iteration 353, loss = 0.05311445
Iteration 354, loss = 0.05282293
Iteration 355, loss = 0.05253396
Iteration 356, loss = 0.05224753
Iteration 357, loss = 0.05196359
Iteration 358, loss = 0.05168213
Iteration 359, loss = 0.05140310
Iteration 360, loss = 0.05112648
Iteration 361, loss = 0.05085225
Iteration 362, loss = 0.05058037
Iteration 363, loss = 0.05031082
Iteration 364, loss = 0.05004357
Iteration 365, loss = 0.04977859
Iteration 366, loss = 0.04951586
Iteration 367, loss = 0.04925536
Iteration 368, loss = 0.04899704
Iteration 369, loss = 0.04874090
Iteration 370, loss = 0.04848691
Iteration 371, loss = 0.04823503
Iteration 372, loss = 0.04798525
Iteration 373, loss = 0.04773755
Iteration 374, loss = 0.04749190
Iteration 375, loss = 0.04724827
Iteration 376, loss = 0.04700665
Iteration 377, loss = 0.04676701
Iteration 378, loss = 0.04652932
Iteration 379, loss = 0.04629358
Iteration 380, loss = 0.04605975
Iteration 381, loss = 0.04582782
Iteration 382, loss = 0.04559776
Iteration 383, loss = 0.04536955
Iteration 384, loss = 0.04514318
Iteration 385, loss = 0.04491862
Iteration 386, loss = 0.04469585
Iteration 387, loss = 0.04447486
Iteration 388, loss = 0.04425562
Iteration 389, loss = 0.04403812
Iteration 390, loss = 0.04382233
Iteration 391, loss = 0.04360824
Iteration 392, loss = 0.04339583
Iteration 393, loss = 0.04318509
Iteration 394, loss = 0.04297598
Iteration 395, loss = 0.04276851
Iteration 396, loss = 0.04256264
Iteration 397, loss = 0.04235837
Iteration 398, loss = 0.04215567
Iteration 399, loss = 0.04195453
Iteration 400, loss = 0.04175493
Iteration 401, loss = 0.04155686
Iteration 402, loss = 0.04136030
Iteration 403, loss = 0.04116523
Iteration 404, loss = 0.04097164
Iteration 405, loss = 0.04077952
Iteration 406, loss = 0.04058885
Iteration 407, loss = 0.04039961
Iteration 408, loss = 0.04021178
Iteration 409, loss = 0.04002537
Iteration 410, loss = 0.03984034
Iteration 411, loss = 0.03965669
Iteration 412, loss = 0.03947440
Iteration 413, loss = 0.03929346
Iteration 414, loss = 0.03911386
Iteration 415, loss = 0.03893557
Iteration 416, loss = 0.03875859
Iteration 417, loss = 0.03858291
Iteration 418, loss = 0.03840851
Iteration 419, loss = 0.03823538
Iteration 420, loss = 0.03806350
Iteration 421, loss = 0.03789287
Iteration 422, loss = 0.03772347
Iteration 423, loss = 0.03755529
Iteration 424, loss = 0.03738832
Iteration 425, loss = 0.03722254
Iteration 426, loss = 0.03705795
Iteration 427, loss = 0.03689453
Iteration 428, loss = 0.03673227
Iteration 429, loss = 0.03657116
Iteration 430, loss = 0.03641118
Iteration 431, loss = 0.03625234
Iteration 432, loss = 0.03609461
Iteration 433, loss = 0.03593799
Iteration 434, loss = 0.03578246
Iteration 435, loss = 0.03562802
Iteration 436, loss = 0.03547465
Iteration 437, loss = 0.03532234
Iteration 438, loss = 0.03517109
Iteration 439, loss = 0.03502089
Iteration 440, loss = 0.03487171
Iteration 441, loss = 0.03472356
Iteration 442, loss = 0.03457643
Iteration 443, loss = 0.03443030
Iteration 444, loss = 0.03428517
Iteration 445, loss = 0.03414102
Iteration 446, loss = 0.03399785
Iteration 447, loss = 0.03385565
Iteration 448, loss = 0.03371441
Iteration 449, loss = 0.03357412
Iteration 450, loss = 0.03343477
Iteration 451, loss = 0.03329635
Iteration 452, loss = 0.03315886
Iteration 453, loss = 0.03302228
Iteration 454, loss = 0.03288661
Iteration 455, loss = 0.03275184
Iteration 456, loss = 0.03261796
Iteration 457, loss = 0.03248496
Iteration 458, loss = 0.03235284
Iteration 459, loss = 0.03222159
Iteration 460, loss = 0.03209119
Iteration 461, loss = 0.03196165
Iteration 462, loss = 0.03183295
Iteration 463, loss = 0.03170508
Iteration 464, loss = 0.03157805
Iteration 465, loss = 0.03145184
Iteration 466, loss = 0.03132644
Iteration 467, loss = 0.03120185
Iteration 468, loss = 0.03107806
Iteration 469, loss = 0.03095506
Iteration 470, loss = 0.03083284
Iteration 471, loss = 0.03071141
Iteration 472, loss = 0.03059075
Iteration 473, loss = 0.03047085
Iteration 474, loss = 0.03035171
Iteration 475, loss = 0.03023333
Iteration 476, loss = 0.03011569
Iteration 477, loss = 0.02999879
Iteration 478, loss = 0.02988262
Iteration 479, loss = 0.02976718
Iteration 480, loss = 0.02965246
Iteration 481, loss = 0.02953845
Iteration 482, loss = 0.02942515
Iteration 483, loss = 0.02931255
Iteration 484, loss = 0.02920065
Iteration 485, loss = 0.02908944
Iteration 486, loss = 0.02897891
Iteration 487, loss = 0.02886907
Iteration 488, loss = 0.02875989
Iteration 489, loss = 0.02865138
Iteration 490, loss = 0.02854353
Iteration 491, loss = 0.02843634
Iteration 492, loss = 0.02832980
Iteration 493, loss = 0.02822391
Iteration 494, loss = 0.02811865
Iteration 495, loss = 0.02801403
Iteration 496, loss = 0.02791003
Iteration 497, loss = 0.02780666
Iteration 498, loss = 0.02770391
Iteration 499, loss = 0.02760178
Iteration 500, loss = 0.02750025
Iteration 501, loss = 0.02739932
Iteration 502, loss = 0.02729900
Iteration 503, loss = 0.02719926
Iteration 504, loss = 0.02710012
Iteration 505, loss = 0.02700156
Iteration 506, loss = 0.02690358
Iteration 507, loss = 0.02680617
Iteration 508, loss = 0.02670934
Iteration 509, loss = 0.02661307
Iteration 510, loss = 0.02651736
Iteration 511, loss = 0.02642221
Iteration 512, loss = 0.02632761
Iteration 513, loss = 0.02623355
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
