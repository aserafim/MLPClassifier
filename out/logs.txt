Iteration 1, loss = 1.95232352
Iteration 2, loss = 1.93371566
Iteration 3, loss = 1.91534534
Iteration 4, loss = 1.89720608
Iteration 5, loss = 1.87929225
Iteration 6, loss = 1.86159544
Iteration 7, loss = 1.84410628
Iteration 8, loss = 1.82681481
Iteration 9, loss = 1.80970996
Iteration 10, loss = 1.79277956
Iteration 11, loss = 1.77601090
Iteration 12, loss = 1.75939112
Iteration 13, loss = 1.74290758
Iteration 14, loss = 1.72654815
Iteration 15, loss = 1.71030146
Iteration 16, loss = 1.69415710
Iteration 17, loss = 1.67810568
Iteration 18, loss = 1.66213889
Iteration 19, loss = 1.64624931
Iteration 20, loss = 1.63043042
Iteration 21, loss = 1.61467646
Iteration 22, loss = 1.59898243
Iteration 23, loss = 1.58334404
Iteration 24, loss = 1.56775764
Iteration 25, loss = 1.55222017
Iteration 26, loss = 1.53672908
Iteration 27, loss = 1.52128225
Iteration 28, loss = 1.50587799
Iteration 29, loss = 1.49051494
Iteration 30, loss = 1.47519208
Iteration 31, loss = 1.45990868
Iteration 32, loss = 1.44466429
Iteration 33, loss = 1.42945875
Iteration 34, loss = 1.41429218
Iteration 35, loss = 1.39916496
Iteration 36, loss = 1.38407776
Iteration 37, loss = 1.36903147
Iteration 38, loss = 1.35402728
Iteration 39, loss = 1.33906657
Iteration 40, loss = 1.32415096
Iteration 41, loss = 1.30928227
Iteration 42, loss = 1.29446247
Iteration 43, loss = 1.27969371
Iteration 44, loss = 1.26497825
Iteration 45, loss = 1.25031845
Iteration 46, loss = 1.23571678
Iteration 47, loss = 1.22117574
Iteration 48, loss = 1.20669791
Iteration 49, loss = 1.19228590
Iteration 50, loss = 1.17794235
Iteration 51, loss = 1.16366991
Iteration 52, loss = 1.14947126
Iteration 53, loss = 1.13534906
Iteration 54, loss = 1.12130597
Iteration 55, loss = 1.10734463
Iteration 56, loss = 1.09346769
Iteration 57, loss = 1.07967774
Iteration 58, loss = 1.06597736
Iteration 59, loss = 1.05236910
Iteration 60, loss = 1.03885545
Iteration 61, loss = 1.02543889
Iteration 62, loss = 1.01212183
Iteration 63, loss = 0.99890662
Iteration 64, loss = 0.98579557
Iteration 65, loss = 0.97279091
Iteration 66, loss = 0.95989482
Iteration 67, loss = 0.94710939
Iteration 68, loss = 0.93443666
Iteration 69, loss = 0.92187855
Iteration 70, loss = 0.90943693
Iteration 71, loss = 0.89711358
Iteration 72, loss = 0.88491016
Iteration 73, loss = 0.87282828
Iteration 74, loss = 0.86086941
Iteration 75, loss = 0.84903496
Iteration 76, loss = 0.83732623
Iteration 77, loss = 0.82574439
Iteration 78, loss = 0.81429055
Iteration 79, loss = 0.80296569
Iteration 80, loss = 0.79177069
Iteration 81, loss = 0.78070634
Iteration 82, loss = 0.76977331
Iteration 83, loss = 0.75897217
Iteration 84, loss = 0.74830340
Iteration 85, loss = 0.73776735
Iteration 86, loss = 0.72736429
Iteration 87, loss = 0.71709438
Iteration 88, loss = 0.70695769
Iteration 89, loss = 0.69695420
Iteration 90, loss = 0.68708376
Iteration 91, loss = 0.67734616
Iteration 92, loss = 0.66774110
Iteration 93, loss = 0.65826818
Iteration 94, loss = 0.64892692
Iteration 95, loss = 0.63971676
Iteration 96, loss = 0.63063706
Iteration 97, loss = 0.62168712
Iteration 98, loss = 0.61286615
Iteration 99, loss = 0.60417330
Iteration 100, loss = 0.59560767
Iteration 101, loss = 0.58716830
Iteration 102, loss = 0.57885415
Iteration 103, loss = 0.57066415
Iteration 104, loss = 0.56259719
Iteration 105, loss = 0.55465209
Iteration 106, loss = 0.54682766
Iteration 107, loss = 0.53912264
Iteration 108, loss = 0.53153577
Iteration 109, loss = 0.52406574
Iteration 110, loss = 0.51671121
Iteration 111, loss = 0.50947082
Iteration 112, loss = 0.50234321
Iteration 113, loss = 0.49532696
Iteration 114, loss = 0.48842067
Iteration 115, loss = 0.48162291
Iteration 116, loss = 0.47493225
Iteration 117, loss = 0.46834725
Iteration 118, loss = 0.46186644
Iteration 119, loss = 0.45548838
Iteration 120, loss = 0.44921161
Iteration 121, loss = 0.44303467
Iteration 122, loss = 0.43695611
Iteration 123, loss = 0.43097448
Iteration 124, loss = 0.42508833
Iteration 125, loss = 0.41929623
Iteration 126, loss = 0.41359673
Iteration 127, loss = 0.40798843
Iteration 128, loss = 0.40246990
Iteration 129, loss = 0.39703975
Iteration 130, loss = 0.39169658
Iteration 131, loss = 0.38643902
Iteration 132, loss = 0.38126572
Iteration 133, loss = 0.37617532
Iteration 134, loss = 0.37116648
Iteration 135, loss = 0.36623791
Iteration 136, loss = 0.36138829
Iteration 137, loss = 0.35661635
Iteration 138, loss = 0.35192081
Iteration 139, loss = 0.34730044
Iteration 140, loss = 0.34275399
Iteration 141, loss = 0.33828026
Iteration 142, loss = 0.33387804
Iteration 143, loss = 0.32954617
Iteration 144, loss = 0.32528348
Iteration 145, loss = 0.32108883
Iteration 146, loss = 0.31696110
Iteration 147, loss = 0.31289917
Iteration 148, loss = 0.30890197
Iteration 149, loss = 0.30496841
Iteration 150, loss = 0.30109744
Iteration 151, loss = 0.29728802
Iteration 152, loss = 0.29353914
Iteration 153, loss = 0.28984979
Iteration 154, loss = 0.28621897
Iteration 155, loss = 0.28264573
Iteration 156, loss = 0.27912909
Iteration 157, loss = 0.27566813
Iteration 158, loss = 0.27226192
Iteration 159, loss = 0.26890954
Iteration 160, loss = 0.26561010
Iteration 161, loss = 0.26236271
Iteration 162, loss = 0.25916653
Iteration 163, loss = 0.25602068
Iteration 164, loss = 0.25292433
Iteration 165, loss = 0.24987666
Iteration 166, loss = 0.24687685
Iteration 167, loss = 0.24392410
Iteration 168, loss = 0.24101763
Iteration 169, loss = 0.23815666
Iteration 170, loss = 0.23534044
Iteration 171, loss = 0.23256821
Iteration 172, loss = 0.22983923
Iteration 173, loss = 0.22715277
Iteration 174, loss = 0.22450813
Iteration 175, loss = 0.22190460
Iteration 176, loss = 0.21934148
Iteration 177, loss = 0.21681809
Iteration 178, loss = 0.21433376
Iteration 179, loss = 0.21188784
Iteration 180, loss = 0.20947966
Iteration 181, loss = 0.20710859
Iteration 182, loss = 0.20477400
Iteration 183, loss = 0.20247526
Iteration 184, loss = 0.20021177
Iteration 185, loss = 0.19798292
Iteration 186, loss = 0.19578813
Iteration 187, loss = 0.19362680
Iteration 188, loss = 0.19149836
Iteration 189, loss = 0.18940225
Iteration 190, loss = 0.18733791
Iteration 191, loss = 0.18530480
Iteration 192, loss = 0.18330238
Iteration 193, loss = 0.18133011
Iteration 194, loss = 0.17938748
Iteration 195, loss = 0.17747397
Iteration 196, loss = 0.17558908
Iteration 197, loss = 0.17373232
Iteration 198, loss = 0.17190318
Iteration 199, loss = 0.17010120
Iteration 200, loss = 0.16832591
Iteration 201, loss = 0.16657683
Iteration 202, loss = 0.16485352
Iteration 203, loss = 0.16315552
Iteration 204, loss = 0.16148239
Iteration 205, loss = 0.15983371
Iteration 206, loss = 0.15820904
Iteration 207, loss = 0.15660797
Iteration 208, loss = 0.15503009
Iteration 209, loss = 0.15347500
Iteration 210, loss = 0.15194229
Iteration 211, loss = 0.15043159
Iteration 212, loss = 0.14894250
Iteration 213, loss = 0.14747466
Iteration 214, loss = 0.14602770
Iteration 215, loss = 0.14460125
Iteration 216, loss = 0.14319496
Iteration 217, loss = 0.14180849
Iteration 218, loss = 0.14044150
Iteration 219, loss = 0.13909364
Iteration 220, loss = 0.13776459
Iteration 221, loss = 0.13645403
Iteration 222, loss = 0.13516164
Iteration 223, loss = 0.13388711
Iteration 224, loss = 0.13263014
Iteration 225, loss = 0.13139043
Iteration 226, loss = 0.13016768
Iteration 227, loss = 0.12896162
Iteration 228, loss = 0.12777196
Iteration 229, loss = 0.12659842
Iteration 230, loss = 0.12544073
Iteration 231, loss = 0.12429863
Iteration 232, loss = 0.12317186
Iteration 233, loss = 0.12206015
Iteration 234, loss = 0.12096328
Iteration 235, loss = 0.11988097
Iteration 236, loss = 0.11881301
Iteration 237, loss = 0.11775914
Iteration 238, loss = 0.11671914
Iteration 239, loss = 0.11569278
Iteration 240, loss = 0.11467985
Iteration 241, loss = 0.11368011
Iteration 242, loss = 0.11269336
Iteration 243, loss = 0.11171939
Iteration 244, loss = 0.11075798
Iteration 245, loss = 0.10980895
Iteration 246, loss = 0.10887209
Iteration 247, loss = 0.10794720
Iteration 248, loss = 0.10703410
Iteration 249, loss = 0.10613259
Iteration 250, loss = 0.10524250
Iteration 251, loss = 0.10436365
Iteration 252, loss = 0.10349585
Iteration 253, loss = 0.10263893
Iteration 254, loss = 0.10179273
Iteration 255, loss = 0.10095707
Iteration 256, loss = 0.10013179
Iteration 257, loss = 0.09931674
Iteration 258, loss = 0.09851175
Iteration 259, loss = 0.09771666
Iteration 260, loss = 0.09693133
Iteration 261, loss = 0.09615560
Iteration 262, loss = 0.09538932
Iteration 263, loss = 0.09463236
Iteration 264, loss = 0.09388457
Iteration 265, loss = 0.09314582
Iteration 266, loss = 0.09241595
Iteration 267, loss = 0.09169484
Iteration 268, loss = 0.09098237
Iteration 269, loss = 0.09027838
Iteration 270, loss = 0.08958277
Iteration 271, loss = 0.08889540
Iteration 272, loss = 0.08821616
Iteration 273, loss = 0.08754491
Iteration 274, loss = 0.08688154
Iteration 275, loss = 0.08622593
Iteration 276, loss = 0.08557798
Iteration 277, loss = 0.08493756
Iteration 278, loss = 0.08430456
Iteration 279, loss = 0.08367887
Iteration 280, loss = 0.08306040
Iteration 281, loss = 0.08244902
Iteration 282, loss = 0.08184465
Iteration 283, loss = 0.08124717
Iteration 284, loss = 0.08065648
Iteration 285, loss = 0.08007249
Iteration 286, loss = 0.07949510
Iteration 287, loss = 0.07892421
Iteration 288, loss = 0.07835973
Iteration 289, loss = 0.07780157
Iteration 290, loss = 0.07724964
Iteration 291, loss = 0.07670384
Iteration 292, loss = 0.07616409
Iteration 293, loss = 0.07563030
Iteration 294, loss = 0.07510239
Iteration 295, loss = 0.07458028
Iteration 296, loss = 0.07406388
Iteration 297, loss = 0.07355310
Iteration 298, loss = 0.07304788
Iteration 299, loss = 0.07254813
Iteration 300, loss = 0.07205378
Iteration 301, loss = 0.07156474
Iteration 302, loss = 0.07108096
Iteration 303, loss = 0.07060234
Iteration 304, loss = 0.07012882
Iteration 305, loss = 0.06966033
Iteration 306, loss = 0.06919680
Iteration 307, loss = 0.06873816
Iteration 308, loss = 0.06828435
Iteration 309, loss = 0.06783529
Iteration 310, loss = 0.06739091
Iteration 311, loss = 0.06695117
Iteration 312, loss = 0.06651599
Iteration 313, loss = 0.06608530
Iteration 314, loss = 0.06565906
Iteration 315, loss = 0.06523719
Iteration 316, loss = 0.06481964
Iteration 317, loss = 0.06440636
Iteration 318, loss = 0.06399727
Iteration 319, loss = 0.06359233
Iteration 320, loss = 0.06319148
Iteration 321, loss = 0.06279467
Iteration 322, loss = 0.06240184
Iteration 323, loss = 0.06201294
Iteration 324, loss = 0.06162791
Iteration 325, loss = 0.06124671
Iteration 326, loss = 0.06086928
Iteration 327, loss = 0.06049557
Iteration 328, loss = 0.06012554
Iteration 329, loss = 0.05975914
Iteration 330, loss = 0.05939631
Iteration 331, loss = 0.05903702
Iteration 332, loss = 0.05868121
Iteration 333, loss = 0.05832884
Iteration 334, loss = 0.05797987
Iteration 335, loss = 0.05763425
Iteration 336, loss = 0.05729194
Iteration 337, loss = 0.05695290
Iteration 338, loss = 0.05661708
Iteration 339, loss = 0.05628444
Iteration 340, loss = 0.05595495
Iteration 341, loss = 0.05562856
Iteration 342, loss = 0.05530523
Iteration 343, loss = 0.05498492
Iteration 344, loss = 0.05466761
Iteration 345, loss = 0.05435323
Iteration 346, loss = 0.05404177
Iteration 347, loss = 0.05373319
Iteration 348, loss = 0.05342744
Iteration 349, loss = 0.05312450
Iteration 350, loss = 0.05282433
Iteration 351, loss = 0.05252689
Iteration 352, loss = 0.05223215
Iteration 353, loss = 0.05194008
Iteration 354, loss = 0.05165064
Iteration 355, loss = 0.05136380
Iteration 356, loss = 0.05107954
Iteration 357, loss = 0.05079781
Iteration 358, loss = 0.05051860
Iteration 359, loss = 0.05024186
Iteration 360, loss = 0.04996756
Iteration 361, loss = 0.04969569
Iteration 362, loss = 0.04942621
Iteration 363, loss = 0.04915908
Iteration 364, loss = 0.04889429
Iteration 365, loss = 0.04863181
Iteration 366, loss = 0.04837160
Iteration 367, loss = 0.04811364
Iteration 368, loss = 0.04785791
Iteration 369, loss = 0.04760437
Iteration 370, loss = 0.04735301
Iteration 371, loss = 0.04710379
Iteration 372, loss = 0.04685669
Iteration 373, loss = 0.04661169
Iteration 374, loss = 0.04636876
Iteration 375, loss = 0.04612788
Iteration 376, loss = 0.04588903
Iteration 377, loss = 0.04565217
Iteration 378, loss = 0.04541730
Iteration 379, loss = 0.04518438
Iteration 380, loss = 0.04495339
Iteration 381, loss = 0.04472432
Iteration 382, loss = 0.04449714
Iteration 383, loss = 0.04427182
Iteration 384, loss = 0.04404835
Iteration 385, loss = 0.04382671
Iteration 386, loss = 0.04360687
Iteration 387, loss = 0.04338882
Iteration 388, loss = 0.04317254
Iteration 389, loss = 0.04295800
Iteration 390, loss = 0.04274519
Iteration 391, loss = 0.04253408
Iteration 392, loss = 0.04232467
Iteration 393, loss = 0.04211692
Iteration 394, loss = 0.04191083
Iteration 395, loss = 0.04170637
Iteration 396, loss = 0.04150353
Iteration 397, loss = 0.04130229
Iteration 398, loss = 0.04110263
Iteration 399, loss = 0.04090453
Iteration 400, loss = 0.04070798
Iteration 401, loss = 0.04051296
Iteration 402, loss = 0.04031945
Iteration 403, loss = 0.04012745
Iteration 404, loss = 0.03993692
Iteration 405, loss = 0.03974786
Iteration 406, loss = 0.03956025
Iteration 407, loss = 0.03937408
Iteration 408, loss = 0.03918933
Iteration 409, loss = 0.03900598
Iteration 410, loss = 0.03882402
Iteration 411, loss = 0.03864344
Iteration 412, loss = 0.03846422
Iteration 413, loss = 0.03828635
Iteration 414, loss = 0.03810982
Iteration 415, loss = 0.03793460
Iteration 416, loss = 0.03776069
Iteration 417, loss = 0.03758807
Iteration 418, loss = 0.03741673
Iteration 419, loss = 0.03724666
Iteration 420, loss = 0.03707784
Iteration 421, loss = 0.03691026
Iteration 422, loss = 0.03674391
Iteration 423, loss = 0.03657877
Iteration 424, loss = 0.03641484
Iteration 425, loss = 0.03625210
Iteration 426, loss = 0.03609054
Iteration 427, loss = 0.03593015
Iteration 428, loss = 0.03577091
Iteration 429, loss = 0.03561282
Iteration 430, loss = 0.03545586
Iteration 431, loss = 0.03530002
Iteration 432, loss = 0.03514529
Iteration 433, loss = 0.03499167
Iteration 434, loss = 0.03483913
Iteration 435, loss = 0.03468767
Iteration 436, loss = 0.03453728
Iteration 437, loss = 0.03438794
Iteration 438, loss = 0.03423966
Iteration 439, loss = 0.03409241
Iteration 440, loss = 0.03394618
Iteration 441, loss = 0.03380098
Iteration 442, loss = 0.03365678
Iteration 443, loss = 0.03351358
Iteration 444, loss = 0.03337136
Iteration 445, loss = 0.03323013
Iteration 446, loss = 0.03308986
Iteration 447, loss = 0.03295056
Iteration 448, loss = 0.03281220
Iteration 449, loss = 0.03267479
Iteration 450, loss = 0.03253831
Iteration 451, loss = 0.03240275
Iteration 452, loss = 0.03226812
Iteration 453, loss = 0.03213438
Iteration 454, loss = 0.03200155
Iteration 455, loss = 0.03186961
Iteration 456, loss = 0.03173855
Iteration 457, loss = 0.03160836
Iteration 458, loss = 0.03147904
Iteration 459, loss = 0.03135057
Iteration 460, loss = 0.03122296
Iteration 461, loss = 0.03109619
Iteration 462, loss = 0.03097025
Iteration 463, loss = 0.03084514
Iteration 464, loss = 0.03072085
Iteration 465, loss = 0.03059737
Iteration 466, loss = 0.03047470
Iteration 467, loss = 0.03035282
Iteration 468, loss = 0.03023174
Iteration 469, loss = 0.03011144
Iteration 470, loss = 0.02999191
Iteration 471, loss = 0.02987315
Iteration 472, loss = 0.02975515
Iteration 473, loss = 0.02963791
Iteration 474, loss = 0.02952142
Iteration 475, loss = 0.02940567
Iteration 476, loss = 0.02929066
Iteration 477, loss = 0.02917638
Iteration 478, loss = 0.02906281
Iteration 479, loss = 0.02894997
Iteration 480, loss = 0.02883783
Iteration 481, loss = 0.02872640
Iteration 482, loss = 0.02861567
Iteration 483, loss = 0.02850563
Iteration 484, loss = 0.02839627
Iteration 485, loss = 0.02828760
Iteration 486, loss = 0.02817960
Iteration 487, loss = 0.02807226
Iteration 488, loss = 0.02796559
Iteration 489, loss = 0.02785958
Iteration 490, loss = 0.02775421
Iteration 491, loss = 0.02764950
Iteration 492, loss = 0.02754542
Iteration 493, loss = 0.02744198
Iteration 494, loss = 0.02733916
Iteration 495, loss = 0.02723698
Iteration 496, loss = 0.02713541
Iteration 497, loss = 0.02703445
Iteration 498, loss = 0.02693410
Iteration 499, loss = 0.02683436
Iteration 500, loss = 0.02673521
Iteration 501, loss = 0.02663666
Iteration 502, loss = 0.02653869
Iteration 503, loss = 0.02644131
Iteration 504, loss = 0.02634451
Iteration 505, loss = 0.02624829
Iteration 506, loss = 0.02615263
Iteration 507, loss = 0.02605753
Iteration 508, loss = 0.02596300
Iteration 509, loss = 0.02586902
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
