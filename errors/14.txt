Iteration 1, loss = 0.68891825
Iteration 2, loss = 1.07836867
Iteration 3, loss = 2.96982956
Iteration 4, loss = 1.05922475
Iteration 5, loss = 0.61490214
Iteration 6, loss = 1.69664811
Iteration 7, loss = 1.25791802
Iteration 8, loss = 0.72914456
Iteration 9, loss = 0.88297768
Iteration 10, loss = 0.95444921
Iteration 11, loss = 0.87654456
Iteration 12, loss = 0.75276846
Iteration 13, loss = 1.73697476
Iteration 14, loss = 1.07796774
Iteration 15, loss = 0.80507762
Iteration 16, loss = 0.97629167
Iteration 17, loss = 0.97587346
Iteration 18, loss = 0.74938292
Iteration 19, loss = 0.74874432
Iteration 20, loss = 0.71931090
Iteration 21, loss = 0.73776802
Iteration 22, loss = 1.01292273
Iteration 23, loss = 0.75153454
Iteration 24, loss = 0.76688008
Iteration 25, loss = 0.81303237
Iteration 26, loss = 0.78845355
Iteration 27, loss = 0.79385594
Iteration 28, loss = 0.72134309
Iteration 29, loss = 0.90021279
Iteration 30, loss = 0.73860513
Iteration 31, loss = 0.78593108
Iteration 32, loss = 0.75824766
Iteration 33, loss = 0.75708574
Iteration 34, loss = 0.75616842
Iteration 35, loss = 0.76430171
Iteration 36, loss = 0.75717101
Iteration 37, loss = 0.75431232
Iteration 38, loss = 0.75164826
Iteration 39, loss = 0.90482202
Iteration 40, loss = 0.60690466
Iteration 41, loss = 0.81544744
Iteration 42, loss = 0.79112649
Iteration 43, loss = 0.73807790
Iteration 44, loss = 0.79004024
Iteration 45, loss = 0.79067071
Iteration 46, loss = 0.74132531
Iteration 47, loss = 0.76872338
Iteration 48, loss = 0.78242030
Iteration 49, loss = 0.74164003
Iteration 50, loss = 0.74918553
Iteration 51, loss = 0.69019486
Iteration 52, loss = 0.70556563
Iteration 53, loss = 0.74870249
Iteration 54, loss = 0.72738015
Iteration 55, loss = 0.75038724
Iteration 56, loss = 0.75199412
Iteration 57, loss = 0.73050855
Iteration 58, loss = 0.73976090
Iteration 59, loss = 0.74104817
Iteration 60, loss = 0.78537611
Iteration 61, loss = 0.74098443
Iteration 62, loss = 0.74073366
Iteration 63, loss = 0.71831047
Iteration 64, loss = 0.73365903
Iteration 65, loss = 0.73722928
Iteration 66, loss = 0.71603678
Iteration 67, loss = 0.71890599
Iteration 68, loss = 0.68830765
Iteration 69, loss = 0.74983344
Iteration 70, loss = 0.73602308
Iteration 71, loss = 0.73791104
Iteration 72, loss = 0.76309064
Iteration 73, loss = 0.74579380
Iteration 74, loss = 0.73104043
Iteration 75, loss = 0.74908599
Iteration 76, loss = 0.74203451
Iteration 77, loss = 0.72315072
Iteration 78, loss = 0.71528963
Iteration 79, loss = 0.77506877
Iteration 80, loss = 0.70777309
Iteration 81, loss = 0.74790614
Iteration 82, loss = 0.86556009
Iteration 83, loss = 0.71841667
Iteration 84, loss = 0.84633696
Iteration 85, loss = 0.79877095
Iteration 86, loss = 0.74557101
Iteration 87, loss = 0.82886751
Iteration 88, loss = 0.80913310
Iteration 89, loss = 0.74530639
Iteration 90, loss = 0.79451252
Iteration 91, loss = 0.79410909
Iteration 92, loss = 0.73597415
Iteration 93, loss = 0.76039627
Iteration 94, loss = 0.77010918
Iteration 95, loss = 0.72494375
Iteration 96, loss = 0.74085333
Iteration 97, loss = 0.74452779
Iteration 98, loss = 0.71570132
Iteration 99, loss = 0.72160686
Iteration 100, loss = 0.73311521
Iteration 101, loss = 0.71324982
Iteration 102, loss = 0.71408317
Iteration 103, loss = 0.72423338
Iteration 104, loss = 0.70992023
Iteration 105, loss = 0.70797682
Iteration 106, loss = 0.71421472
Iteration 107, loss = 0.69731677
Iteration 108, loss = 0.73767631
Iteration 109, loss = 0.69905398
Iteration 110, loss = 0.61484150
Iteration 111, loss = 0.83263981
Iteration 112, loss = 0.84926005
Iteration 113, loss = 0.72723182
Iteration 114, loss = 0.78401731
Iteration 115, loss = 0.83731411
Iteration 116, loss = 0.74494562
Iteration 117, loss = 0.82422866
Iteration 118, loss = 0.83269470
Iteration 119, loss = 0.73247633
Iteration 120, loss = 0.73589132
Iteration 121, loss = 0.77928314
Iteration 122, loss = 0.73699522
Iteration 123, loss = 0.73735833
Iteration 124, loss = 0.76432897
Iteration 125, loss = 0.73967253
Iteration 126, loss = 0.72048177
Iteration 127, loss = 0.74100417
Iteration 128, loss = 0.73551422
Iteration 129, loss = 0.71235013
Iteration 130, loss = 0.71093422
Iteration 131, loss = 0.71667782
Iteration 132, loss = 0.71985736
Iteration 133, loss = 0.71979172
Iteration 134, loss = 0.71953578
Iteration 135, loss = 0.72021003
Iteration 136, loss = 0.71919011
Iteration 137, loss = 0.71733249
Iteration 138, loss = 0.71683108
Iteration 139, loss = 0.71638316
Iteration 140, loss = 0.71536831
Iteration 141, loss = 0.71514819
Iteration 142, loss = 0.71537218
Iteration 143, loss = 0.71494374
Iteration 144, loss = 0.71457897
Iteration 145, loss = 0.71469259
Iteration 146, loss = 0.71442284
Iteration 147, loss = 0.71390572
Iteration 148, loss = 0.71379128
Iteration 149, loss = 0.71362100
Iteration 150, loss = 0.71314646
Iteration 151, loss = 0.71291495
Iteration 152, loss = 0.71284191
Iteration 153, loss = 0.71254492
Iteration 154, loss = 0.71230114
Iteration 155, loss = 0.71221229
Iteration 156, loss = 0.71194845
Iteration 157, loss = 0.71161337
Iteration 158, loss = 0.71142225
Iteration 159, loss = 0.71107014
Iteration 160, loss = 0.71120155
Iteration 161, loss = 0.71071902
Iteration 162, loss = 0.71760923
Iteration 163, loss = 0.71411311
Iteration 164, loss = 0.71888526
Iteration 165, loss = 0.71750531
Iteration 166, loss = 0.71807876
Iteration 167, loss = 0.72154339
Iteration 168, loss = 0.71995865
Iteration 169, loss = 0.71709560
Iteration 170, loss = 0.71761622
Iteration 171, loss = 0.71626151
Iteration 172, loss = 0.71296281
Iteration 173, loss = 0.71268914
Iteration 174, loss = 0.71311116
Iteration 175, loss = 0.71160551
Iteration 176, loss = 0.71137031
Iteration 177, loss = 0.71235736
Iteration 178, loss = 0.71172992
Iteration 179, loss = 0.71103325
Iteration 180, loss = 0.71143333
Iteration 181, loss = 0.71074345
Iteration 182, loss = 0.70916806
Iteration 183, loss = 0.70826670
Iteration 184, loss = 0.70729222
Iteration 185, loss = 0.70598913
Iteration 186, loss = 0.70525880
Iteration 187, loss = 0.70460083
Iteration 188, loss = 0.70307798
Iteration 189, loss = 0.70150762
Iteration 190, loss = 0.70037458
Iteration 191, loss = 0.69888735
Iteration 192, loss = 0.69660942
Iteration 193, loss = 0.69315207
Iteration 194, loss = 0.68903058
Iteration 195, loss = 0.66719692
Iteration 196, loss = 0.82261945
Iteration 197, loss = 0.68796240
Iteration 198, loss = 0.89434772
Iteration 199, loss = 0.74032599
Iteration 200, loss = 0.72650371
Iteration 201, loss = 0.84172614
Iteration 202, loss = 0.77926505
Iteration 203, loss = 0.76221486
Iteration 204, loss = 0.80421032
Iteration 205, loss = 0.78024953
Iteration 206, loss = 0.75948314
Iteration 207, loss = 0.78179345
Iteration 208, loss = 0.75630975
Iteration 209, loss = 0.74095073
Iteration 210, loss = 0.75640416
Iteration 211, loss = 0.73535721
Iteration 212, loss = 0.72693664
Iteration 213, loss = 0.73820445
Iteration 214, loss = 0.72131935
Iteration 215, loss = 0.71816644
Iteration 216, loss = 0.72604987
Iteration 217, loss = 0.71267837
Iteration 218, loss = 0.71126975
Iteration 219, loss = 0.71565687
Iteration 220, loss = 0.70528924
Iteration 221, loss = 0.70482311
Iteration 222, loss = 0.70265996
Iteration 223, loss = 0.68448090
Iteration 224, loss = 0.84025252
Iteration 225, loss = 0.78974533
Iteration 226, loss = 0.82673389
Iteration 227, loss = 0.73900023
Iteration 228, loss = 0.81627872
Iteration 229, loss = 0.80411600
Iteration 230, loss = 0.75903771
Iteration 231, loss = 0.81451464
Iteration 232, loss = 0.78616374
Iteration 233, loss = 0.75873563
Iteration 234, loss = 0.79503813
Iteration 235, loss = 0.76312603
Iteration 236, loss = 0.75221821
Iteration 237, loss = 0.77207369
Iteration 238, loss = 0.73673643
Iteration 239, loss = 0.82701897
Iteration 240, loss = 0.73538312
Iteration 241, loss = 0.81111011
Iteration 242, loss = 0.72878313
Iteration 243, loss = 0.77927007
Iteration 244, loss = 0.73639452
Iteration 245, loss = 1.14261411
Iteration 246, loss = 0.81305051
Iteration 247, loss = 0.81825923
Iteration 248, loss = 0.71456973
Iteration 249, loss = 0.76069802
Iteration 250, loss = 0.76472425
Iteration 251, loss = 0.77958185
Iteration 252, loss = 0.78618849
Iteration 253, loss = 0.77626142
Iteration 254, loss = 0.78148995
Iteration 255, loss = 0.76719967
Iteration 256, loss = 0.76065698
Iteration 257, loss = 0.75474843
Iteration 258, loss = 0.74123088
Iteration 259, loss = 0.74057255
Iteration 260, loss = 0.73129231
Iteration 261, loss = 0.72773818
Iteration 262, loss = 0.72504309
Iteration 263, loss = 0.72379412
Iteration 264, loss = 0.71989347
Iteration 265, loss = 0.72027674
Iteration 266, loss = 0.72041474
Iteration 267, loss = 0.67150721
Iteration 268, loss = 0.72833956
Iteration 269, loss = 0.75998687
Iteration 270, loss = 0.73274380
Iteration 271, loss = 0.77682826
Iteration 272, loss = 0.74041549
Iteration 273, loss = 0.74153232
Iteration 274, loss = 0.75919409
Iteration 275, loss = 0.72450450
Iteration 276, loss = 0.74163237
Iteration 277, loss = 0.73917750
Iteration 278, loss = 0.72094696
Iteration 279, loss = 0.74020237
Iteration 280, loss = 0.72738889
Iteration 281, loss = 0.72493330
Iteration 282, loss = 0.73546704
Iteration 283, loss = 0.72085732
Iteration 284, loss = 0.72682676
Iteration 285, loss = 0.72703660
Iteration 286, loss = 0.71749371
Iteration 287, loss = 0.72443226
Iteration 288, loss = 0.71636590
Iteration 289, loss = 0.69014152
Iteration 290, loss = 0.72865598
Iteration 291, loss = 0.72926606
Iteration 292, loss = 0.73982062
Iteration 293, loss = 0.72574140
Iteration 294, loss = 0.73783882
Iteration 295, loss = 0.72483530
Iteration 296, loss = 0.72930087
Iteration 297, loss = 0.72453238
Iteration 298, loss = 0.71900084
Iteration 299, loss = 0.72174775
Iteration 300, loss = 0.71071601
Iteration 301, loss = 0.71038486
Iteration 302, loss = 0.74357878
Iteration 303, loss = 0.66496621
Iteration 304, loss = 0.83920400
Iteration 305, loss = 0.73581705
Iteration 306, loss = 0.84560174
Iteration 307, loss = 0.77281017
Iteration 308, loss = 0.77889288
Iteration 309, loss = 0.80540235
Iteration 310, loss = 0.73902202
Iteration 311, loss = 0.77388856
Iteration 312, loss = 0.72026028
Iteration 313, loss = 0.72111370
Iteration 314, loss = 0.75985667
Iteration 315, loss = 0.72609912
Iteration 316, loss = 0.73025733
Iteration 317, loss = 0.76847083
Iteration 318, loss = 0.71802717
Iteration 319, loss = 0.76731607
Iteration 320, loss = 0.73817505
Iteration 321, loss = 0.70436209
Iteration 322, loss = 0.75670642
Iteration 323, loss = 1.14577271
Iteration 324, loss = 0.98858962
Iteration 325, loss = 0.77282937
Iteration 326, loss = 1.07949369
Iteration 327, loss = 0.92222495
Iteration 328, loss = 0.77429252
Iteration 329, loss = 0.98603362
Iteration 330, loss = 0.85117875
Iteration 331, loss = 0.76238278
Iteration 332, loss = 0.91467330
Iteration 333, loss = 0.79323816
Iteration 334, loss = 0.75484927
Iteration 335, loss = 0.83377171
Iteration 336, loss = 0.74010122
Iteration 337, loss = 0.79369369
Iteration 338, loss = 0.80110838
Iteration 339, loss = 0.72610688
Iteration 340, loss = 0.70592803
Iteration 341, loss = 0.75123004
Iteration 342, loss = 0.74523252
Iteration 343, loss = 0.75532694
Iteration 344, loss = 0.75651187
Iteration 345, loss = 0.74812555
Iteration 346, loss = 0.75185583
Iteration 347, loss = 0.74769513
Iteration 348, loss = 0.74002764
Iteration 349, loss = 0.74115923
Iteration 350, loss = 0.73464740
Iteration 351, loss = 0.72757205
Iteration 352, loss = 0.71800187
Iteration 353, loss = 0.73675368
Iteration 354, loss = 0.73552868
Iteration 355, loss = 0.73880733
Iteration 356, loss = 0.73899888
Iteration 357, loss = 0.73252576
Iteration 358, loss = 0.69695061
Iteration 359, loss = 0.73459768
Iteration 360, loss = 0.74224882
Iteration 361, loss = 0.73763141
Iteration 362, loss = 0.74263357
Iteration 363, loss = 0.74802055
Iteration 364, loss = 0.74306882
Iteration 365, loss = 0.74462092
Iteration 366, loss = 0.74459242
Iteration 367, loss = 0.73850712
Iteration 368, loss = 0.73838666
Iteration 369, loss = 0.73636016
Iteration 370, loss = 0.73122722
Iteration 371, loss = 0.72830247
Iteration 372, loss = 0.71823477
Iteration 373, loss = 1.35736870
Iteration 374, loss = 1.07231120
Iteration 375, loss = 1.18008334
Iteration 376, loss = 0.83222424
Iteration 377, loss = 0.84250385
Iteration 378, loss = 1.07293779
Iteration 379, loss = 0.86384431
Iteration 380, loss = 0.77997481
Iteration 381, loss = 1.17246306
Iteration 382, loss = 1.02183031
Iteration 383, loss = 0.82347701
Iteration 384, loss = 1.08794616
Iteration 385, loss = 0.95597546
Iteration 386, loss = 0.79898754
Iteration 387, loss = 0.95540008
Iteration 388, loss = 0.89928241
Iteration 389, loss = 0.69015411
Iteration 390, loss = 0.93391552
Iteration 391, loss = 0.84280602
Iteration 392, loss = 0.77160460
Iteration 393, loss = 0.87511629
Iteration 394, loss = 0.84144028
Iteration 395, loss = 0.75958827
Iteration 396, loss = 0.82260596
Iteration 397, loss = 0.82011210
Iteration 398, loss = 0.72938324
Iteration 399, loss = 0.86563806
Iteration 400, loss = 0.83112039
Iteration 401, loss = 0.99276503
Iteration 402, loss = 0.81081862
Iteration 403, loss = 0.84174366
Iteration 404, loss = 0.93002092
Iteration 405, loss = 0.78732218
Iteration 406, loss = 0.82982384
Iteration 407, loss = 0.87761660
Iteration 408, loss = 0.76721249
Iteration 409, loss = 0.80771100
Iteration 410, loss = 0.83357574
Iteration 411, loss = 0.75281619
Iteration 412, loss = 0.78792293
Iteration 413, loss = 0.79724199
Iteration 414, loss = 0.74309180
Iteration 415, loss = 0.76875347
Iteration 416, loss = 0.73325539
Iteration 417, loss = 1.46979994
Iteration 418, loss = 0.77839595
Iteration 419, loss = 0.69307926
Iteration 420, loss = 1.05039556
Iteration 421, loss = 0.83576032
Iteration 422, loss = 0.86856040
Iteration 423, loss = 1.04930543
Iteration 424, loss = 0.95364359
Iteration 425, loss = 0.82231575
Iteration 426, loss = 0.94145836
Iteration 427, loss = 0.96898852
Iteration 428, loss = 0.83388131
Iteration 429, loss = 0.83586413
Iteration 430, loss = 0.90995890
Iteration 431, loss = 0.84066956
Iteration 432, loss = 0.77628836
Iteration 433, loss = 0.83377499
Iteration 434, loss = 0.83025829
Iteration 435, loss = 0.76210583
Iteration 436, loss = 0.77899756
Iteration 437, loss = 0.80980085
Iteration 438, loss = 0.76838273
Iteration 439, loss = 0.75277120
Iteration 440, loss = 0.78570450
Iteration 441, loss = 0.77336452
Iteration 442, loss = 0.74592943
Iteration 443, loss = 0.76397115
Iteration 444, loss = 0.77053654
Iteration 445, loss = 0.74684335
Iteration 446, loss = 0.74879406
Iteration 447, loss = 0.76219995
Iteration 448, loss = 0.74908472
Iteration 449, loss = 0.74155070
Iteration 450, loss = 0.75312893
Iteration 451, loss = 0.75005396
Iteration 452, loss = 0.73988064
Iteration 453, loss = 0.74582272
Iteration 454, loss = 0.74866725
Iteration 455, loss = 0.74027396
Iteration 456, loss = 0.74078613
Iteration 457, loss = 0.74541695
Iteration 458, loss = 0.74050174
Iteration 459, loss = 0.73769750
Iteration 460, loss = 0.74149019
Iteration 461, loss = 0.73979952
Iteration 462, loss = 0.73598575
Iteration 463, loss = 0.73793942
Iteration 464, loss = 0.73833205
Iteration 465, loss = 0.73505149
Iteration 466, loss = 0.73529105
Iteration 467, loss = 0.73651096
Iteration 468, loss = 0.73431450
Iteration 469, loss = 0.73323446
Iteration 470, loss = 0.73345129
Iteration 471, loss = 0.71629323
Iteration 472, loss = 0.75114794
Iteration 473, loss = 0.73767145
Iteration 474, loss = 0.74477987
Iteration 475, loss = 0.75294974
Iteration 476, loss = 0.74227919
Iteration 477, loss = 0.74289499
Iteration 478, loss = 0.74829344
Iteration 479, loss = 0.73978743
Iteration 480, loss = 0.73773301
Iteration 481, loss = 0.74263464
Iteration 482, loss = 0.73794220
Iteration 483, loss = 0.73592327
Iteration 484, loss = 0.74043335
Iteration 485, loss = 0.73814882
Iteration 486, loss = 0.73590835
Iteration 487, loss = 0.73896571
Iteration 488, loss = 0.73758509
Iteration 489, loss = 0.73513671
Iteration 490, loss = 0.73703332
Iteration 491, loss = 0.73642481
Iteration 492, loss = 0.73442763
Iteration 493, loss = 0.73579234
Iteration 494, loss = 0.73582551
Iteration 495, loss = 0.73432417
Iteration 496, loss = 0.73516801
Iteration 497, loss = 0.73535129
Iteration 498, loss = 0.73409350
Iteration 499, loss = 0.73444111
Iteration 500, loss = 0.73456179
Iteration 501, loss = 0.73348097
Iteration 502, loss = 0.73352245
Iteration 503, loss = 0.73363671
Iteration 504, loss = 0.73281746
Iteration 505, loss = 0.73274676
Iteration 506, loss = 0.73285926
Iteration 507, loss = 0.73225091
Iteration 508, loss = 0.73212095
Iteration 509, loss = 0.73219825
Iteration 510, loss = 0.73171695
Iteration 511, loss = 0.73152464
Iteration 512, loss = 0.73153438
Iteration 513, loss = 0.73113111
Iteration 514, loss = 0.73090309
Iteration 515, loss = 0.73085998
Iteration 516, loss = 0.73051890
Iteration 517, loss = 0.73028247
Iteration 518, loss = 0.73020343
Iteration 519, loss = 0.72991030
Iteration 520, loss = 0.72967571
Iteration 521, loss = 0.72956699
Iteration 522, loss = 0.72930336
Iteration 523, loss = 0.72907145
Iteration 524, loss = 0.72894103
Iteration 525, loss = 0.72870195
Iteration 526, loss = 0.72847941
Iteration 527, loss = 0.72833568
Iteration 528, loss = 0.72811534
Iteration 529, loss = 0.72790315
Iteration 530, loss = 0.72775028
Iteration 531, loss = 0.72754129
Iteration 532, loss = 0.72733464
Iteration 533, loss = 0.72717253
Iteration 534, loss = 0.72697048
Iteration 535, loss = 0.72676909
Iteration 536, loss = 0.72660135
Iteration 537, loss = 0.72640539
Iteration 538, loss = 0.72620992
Iteration 539, loss = 0.72603974
Iteration 540, loss = 0.72584921
Iteration 541, loss = 0.72565868
Iteration 542, loss = 0.72548630
Iteration 543, loss = 0.72529842
Iteration 544, loss = 0.72510992
Iteration 545, loss = 0.72493381
Iteration 546, loss = 0.72474479
Iteration 547, loss = 0.72455272
Iteration 548, loss = 0.72436449
Iteration 549, loss = 0.72415698
Iteration 550, loss = 0.72392773
Iteration 551, loss = 0.72365880
Iteration 552, loss = 0.72328707
Iteration 553, loss = 0.72276877
Iteration 554, loss = 0.72225312
Iteration 555, loss = 0.72199579
Iteration 556, loss = 0.72185159
Iteration 557, loss = 0.72165615
Iteration 558, loss = 0.72138019
Iteration 559, loss = 0.72105702
Iteration 560, loss = 0.72073650
Iteration 561, loss = 0.72045221
Iteration 562, loss = 0.72021142
Iteration 563, loss = 0.71999056
Iteration 564, loss = 0.71974586
Iteration 565, loss = 0.71942274
Iteration 566, loss = 0.71894814
Iteration 567, loss = 0.71822111
Iteration 568, loss = 0.71724726
Iteration 569, loss = 0.71703410
Iteration 570, loss = 0.71560591
Iteration 571, loss = 0.71464248
Iteration 572, loss = 0.71322170
Iteration 573, loss = 0.71296202
Iteration 574, loss = 0.71212878
Iteration 575, loss = 0.71052394
Iteration 576, loss = 0.70817800
Iteration 577, loss = 0.70611060
Iteration 578, loss = 0.70674861
Iteration 579, loss = 0.70375361
Iteration 580, loss = 0.70125467
Iteration 581, loss = 0.70035784
Iteration 582, loss = 0.69864135
Iteration 583, loss = 0.69532015
Iteration 584, loss = 0.68721548
Iteration 585, loss = 0.65820112
Iteration 586, loss = 1.21607002
Iteration 587, loss = 1.02012351
Iteration 588, loss = 1.06614163
Iteration 589, loss = 0.78566650
Iteration 590, loss = 0.95045667
Iteration 591, loss = 1.08437684
Iteration 592, loss = 0.88388107
Iteration 593, loss = 0.88774943
Iteration 594, loss = 1.03233256
Iteration 595, loss = 0.89141416
Iteration 596, loss = 0.82524829
Iteration 597, loss = 0.89562395
Iteration 598, loss = 0.90048454
Iteration 599, loss = 0.97540437
Iteration 600, loss = 0.98279907
Iteration 601, loss = 1.25440296
Iteration 602, loss = 1.33384758
Iteration 603, loss = 0.87183299
Iteration 604, loss = 1.08074481
Iteration 605, loss = 1.23305883
Iteration 606, loss = 0.88129456
Iteration 607, loss = 0.93208249
Iteration 608, loss = 1.10285381
Iteration 609, loss = 0.85711170
Iteration 610, loss = 0.83589160
Iteration 611, loss = 0.99360292
Iteration 612, loss = 0.82886206
Iteration 613, loss = 0.78469208
Iteration 614, loss = 0.91586812
Iteration 615, loss = 0.80621551
Iteration 616, loss = 0.76425952
Iteration 617, loss = 0.86642331
Iteration 618, loss = 0.79078223
Iteration 619, loss = 0.75477685
Iteration 620, loss = 0.83183599
Iteration 621, loss = 0.77745187
Iteration 622, loss = 0.75005213
Iteration 623, loss = 0.80639187
Iteration 624, loss = 0.76607576
Iteration 625, loss = 0.74596460
Iteration 626, loss = 0.78696571
Iteration 627, loss = 0.75599430
Iteration 628, loss = 0.74262023
Iteration 629, loss = 0.77212629
Iteration 630, loss = 0.74817223
Iteration 631, loss = 0.73968092
Iteration 632, loss = 0.76088180
Iteration 633, loss = 0.74216651
Iteration 634, loss = 0.73753266
Iteration 635, loss = 0.75241281
Iteration 636, loss = 0.73775110
Iteration 637, loss = 0.73558852
Iteration 638, loss = 0.74575176
Iteration 639, loss = 0.73395962
Iteration 640, loss = 0.73297631
Iteration 641, loss = 0.73883015
Iteration 642, loss = 0.72783097
Iteration 643, loss = 0.71439490
Iteration 644, loss = 0.76149843
Iteration 645, loss = 0.73831783
Iteration 646, loss = 0.75298064
Iteration 647, loss = 0.75851962
Iteration 648, loss = 0.73654483
Iteration 649, loss = 0.74297403
Iteration 650, loss = 0.74756175
Iteration 651, loss = 0.73243492
Iteration 652, loss = 0.73814222
Iteration 653, loss = 0.74368987
Iteration 654, loss = 0.73323700
Iteration 655, loss = 0.73676661
Iteration 656, loss = 0.74069328
Iteration 657, loss = 0.73252071
Iteration 658, loss = 0.73449741
Iteration 659, loss = 0.73745037
Iteration 660, loss = 0.73141210
Iteration 661, loss = 0.73267462
Iteration 662, loss = 0.73485215
Iteration 663, loss = 0.73058683
Iteration 664, loss = 0.73133991
Iteration 665, loss = 0.73278593
Iteration 666, loss = 0.72912642
Iteration 667, loss = 0.72806093
Iteration 668, loss = 0.73164877
Iteration 669, loss = 0.73740640
Iteration 670, loss = 0.69770447
Iteration 671, loss = 0.73072748
Iteration 672, loss = 0.79710827
Iteration 673, loss = 0.78213262
Iteration 674, loss = 0.77282319
Iteration 675, loss = 0.79481104
Iteration 676, loss = 0.77109988
Iteration 677, loss = 0.75424172
Iteration 678, loss = 0.76734757
Iteration 679, loss = 0.75140264
Iteration 680, loss = 0.74269263
Iteration 681, loss = 0.75638373
Iteration 682, loss = 0.74880704
Iteration 683, loss = 0.74506758
Iteration 684, loss = 0.75601874
Iteration 685, loss = 0.74984137
Iteration 686, loss = 0.74593679
Iteration 687, loss = 0.75271979
Iteration 688, loss = 0.74708134
Iteration 689, loss = 0.74371238
Iteration 690, loss = 0.74833315
Iteration 691, loss = 0.74432557
Iteration 692, loss = 0.74237297
Iteration 693, loss = 0.74602609
Iteration 694, loss = 0.74281823
Iteration 695, loss = 0.74062455
Iteration 696, loss = 0.74096992
Iteration 697, loss = 0.71893035
Iteration 698, loss = 0.74791713
Iteration 699, loss = 0.74825231
Iteration 700, loss = 0.75043897
Iteration 701, loss = 0.75200192
Iteration 702, loss = 0.75758185
Iteration 703, loss = 0.76127120
Iteration 704, loss = 0.74310006
Iteration 705, loss = 0.72429873
Iteration 706, loss = 0.82555485
Iteration 707, loss = 0.76394506
Iteration 708, loss = 0.77754522
Iteration 709, loss = 0.80923536
Iteration 710, loss = 0.75980281
Iteration 711, loss = 0.76376288
Iteration 712, loss = 0.78005637
Iteration 713, loss = 0.77448008
Iteration 714, loss = 0.75472636
Iteration 715, loss = 0.80385159
Iteration 716, loss = 0.77677919
Iteration 717, loss = 0.75111996
Iteration 718, loss = 0.78391838
Iteration 719, loss = 0.76136498
Iteration 720, loss = 0.76050946
Iteration 721, loss = 0.76104673
Iteration 722, loss = 0.69268677
Iteration 723, loss = 0.83773322
Iteration 724, loss = 0.78125268
Iteration 725, loss = 0.76043140
Iteration 726, loss = 0.80373732
Iteration 727, loss = 0.76528897
Iteration 728, loss = 0.73848768
Iteration 729, loss = 0.77115255
Iteration 730, loss = 0.72766862
Iteration 731, loss = 0.98519936
Iteration 732, loss = 0.80381629
Iteration 733, loss = 0.80524463
Iteration 734, loss = 0.88432961
Iteration 735, loss = 0.84320949
Iteration 736, loss = 0.74706375
Iteration 737, loss = 0.89647509
Iteration 738, loss = 0.84483438
Iteration 739, loss = 0.79014334
Iteration 740, loss = 0.86715949
Iteration 741, loss = 0.84558877
Iteration 742, loss = 0.78572034
Iteration 743, loss = 0.83187946
Iteration 744, loss = 0.82720150
Iteration 745, loss = 0.77583149
Iteration 746, loss = 0.80311683
Iteration 747, loss = 0.80860929
Iteration 748, loss = 0.75196881
Iteration 749, loss = 0.89610575
Iteration 750, loss = 0.83110016
Iteration 751, loss = 0.79701349
Iteration 752, loss = 0.87227879
Iteration 753, loss = 0.84805164
Iteration 754, loss = 0.78462517
Iteration 755, loss = 0.82229542
Iteration 756, loss = 0.83081667
Iteration 757, loss = 0.77793925
Iteration 758, loss = 0.78835852
Iteration 759, loss = 0.81461225
Iteration 760, loss = 0.78353894
Iteration 761, loss = 0.77547306
Iteration 762, loss = 0.80142670
Iteration 763, loss = 0.78788930
Iteration 764, loss = 0.77050344
Iteration 765, loss = 0.78716721
Iteration 766, loss = 0.78549923
Iteration 767, loss = 0.76762104
Iteration 768, loss = 0.77473892
Iteration 769, loss = 0.77980308
Iteration 770, loss = 0.76606729
Iteration 771, loss = 0.76568630
Iteration 772, loss = 0.77228188
Iteration 773, loss = 0.76400692
Iteration 774, loss = 0.76038341
Iteration 775, loss = 0.76553699
Iteration 776, loss = 0.76021958
Iteration 777, loss = 0.75300613
Iteration 778, loss = 0.74188754
Iteration 779, loss = 0.79536204
Iteration 780, loss = 0.76809423
Iteration 781, loss = 0.80968068
Iteration 782, loss = 0.77971315
Iteration 783, loss = 0.78587801
Iteration 784, loss = 0.79310577
Iteration 785, loss = 0.75971929
Iteration 786, loss = 0.72609178
Iteration 787, loss = 0.88394977
Iteration 788, loss = 0.77434424
Iteration 789, loss = 0.91410300
Iteration 790, loss = 0.82507731
Iteration 791, loss = 0.78918597
Iteration 792, loss = 0.87532347
Iteration 793, loss = 0.78901988
Iteration 794, loss = 0.79518221
Iteration 795, loss = 0.84379680
Iteration 796, loss = 0.77276492
Iteration 797, loss = 0.79712320
Iteration 798, loss = 0.81812893
Iteration 799, loss = 0.76532794
Iteration 800, loss = 0.79402246
Iteration 801, loss = 0.79796005
Iteration 802, loss = 0.76249285
Iteration 803, loss = 0.78929171
Iteration 804, loss = 0.78344530
Iteration 805, loss = 0.76190781
Iteration 806, loss = 0.78361477
Iteration 807, loss = 0.77295757
Iteration 808, loss = 0.76165431
Iteration 809, loss = 0.77763011
Iteration 810, loss = 0.76593787
Iteration 811, loss = 0.76182052
Iteration 812, loss = 0.77252852
Iteration 813, loss = 0.76168374
Iteration 814, loss = 0.76182205
Iteration 815, loss = 0.76790687
Iteration 816, loss = 0.75886087
Iteration 817, loss = 0.76114721
Iteration 818, loss = 0.76299324
Iteration 819, loss = 0.75946709
Iteration 820, loss = 0.76303528
Iteration 821, loss = 0.76425983
Iteration 822, loss = 0.75768534
Iteration 823, loss = 0.76425752
Iteration 824, loss = 0.75675814
Iteration 825, loss = 0.76014659
Iteration 826, loss = 0.75818549
Iteration 827, loss = 0.75433817
Iteration 828, loss = 0.76358054
Iteration 829, loss = 0.76289019
Iteration 830, loss = 0.76975784
Iteration 831, loss = 0.76160008
Iteration 832, loss = 0.77204824
Iteration 833, loss = 0.76194181
Iteration 834, loss = 0.76419082
Iteration 835, loss = 0.76202793
Iteration 836, loss = 0.75606747
Iteration 837, loss = 0.76079372
Iteration 838, loss = 0.75464026
Iteration 839, loss = 0.75835405
Iteration 840, loss = 0.75720891
Iteration 841, loss = 0.75569700
Iteration 842, loss = 0.75791031
Iteration 843, loss = 0.75389636
Iteration 844, loss = 0.75610309
Iteration 845, loss = 0.75407258
Iteration 846, loss = 0.75359358
Iteration 847, loss = 0.75423469
Iteration 848, loss = 0.75196105
Iteration 849, loss = 0.75332825
Iteration 850, loss = 0.75165577
Iteration 851, loss = 0.75183883
Iteration 852, loss = 0.75178359
Iteration 853, loss = 0.75065013
Iteration 854, loss = 0.75135299
Iteration 855, loss = 0.75008789
Iteration 856, loss = 0.75032484
Iteration 857, loss = 0.74984267
Iteration 858, loss = 0.74924682
Iteration 859, loss = 0.74941612
Iteration 860, loss = 0.74851932
Iteration 861, loss = 0.74867683
Iteration 862, loss = 0.74813509
Iteration 863, loss = 0.74788151
Iteration 864, loss = 0.74779309
Iteration 865, loss = 0.74722062
Iteration 866, loss = 0.74723543
Iteration 867, loss = 0.74670309
Iteration 868, loss = 0.74652077
Iteration 869, loss = 0.74623992
Iteration 870, loss = 0.74584049
Iteration 871, loss = 0.74571822
Iteration 872, loss = 0.74526720
Iteration 873, loss = 0.74509075
Iteration 874, loss = 0.74472101
Iteration 875, loss = 0.74431478
Iteration 876, loss = 0.74360612
Iteration 877, loss = 0.74325683
Iteration 878, loss = 0.74313159
Iteration 879, loss = 0.74232330
Iteration 880, loss = 0.74190371
Iteration 881, loss = 0.74140489
Iteration 882, loss = 0.74170325
Iteration 883, loss = 0.74104378
Iteration 884, loss = 0.74060974
Iteration 885, loss = 0.74056728
Iteration 886, loss = 0.74013608
Iteration 887, loss = 0.73931453
Iteration 888, loss = 0.73874174
Iteration 889, loss = 0.73837315
Iteration 890, loss = 0.73866205
Iteration 891, loss = 0.73800607
Iteration 892, loss = 0.73690559
Iteration 893, loss = 0.73476587
Iteration 894, loss = 0.73275593
Iteration 895, loss = 0.71129853
Iteration 896, loss = 0.72881195
Iteration 897, loss = 0.93706548
Iteration 898, loss = 0.77205511
Iteration 899, loss = 0.91588520
Iteration 900, loss = 0.76494276
Iteration 901, loss = 0.88385501
Iteration 902, loss = 0.76420314
Iteration 903, loss = 0.84245779
Iteration 904, loss = 0.77352072
Iteration 905, loss = 0.80218436
Iteration 906, loss = 0.78963919
Iteration 907, loss = 0.77152471
Iteration 908, loss = 0.80017484
Iteration 909, loss = 0.75504384
Iteration 910, loss = 0.79961194
Iteration 911, loss = 0.75048888
Iteration 912, loss = 0.78837111
Iteration 913, loss = 0.75449937
Iteration 914, loss = 0.77276731
Iteration 915, loss = 0.76130586
Iteration 916, loss = 0.75839385
Iteration 917, loss = 0.76581423
Iteration 918, loss = 0.74969782
Iteration 919, loss = 0.76590714
Iteration 920, loss = 0.74648819
Iteration 921, loss = 0.76172659
Iteration 922, loss = 0.74769132
Iteration 923, loss = 0.75562550
Iteration 924, loss = 0.74998623
Iteration 925, loss = 0.74954164
Iteration 926, loss = 0.75150427
Iteration 927, loss = 0.74575533
Iteration 928, loss = 0.75159862
Iteration 929, loss = 0.74400390
Iteration 930, loss = 0.74987194
Iteration 931, loss = 0.74385657
Iteration 932, loss = 0.74716891
Iteration 933, loss = 0.74422395
Iteration 934, loss = 0.74382560
Iteration 935, loss = 0.74395196
Iteration 936, loss = 0.74185738
Iteration 937, loss = 0.74376662
Iteration 938, loss = 0.74079369
Iteration 939, loss = 0.74283888
Iteration 940, loss = 0.74016999
Iteration 941, loss = 0.74159978
Iteration 942, loss = 0.73981624
Iteration 943, loss = 0.73985488
Iteration 944, loss = 0.73933781
Iteration 945, loss = 0.73952813
Iteration 946, loss = 0.74030421
Iteration 947, loss = 0.73835160
Iteration 948, loss = 0.73754192
Iteration 949, loss = 0.73491413
Iteration 950, loss = 0.72840695
Iteration 951, loss = 0.70597568
Iteration 952, loss = 1.00562361
Iteration 953, loss = 0.82122042
Iteration 954, loss = 1.35566653
Iteration 955, loss = 0.78005042
Iteration 956, loss = 1.27778089
Iteration 957, loss = 1.18243001
Iteration 958, loss = 0.80217799
Iteration 959, loss = 1.17034855
Iteration 960, loss = 0.96067965
Iteration 961, loss = 0.83338896
Iteration 962, loss = 1.05697605
Iteration 963, loss = 0.80740598
Iteration 964, loss = 0.87820235
Iteration 965, loss = 0.95501975
Iteration 966, loss = 0.75361946
Iteration 967, loss = 0.90171219
Iteration 968, loss = 0.86012535
Iteration 969, loss = 0.76510039
Iteration 970, loss = 0.88423712
Iteration 971, loss = 0.78138411
Iteration 972, loss = 0.79215060
Iteration 973, loss = 0.84005303
Iteration 974, loss = 0.74804562
Iteration 975, loss = 0.80912817
Iteration 976, loss = 0.79180641
Iteration 977, loss = 0.75135605
Iteration 978, loss = 0.80472295
Iteration 979, loss = 0.75784739
Iteration 980, loss = 0.76642804
Iteration 981, loss = 0.78443140
Iteration 982, loss = 0.74456681
Iteration 983, loss = 0.77310336
Iteration 984, loss = 0.75990088
Iteration 985, loss = 0.74620342
Iteration 986, loss = 0.76722078
Iteration 987, loss = 0.74373287
Iteration 988, loss = 0.75209441
Iteration 989, loss = 0.75552282
Iteration 990, loss = 0.74033120
Iteration 991, loss = 0.75432899
Iteration 992, loss = 0.74511035
Iteration 993, loss = 0.74324031
Iteration 994, loss = 0.75042004
Iteration 995, loss = 0.73959318
Iteration 996, loss = 0.74553768
Iteration 997, loss = 0.74379464
Iteration 998, loss = 0.73885929
Iteration 999, loss = 0.74458199
Iteration 1000, loss = 0.73879253
