Iteration 1, loss = 0.70379086
Iteration 2, loss = 1.99368074
Iteration 3, loss = 1.05169350
Iteration 4, loss = 0.75144902
Iteration 5, loss = 0.95726027
Iteration 6, loss = 1.02289151
Iteration 7, loss = 0.96345790
Iteration 8, loss = 0.84587906
Iteration 9, loss = 0.74821206
Iteration 10, loss = 0.72560312
Iteration 11, loss = 0.76877627
Iteration 12, loss = 0.81351871
Iteration 13, loss = 1.19791193
Iteration 14, loss = 0.79115419
Iteration 15, loss = 0.70897531
Iteration 16, loss = 0.70120946
Iteration 17, loss = 0.73338362
Iteration 18, loss = 0.77584931
Iteration 19, loss = 0.79698556
Iteration 20, loss = 0.78089795
Iteration 21, loss = 0.68800849
Iteration 22, loss = 0.83279641
Iteration 23, loss = 0.69019160
Iteration 24, loss = 0.69806574
Iteration 25, loss = 0.70142922
Iteration 26, loss = 0.70462806
Iteration 27, loss = 0.70573256
Iteration 28, loss = 0.70842095
Iteration 29, loss = 0.71006743
Iteration 30, loss = 0.70523421
Iteration 31, loss = 0.95127195
Iteration 32, loss = 0.76571442
Iteration 33, loss = 0.59618791
Iteration 34, loss = 0.63937386
Iteration 35, loss = 0.81166892
Iteration 36, loss = 0.70011512
Iteration 37, loss = 0.71617753
Iteration 38, loss = 0.73768719
Iteration 39, loss = 0.72363167
Iteration 40, loss = 0.74264251
Iteration 41, loss = 0.79409565
Iteration 42, loss = 0.72565456
Iteration 43, loss = 0.75167479
Iteration 44, loss = 0.73647141
Iteration 45, loss = 0.71760465
Iteration 46, loss = 0.72951446
Iteration 47, loss = 0.87658201
Iteration 48, loss = 0.67928957
Iteration 49, loss = 0.55619186
Iteration 50, loss = 1.13417391
Iteration 51, loss = 0.72389473
Iteration 52, loss = 0.75631940
Iteration 53, loss = 0.74387237
Iteration 54, loss = 0.72801423
Iteration 55, loss = 0.74288313
Iteration 56, loss = 0.75628545
Iteration 57, loss = 0.74401455
Iteration 58, loss = 0.73204999
Iteration 59, loss = 0.74068581
Iteration 60, loss = 0.74803279
Iteration 61, loss = 0.73835516
Iteration 62, loss = 0.73065957
Iteration 63, loss = 0.73604362
Iteration 64, loss = 0.73881136
Iteration 65, loss = 0.72968183
Iteration 66, loss = 0.72299271
Iteration 67, loss = 0.72557614
Iteration 68, loss = 0.72498470
Iteration 69, loss = 0.71710361
Iteration 70, loss = 0.71248745
Iteration 71, loss = 0.70347414
Iteration 72, loss = 0.91032189
Iteration 73, loss = 0.71342494
Iteration 74, loss = 0.65303401
Iteration 75, loss = 0.83277982
Iteration 76, loss = 0.78729929
Iteration 77, loss = 0.72256241
Iteration 78, loss = 0.75854822
Iteration 79, loss = 0.80648122
Iteration 80, loss = 0.77635797
Iteration 81, loss = 0.72820354
Iteration 82, loss = 0.74341506
Iteration 83, loss = 0.77446600
Iteration 84, loss = 0.75508007
Iteration 85, loss = 0.71963206
Iteration 86, loss = 0.72521034
Iteration 87, loss = 0.74593324
Iteration 88, loss = 0.73469574
Iteration 89, loss = 0.71040221
Iteration 90, loss = 0.71333000
Iteration 91, loss = 0.72871642
Iteration 92, loss = 0.72244312
Iteration 93, loss = 0.70645030
Iteration 94, loss = 0.70837516
Iteration 95, loss = 0.71847530
Iteration 96, loss = 0.71423522
Iteration 97, loss = 0.70369623
Iteration 98, loss = 0.70527760
Iteration 99, loss = 0.71192286
Iteration 100, loss = 0.70862067
Iteration 101, loss = 0.70165769
Iteration 102, loss = 0.70312941
Iteration 103, loss = 0.70717525
Iteration 104, loss = 0.70408314
Iteration 105, loss = 0.69895423
Iteration 106, loss = 0.69775865
Iteration 107, loss = 0.70125241
Iteration 108, loss = 0.69148971
Iteration 109, loss = 0.72630173
Iteration 110, loss = 0.71702190
Iteration 111, loss = 0.70762535
Iteration 112, loss = 0.72042011
Iteration 113, loss = 0.72782767
Iteration 114, loss = 0.71528418
Iteration 115, loss = 0.70748181
Iteration 116, loss = 0.71415825
Iteration 117, loss = 0.71417912
Iteration 118, loss = 0.70362217
Iteration 119, loss = 0.69925564
Iteration 120, loss = 0.70197171
Iteration 121, loss = 0.68295363
Iteration 122, loss = 0.88564460
Iteration 123, loss = 0.74119854
Iteration 124, loss = 0.72214209
Iteration 125, loss = 0.82670125
Iteration 126, loss = 0.84859960
Iteration 127, loss = 0.76117817
Iteration 128, loss = 0.70464015
Iteration 129, loss = 0.75383096
Iteration 130, loss = 0.79695040
Iteration 131, loss = 0.75976098
Iteration 132, loss = 0.70376814
Iteration 133, loss = 0.71277139
Iteration 134, loss = 0.75183106
Iteration 135, loss = 0.74515240
Iteration 136, loss = 0.70597395
Iteration 137, loss = 0.69536470
Iteration 138, loss = 0.72045468
Iteration 139, loss = 0.72960131
Iteration 140, loss = 0.70595531
Iteration 141, loss = 0.68599432
Iteration 142, loss = 0.68347339
Iteration 143, loss = 0.74747690
Iteration 144, loss = 0.69211501
Iteration 145, loss = 0.71274261
Iteration 146, loss = 0.74341073
Iteration 147, loss = 0.70603828
Iteration 148, loss = 0.88145340
Iteration 149, loss = 0.68900066
Iteration 150, loss = 0.70733018
Iteration 151, loss = 0.70098182
Iteration 152, loss = 0.69704580
Iteration 153, loss = 0.70640002
Iteration 154, loss = 0.71126554
Iteration 155, loss = 0.69911367
Iteration 156, loss = 0.68619432
Iteration 157, loss = 0.64488955
Iteration 158, loss = 1.27337863
Iteration 159, loss = 0.58634574
Iteration 160, loss = 1.30861092
Iteration 161, loss = 1.44966862
Iteration 162, loss = 1.16673702
Iteration 163, loss = 0.79375024
Iteration 164, loss = 0.89745038
Iteration 165, loss = 1.18634638
Iteration 166, loss = 1.20196732
Iteration 167, loss = 0.96312375
Iteration 168, loss = 0.77612789
Iteration 169, loss = 0.90121651
Iteration 170, loss = 1.04863897
Iteration 171, loss = 0.99568620
Iteration 172, loss = 0.82153370
Iteration 173, loss = 0.76536401
Iteration 174, loss = 0.87147000
Iteration 175, loss = 0.92396626
Iteration 176, loss = 0.84396083
Iteration 177, loss = 0.74476022
Iteration 178, loss = 0.76149328
Iteration 179, loss = 0.82883430
Iteration 180, loss = 0.82248392
Iteration 181, loss = 0.75196091
Iteration 182, loss = 0.71919199
Iteration 183, loss = 0.75682802
Iteration 184, loss = 0.78337960
Iteration 185, loss = 0.75345681
Iteration 186, loss = 0.71373203
Iteration 187, loss = 0.71999576
Iteration 188, loss = 0.74791302
Iteration 189, loss = 0.74583367
Iteration 190, loss = 0.71808491
Iteration 191, loss = 0.70786334
Iteration 192, loss = 0.72457897
Iteration 193, loss = 0.73415673
Iteration 194, loss = 0.72070097
Iteration 195, loss = 0.70691182
Iteration 196, loss = 0.71243289
Iteration 197, loss = 0.72306785
Iteration 198, loss = 0.71945105
Iteration 199, loss = 0.70810663
Iteration 200, loss = 0.70659344
Iteration 201, loss = 0.71384137
Iteration 202, loss = 0.71512902
Iteration 203, loss = 0.70792740
Iteration 204, loss = 0.70344043
Iteration 205, loss = 0.70639961
Iteration 206, loss = 0.70863295
Iteration 207, loss = 0.70347975
Iteration 208, loss = 0.69773563
Iteration 209, loss = 0.69658508
Iteration 210, loss = 0.69561613
Iteration 211, loss = 0.68587920
Iteration 212, loss = 0.85954817
Iteration 213, loss = 0.66010562
Iteration 214, loss = 0.89022178
Iteration 215, loss = 0.95766194
Iteration 216, loss = 0.84407557
Iteration 217, loss = 0.73770442
Iteration 218, loss = 0.79732405
Iteration 219, loss = 0.88632017
Iteration 220, loss = 0.85822915
Iteration 221, loss = 0.75811503
Iteration 222, loss = 0.73025567
Iteration 223, loss = 0.78871529
Iteration 224, loss = 0.81117596
Iteration 225, loss = 0.75947547
Iteration 226, loss = 0.71158940
Iteration 227, loss = 0.73162515
Iteration 228, loss = 0.76812866
Iteration 229, loss = 0.75639232
Iteration 230, loss = 0.71830059
Iteration 231, loss = 0.71331509
Iteration 232, loss = 0.73981265
Iteration 233, loss = 0.74719690
Iteration 234, loss = 0.72483961
Iteration 235, loss = 0.70951473
Iteration 236, loss = 0.72097215
Iteration 237, loss = 0.73268719
Iteration 238, loss = 0.72305491
Iteration 239, loss = 0.70713168
Iteration 240, loss = 0.70480255
Iteration 241, loss = 0.64976357
Iteration 242, loss = 0.78419399
Iteration 243, loss = 0.72782101
Iteration 244, loss = 0.72745572
Iteration 245, loss = 0.77043697
Iteration 246, loss = 0.76063788
Iteration 247, loss = 0.71894030
Iteration 248, loss = 0.72242904
Iteration 249, loss = 0.74829868
Iteration 250, loss = 0.73719775
Iteration 251, loss = 0.71204238
Iteration 252, loss = 0.71982131
Iteration 253, loss = 0.73667973
Iteration 254, loss = 0.72715965
Iteration 255, loss = 0.71256265
Iteration 256, loss = 0.72003659
Iteration 257, loss = 0.72913504
Iteration 258, loss = 0.72004471
Iteration 259, loss = 0.71130751
Iteration 260, loss = 0.71757166
Iteration 261, loss = 0.72212645
Iteration 262, loss = 0.71507398
Iteration 263, loss = 0.71091815
Iteration 264, loss = 0.71617115
Iteration 265, loss = 0.71805860
Iteration 266, loss = 0.71273827
Iteration 267, loss = 0.71103203
Iteration 268, loss = 0.71474503
Iteration 269, loss = 0.71484121
Iteration 270, loss = 0.71105020
Iteration 271, loss = 0.71075997
Iteration 272, loss = 0.71311121
Iteration 273, loss = 0.71213714
Iteration 274, loss = 0.70824178
Iteration 275, loss = 0.70857166
Iteration 276, loss = 0.70664810
Iteration 277, loss = 0.71498341
Iteration 278, loss = 0.71370616
Iteration 279, loss = 0.71736656
Iteration 280, loss = 0.71955179
Iteration 281, loss = 0.71788639
Iteration 282, loss = 0.71416182
Iteration 283, loss = 0.71310797
Iteration 284, loss = 0.71341005
Iteration 285, loss = 0.71259566
Iteration 286, loss = 0.71151298
Iteration 287, loss = 0.71206476
Iteration 288, loss = 0.71312297
Iteration 289, loss = 0.71285043
Iteration 290, loss = 0.71213676
Iteration 291, loss = 0.71234297
Iteration 292, loss = 0.71265485
Iteration 293, loss = 0.71204551
Iteration 294, loss = 0.71130141
Iteration 295, loss = 0.71127368
Iteration 296, loss = 0.71132367
Iteration 297, loss = 0.71086405
Iteration 298, loss = 0.71050282
Iteration 299, loss = 0.71068595
Iteration 300, loss = 0.71086040
Iteration 301, loss = 0.71065157
Iteration 302, loss = 0.71047863
Iteration 303, loss = 0.71056173
Iteration 304, loss = 0.71050597
Iteration 305, loss = 0.71035825
Iteration 306, loss = 0.71020660
Iteration 307, loss = 0.71042423
Iteration 308, loss = 0.71065034
Iteration 309, loss = 0.71063967
Iteration 310, loss = 0.71038807
Iteration 311, loss = 0.71009393
Iteration 312, loss = 0.70987256
Iteration 313, loss = 0.70970215
Iteration 314, loss = 0.70957203
Iteration 315, loss = 0.70949903
Iteration 316, loss = 0.70944686
Iteration 317, loss = 0.70937154
Iteration 318, loss = 0.70929185
Iteration 319, loss = 0.70922649
Iteration 320, loss = 0.70914604
Iteration 321, loss = 0.70902979
Iteration 322, loss = 0.70890670
Iteration 323, loss = 0.70880670
Iteration 324, loss = 0.70872128
Iteration 325, loss = 0.70863623
Iteration 326, loss = 0.70855632
Iteration 327, loss = 0.70848024
Iteration 328, loss = 0.70839306
Iteration 329, loss = 0.70829427
Iteration 330, loss = 0.70819951
Iteration 331, loss = 0.70811275
Iteration 332, loss = 0.70802416
Iteration 333, loss = 0.70793049
Iteration 334, loss = 0.70783355
Iteration 335, loss = 0.70772426
Iteration 336, loss = 0.70758271
Iteration 337, loss = 0.70737407
Iteration 338, loss = 0.70700349
Iteration 339, loss = 0.70623264
Iteration 340, loss = 0.70414160
Iteration 341, loss = 0.69751450
Iteration 342, loss = 0.54872108
Iteration 343, loss = 0.88369448
Iteration 344, loss = 0.92971549
Iteration 345, loss = 1.02328717
Iteration 346, loss = 0.86469120
Iteration 347, loss = 0.74349026
Iteration 348, loss = 0.86501494
Iteration 349, loss = 0.94927023
Iteration 350, loss = 0.85302705
Iteration 351, loss = 0.74039982
Iteration 352, loss = 0.78904164
Iteration 353, loss = 0.85817604
Iteration 354, loss = 0.80993854
Iteration 355, loss = 0.72717219
Iteration 356, loss = 0.74439032
Iteration 357, loss = 0.79910000
Iteration 358, loss = 0.78007333
Iteration 359, loss = 0.72344048
Iteration 360, loss = 0.72532195
Iteration 361, loss = 0.76356531
Iteration 362, loss = 0.75796582
Iteration 363, loss = 0.71994831
Iteration 364, loss = 0.71557247
Iteration 365, loss = 0.74129818
Iteration 366, loss = 0.74219426
Iteration 367, loss = 0.71783848
Iteration 368, loss = 0.71224110
Iteration 369, loss = 0.72911250
Iteration 370, loss = 0.73210989
Iteration 371, loss = 0.71639729
Iteration 372, loss = 0.71082030
Iteration 373, loss = 0.72127311
Iteration 374, loss = 0.72418540
Iteration 375, loss = 0.71387483
Iteration 376, loss = 0.70908296
Iteration 377, loss = 0.71548450
Iteration 378, loss = 0.71790494
Iteration 379, loss = 0.71127511
Iteration 380, loss = 0.70765136
Iteration 381, loss = 0.71167081
Iteration 382, loss = 0.71356590
Iteration 383, loss = 0.70932039
Iteration 384, loss = 0.70672807
Iteration 385, loss = 0.70929023
Iteration 386, loss = 0.71069734
Iteration 387, loss = 0.70798988
Iteration 388, loss = 0.70621879
Iteration 389, loss = 0.70787615
Iteration 390, loss = 0.70884526
Iteration 391, loss = 0.70705143
Iteration 392, loss = 0.70581398
Iteration 393, loss = 0.70684509
Iteration 394, loss = 0.70743976
Iteration 395, loss = 0.70620536
Iteration 396, loss = 0.70534209
Iteration 397, loss = 0.70598254
Iteration 398, loss = 0.70632619
Iteration 399, loss = 0.70546707
Iteration 400, loss = 0.70487878
Iteration 401, loss = 0.70528041
Iteration 402, loss = 0.70545720
Iteration 403, loss = 0.70484142
Iteration 404, loss = 0.70442857
Iteration 405, loss = 0.70465724
Iteration 406, loss = 0.70470395
Iteration 407, loss = 0.70423496
Iteration 408, loss = 0.70393630
Iteration 409, loss = 0.70406842
Iteration 410, loss = 0.70407094
Iteration 411, loss = 0.70375092
Iteration 412, loss = 0.70356472
Iteration 413, loss = 0.70363803
Iteration 414, loss = 0.70373022
Iteration 415, loss = 0.70340031
Iteration 416, loss = 0.70341910
Iteration 417, loss = 0.70352254
Iteration 418, loss = 0.70339345
Iteration 419, loss = 0.70312468
Iteration 420, loss = 0.70299688
Iteration 421, loss = 0.70297525
Iteration 422, loss = 0.70287498
Iteration 423, loss = 0.70274183
Iteration 424, loss = 0.70270321
Iteration 425, loss = 0.70268935
Iteration 426, loss = 0.70258838
Iteration 427, loss = 0.70246451
Iteration 428, loss = 0.70240890
Iteration 429, loss = 0.70236615
Iteration 430, loss = 0.70226775
Iteration 431, loss = 0.70216488
Iteration 432, loss = 0.70210967
Iteration 433, loss = 0.70205536
Iteration 434, loss = 0.70196085
Iteration 435, loss = 0.70186435
Iteration 436, loss = 0.70179372
Iteration 437, loss = 0.70171459
Iteration 438, loss = 0.70160483
Iteration 439, loss = 0.70147625
Iteration 440, loss = 0.70109049
Iteration 441, loss = 0.70105319
Iteration 442, loss = 0.70145994
Iteration 443, loss = 0.70189847
Iteration 444, loss = 0.70190189
Iteration 445, loss = 0.73639820
Iteration 446, loss = 0.70989538
Iteration 447, loss = 0.72006613
Iteration 448, loss = 0.71823996
Iteration 449, loss = 0.71920872
Iteration 450, loss = 0.73099180
Iteration 451, loss = 0.73854497
Iteration 452, loss = 0.73646086
Iteration 453, loss = 0.73602214
Iteration 454, loss = 0.74064764
Iteration 455, loss = 0.74057489
Iteration 456, loss = 0.73424524
Iteration 457, loss = 0.72960777
Iteration 458, loss = 0.72723168
Iteration 459, loss = 0.71812725
Iteration 460, loss = 0.76532140
Iteration 461, loss = 0.74766167
Iteration 462, loss = 0.76871354
Iteration 463, loss = 0.75401448
Iteration 464, loss = 0.75096989
Iteration 465, loss = 0.77015640
Iteration 466, loss = 0.76887919
Iteration 467, loss = 0.73667590
Iteration 468, loss = 0.75443892
Iteration 469, loss = 0.75403322
Iteration 470, loss = 0.75463779
Iteration 471, loss = 0.75502591
Iteration 472, loss = 0.74970786
Iteration 473, loss = 0.74213749
Iteration 474, loss = 0.73757778
Iteration 475, loss = 0.73435169
Iteration 476, loss = 0.72929300
Iteration 477, loss = 0.72558391
Iteration 478, loss = 0.72534533
Iteration 479, loss = 0.72603377
Iteration 480, loss = 0.72537674
Iteration 481, loss = 0.72495981
Iteration 482, loss = 0.72610427
Iteration 483, loss = 0.72637713
Iteration 484, loss = 0.72538498
Iteration 485, loss = 0.72495121
Iteration 486, loss = 0.72524738
Iteration 487, loss = 0.72468985
Iteration 488, loss = 0.72344420
Iteration 489, loss = 0.72285512
Iteration 490, loss = 0.72262650
Iteration 491, loss = 0.72167801
Iteration 492, loss = 0.72056884
Iteration 493, loss = 0.72052295
Iteration 494, loss = 0.72052373
Iteration 495, loss = 0.71985668
Iteration 496, loss = 0.71924945
Iteration 497, loss = 0.71936582
Iteration 498, loss = 0.71892935
Iteration 499, loss = 0.71853802
Iteration 500, loss = 0.71836747
Iteration 501, loss = 0.71830266
Iteration 502, loss = 0.71799147
Iteration 503, loss = 0.71759811
Iteration 504, loss = 0.71743344
Iteration 505, loss = 0.71716486
Iteration 506, loss = 0.71692326
Iteration 507, loss = 0.71661486
Iteration 508, loss = 0.71634716
Iteration 509, loss = 0.71608487
Iteration 510, loss = 0.71590723
Iteration 511, loss = 0.71577956
Iteration 512, loss = 0.71560475
Iteration 513, loss = 0.71545353
Iteration 514, loss = 0.71530068
Iteration 515, loss = 0.71518781
Iteration 516, loss = 0.71506528
Iteration 517, loss = 0.71486217
Iteration 518, loss = 0.71414265
Iteration 519, loss = 0.71409286
Iteration 520, loss = 0.71398388
Iteration 521, loss = 0.71375574
Iteration 522, loss = 0.71346067
Iteration 523, loss = 0.69928271
Iteration 524, loss = 0.74049389
Iteration 525, loss = 0.72010545
Iteration 526, loss = 0.74360868
Iteration 527, loss = 0.75439676
Iteration 528, loss = 0.73772299
Iteration 529, loss = 0.74605215
Iteration 530, loss = 0.75550312
Iteration 531, loss = 0.74017966
Iteration 532, loss = 0.73782405
Iteration 533, loss = 0.74428006
Iteration 534, loss = 0.73237387
Iteration 535, loss = 0.72345780
Iteration 536, loss = 0.71132396
Iteration 537, loss = 0.70718301
Iteration 538, loss = 0.83771416
Iteration 539, loss = 0.83807572
Iteration 540, loss = 0.77082239
Iteration 541, loss = 0.83349966
Iteration 542, loss = 0.86511325
Iteration 543, loss = 0.80300206
Iteration 544, loss = 0.80796248
Iteration 545, loss = 0.84513063
Iteration 546, loss = 0.80388185
Iteration 547, loss = 0.77554164
Iteration 548, loss = 0.80216049
Iteration 549, loss = 0.78697665
Iteration 550, loss = 0.75177558
Iteration 551, loss = 0.76475083
Iteration 552, loss = 0.76924527
Iteration 553, loss = 0.74229493
Iteration 554, loss = 0.74283260
Iteration 555, loss = 0.75520590
Iteration 556, loss = 0.74079747
Iteration 557, loss = 0.73380532
Iteration 558, loss = 0.74577766
Iteration 559, loss = 0.74170349
Iteration 560, loss = 0.73249785
Iteration 561, loss = 0.73981828
Iteration 562, loss = 0.74172827
Iteration 563, loss = 0.73319827
Iteration 564, loss = 0.73495509
Iteration 565, loss = 0.73899025
Iteration 566, loss = 0.73326587
Iteration 567, loss = 0.73148672
Iteration 568, loss = 0.73529662
Iteration 569, loss = 0.73257611
Iteration 570, loss = 0.72926046
Iteration 571, loss = 0.73166631
Iteration 572, loss = 0.73118294
Iteration 573, loss = 0.72795454
Iteration 574, loss = 0.72893799
Iteration 575, loss = 0.72979360
Iteration 576, loss = 0.72750513
Iteration 577, loss = 0.72739673
Iteration 578, loss = 0.72860467
Iteration 579, loss = 0.72729343
Iteration 580, loss = 0.72651143
Iteration 581, loss = 0.72746207
Iteration 582, loss = 0.72690732
Iteration 583, loss = 0.72589177
Iteration 584, loss = 0.72639809
Iteration 585, loss = 0.72633093
Iteration 586, loss = 0.72539823
Iteration 587, loss = 0.72548750
Iteration 588, loss = 0.72564094
Iteration 589, loss = 0.72493795
Iteration 590, loss = 0.72474737
Iteration 591, loss = 0.72494622
Iteration 592, loss = 0.72450545
Iteration 593, loss = 0.72419096
Iteration 594, loss = 0.72434395
Iteration 595, loss = 0.72411941
Iteration 596, loss = 0.72378655
Iteration 597, loss = 0.72384892
Iteration 598, loss = 0.72362566
Iteration 599, loss = 0.72294107
Iteration 600, loss = 0.72341548
Iteration 601, loss = 0.72342117
Iteration 602, loss = 0.72376489
Iteration 603, loss = 0.72387067
Iteration 604, loss = 0.69924382
Iteration 605, loss = 0.74206676
Iteration 606, loss = 0.77513129
Iteration 607, loss = 0.78619394
Iteration 608, loss = 0.74735037
Iteration 609, loss = 0.76650102
Iteration 610, loss = 0.78235823
Iteration 611, loss = 0.74683322
Iteration 612, loss = 0.73315707
Iteration 613, loss = 0.93650761
Iteration 614, loss = 0.74015990
Iteration 615, loss = 0.88492201
Iteration 616, loss = 0.85388229
Iteration 617, loss = 0.74476618
Iteration 618, loss = 0.85776072
Iteration 619, loss = 0.80217726
Iteration 620, loss = 0.74271405
Iteration 621, loss = 0.82404133
Iteration 622, loss = 0.77204446
Iteration 623, loss = 0.74317065
Iteration 624, loss = 0.79328242
Iteration 625, loss = 0.78001417
Iteration 626, loss = 0.74718524
Iteration 627, loss = 0.80462517
Iteration 628, loss = 0.77292188
Iteration 629, loss = 0.74006053
Iteration 630, loss = 0.78099426
Iteration 631, loss = 0.76464319
Iteration 632, loss = 0.73633279
Iteration 633, loss = 0.76582346
Iteration 634, loss = 0.75983591
Iteration 635, loss = 0.73638436
Iteration 636, loss = 0.75603650
Iteration 637, loss = 0.75530315
Iteration 638, loss = 0.73596260
Iteration 639, loss = 0.74816180
Iteration 640, loss = 0.75047951
Iteration 641, loss = 0.73558234
Iteration 642, loss = 0.74288773
Iteration 643, loss = 0.74648390
Iteration 644, loss = 0.73517377
Iteration 645, loss = 0.73893169
Iteration 646, loss = 0.74271362
Iteration 647, loss = 0.73438934
Iteration 648, loss = 0.73606104
Iteration 649, loss = 0.73964799
Iteration 650, loss = 0.73376874
Iteration 651, loss = 0.73419011
Iteration 652, loss = 0.73724277
Iteration 653, loss = 0.73304854
Iteration 654, loss = 0.73265800
Iteration 655, loss = 0.73501823
Iteration 656, loss = 0.73205421
Iteration 657, loss = 0.73130546
Iteration 658, loss = 0.73312949
Iteration 659, loss = 0.73109801
Iteration 660, loss = 0.73023942
Iteration 661, loss = 0.73157460
Iteration 662, loss = 0.73016118
Iteration 663, loss = 0.72929072
Iteration 664, loss = 0.73022618
Iteration 665, loss = 0.72922489
Iteration 666, loss = 0.72723642
Iteration 667, loss = 0.73850444
Iteration 668, loss = 0.73409205
Iteration 669, loss = 0.74367985
Iteration 670, loss = 0.74653257
Iteration 671, loss = 0.73885066
Iteration 672, loss = 0.74081407
Iteration 673, loss = 0.73741291
Iteration 674, loss = 0.73064624
Iteration 675, loss = 0.73286984
Iteration 676, loss = 0.73094283
Iteration 677, loss = 0.72801385
Iteration 678, loss = 0.73104494
Iteration 679, loss = 0.72941779
Iteration 680, loss = 0.72726891
Iteration 681, loss = 0.72829394
Iteration 682, loss = 0.72597343
Iteration 683, loss = 0.72448274
Iteration 684, loss = 0.72486093
Iteration 685, loss = 0.72257883
Iteration 686, loss = 0.72123007
Iteration 687, loss = 0.72062474
Iteration 688, loss = 0.71834404
Iteration 689, loss = 0.71797683
Iteration 690, loss = 0.71696276
Iteration 691, loss = 0.71205531
Iteration 692, loss = 0.70791833
Iteration 693, loss = 0.70279999
Iteration 694, loss = 0.64856112
Iteration 695, loss = 0.97671137
Iteration 696, loss = 0.75848507
Iteration 697, loss = 0.94849478
Iteration 698, loss = 0.97650983
Iteration 699, loss = 0.77800629
Iteration 700, loss = 0.84286031
Iteration 701, loss = 0.92843816
Iteration 702, loss = 0.79233374
Iteration 703, loss = 0.77152141
Iteration 704, loss = 0.86581515
Iteration 705, loss = 0.79770182
Iteration 706, loss = 0.73876828
Iteration 707, loss = 0.81338409
Iteration 708, loss = 0.79833977
Iteration 709, loss = 0.73535889
Iteration 710, loss = 0.77855676
Iteration 711, loss = 0.79386943
Iteration 712, loss = 0.74252047
Iteration 713, loss = 0.75605398
Iteration 714, loss = 0.78186620
Iteration 715, loss = 0.74714156
Iteration 716, loss = 0.74147763
Iteration 717, loss = 0.76697587
Iteration 718, loss = 0.74898751
Iteration 719, loss = 0.73440994
Iteration 720, loss = 0.75355299
Iteration 721, loss = 0.74808976
Iteration 722, loss = 0.73194035
Iteration 723, loss = 0.74327566
Iteration 724, loss = 0.74538966
Iteration 725, loss = 0.73171146
Iteration 726, loss = 0.73628287
Iteration 727, loss = 0.74169640
Iteration 728, loss = 0.73192488
Iteration 729, loss = 0.73182693
Iteration 730, loss = 0.73779069
Iteration 731, loss = 0.73201307
Iteration 732, loss = 0.72935755
Iteration 733, loss = 0.73420521
Iteration 734, loss = 0.73146002
Iteration 735, loss = 0.72786421
Iteration 736, loss = 0.73115377
Iteration 737, loss = 0.73059621
Iteration 738, loss = 0.72723883
Iteration 739, loss = 0.72899969
Iteration 740, loss = 0.72951505
Iteration 741, loss = 0.72673497
Iteration 742, loss = 0.72726890
Iteration 743, loss = 0.72821330
Iteration 744, loss = 0.72620406
Iteration 745, loss = 0.72592550
Iteration 746, loss = 0.72686133
Iteration 747, loss = 0.72561060
Iteration 748, loss = 0.72499932
Iteration 749, loss = 0.72578348
Iteration 750, loss = 0.72509390
Iteration 751, loss = 0.72431404
Iteration 752, loss = 0.72479975
Iteration 753, loss = 0.72447706
Iteration 754, loss = 0.72371499
Iteration 755, loss = 0.72392176
Iteration 756, loss = 0.72378476
Iteration 757, loss = 0.72310643
Iteration 758, loss = 0.72310893
Iteration 759, loss = 0.72307997
Iteration 760, loss = 0.72253313
Iteration 761, loss = 0.72239160
Iteration 762, loss = 0.72238481
Iteration 763, loss = 0.72196480
Iteration 764, loss = 0.72174975
Iteration 765, loss = 0.72172952
Iteration 766, loss = 0.72140544
Iteration 767, loss = 0.72115061
Iteration 768, loss = 0.72109718
Iteration 769, loss = 0.72084285
Iteration 770, loss = 0.72057346
Iteration 771, loss = 0.72047996
Iteration 772, loss = 0.72027486
Iteration 773, loss = 0.72001864
Iteration 774, loss = 0.71989869
Iteration 775, loss = 0.71972444
Iteration 776, loss = 0.71948533
Iteration 777, loss = 0.71934420
Iteration 778, loss = 0.71918670
Iteration 779, loss = 0.71896480
Iteration 780, loss = 0.71880712
Iteration 781, loss = 0.71865645
Iteration 782, loss = 0.71845195
Iteration 783, loss = 0.71828599
Iteration 784, loss = 0.71813808
Iteration 785, loss = 0.71794904
Iteration 786, loss = 0.71778019
Iteration 787, loss = 0.71763148
Iteration 788, loss = 0.71745114
Iteration 789, loss = 0.71727631
Iteration 790, loss = 0.71711644
Iteration 791, loss = 0.71692542
Iteration 792, loss = 0.71670855
Iteration 793, loss = 0.71642866
Iteration 794, loss = 0.71589324
Iteration 795, loss = 0.71521293
Iteration 796, loss = 0.71473187
Iteration 797, loss = 0.71320598
Iteration 798, loss = 0.71182330
Iteration 799, loss = 0.71006263
Iteration 800, loss = 0.70626308
Iteration 801, loss = 0.70919289
Iteration 802, loss = 0.77730087
Iteration 803, loss = 0.79510774
Iteration 804, loss = 0.74398586
Iteration 805, loss = 0.78153831
Iteration 806, loss = 0.80058550
Iteration 807, loss = 0.75351506
Iteration 808, loss = 0.76121397
Iteration 809, loss = 0.77922357
Iteration 810, loss = 0.74411274
Iteration 811, loss = 0.73915351
Iteration 812, loss = 0.75779498
Iteration 813, loss = 0.73723001
Iteration 814, loss = 0.72884538
Iteration 815, loss = 0.74634720
Iteration 816, loss = 0.73743367
Iteration 817, loss = 0.72831283
Iteration 818, loss = 0.74158560
Iteration 819, loss = 0.73847468
Iteration 820, loss = 0.72878047
Iteration 821, loss = 0.73673564
Iteration 822, loss = 0.73651967
Iteration 823, loss = 0.72778955
Iteration 824, loss = 0.73182780
Iteration 825, loss = 0.73306250
Iteration 826, loss = 0.72546321
Iteration 827, loss = 0.72513142
Iteration 828, loss = 0.71426126
Iteration 829, loss = 0.73780407
Iteration 830, loss = 0.73437197
Iteration 831, loss = 0.73289578
Iteration 832, loss = 0.73733029
Iteration 833, loss = 0.73570336
Iteration 834, loss = 0.73039095
Iteration 835, loss = 0.73115246
Iteration 836, loss = 0.73278940
Iteration 837, loss = 0.73018806
Iteration 838, loss = 0.72978109
Iteration 839, loss = 0.73256562
Iteration 840, loss = 0.73244179
Iteration 841, loss = 0.73092395
Iteration 842, loss = 0.73203793
Iteration 843, loss = 0.73267595
Iteration 844, loss = 0.73106211
Iteration 845, loss = 0.73068366
Iteration 846, loss = 0.73155091
Iteration 847, loss = 0.73091764
Iteration 848, loss = 0.73005393
Iteration 849, loss = 0.73058640
Iteration 850, loss = 0.73070321
Iteration 851, loss = 0.72990485
Iteration 852, loss = 0.72989142
Iteration 853, loss = 0.73027441
Iteration 854, loss = 0.72983560
Iteration 855, loss = 0.72942618
Iteration 856, loss = 0.72960206
Iteration 857, loss = 0.72939292
Iteration 858, loss = 0.72881486
Iteration 859, loss = 0.72868040
Iteration 860, loss = 0.72863163
Iteration 861, loss = 0.72821375
Iteration 862, loss = 0.72795223
Iteration 863, loss = 0.72796320
Iteration 864, loss = 0.72774758
Iteration 865, loss = 0.72742791
Iteration 866, loss = 0.72732888
Iteration 867, loss = 0.72718220
Iteration 868, loss = 0.72685465
Iteration 869, loss = 0.72663781
Iteration 870, loss = 0.72651000
Iteration 871, loss = 0.72625617
Iteration 872, loss = 0.72600574
Iteration 873, loss = 0.72586826
Iteration 874, loss = 0.72567012
Iteration 875, loss = 0.72534097
Iteration 876, loss = 0.72479865
Iteration 877, loss = 0.72459650
Iteration 878, loss = 0.72453582
Iteration 879, loss = 0.72436694
Iteration 880, loss = 0.72409187
Iteration 881, loss = 0.72332161
Iteration 882, loss = 0.72305789
Iteration 883, loss = 0.72289743
Iteration 884, loss = 0.72281814
Iteration 885, loss = 0.72259469
Iteration 886, loss = 0.72213847
Iteration 887, loss = 0.72182992
Iteration 888, loss = 0.72149649
Iteration 889, loss = 0.72116084
Iteration 890, loss = 0.72141282
Iteration 891, loss = 0.72056053
Iteration 892, loss = 0.72011564
Iteration 893, loss = 0.71965084
Iteration 894, loss = 0.71837658
Iteration 895, loss = 0.71806435
Iteration 896, loss = 0.71478692
Iteration 897, loss = 0.70999870
Iteration 898, loss = 0.63999757
Iteration 899, loss = 1.02062623
Iteration 900, loss = 0.73970296
Iteration 901, loss = 1.00109659
Iteration 902, loss = 0.93640365
Iteration 903, loss = 0.75188151
Iteration 904, loss = 0.92697155
Iteration 905, loss = 0.88334271
Iteration 906, loss = 0.74094958
Iteration 907, loss = 0.85915533
Iteration 908, loss = 0.84183172
Iteration 909, loss = 0.73162053
Iteration 910, loss = 0.81159099
Iteration 911, loss = 0.81509574
Iteration 912, loss = 0.73169233
Iteration 913, loss = 0.78343538
Iteration 914, loss = 0.79781618
Iteration 915, loss = 0.73476190
Iteration 916, loss = 0.76514679
Iteration 917, loss = 0.78283747
Iteration 918, loss = 0.73506038
Iteration 919, loss = 0.75012539
Iteration 920, loss = 0.76797753
Iteration 921, loss = 0.73401638
Iteration 922, loss = 0.74088238
Iteration 923, loss = 0.75783989
Iteration 924, loss = 0.73405038
Iteration 925, loss = 0.73529561
Iteration 926, loss = 0.74957125
Iteration 927, loss = 0.73323678
Iteration 928, loss = 0.73166617
Iteration 929, loss = 0.74302440
Iteration 930, loss = 0.73187562
Iteration 931, loss = 0.72874492
Iteration 932, loss = 0.73768386
Iteration 933, loss = 0.73045501
Iteration 934, loss = 0.72697497
Iteration 935, loss = 0.73376915
Iteration 936, loss = 0.72933839
Iteration 937, loss = 0.72605619
Iteration 938, loss = 0.73100789
Iteration 939, loss = 0.72822588
Iteration 940, loss = 0.72519503
Iteration 941, loss = 0.72830741
Iteration 942, loss = 0.72665740
Iteration 943, loss = 0.72406015
Iteration 944, loss = 0.72635794
Iteration 945, loss = 0.72510734
Iteration 946, loss = 0.72283007
Iteration 947, loss = 0.72414470
Iteration 948, loss = 0.72338151
Iteration 949, loss = 0.72136708
Iteration 950, loss = 0.72203712
Iteration 951, loss = 0.71995445
Iteration 952, loss = 0.71819618
Iteration 953, loss = 0.71797161
Iteration 954, loss = 0.71411544
Iteration 955, loss = 0.69042869
Iteration 956, loss = 0.95267323
Iteration 957, loss = 0.73251062
Iteration 958, loss = 0.95887715
Iteration 959, loss = 0.85459970
Iteration 960, loss = 0.76388230
Iteration 961, loss = 0.91304736
Iteration 962, loss = 0.79682249
Iteration 963, loss = 0.77133974
Iteration 964, loss = 0.86294380
Iteration 965, loss = 0.75640490
Iteration 966, loss = 0.76954815
Iteration 967, loss = 0.81864274
Iteration 968, loss = 0.73480277
Iteration 969, loss = 0.76498941
Iteration 970, loss = 0.78694687
Iteration 971, loss = 0.72544906
Iteration 972, loss = 0.76066863
Iteration 973, loss = 0.76324175
Iteration 974, loss = 0.72231156
Iteration 975, loss = 0.75291053
Iteration 976, loss = 0.73865865
Iteration 977, loss = 0.68218893
Iteration 978, loss = 0.93495283
Iteration 979, loss = 0.72891729
Iteration 980, loss = 0.91070801
Iteration 981, loss = 0.97851829
Iteration 982, loss = 0.79696956
Iteration 983, loss = 0.79815917
Iteration 984, loss = 0.92713356
Iteration 985, loss = 0.84728762
Iteration 986, loss = 0.74818293
Iteration 987, loss = 0.83670860
Iteration 988, loss = 0.84821589
Iteration 989, loss = 0.74940104
Iteration 990, loss = 0.76398334
Iteration 991, loss = 0.81591098
Iteration 992, loss = 0.76174549
Iteration 993, loss = 0.73167378
Iteration 994, loss = 0.78087707
Iteration 995, loss = 0.77193727
Iteration 996, loss = 0.72970909
Iteration 997, loss = 0.75302253
Iteration 998, loss = 0.76967219
Iteration 999, loss = 0.73660896
Iteration 1000, loss = 0.73417477
