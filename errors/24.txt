Iteration 1, loss = 0.70168666
Iteration 2, loss = 5.52349379
Iteration 3, loss = 1.15767669
Iteration 4, loss = 1.39020265
Iteration 5, loss = 1.78327728
Iteration 6, loss = 1.48482333
Iteration 7, loss = 1.05976766
Iteration 8, loss = 0.59629879
Iteration 9, loss = 1.49492561
Iteration 10, loss = 0.79428587
Iteration 11, loss = 0.95087139
Iteration 12, loss = 0.88502608
Iteration 13, loss = 0.77850028
Iteration 14, loss = 0.74378769
Iteration 15, loss = 0.97568285
Iteration 16, loss = 0.77949431
Iteration 17, loss = 0.80277386
Iteration 18, loss = 0.86259133
Iteration 19, loss = 0.82005798
Iteration 20, loss = 0.98089306
Iteration 21, loss = 1.12047928
Iteration 22, loss = 0.76785939
Iteration 23, loss = 0.84006434
Iteration 24, loss = 0.84894556
Iteration 25, loss = 0.76974839
Iteration 26, loss = 0.80279150
Iteration 27, loss = 0.86444205
Iteration 28, loss = 0.80455858
Iteration 29, loss = 0.77911869
Iteration 30, loss = 0.95248412
Iteration 31, loss = 1.04158856
Iteration 32, loss = 0.88258418
Iteration 33, loss = 0.81504366
Iteration 34, loss = 0.79724962
Iteration 35, loss = 0.77521555
Iteration 36, loss = 0.76320468
Iteration 37, loss = 0.76530133
Iteration 38, loss = 0.70955606
Iteration 39, loss = 0.77847082
Iteration 40, loss = 0.76469341
Iteration 41, loss = 0.78853787
Iteration 42, loss = 0.75608419
Iteration 43, loss = 0.73652134
Iteration 44, loss = 0.87616335
Iteration 45, loss = 0.77290722
Iteration 46, loss = 0.89027474
Iteration 47, loss = 0.76618956
Iteration 48, loss = 0.81868446
Iteration 49, loss = 0.81646471
Iteration 50, loss = 0.75482017
Iteration 51, loss = 0.80494779
Iteration 52, loss = 0.74457860
Iteration 53, loss = 1.13798225
Iteration 54, loss = 0.79244739
Iteration 55, loss = 0.90373315
Iteration 56, loss = 1.00564085
Iteration 57, loss = 0.71086005
Iteration 58, loss = 0.96760957
Iteration 59, loss = 0.93732993
Iteration 60, loss = 0.70376067
Iteration 61, loss = 1.08427487
Iteration 62, loss = 1.02049713
Iteration 63, loss = 0.70780350
Iteration 64, loss = 0.78908028
Iteration 65, loss = 0.94729387
Iteration 66, loss = 0.79204789
Iteration 67, loss = 0.70070229
Iteration 68, loss = 0.53854104
Iteration 69, loss = 0.73021749
Iteration 70, loss = 0.96686922
Iteration 71, loss = 0.78982968
Iteration 72, loss = 0.80678609
Iteration 73, loss = 1.28342974
Iteration 74, loss = 0.72959644
Iteration 75, loss = 0.75102353
Iteration 76, loss = 0.91447659
Iteration 77, loss = 0.89725129
Iteration 78, loss = 0.85443090
Iteration 79, loss = 0.74937506
Iteration 80, loss = 0.66106585
Iteration 81, loss = 0.76097693
Iteration 82, loss = 0.77726494
Iteration 83, loss = 0.80568189
Iteration 84, loss = 1.01844650
Iteration 85, loss = 0.86964214
Iteration 86, loss = 0.99258875
Iteration 87, loss = 0.80765021
Iteration 88, loss = 1.09079590
Iteration 89, loss = 0.97324205
Iteration 90, loss = 0.72783790
Iteration 91, loss = 0.85355674
Iteration 92, loss = 0.76577465
Iteration 93, loss = 0.85564005
Iteration 94, loss = 0.79729350
Iteration 95, loss = 0.83535310
Iteration 96, loss = 0.75790457
Iteration 97, loss = 1.04334478
Iteration 98, loss = 0.76346258
Iteration 99, loss = 1.29483386
Iteration 100, loss = 1.01614544
Iteration 101, loss = 0.86036745
Iteration 102, loss = 1.16193508
Iteration 103, loss = 0.93118282
Iteration 104, loss = 0.84764094
Iteration 105, loss = 1.02635565
Iteration 106, loss = 0.77981059
Iteration 107, loss = 0.81025964
Iteration 108, loss = 0.77290328
Iteration 109, loss = 0.75945749
Iteration 110, loss = 0.92956988
Iteration 111, loss = 0.83622408
Iteration 112, loss = 0.90955715
Iteration 113, loss = 0.77219109
Iteration 114, loss = 1.12301279
Iteration 115, loss = 0.95420053
Iteration 116, loss = 0.80195456
Iteration 117, loss = 1.02290087
Iteration 118, loss = 0.94983677
Iteration 119, loss = 0.78740276
Iteration 120, loss = 0.93742596
Iteration 121, loss = 0.91809185
Iteration 122, loss = 0.77703432
Iteration 123, loss = 0.87133924
Iteration 124, loss = 0.87834985
Iteration 125, loss = 0.76560765
Iteration 126, loss = 0.82385257
Iteration 127, loss = 0.84189937
Iteration 128, loss = 0.75640649
Iteration 129, loss = 0.79350561
Iteration 130, loss = 0.80691405
Iteration 131, loss = 0.74863269
Iteration 132, loss = 0.77289387
Iteration 133, loss = 0.78439397
Iteration 134, loss = 0.74616142
Iteration 135, loss = 0.76002345
Iteration 136, loss = 0.77094158
Iteration 137, loss = 0.74160566
Iteration 138, loss = 0.75030606
Iteration 139, loss = 0.75997291
Iteration 140, loss = 0.73852292
Iteration 141, loss = 0.74384561
Iteration 142, loss = 0.75097585
Iteration 143, loss = 0.73423696
Iteration 144, loss = 0.75764612
Iteration 145, loss = 0.73444197
Iteration 146, loss = 0.72019423
Iteration 147, loss = 1.19338680
Iteration 148, loss = 0.76803405
Iteration 149, loss = 1.13334321
Iteration 150, loss = 1.20688167
Iteration 151, loss = 0.88167982
Iteration 152, loss = 0.89108003
Iteration 153, loss = 1.14078613
Iteration 154, loss = 1.03401512
Iteration 155, loss = 0.82039366
Iteration 156, loss = 0.96318237
Iteration 157, loss = 1.03461626
Iteration 158, loss = 0.85998083
Iteration 159, loss = 0.82430101
Iteration 160, loss = 0.94498864
Iteration 161, loss = 0.88388397
Iteration 162, loss = 0.76690447
Iteration 163, loss = 1.01877638
Iteration 164, loss = 0.87145206
Iteration 165, loss = 0.78229655
Iteration 166, loss = 0.79672916
Iteration 167, loss = 0.76859133
Iteration 168, loss = 0.79235199
Iteration 169, loss = 0.78815377
Iteration 170, loss = 0.70643124
Iteration 171, loss = 0.91048892
Iteration 172, loss = 0.77373081
Iteration 173, loss = 0.89542435
Iteration 174, loss = 0.83239768
Iteration 175, loss = 0.79922405
Iteration 176, loss = 0.86823261
Iteration 177, loss = 0.77965176
Iteration 178, loss = 0.81281162
Iteration 179, loss = 0.82149349
Iteration 180, loss = 0.76166687
Iteration 181, loss = 0.81037816
Iteration 182, loss = 0.78249853
Iteration 183, loss = 0.76410612
Iteration 184, loss = 0.79656571
Iteration 185, loss = 0.75913481
Iteration 186, loss = 0.77002749
Iteration 187, loss = 0.77817945
Iteration 188, loss = 0.75146108
Iteration 189, loss = 0.77174076
Iteration 190, loss = 0.76187389
Iteration 191, loss = 0.75166884
Iteration 192, loss = 0.76633757
Iteration 193, loss = 0.74998866
Iteration 194, loss = 0.75317298
Iteration 195, loss = 0.75648180
Iteration 196, loss = 0.74399333
Iteration 197, loss = 0.75180275
Iteration 198, loss = 0.74299987
Iteration 199, loss = 0.78045288
Iteration 200, loss = 0.90261531
Iteration 201, loss = 0.84443928
Iteration 202, loss = 0.77170118
Iteration 203, loss = 0.89324564
Iteration 204, loss = 0.81131862
Iteration 205, loss = 0.79238281
Iteration 206, loss = 0.80744510
Iteration 207, loss = 0.77845539
Iteration 208, loss = 0.75655557
Iteration 209, loss = 0.84426434
Iteration 210, loss = 0.75796452
Iteration 211, loss = 0.81329862
Iteration 212, loss = 0.82724446
Iteration 213, loss = 0.76779775
Iteration 214, loss = 0.81420025
Iteration 215, loss = 0.79386347
Iteration 216, loss = 0.75823274
Iteration 217, loss = 0.79361466
Iteration 218, loss = 0.76407200
Iteration 219, loss = 0.75540945
Iteration 220, loss = 0.77913363
Iteration 221, loss = 0.75109370
Iteration 222, loss = 0.75915382
Iteration 223, loss = 0.76846217
Iteration 224, loss = 0.74708075
Iteration 225, loss = 0.76042842
Iteration 226, loss = 0.75751951
Iteration 227, loss = 0.74567194
Iteration 228, loss = 0.75815100
Iteration 229, loss = 0.74910670
Iteration 230, loss = 0.74582879
Iteration 231, loss = 0.75313840
Iteration 232, loss = 0.74353255
Iteration 233, loss = 0.74607489
Iteration 234, loss = 0.74769125
Iteration 235, loss = 0.74031523
Iteration 236, loss = 0.74499509
Iteration 237, loss = 0.74232893
Iteration 238, loss = 0.73917508
Iteration 239, loss = 0.74281207
Iteration 240, loss = 0.73828879
Iteration 241, loss = 0.73808582
Iteration 242, loss = 0.73859962
Iteration 243, loss = 0.73338714
Iteration 244, loss = 0.72717454
Iteration 245, loss = 0.83199635
Iteration 246, loss = 0.87918589
Iteration 247, loss = 0.83714280
Iteration 248, loss = 0.75993589
Iteration 249, loss = 0.88374905
Iteration 250, loss = 0.81067640
Iteration 251, loss = 0.78411776
Iteration 252, loss = 0.85855900
Iteration 253, loss = 0.77725111
Iteration 254, loss = 0.78611165
Iteration 255, loss = 0.81831162
Iteration 256, loss = 0.75025825
Iteration 257, loss = 0.77897500
Iteration 258, loss = 0.78144717
Iteration 259, loss = 0.73728598
Iteration 260, loss = 0.77089456
Iteration 261, loss = 0.71146128
Iteration 262, loss = 0.92047832
Iteration 263, loss = 0.75428830
Iteration 264, loss = 0.84518143
Iteration 265, loss = 0.87091010
Iteration 266, loss = 0.75777940
Iteration 267, loss = 0.86134087
Iteration 268, loss = 0.82066768
Iteration 269, loss = 0.77371154
Iteration 270, loss = 0.84505130
Iteration 271, loss = 0.77613841
Iteration 272, loss = 0.78212521
Iteration 273, loss = 0.81073939
Iteration 274, loss = 0.74998997
Iteration 275, loss = 0.78268111
Iteration 276, loss = 0.77389367
Iteration 277, loss = 0.74119125
Iteration 278, loss = 0.77269454
Iteration 279, loss = 0.74462469
Iteration 280, loss = 0.73934426
Iteration 281, loss = 0.76817837
Iteration 282, loss = 0.72952494
Iteration 283, loss = 0.75810420
Iteration 284, loss = 0.73788686
Iteration 285, loss = 0.73078272
Iteration 286, loss = 0.74234136
Iteration 287, loss = 0.71258904
Iteration 288, loss = 0.71567070
Iteration 289, loss = 0.80934831
Iteration 290, loss = 0.96263168
Iteration 291, loss = 1.23765119
Iteration 292, loss = 0.81006357
Iteration 293, loss = 1.27521312
Iteration 294, loss = 1.00706178
Iteration 295, loss = 0.91400889
Iteration 296, loss = 1.15296481
Iteration 297, loss = 0.83745090
Iteration 298, loss = 0.97582851
Iteration 299, loss = 1.02236726
Iteration 300, loss = 0.78352410
Iteration 301, loss = 0.98134230
Iteration 302, loss = 0.88385203
Iteration 303, loss = 0.80804906
Iteration 304, loss = 0.93409550
Iteration 305, loss = 0.78247493
Iteration 306, loss = 0.84085984
Iteration 307, loss = 0.85272053
Iteration 308, loss = 0.74917838
Iteration 309, loss = 0.83578251
Iteration 310, loss = 0.85125554
Iteration 311, loss = 0.83961111
Iteration 312, loss = 0.89683644
Iteration 313, loss = 0.76270768
Iteration 314, loss = 0.88664158
Iteration 315, loss = 0.80255397
Iteration 316, loss = 0.80440543
Iteration 317, loss = 0.84427803
Iteration 318, loss = 0.75386469
Iteration 319, loss = 0.82140469
Iteration 320, loss = 0.77292375
Iteration 321, loss = 0.76801097
Iteration 322, loss = 0.79484063
Iteration 323, loss = 0.80076099
Iteration 324, loss = 1.01165117
Iteration 325, loss = 0.91177318
Iteration 326, loss = 0.74191160
Iteration 327, loss = 1.17327830
Iteration 328, loss = 0.94388828
Iteration 329, loss = 0.94279779
Iteration 330, loss = 0.94754828
Iteration 331, loss = 0.77837155
Iteration 332, loss = 0.94120947
Iteration 333, loss = 0.75166160
Iteration 334, loss = 0.93936322
Iteration 335, loss = 0.80903464
Iteration 336, loss = 0.84329066
Iteration 337, loss = 0.87593126
Iteration 338, loss = 0.77551903
Iteration 339, loss = 0.78232335
Iteration 340, loss = 0.79281350
Iteration 341, loss = 0.71946284
Iteration 342, loss = 0.99519644
Iteration 343, loss = 0.80805058
Iteration 344, loss = 0.98904204
Iteration 345, loss = 0.78665947
Iteration 346, loss = 0.93535249
Iteration 347, loss = 0.82617978
Iteration 348, loss = 0.85347770
Iteration 349, loss = 0.85792149
Iteration 350, loss = 0.78315662
Iteration 351, loss = 0.85882572
Iteration 352, loss = 0.75676818
Iteration 353, loss = 0.83366127
Iteration 354, loss = 0.76449240
Iteration 355, loss = 0.79442470
Iteration 356, loss = 0.74020156
Iteration 357, loss = 0.67765162
Iteration 358, loss = 0.75546914
Iteration 359, loss = 1.22135659
Iteration 360, loss = 0.83194317
Iteration 361, loss = 1.08298704
Iteration 362, loss = 1.05541620
Iteration 363, loss = 0.81462416
Iteration 364, loss = 0.86197577
Iteration 365, loss = 1.01403940
Iteration 366, loss = 0.83676522
Iteration 367, loss = 1.02453935
Iteration 368, loss = 0.84144185
Iteration 369, loss = 0.98662864
Iteration 370, loss = 0.84890534
Iteration 371, loss = 0.87486165
Iteration 372, loss = 0.82477601
Iteration 373, loss = 0.81873459
Iteration 374, loss = 0.81446056
Iteration 375, loss = 0.80803478
Iteration 376, loss = 0.80474655
Iteration 377, loss = 0.80076633
Iteration 378, loss = 0.79790781
Iteration 379, loss = 0.79549415
Iteration 380, loss = 0.79349564
Iteration 381, loss = 0.79216822
Iteration 382, loss = 0.79086758
Iteration 383, loss = 0.79082300
Iteration 384, loss = 0.78988552
Iteration 385, loss = 0.78986347
Iteration 386, loss = 0.78879168
Iteration 387, loss = 0.78864910
Iteration 388, loss = 0.78746139
Iteration 389, loss = 0.78488510
Iteration 390, loss = 0.81833332
Iteration 391, loss = 0.87807035
Iteration 392, loss = 0.78790161
Iteration 393, loss = 0.86526275
Iteration 394, loss = 0.78719287
Iteration 395, loss = 0.84288369
Iteration 396, loss = 0.76027237
Iteration 397, loss = 1.16562695
Iteration 398, loss = 0.95949995
Iteration 399, loss = 1.05493972
Iteration 400, loss = 0.88154279
Iteration 401, loss = 1.00919020
Iteration 402, loss = 0.83715194
Iteration 403, loss = 0.97561579
Iteration 404, loss = 0.81420092
Iteration 405, loss = 0.94118192
Iteration 406, loss = 0.77518435
Iteration 407, loss = 0.86344128
Iteration 408, loss = 0.80094344
Iteration 409, loss = 0.85269010
Iteration 410, loss = 0.79596374
Iteration 411, loss = 0.83597188
Iteration 412, loss = 0.77503594
Iteration 413, loss = 0.87722932
Iteration 414, loss = 0.82869487
Iteration 415, loss = 0.85703468
Iteration 416, loss = 0.82620807
Iteration 417, loss = 0.83905411
Iteration 418, loss = 0.82151626
Iteration 419, loss = 0.82482563
Iteration 420, loss = 0.81560806
Iteration 421, loss = 0.81372015
Iteration 422, loss = 0.81188695
Iteration 423, loss = 0.80654712
Iteration 424, loss = 0.80894117
Iteration 425, loss = 0.80120255
Iteration 426, loss = 0.79511247
Iteration 427, loss = 0.79717323
Iteration 428, loss = 0.80123465
Iteration 429, loss = 0.79884610
Iteration 430, loss = 0.80170754
Iteration 431, loss = 0.79762487
Iteration 432, loss = 0.79800539
Iteration 433, loss = 0.79705790
Iteration 434, loss = 0.80672257
Iteration 435, loss = 0.79208513
Iteration 436, loss = 0.80422933
Iteration 437, loss = 0.79085170
Iteration 438, loss = 0.79945181
Iteration 439, loss = 0.78153762
Iteration 440, loss = 0.81583179
Iteration 441, loss = 0.79373538
Iteration 442, loss = 0.81140501
Iteration 443, loss = 0.79241359
Iteration 444, loss = 0.80638444
Iteration 445, loss = 0.79054248
Iteration 446, loss = 0.80198757
Iteration 447, loss = 0.78908518
Iteration 448, loss = 0.79855500
Iteration 449, loss = 0.78735267
Iteration 450, loss = 0.81663388
Iteration 451, loss = 0.81955589
Iteration 452, loss = 0.79995744
Iteration 453, loss = 0.81752724
Iteration 454, loss = 0.80112338
Iteration 455, loss = 0.81233559
Iteration 456, loss = 0.79870805
Iteration 457, loss = 0.80583792
Iteration 458, loss = 0.79540445
Iteration 459, loss = 0.80046482
Iteration 460, loss = 0.79313787
Iteration 461, loss = 0.79717154
Iteration 462, loss = 0.79208903
Iteration 463, loss = 0.79504996
Iteration 464, loss = 0.79112462
Iteration 465, loss = 0.79299026
Iteration 466, loss = 0.78972556
Iteration 467, loss = 0.79081422
Iteration 468, loss = 0.78811471
Iteration 469, loss = 0.78880463
Iteration 470, loss = 0.78654831
Iteration 471, loss = 0.78686438
Iteration 472, loss = 0.78521504
Iteration 473, loss = 0.78559772
Iteration 474, loss = 0.78402299
Iteration 475, loss = 0.78408882
Iteration 476, loss = 0.78275524
Iteration 477, loss = 0.78273544
Iteration 478, loss = 0.78125326
Iteration 479, loss = 0.78116319
Iteration 480, loss = 0.77989011
Iteration 481, loss = 0.77952838
Iteration 482, loss = 0.77757538
Iteration 483, loss = 0.77538247
Iteration 484, loss = 0.76381674
Iteration 485, loss = 0.78881123
Iteration 486, loss = 0.80311443
Iteration 487, loss = 0.79183051
Iteration 488, loss = 0.79820053
Iteration 489, loss = 0.78945950
Iteration 490, loss = 0.79155341
Iteration 491, loss = 0.78514715
Iteration 492, loss = 0.78523736
Iteration 493, loss = 0.78123780
Iteration 494, loss = 0.77857348
Iteration 495, loss = 0.78180189
Iteration 496, loss = 0.77590868
Iteration 497, loss = 0.77893008
Iteration 498, loss = 0.77799595
Iteration 499, loss = 0.77248297
Iteration 500, loss = 0.77396701
Iteration 501, loss = 0.77468593
Iteration 502, loss = 0.79105115
Iteration 503, loss = 0.74703030
Iteration 504, loss = 0.77834911
Iteration 505, loss = 0.84710949
Iteration 506, loss = 0.78311809
Iteration 507, loss = 0.83932450
Iteration 508, loss = 0.77949963
Iteration 509, loss = 0.82460410
Iteration 510, loss = 0.77194468
Iteration 511, loss = 0.80715318
Iteration 512, loss = 0.76556775
Iteration 513, loss = 0.79065895
Iteration 514, loss = 0.73169758
Iteration 515, loss = 0.95142184
Iteration 516, loss = 0.90390259
Iteration 517, loss = 1.37063082
Iteration 518, loss = 1.39472899
Iteration 519, loss = 1.22721643
Iteration 520, loss = 1.11475355
Iteration 521, loss = 1.00462948
Iteration 522, loss = 0.89639050
Iteration 523, loss = 1.01075083
Iteration 524, loss = 0.84970043
Iteration 525, loss = 0.98750898
Iteration 526, loss = 0.82779866
Iteration 527, loss = 0.95064224
Iteration 528, loss = 0.81909102
Iteration 529, loss = 0.91221640
Iteration 530, loss = 0.81522606
Iteration 531, loss = 0.87539201
Iteration 532, loss = 0.81486428
Iteration 533, loss = 0.84417315
Iteration 534, loss = 0.81483171
Iteration 535, loss = 0.82080798
Iteration 536, loss = 0.81469539
Iteration 537, loss = 0.80280665
Iteration 538, loss = 0.81182120
Iteration 539, loss = 0.78832644
Iteration 540, loss = 0.79759627
Iteration 541, loss = 0.81917614
Iteration 542, loss = 0.90989967
Iteration 543, loss = 0.86491869
Iteration 544, loss = 0.84331420
Iteration 545, loss = 0.88356562
Iteration 546, loss = 0.79248816
Iteration 547, loss = 0.87363075
Iteration 548, loss = 0.76494384
Iteration 549, loss = 0.70583736
Iteration 550, loss = 0.96242311
Iteration 551, loss = 0.79784175
Iteration 552, loss = 0.96255412
Iteration 553, loss = 0.79548811
Iteration 554, loss = 0.92212758
Iteration 555, loss = 0.82476441
Iteration 556, loss = 0.86332959
Iteration 557, loss = 0.84713641
Iteration 558, loss = 0.81158238
Iteration 559, loss = 0.85451218
Iteration 560, loss = 0.78315109
Iteration 561, loss = 0.84765994
Iteration 562, loss = 0.77671851
Iteration 563, loss = 0.83139929
Iteration 564, loss = 0.78240445
Iteration 565, loss = 0.81128824
Iteration 566, loss = 0.79008949
Iteration 567, loss = 0.79214239
Iteration 568, loss = 0.79402986
Iteration 569, loss = 0.77300874
Iteration 570, loss = 0.75767846
Iteration 571, loss = 0.91413871
Iteration 572, loss = 0.80764422
Iteration 573, loss = 0.90416853
Iteration 574, loss = 0.80708139
Iteration 575, loss = 0.88248869
Iteration 576, loss = 0.79456474
Iteration 577, loss = 0.85523587
Iteration 578, loss = 0.78103971
Iteration 579, loss = 0.83291307
Iteration 580, loss = 0.77437650
Iteration 581, loss = 0.82306459
Iteration 582, loss = 0.77492769
Iteration 583, loss = 0.81391987
Iteration 584, loss = 0.77783577
Iteration 585, loss = 0.80834885
Iteration 586, loss = 0.77781185
Iteration 587, loss = 0.80046223
Iteration 588, loss = 0.77546382
Iteration 589, loss = 0.78150026
Iteration 590, loss = 0.77154991
Iteration 591, loss = 0.77428242
Iteration 592, loss = 0.76480017
Iteration 593, loss = 0.75953355
Iteration 594, loss = 0.64630928
Iteration 595, loss = 1.03071837
Iteration 596, loss = 0.78535519
Iteration 597, loss = 1.00717438
Iteration 598, loss = 0.81175001
Iteration 599, loss = 0.97355014
Iteration 600, loss = 0.83531184
Iteration 601, loss = 0.93309294
Iteration 602, loss = 0.84729849
Iteration 603, loss = 0.88849662
Iteration 604, loss = 0.85011983
Iteration 605, loss = 0.84827702
Iteration 606, loss = 0.84615336
Iteration 607, loss = 0.81830221
Iteration 608, loss = 0.83968296
Iteration 609, loss = 0.79839299
Iteration 610, loss = 0.83233288
Iteration 611, loss = 0.78661071
Iteration 612, loss = 0.82246847
Iteration 613, loss = 0.78830635
Iteration 614, loss = 0.77910379
Iteration 615, loss = 0.78821559
Iteration 616, loss = 0.77851099
Iteration 617, loss = 0.83887916
Iteration 618, loss = 0.79476345
Iteration 619, loss = 0.83134130
Iteration 620, loss = 0.79411899
Iteration 621, loss = 0.81936501
Iteration 622, loss = 0.79024043
Iteration 623, loss = 0.80792112
Iteration 624, loss = 0.78763204
Iteration 625, loss = 0.80053477
Iteration 626, loss = 0.78719728
Iteration 627, loss = 0.79615439
Iteration 628, loss = 0.78710007
Iteration 629, loss = 0.79267132
Iteration 630, loss = 0.78666941
Iteration 631, loss = 0.78954366
Iteration 632, loss = 0.78578367
Iteration 633, loss = 0.78692871
Iteration 634, loss = 0.78470419
Iteration 635, loss = 0.78414949
Iteration 636, loss = 0.78277232
Iteration 637, loss = 0.78011850
Iteration 638, loss = 0.77961402
Iteration 639, loss = 0.77741490
Iteration 640, loss = 0.77302016
Iteration 641, loss = 0.74726780
Iteration 642, loss = 0.85092543
Iteration 643, loss = 0.87531552
Iteration 644, loss = 0.80115266
Iteration 645, loss = 0.77524659
Iteration 646, loss = 1.00089579
Iteration 647, loss = 0.85168942
Iteration 648, loss = 0.92866276
Iteration 649, loss = 0.88980613
Iteration 650, loss = 0.84746041
Iteration 651, loss = 0.89930699
Iteration 652, loss = 0.79874954
Iteration 653, loss = 0.88680155
Iteration 654, loss = 0.77558479
Iteration 655, loss = 0.86603331
Iteration 656, loss = 0.77168569
Iteration 657, loss = 0.84641324
Iteration 658, loss = 0.77687481
Iteration 659, loss = 0.82315990
Iteration 660, loss = 0.77844894
Iteration 661, loss = 0.80937591
Iteration 662, loss = 0.75985071
Iteration 663, loss = 0.78959889
Iteration 664, loss = 0.74780685
Iteration 665, loss = 2.10049085
Iteration 666, loss = 0.79896336
Iteration 667, loss = 2.24278558
Iteration 668, loss = 1.65045364
Iteration 669, loss = 0.94537673
Iteration 670, loss = 1.57583348
Iteration 671, loss = 0.77796192
Iteration 672, loss = 2.39631138
Iteration 673, loss = 1.86039198
Iteration 674, loss = 1.01870855
Iteration 675, loss = 1.91865690
Iteration 676, loss = 1.56697250
Iteration 677, loss = 1.02196662
Iteration 678, loss = 1.59730478
Iteration 679, loss = 1.15664416
Iteration 680, loss = 1.11999029
Iteration 681, loss = 1.28067731
Iteration 682, loss = 0.87501705
Iteration 683, loss = 1.12071699
Iteration 684, loss = 1.06155430
Iteration 685, loss = 0.84736600
Iteration 686, loss = 1.07203771
Iteration 687, loss = 0.85163280
Iteration 688, loss = 0.93720045
Iteration 689, loss = 0.95672063
Iteration 690, loss = 0.81107172
Iteration 691, loss = 0.96062749
Iteration 692, loss = 0.83163526
Iteration 693, loss = 0.88273257
Iteration 694, loss = 0.89145841
Iteration 695, loss = 0.80951078
Iteration 696, loss = 0.89505946
Iteration 697, loss = 0.80707900
Iteration 698, loss = 0.84771220
Iteration 699, loss = 0.83538346
Iteration 700, loss = 0.79370547
Iteration 701, loss = 0.73929767
Iteration 702, loss = 0.92689146
Iteration 703, loss = 0.97665863
Iteration 704, loss = 1.14994078
Iteration 705, loss = 0.82073240
Iteration 706, loss = 1.02961891
Iteration 707, loss = 1.01005221
Iteration 708, loss = 0.81572681
Iteration 709, loss = 1.01321107
Iteration 710, loss = 0.86509225
Iteration 711, loss = 0.85943150
Iteration 712, loss = 0.94352295
Iteration 713, loss = 0.78969913
Iteration 714, loss = 0.89104134
Iteration 715, loss = 0.85033109
Iteration 716, loss = 0.79203997
Iteration 717, loss = 0.86720221
Iteration 718, loss = 0.77861054
Iteration 719, loss = 0.78399374
Iteration 720, loss = 1.24602328
Iteration 721, loss = 0.83282573
Iteration 722, loss = 1.25961289
Iteration 723, loss = 0.97776447
Iteration 724, loss = 0.91499259
Iteration 725, loss = 0.73188303
Iteration 726, loss = 0.77933076
Iteration 727, loss = 0.65033530
Iteration 728, loss = 0.90902038
Iteration 729, loss = 0.96338432
Iteration 730, loss = 1.13259707
Iteration 731, loss = 0.82317605
Iteration 732, loss = 1.03718774
Iteration 733, loss = 0.97466358
Iteration 734, loss = 0.83243463
Iteration 735, loss = 1.00213545
Iteration 736, loss = 0.82088894
Iteration 737, loss = 0.90339233
Iteration 738, loss = 0.90202092
Iteration 739, loss = 0.79612036
Iteration 740, loss = 0.90418820
Iteration 741, loss = 0.79056060
Iteration 742, loss = 0.71329351
Iteration 743, loss = 1.50180944
Iteration 744, loss = 0.80137118
Iteration 745, loss = 1.36828243
Iteration 746, loss = 1.43510096
Iteration 747, loss = 0.83991456
Iteration 748, loss = 1.22158430
Iteration 749, loss = 1.31649376
Iteration 750, loss = 0.80003276
Iteration 751, loss = 0.84802751
Iteration 752, loss = 1.20254689
Iteration 753, loss = 1.03343482
Iteration 754, loss = 0.86153076
Iteration 755, loss = 1.10562238
Iteration 756, loss = 0.92078314
Iteration 757, loss = 0.87336480
Iteration 758, loss = 1.02334250
Iteration 759, loss = 0.83828887
Iteration 760, loss = 0.88959434
Iteration 761, loss = 0.94767636
Iteration 762, loss = 0.80090788
Iteration 763, loss = 0.89754750
Iteration 764, loss = 0.87826389
Iteration 765, loss = 0.79394428
Iteration 766, loss = 0.82341626
Iteration 767, loss = 0.80487231
Iteration 768, loss = 0.82642005
Iteration 769, loss = 0.82160517
Iteration 770, loss = 0.83482539
Iteration 771, loss = 0.82927266
Iteration 772, loss = 0.83354122
Iteration 773, loss = 0.82764551
Iteration 774, loss = 0.82530075
Iteration 775, loss = 0.81925062
Iteration 776, loss = 0.81491460
Iteration 777, loss = 0.81181171
Iteration 778, loss = 0.80879513
Iteration 779, loss = 0.80902456
Iteration 780, loss = 0.80687958
Iteration 781, loss = 0.80814638
Iteration 782, loss = 0.80559957
Iteration 783, loss = 0.80634172
Iteration 784, loss = 0.80259179
Iteration 785, loss = 0.80092625
Iteration 786, loss = 0.79435973
Iteration 787, loss = 0.78960732
Iteration 788, loss = 0.77749462
Iteration 789, loss = 0.57332413
Iteration 790, loss = 0.87543533
Iteration 791, loss = 1.53935480
Iteration 792, loss = 1.10799479
Iteration 793, loss = 1.21774683
Iteration 794, loss = 1.32248369
Iteration 795, loss = 0.85965404
Iteration 796, loss = 1.26749310
Iteration 797, loss = 0.90507546
Iteration 798, loss = 1.11555317
Iteration 799, loss = 1.06892091
Iteration 800, loss = 0.88905878
Iteration 801, loss = 1.08869834
Iteration 802, loss = 0.82234380
Iteration 803, loss = 1.02437726
Iteration 804, loss = 0.88871708
Iteration 805, loss = 0.91343581
Iteration 806, loss = 0.94606259
Iteration 807, loss = 0.82486954
Iteration 808, loss = 0.94467299
Iteration 809, loss = 0.81052662
Iteration 810, loss = 0.90655669
Iteration 811, loss = 0.84124885
Iteration 812, loss = 0.85350338
Iteration 813, loss = 0.86624807
Iteration 814, loss = 0.81309531
Iteration 815, loss = 0.86898502
Iteration 816, loss = 0.80330139
Iteration 817, loss = 0.85488116
Iteration 818, loss = 0.82660001
Iteration 819, loss = 0.87618855
Iteration 820, loss = 0.84795800
Iteration 821, loss = 0.83827729
Iteration 822, loss = 0.86804507
Iteration 823, loss = 0.81165626
Iteration 824, loss = 0.86073530
Iteration 825, loss = 0.80669107
Iteration 826, loss = 0.83861049
Iteration 827, loss = 0.81055804
Iteration 828, loss = 0.80703410
Iteration 829, loss = 0.75494067
Iteration 830, loss = 0.92527817
Iteration 831, loss = 1.06475224
Iteration 832, loss = 1.00226983
Iteration 833, loss = 0.92070025
Iteration 834, loss = 0.97343379
Iteration 835, loss = 1.28247424
Iteration 836, loss = 0.82772066
Iteration 837, loss = 1.25167149
Iteration 838, loss = 0.89596137
Iteration 839, loss = 1.18884716
Iteration 840, loss = 1.00729538
Iteration 841, loss = 1.03993047
Iteration 842, loss = 1.05520058
Iteration 843, loss = 0.88990772
Iteration 844, loss = 1.03819401
Iteration 845, loss = 0.81897592
Iteration 846, loss = 1.00031823
Iteration 847, loss = 0.81501017
Iteration 848, loss = 0.96016673
Iteration 849, loss = 0.83882589
Iteration 850, loss = 0.91401165
Iteration 851, loss = 0.86309281
Iteration 852, loss = 0.86857403
Iteration 853, loss = 0.87524243
Iteration 854, loss = 0.83289680
Iteration 855, loss = 0.87493294
Iteration 856, loss = 0.81133725
Iteration 857, loss = 0.85967008
Iteration 858, loss = 0.80879042
Iteration 859, loss = 0.84356790
Iteration 860, loss = 0.80897666
Iteration 861, loss = 0.83972601
Iteration 862, loss = 0.80767566
Iteration 863, loss = 0.83149528
Iteration 864, loss = 0.80349421
Iteration 865, loss = 0.81379166
Iteration 866, loss = 0.80606303
Iteration 867, loss = 0.82928418
Iteration 868, loss = 0.80931538
Iteration 869, loss = 0.82377698
Iteration 870, loss = 0.81090319
Iteration 871, loss = 0.81732515
Iteration 872, loss = 0.81042688
Iteration 873, loss = 0.81164053
Iteration 874, loss = 0.81000156
Iteration 875, loss = 0.80804695
Iteration 876, loss = 0.80986863
Iteration 877, loss = 0.80575341
Iteration 878, loss = 0.80922237
Iteration 879, loss = 0.80383444
Iteration 880, loss = 0.80793310
Iteration 881, loss = 0.80224823
Iteration 882, loss = 0.80642659
Iteration 883, loss = 0.80106299
Iteration 884, loss = 0.80490955
Iteration 885, loss = 0.80018048
Iteration 886, loss = 0.80343047
Iteration 887, loss = 0.79941886
Iteration 888, loss = 0.80193443
Iteration 889, loss = 0.79805963
Iteration 890, loss = 0.80153622
Iteration 891, loss = 0.79908170
Iteration 892, loss = 0.80046807
Iteration 893, loss = 0.79783494
Iteration 894, loss = 0.79850427
Iteration 895, loss = 0.79677311
Iteration 896, loss = 0.79733649
Iteration 897, loss = 0.79619988
Iteration 898, loss = 0.79623415
Iteration 899, loss = 0.79527022
Iteration 900, loss = 0.79501790
Iteration 901, loss = 0.79441113
Iteration 902, loss = 0.79404418
Iteration 903, loss = 0.79358796
Iteration 904, loss = 0.79304360
Iteration 905, loss = 0.79268007
Iteration 906, loss = 0.79207438
Iteration 907, loss = 0.79178255
Iteration 908, loss = 0.79114245
Iteration 909, loss = 0.79088951
Iteration 910, loss = 0.79025469
Iteration 911, loss = 0.79003191
Iteration 912, loss = 0.78942419
Iteration 913, loss = 0.78919927
Iteration 914, loss = 0.78858388
Iteration 915, loss = 0.78831274
Iteration 916, loss = 0.78725949
Iteration 917, loss = 0.79105937
Iteration 918, loss = 0.79155240
Iteration 919, loss = 0.79214029
Iteration 920, loss = 0.79292841
Iteration 921, loss = 0.79101353
Iteration 922, loss = 0.79152195
Iteration 923, loss = 0.78815266
Iteration 924, loss = 0.78928070
Iteration 925, loss = 0.78620771
Iteration 926, loss = 0.78822204
Iteration 927, loss = 0.78548870
Iteration 928, loss = 0.78759264
Iteration 929, loss = 0.78487019
Iteration 930, loss = 0.78656781
Iteration 931, loss = 0.78397865
Iteration 932, loss = 0.78531717
Iteration 933, loss = 0.78312433
Iteration 934, loss = 0.78414646
Iteration 935, loss = 0.78235769
Iteration 936, loss = 0.78295201
Iteration 937, loss = 0.78141726
Iteration 938, loss = 0.78143317
Iteration 939, loss = 0.77984652
Iteration 940, loss = 0.77882856
Iteration 941, loss = 0.77604622
Iteration 942, loss = 0.77104717
Iteration 943, loss = 0.74093716
Iteration 944, loss = 0.84203119
Iteration 945, loss = 0.92029201
Iteration 946, loss = 0.79447901
Iteration 947, loss = 0.89058415
Iteration 948, loss = 0.79485505
Iteration 949, loss = 0.84205002
Iteration 950, loss = 0.82520204
Iteration 951, loss = 0.79515459
Iteration 952, loss = 0.83658565
Iteration 953, loss = 0.77962876
Iteration 954, loss = 0.81687535
Iteration 955, loss = 0.76701347
Iteration 956, loss = 0.78468015
Iteration 957, loss = 0.79000422
Iteration 958, loss = 0.78656326
Iteration 959, loss = 0.79231086
Iteration 960, loss = 0.79763265
Iteration 961, loss = 0.80011505
Iteration 962, loss = 0.80237201
Iteration 963, loss = 0.80220606
Iteration 964, loss = 0.80018679
Iteration 965, loss = 0.79883735
Iteration 966, loss = 0.79594491
Iteration 967, loss = 0.79455703
Iteration 968, loss = 0.79366234
Iteration 969, loss = 0.79367666
Iteration 970, loss = 0.79477037
Iteration 971, loss = 0.79482428
Iteration 972, loss = 0.79517328
Iteration 973, loss = 0.79523731
Iteration 974, loss = 0.79497286
Iteration 975, loss = 0.79496175
Iteration 976, loss = 0.79438356
Iteration 977, loss = 0.79409610
Iteration 978, loss = 0.79368628
Iteration 979, loss = 0.79306263
Iteration 980, loss = 0.79262743
Iteration 981, loss = 0.79165319
Iteration 982, loss = 0.79094439
Iteration 983, loss = 0.79034852
Iteration 984, loss = 0.78835255
Iteration 985, loss = 0.78097270
Iteration 986, loss = 0.80891456
Iteration 987, loss = 0.84101036
Iteration 988, loss = 0.79963922
Iteration 989, loss = 0.83950817
Iteration 990, loss = 0.80434167
Iteration 991, loss = 0.81439847
Iteration 992, loss = 0.81178638
Iteration 993, loss = 0.79268040
Iteration 994, loss = 0.81267248
Iteration 995, loss = 0.78960607
Iteration 996, loss = 0.80522282
Iteration 997, loss = 0.79672878
Iteration 998, loss = 0.79333105
Iteration 999, loss = 0.80020260
Iteration 1000, loss = 0.78595145
Iteration 1001, loss = 0.79616622
Iteration 1002, loss = 0.78719237
Iteration 1003, loss = 0.78980524
Iteration 1004, loss = 0.79074151
Iteration 1005, loss = 0.78437581
Iteration 1006, loss = 0.78987225
Iteration 1007, loss = 0.78286264
Iteration 1008, loss = 0.78268869
Iteration 1009, loss = 0.78183579
Iteration 1010, loss = 0.78044390
Iteration 1011, loss = 0.78007556
Iteration 1012, loss = 0.78109363
Iteration 1013, loss = 0.77881873
Iteration 1014, loss = 0.77925383
Iteration 1015, loss = 0.77655155
Iteration 1016, loss = 0.77116838
Iteration 1017, loss = 0.68678177
Iteration 1018, loss = 0.90228889
Iteration 1019, loss = 0.82467541
Iteration 1020, loss = 0.87131992
Iteration 1021, loss = 0.88015107
Iteration 1022, loss = 0.84715353
Iteration 1023, loss = 0.90264017
Iteration 1024, loss = 0.83068425
Iteration 1025, loss = 0.88357910
Iteration 1026, loss = 0.82250649
Iteration 1027, loss = 0.84345155
Iteration 1028, loss = 0.82244057
Iteration 1029, loss = 0.80821696
Iteration 1030, loss = 0.82201088
Iteration 1031, loss = 0.78905220
Iteration 1032, loss = 0.81491049
Iteration 1033, loss = 0.78669627
Iteration 1034, loss = 0.80280385
Iteration 1035, loss = 0.79313599
Iteration 1036, loss = 0.79159018
Iteration 1037, loss = 0.79876971
Iteration 1038, loss = 0.78525318
Iteration 1039, loss = 0.79813409
Iteration 1040, loss = 0.78442511
Iteration 1041, loss = 0.78129190
Iteration 1042, loss = 0.78866778
Iteration 1043, loss = 0.80447762
Iteration 1044, loss = 0.80027347
Iteration 1045, loss = 0.81731788
Iteration 1046, loss = 0.81370138
Iteration 1047, loss = 0.81809921
Iteration 1048, loss = 0.81745092
Iteration 1049, loss = 0.80767972
Iteration 1050, loss = 0.80631800
Iteration 1051, loss = 0.75490989
Iteration 1052, loss = 0.86295754
Iteration 1053, loss = 0.93519648
Iteration 1054, loss = 0.81805675
Iteration 1055, loss = 0.93536840
Iteration 1056, loss = 0.79292564
Iteration 1057, loss = 0.91249051
Iteration 1058, loss = 0.86237393
Iteration 1059, loss = 0.84419330
Iteration 1060, loss = 0.89985362
Iteration 1061, loss = 0.81849214
Iteration 1062, loss = 0.90707810
Iteration 1063, loss = 0.80368230
Iteration 1064, loss = 0.88663515
Iteration 1065, loss = 0.79703508
Iteration 1066, loss = 0.85481403
Iteration 1067, loss = 0.80298763
Iteration 1068, loss = 0.82392529
Iteration 1069, loss = 0.80675985
Iteration 1070, loss = 0.79300371
Iteration 1071, loss = 0.62362347
Iteration 1072, loss = 1.18323968
Iteration 1073, loss = 1.52143715
Iteration 1074, loss = 1.26817643
Iteration 1075, loss = 1.37270394
Iteration 1076, loss = 1.32476537
Iteration 1077, loss = 1.11770831
Iteration 1078, loss = 1.21455461
Iteration 1079, loss = 0.97698535
Iteration 1080, loss = 1.08722314
Iteration 1081, loss = 0.92275502
Iteration 1082, loss = 0.99109931
Iteration 1083, loss = 0.91073107
Iteration 1084, loss = 0.92623809
Iteration 1085, loss = 0.91310365
Iteration 1086, loss = 0.88160665
Iteration 1087, loss = 0.91836004
Iteration 1088, loss = 0.85290029
Iteration 1089, loss = 0.92045907
Iteration 1090, loss = 0.83245995
Iteration 1091, loss = 0.91730500
Iteration 1092, loss = 0.81922102
Iteration 1093, loss = 0.91030705
Iteration 1094, loss = 0.80943825
Iteration 1095, loss = 0.89886122
Iteration 1096, loss = 0.80404308
Iteration 1097, loss = 0.88531547
Iteration 1098, loss = 0.80045349
Iteration 1099, loss = 0.86971403
Iteration 1100, loss = 0.79983411
Iteration 1101, loss = 0.85454208
Iteration 1102, loss = 0.80070046
Iteration 1103, loss = 0.83898782
Iteration 1104, loss = 0.80307931
Iteration 1105, loss = 0.82568507
Iteration 1106, loss = 0.80561866
Iteration 1107, loss = 0.81420404
Iteration 1108, loss = 0.80757037
Iteration 1109, loss = 0.80527384
Iteration 1110, loss = 0.80858515
Iteration 1111, loss = 0.79917246
Iteration 1112, loss = 0.80833805
Iteration 1113, loss = 0.79513979
Iteration 1114, loss = 0.80643411
Iteration 1115, loss = 0.79288922
Iteration 1116, loss = 0.80363017
Iteration 1117, loss = 0.79195331
Iteration 1118, loss = 0.80019331
Iteration 1119, loss = 0.79131537
Iteration 1120, loss = 0.79642471
Iteration 1121, loss = 0.79151497
Iteration 1122, loss = 0.79336716
Iteration 1123, loss = 0.79165280
Iteration 1124, loss = 0.79076597
Iteration 1125, loss = 0.79134000
Iteration 1126, loss = 0.78866277
Iteration 1127, loss = 0.79061592
Iteration 1128, loss = 0.78716493
Iteration 1129, loss = 0.78940506
Iteration 1130, loss = 0.78601022
Iteration 1131, loss = 0.78398752
Iteration 1132, loss = 0.78550852
Iteration 1133, loss = 0.78367901
Iteration 1134, loss = 0.78349594
Iteration 1135, loss = 0.77993446
Iteration 1136, loss = 0.78399595
Iteration 1137, loss = 0.84116786
Iteration 1138, loss = 0.79906649
Iteration 1139, loss = 0.83588146
Iteration 1140, loss = 0.81648911
Iteration 1141, loss = 0.81565098
Iteration 1142, loss = 0.81743444
Iteration 1143, loss = 0.79096885
Iteration 1144, loss = 0.80187981
Iteration 1145, loss = 0.73573725
Iteration 1146, loss = 0.79987277
Iteration 1147, loss = 0.86459442
Iteration 1148, loss = 0.81094500
Iteration 1149, loss = 0.82674435
Iteration 1150, loss = 0.82270384
Iteration 1151, loss = 0.81120143
Iteration 1152, loss = 0.82276468
Iteration 1153, loss = 0.79937560
Iteration 1154, loss = 0.81414517
Iteration 1155, loss = 0.79733560
Iteration 1156, loss = 0.80413236
Iteration 1157, loss = 0.80162976
Iteration 1158, loss = 0.79739927
Iteration 1159, loss = 0.80464414
Iteration 1160, loss = 0.79503690
Iteration 1161, loss = 0.80327009
Iteration 1162, loss = 0.79600637
Iteration 1163, loss = 0.79849832
Iteration 1164, loss = 0.79732595
Iteration 1165, loss = 0.79389118
Iteration 1166, loss = 0.79722610
Iteration 1167, loss = 0.79153375
Iteration 1168, loss = 0.79422889
Iteration 1169, loss = 0.79107441
Iteration 1170, loss = 0.84426040
Iteration 1171, loss = 0.80825433
Iteration 1172, loss = 0.83712434
Iteration 1173, loss = 0.82347942
Iteration 1174, loss = 0.81638345
Iteration 1175, loss = 0.82568072
Iteration 1176, loss = 0.79949341
Iteration 1177, loss = 0.81854771
Iteration 1178, loss = 0.79687855
Iteration 1179, loss = 0.80893875
Iteration 1180, loss = 0.80342761
Iteration 1181, loss = 0.80080847
Iteration 1182, loss = 0.80816466
Iteration 1183, loss = 0.79640371
Iteration 1184, loss = 0.80627112
Iteration 1185, loss = 0.79634381
Iteration 1186, loss = 0.80040917
Iteration 1187, loss = 0.79854936
Iteration 1188, loss = 0.79532002
Iteration 1189, loss = 0.79959933
Iteration 1190, loss = 0.79334509
Iteration 1191, loss = 0.79786512
Iteration 1192, loss = 0.79377326
Iteration 1193, loss = 0.79445582
Iteration 1194, loss = 0.79445337
Iteration 1195, loss = 0.79160441
Iteration 1196, loss = 0.79387539
Iteration 1197, loss = 0.79053708
Iteration 1198, loss = 0.79212700
Iteration 1199, loss = 0.79075153
Iteration 1200, loss = 0.79022073
Iteration 1201, loss = 0.79085347
Iteration 1202, loss = 0.78893659
Iteration 1203, loss = 0.78995359
Iteration 1204, loss = 0.78827252
Iteration 1205, loss = 0.78817723
Iteration 1206, loss = 0.78760976
Iteration 1207, loss = 0.78662472
Iteration 1208, loss = 0.78662740
Iteration 1209, loss = 0.78452965
Iteration 1210, loss = 0.78249416
Iteration 1211, loss = 0.76365723
Iteration 1212, loss = 0.78899703
Iteration 1213, loss = 0.80513594
Iteration 1214, loss = 0.79171679
Iteration 1215, loss = 0.80006020
Iteration 1216, loss = 0.79383556
Iteration 1217, loss = 0.79047506
Iteration 1218, loss = 0.79455873
Iteration 1219, loss = 0.78625328
Iteration 1220, loss = 0.79287604
Iteration 1221, loss = 0.78751816
Iteration 1222, loss = 0.78939881
Iteration 1223, loss = 0.79075287
Iteration 1224, loss = 0.78691573
Iteration 1225, loss = 0.79050431
Iteration 1226, loss = 0.78629905
Iteration 1227, loss = 0.78781309
Iteration 1228, loss = 0.78642238
Iteration 1229, loss = 0.78532344
Iteration 1230, loss = 0.78797736
Iteration 1231, loss = 0.78511673
Iteration 1232, loss = 0.78552451
Iteration 1233, loss = 0.78266249
Iteration 1234, loss = 0.78125599
Iteration 1235, loss = 0.78077933
Iteration 1236, loss = 0.77937059
Iteration 1237, loss = 0.78102472
Iteration 1238, loss = 0.77901362
Iteration 1239, loss = 0.77807207
Iteration 1240, loss = 0.77600337
Iteration 1241, loss = 0.76777081
Iteration 1242, loss = 0.75628308
Iteration 1243, loss = 0.68983037
Iteration 1244, loss = 1.09008677
Iteration 1245, loss = 1.42116091
Iteration 1246, loss = 1.02971917
Iteration 1247, loss = 1.54473217
Iteration 1248, loss = 1.10360188
Iteration 1249, loss = 1.46263072
Iteration 1250, loss = 1.26599886
Iteration 1251, loss = 1.25385842
Iteration 1252, loss = 1.26486429
Iteration 1253, loss = 1.04090271
Iteration 1254, loss = 1.13813720
Iteration 1255, loss = 0.95596673
Iteration 1256, loss = 1.02673735
Iteration 1257, loss = 0.93803168
Iteration 1258, loss = 0.94611490
Iteration 1259, loss = 0.94373185
Iteration 1260, loss = 0.89013326
Iteration 1261, loss = 0.95030663
Iteration 1262, loss = 0.85014557
Iteration 1263, loss = 0.94161527
Iteration 1264, loss = 0.88673357
Iteration 1265, loss = 1.04583954
Iteration 1266, loss = 0.90608552
Iteration 1267, loss = 1.01411100
Iteration 1268, loss = 0.91248051
Iteration 1269, loss = 0.97560168
Iteration 1270, loss = 0.90324534
Iteration 1271, loss = 0.94167751
Iteration 1272, loss = 0.89029447
Iteration 1273, loss = 0.90677897
Iteration 1274, loss = 0.81288247
Iteration 1275, loss = 0.86669932
Iteration 1276, loss = 0.80307656
Iteration 1277, loss = 0.86418910
Iteration 1278, loss = 0.80741128
Iteration 1279, loss = 0.83775732
Iteration 1280, loss = 0.81656501
Iteration 1281, loss = 0.80959750
Iteration 1282, loss = 0.82434938
Iteration 1283, loss = 0.79586763
Iteration 1284, loss = 0.82363355
Iteration 1285, loss = 0.79561928
Iteration 1286, loss = 0.81318090
Iteration 1287, loss = 0.80047696
Iteration 1288, loss = 0.79916573
Iteration 1289, loss = 0.79953952
Iteration 1290, loss = 0.81000102
Iteration 1291, loss = 0.90136977
Iteration 1292, loss = 0.81997739
Iteration 1293, loss = 0.84214137
Iteration 1294, loss = 0.84067666
Iteration 1295, loss = 0.82139202
Iteration 1296, loss = 0.84567473
Iteration 1297, loss = 0.80418755
Iteration 1298, loss = 0.83852086
Iteration 1299, loss = 0.79549169
Iteration 1300, loss = 0.82579783
Iteration 1301, loss = 0.79567594
Iteration 1302, loss = 0.81271290
Iteration 1303, loss = 0.80024906
Iteration 1304, loss = 0.80154329
Iteration 1305, loss = 0.80399987
Iteration 1306, loss = 0.79346569
Iteration 1307, loss = 0.82149992
Iteration 1308, loss = 0.79436482
Iteration 1309, loss = 0.80808824
Iteration 1310, loss = 0.80317891
Iteration 1311, loss = 0.79452420
Iteration 1312, loss = 0.80604723
Iteration 1313, loss = 0.78550754
Iteration 1314, loss = 0.78140836
Iteration 1315, loss = 0.79163234
Iteration 1316, loss = 0.84048532
Iteration 1317, loss = 0.79593653
Iteration 1318, loss = 0.82811844
Iteration 1319, loss = 0.80084299
Iteration 1320, loss = 0.81024977
Iteration 1321, loss = 0.80493886
Iteration 1322, loss = 0.79572727
Iteration 1323, loss = 0.80678125
Iteration 1324, loss = 0.78851051
Iteration 1325, loss = 0.80545305
Iteration 1326, loss = 0.78586485
Iteration 1327, loss = 0.77798550
Iteration 1328, loss = 0.81619620
Iteration 1329, loss = 0.81852102
Iteration 1330, loss = 0.80580040
Iteration 1331, loss = 0.82585197
Iteration 1332, loss = 0.79485099
Iteration 1333, loss = 0.81870973
Iteration 1334, loss = 0.78916571
Iteration 1335, loss = 0.80871941
Iteration 1336, loss = 0.79117447
Iteration 1337, loss = 0.79956737
Iteration 1338, loss = 0.79571335
Iteration 1339, loss = 0.79212435
Iteration 1340, loss = 0.79804337
Iteration 1341, loss = 0.78720697
Iteration 1342, loss = 0.79645249
Iteration 1343, loss = 0.78476422
Iteration 1344, loss = 0.79204886
Iteration 1345, loss = 0.78471169
Iteration 1346, loss = 0.78742602
Iteration 1347, loss = 0.78574614
Iteration 1348, loss = 0.78362854
Iteration 1349, loss = 0.78583686
Iteration 1350, loss = 0.78100270
Iteration 1351, loss = 0.78448622
Iteration 1352, loss = 0.77980154
Iteration 1353, loss = 0.78223611
Iteration 1354, loss = 0.77947625
Iteration 1355, loss = 0.77971994
Iteration 1356, loss = 0.77921259
Iteration 1357, loss = 0.77760309
Iteration 1358, loss = 0.77854246
Iteration 1359, loss = 0.77616701
Iteration 1360, loss = 0.77729327
Iteration 1361, loss = 0.77529068
Iteration 1362, loss = 0.77571492
Iteration 1363, loss = 0.77468883
Iteration 1364, loss = 0.77415433
Iteration 1365, loss = 0.77401004
Iteration 1366, loss = 0.77283589
Iteration 1367, loss = 0.77308141
Iteration 1368, loss = 0.77183003
Iteration 1369, loss = 0.77194587
Iteration 1370, loss = 0.77104014
Iteration 1371, loss = 0.77074366
Iteration 1372, loss = 0.77028095
Iteration 1373, loss = 0.76960221
Iteration 1374, loss = 0.76941467
Iteration 1375, loss = 0.76857524
Iteration 1376, loss = 0.76836190
Iteration 1377, loss = 0.76750046
Iteration 1378, loss = 0.76702596
Iteration 1379, loss = 0.76628761
Iteration 1380, loss = 0.76479762
Iteration 1381, loss = 0.76415617
Iteration 1382, loss = 0.76381148
Iteration 1383, loss = 0.76601553
Iteration 1384, loss = 0.76837648
Iteration 1385, loss = 0.76771613
Iteration 1386, loss = 0.76568944
Iteration 1387, loss = 0.76322241
Iteration 1388, loss = 0.76026749
Iteration 1389, loss = 0.74988322
Iteration 1390, loss = 0.63248136
Iteration 1391, loss = 1.00075523
Iteration 1392, loss = 1.16759069
Iteration 1393, loss = 1.06085674
Iteration 1394, loss = 1.05676597
Iteration 1395, loss = 1.05853213
Iteration 1396, loss = 0.94836210
Iteration 1397, loss = 1.00226177
Iteration 1398, loss = 0.88861333
Iteration 1399, loss = 0.94533870
Iteration 1400, loss = 0.85502585
Iteration 1401, loss = 0.89684409
Iteration 1402, loss = 0.84140340
Iteration 1403, loss = 0.85805510
Iteration 1404, loss = 1.02945704
Iteration 1405, loss = 0.77490403
Iteration 1406, loss = 1.00123225
Iteration 1407, loss = 0.78478655
Iteration 1408, loss = 0.98186733
Iteration 1409, loss = 0.78891411
Iteration 1410, loss = 0.96078703
Iteration 1411, loss = 0.78866019
Iteration 1412, loss = 0.93995557
Iteration 1413, loss = 0.78298172
Iteration 1414, loss = 0.91803262
Iteration 1415, loss = 0.77803366
Iteration 1416, loss = 0.90018907
Iteration 1417, loss = 0.77332529
Iteration 1418, loss = 0.87672748
Iteration 1419, loss = 0.77487819
Iteration 1420, loss = 0.80163686
Iteration 1421, loss = 0.79035521
Iteration 1422, loss = 0.79610046
Iteration 1423, loss = 0.79422924
Iteration 1424, loss = 0.78181892
Iteration 1425, loss = 0.78805983
Iteration 1426, loss = 0.76972141
Iteration 1427, loss = 0.78238395
Iteration 1428, loss = 0.76484587
Iteration 1429, loss = 0.77930823
Iteration 1430, loss = 0.76533481
Iteration 1431, loss = 0.77621168
Iteration 1432, loss = 0.76592801
Iteration 1433, loss = 0.77082933
Iteration 1434, loss = 0.76464574
Iteration 1435, loss = 0.76419725
Iteration 1436, loss = 0.76191165
Iteration 1437, loss = 0.75695688
Iteration 1438, loss = 0.73091928
Iteration 1439, loss = 0.75842794
Iteration 1440, loss = 0.75872533
Iteration 1441, loss = 0.75724502
Iteration 1442, loss = 0.75519222
Iteration 1443, loss = 0.75175729
Iteration 1444, loss = 0.74189970
Iteration 1445, loss = 0.87012427
Iteration 1446, loss = 1.26940278
Iteration 1447, loss = 0.86894567
Iteration 1448, loss = 1.26376073
Iteration 1449, loss = 1.04180365
Iteration 1450, loss = 1.14953287
Iteration 1451, loss = 1.12297597
Iteration 1452, loss = 0.97857574
Iteration 1453, loss = 1.07827428
Iteration 1454, loss = 0.87120152
Iteration 1455, loss = 1.00661307
Iteration 1456, loss = 0.81606161
Iteration 1457, loss = 0.94724102
Iteration 1458, loss = 0.79306083
Iteration 1459, loss = 0.90486371
Iteration 1460, loss = 0.78473132
Iteration 1461, loss = 0.87673727
Iteration 1462, loss = 0.78291153
Iteration 1463, loss = 0.85508841
Iteration 1464, loss = 0.78229625
Iteration 1465, loss = 0.83731195
Iteration 1466, loss = 0.78093625
Iteration 1467, loss = 0.82175395
Iteration 1468, loss = 0.77866720
Iteration 1469, loss = 0.80806087
Iteration 1470, loss = 0.77540040
Iteration 1471, loss = 0.79064610
Iteration 1472, loss = 0.78002725
Iteration 1473, loss = 0.84990150
Iteration 1474, loss = 0.78145718
Iteration 1475, loss = 0.83124984
Iteration 1476, loss = 0.77604245
Iteration 1477, loss = 0.81261062
Iteration 1478, loss = 0.76787077
Iteration 1479, loss = 0.67405639
Iteration 1480, loss = 0.84493439
Iteration 1481, loss = 0.89043092
Iteration 1482, loss = 0.82311005
Iteration 1483, loss = 0.88369226
Iteration 1484, loss = 0.83425073
Iteration 1485, loss = 0.79575265
Iteration 1486, loss = 0.86670416
Iteration 1487, loss = 0.77490107
Iteration 1488, loss = 0.84129594
Iteration 1489, loss = 0.75720938
Iteration 1490, loss = 0.77396894
Iteration 1491, loss = 0.83188673
Iteration 1492, loss = 0.76033217
Iteration 1493, loss = 0.78586186
Iteration 1494, loss = 0.80739024
Iteration 1495, loss = 0.78818882
Iteration 1496, loss = 0.79963298
Iteration 1497, loss = 0.78325898
Iteration 1498, loss = 0.77989655
Iteration 1499, loss = 0.78171486
Iteration 1500, loss = 0.78948777
Iteration 1501, loss = 0.79099093
Iteration 1502, loss = 0.79201479
Iteration 1503, loss = 0.78939486
Iteration 1504, loss = 0.78621474
Iteration 1505, loss = 0.78433273
Iteration 1506, loss = 0.78195047
Iteration 1507, loss = 0.78278249
Iteration 1508, loss = 0.78156689
Iteration 1509, loss = 0.78223917
Iteration 1510, loss = 0.78107094
Iteration 1511, loss = 0.78094402
Iteration 1512, loss = 0.77951260
Iteration 1513, loss = 0.77815063
Iteration 1514, loss = 0.77590693
Iteration 1515, loss = 0.77099943
Iteration 1516, loss = 0.80561082
Iteration 1517, loss = 0.78713294
Iteration 1518, loss = 0.80557203
Iteration 1519, loss = 0.78263935
Iteration 1520, loss = 0.80016581
Iteration 1521, loss = 0.77846543
Iteration 1522, loss = 0.79457578
Iteration 1523, loss = 0.77765054
Iteration 1524, loss = 0.79141710
Iteration 1525, loss = 0.77871019
Iteration 1526, loss = 0.78782688
Iteration 1527, loss = 0.77843122
Iteration 1528, loss = 0.78369993
Iteration 1529, loss = 0.77772364
Iteration 1530, loss = 0.78008861
Iteration 1531, loss = 0.77724652
Iteration 1532, loss = 0.77758009
Iteration 1533, loss = 0.77356651
Iteration 1534, loss = 0.77271297
Iteration 1535, loss = 0.77228207
Iteration 1536, loss = 0.77203538
Iteration 1537, loss = 0.77149934
Iteration 1538, loss = 0.77060709
Iteration 1539, loss = 0.76907486
Iteration 1540, loss = 0.76733561
Iteration 1541, loss = 0.76590187
Iteration 1542, loss = 0.76382422
Iteration 1543, loss = 0.75525328
Iteration 1544, loss = 0.78293094
Iteration 1545, loss = 0.75989006
Iteration 1546, loss = 0.87754751
Iteration 1547, loss = 0.82982328
Iteration 1548, loss = 0.87933847
Iteration 1549, loss = 0.80535715
Iteration 1550, loss = 0.86286436
Iteration 1551, loss = 0.78426364
Iteration 1552, loss = 0.84265425
Iteration 1553, loss = 0.77334982
Iteration 1554, loss = 0.82853042
Iteration 1555, loss = 0.77260825
Iteration 1556, loss = 0.82045457
Iteration 1557, loss = 0.77432692
Iteration 1558, loss = 0.81119442
Iteration 1559, loss = 0.77449305
Iteration 1560, loss = 0.80126240
Iteration 1561, loss = 0.77288739
Iteration 1562, loss = 0.79291583
Iteration 1563, loss = 0.77226916
Iteration 1564, loss = 0.78694281
Iteration 1565, loss = 0.77240415
Iteration 1566, loss = 0.78148400
Iteration 1567, loss = 0.77116854
Iteration 1568, loss = 0.77709466
Iteration 1569, loss = 0.77062075
Iteration 1570, loss = 0.77408123
Iteration 1571, loss = 0.76941597
Iteration 1572, loss = 0.77126373
Iteration 1573, loss = 0.76848262
Iteration 1574, loss = 0.76890205
Iteration 1575, loss = 0.76703363
Iteration 1576, loss = 0.76609389
Iteration 1577, loss = 0.76514596
Iteration 1578, loss = 0.76383815
Iteration 1579, loss = 0.76302175
Iteration 1580, loss = 0.76204797
Iteration 1581, loss = 0.76238810
Iteration 1582, loss = 0.76127083
Iteration 1583, loss = 0.76109672
Iteration 1584, loss = 0.75826786
Iteration 1585, loss = 0.75653274
Iteration 1586, loss = 0.75353742
Iteration 1587, loss = 0.74764202
Iteration 1588, loss = 0.72705579
Iteration 1589, loss = 0.87646521
Iteration 1590, loss = 0.83010042
Iteration 1591, loss = 0.88489653
Iteration 1592, loss = 0.80610355
Iteration 1593, loss = 0.87062321
Iteration 1594, loss = 0.97185963
Iteration 1595, loss = 0.80890198
Iteration 1596, loss = 0.96150359
Iteration 1597, loss = 0.80141966
Iteration 1598, loss = 0.87536357
Iteration 1599, loss = 0.79058497
Iteration 1600, loss = 0.83236055
Iteration 1601, loss = 0.80102553
Iteration 1602, loss = 0.82699662
Iteration 1603, loss = 0.79251468
Iteration 1604, loss = 0.81103813
Iteration 1605, loss = 0.78408731
Iteration 1606, loss = 0.80096212
Iteration 1607, loss = 0.78140953
Iteration 1608, loss = 0.79611709
Iteration 1609, loss = 0.78204964
Iteration 1610, loss = 0.79292722
Iteration 1611, loss = 0.78177877
Iteration 1612, loss = 0.78949963
Iteration 1613, loss = 0.78123376
Iteration 1614, loss = 0.78645459
Iteration 1615, loss = 0.78007741
Iteration 1616, loss = 0.78387584
Iteration 1617, loss = 0.77935834
Iteration 1618, loss = 0.78135105
Iteration 1619, loss = 0.77758015
Iteration 1620, loss = 0.77841602
Iteration 1621, loss = 0.77561356
Iteration 1622, loss = 0.77607365
Iteration 1623, loss = 0.77437778
Iteration 1624, loss = 0.77482661
Iteration 1625, loss = 0.77402302
Iteration 1626, loss = 0.77440192
Iteration 1627, loss = 0.77375862
Iteration 1628, loss = 0.77344284
Iteration 1629, loss = 0.77258689
Iteration 1630, loss = 0.77192555
Iteration 1631, loss = 0.77124486
Iteration 1632, loss = 0.77060869
Iteration 1633, loss = 0.77013143
Iteration 1634, loss = 0.76951728
Iteration 1635, loss = 0.76914893
Iteration 1636, loss = 0.76858044
Iteration 1637, loss = 0.76834359
Iteration 1638, loss = 0.76788897
Iteration 1639, loss = 0.76774963
Iteration 1640, loss = 0.76728732
Iteration 1641, loss = 0.76702890
Iteration 1642, loss = 0.76643531
Iteration 1643, loss = 0.76607278
Iteration 1644, loss = 0.76373803
Iteration 1645, loss = 0.76754176
Iteration 1646, loss = 0.77098078
Iteration 1647, loss = 0.77323199
Iteration 1648, loss = 0.77372608
Iteration 1649, loss = 0.77289342
Iteration 1650, loss = 0.77046472
Iteration 1651, loss = 0.76905773
Iteration 1652, loss = 0.76694058
Iteration 1653, loss = 0.76695913
Iteration 1654, loss = 0.76624459
Iteration 1655, loss = 0.76725184
Iteration 1656, loss = 0.76681934
Iteration 1657, loss = 0.76754700
Iteration 1658, loss = 0.76657592
Iteration 1659, loss = 0.76677235
Iteration 1660, loss = 0.76563301
Iteration 1661, loss = 0.76578817
Iteration 1662, loss = 0.76484830
Iteration 1663, loss = 0.76505201
Iteration 1664, loss = 0.76429471
Iteration 1665, loss = 0.76447532
Iteration 1666, loss = 0.76374160
Iteration 1667, loss = 0.76377341
Iteration 1668, loss = 0.76306031
Iteration 1669, loss = 0.76303431
Iteration 1670, loss = 0.76242549
Iteration 1671, loss = 0.76239509
Iteration 1672, loss = 0.76186793
Iteration 1673, loss = 0.76177570
Iteration 1674, loss = 0.76123767
Iteration 1675, loss = 0.76102655
Iteration 1676, loss = 0.76045758
Iteration 1677, loss = 0.76017307
Iteration 1678, loss = 0.75961452
Iteration 1679, loss = 0.75924661
Iteration 1680, loss = 0.75856679
Iteration 1681, loss = 0.75807934
Iteration 1682, loss = 0.75764865
Iteration 1683, loss = 0.75740716
Iteration 1684, loss = 0.75689684
Iteration 1685, loss = 0.75642628
Iteration 1686, loss = 0.75587301
Iteration 1687, loss = 0.75549269
Iteration 1688, loss = 0.75502752
Iteration 1689, loss = 0.75465907
Iteration 1690, loss = 0.75424751
Iteration 1691, loss = 0.75385663
Iteration 1692, loss = 0.75331808
Iteration 1693, loss = 0.75273568
Iteration 1694, loss = 0.75218538
Iteration 1695, loss = 0.75179824
Iteration 1696, loss = 0.75135302
Iteration 1697, loss = 0.75079803
Iteration 1698, loss = 0.74992190
Iteration 1699, loss = 0.74884994
Iteration 1700, loss = 0.74806242
Iteration 1701, loss = 0.74756300
Iteration 1702, loss = 0.74712908
Iteration 1703, loss = 0.74675134
Iteration 1704, loss = 0.74633450
Iteration 1705, loss = 0.74582540
Iteration 1706, loss = 0.74512458
Iteration 1707, loss = 0.74411078
Iteration 1708, loss = 0.74299526
Iteration 1709, loss = 0.74174543
Iteration 1710, loss = 0.74019310
Iteration 1711, loss = 0.73902276
Iteration 1712, loss = 0.73808463
Iteration 1713, loss = 0.73591788
Iteration 1714, loss = 0.73203644
Iteration 1715, loss = 0.72851920
Iteration 1716, loss = 0.72534405
Iteration 1717, loss = 0.71345830
Iteration 1718, loss = 0.61585645
Iteration 1719, loss = 1.08812984
Iteration 1720, loss = 0.80125256
Iteration 1721, loss = 1.05213242
Iteration 1722, loss = 0.87763312
Iteration 1723, loss = 0.96909332
Iteration 1724, loss = 0.91663581
Iteration 1725, loss = 0.87562576
Iteration 1726, loss = 0.91489877
Iteration 1727, loss = 0.80829628
Iteration 1728, loss = 0.89378007
Iteration 1729, loss = 0.77376820
Iteration 1730, loss = 0.87204396
Iteration 1731, loss = 0.76148315
Iteration 1732, loss = 0.85341073
Iteration 1733, loss = 0.76242901
Iteration 1734, loss = 0.79787844
Iteration 1735, loss = 0.76650276
Iteration 1736, loss = 0.76812658
Iteration 1737, loss = 0.80089371
Iteration 1738, loss = 0.82392797
Iteration 1739, loss = 0.88141910
Iteration 1740, loss = 0.84197629
Iteration 1741, loss = 0.84188685
Iteration 1742, loss = 0.83469965
Iteration 1743, loss = 0.80449744
Iteration 1744, loss = 0.82391535
Iteration 1745, loss = 0.78371820
Iteration 1746, loss = 0.81829069
Iteration 1747, loss = 0.77625329
Iteration 1748, loss = 0.81266580
Iteration 1749, loss = 0.76941172
Iteration 1750, loss = 0.80251484
Iteration 1751, loss = 0.76303075
Iteration 1752, loss = 0.79318486
Iteration 1753, loss = 0.75936987
Iteration 1754, loss = 0.78610549
Iteration 1755, loss = 0.75571215
Iteration 1756, loss = 0.82729848
Iteration 1757, loss = 0.76342775
Iteration 1758, loss = 0.82351771
Iteration 1759, loss = 0.76076295
Iteration 1760, loss = 0.80988346
Iteration 1761, loss = 0.75612937
Iteration 1762, loss = 0.79497249
Iteration 1763, loss = 0.75609889
Iteration 1764, loss = 0.78394947
Iteration 1765, loss = 0.75713465
Iteration 1766, loss = 0.77197880
Iteration 1767, loss = 0.75387372
Iteration 1768, loss = 0.75888126
Iteration 1769, loss = 0.74586857
Iteration 1770, loss = 0.70698893
Iteration 1771, loss = 0.84108556
Iteration 1772, loss = 0.84867565
Iteration 1773, loss = 0.85150331
Iteration 1774, loss = 0.82556707
Iteration 1775, loss = 0.83685320
Iteration 1776, loss = 0.79759990
Iteration 1777, loss = 0.81823560
Iteration 1778, loss = 0.78120130
Iteration 1779, loss = 0.80820969
Iteration 1780, loss = 0.77568091
Iteration 1781, loss = 0.80393879
Iteration 1782, loss = 0.77396783
Iteration 1783, loss = 0.79651342
Iteration 1784, loss = 0.76366472
Iteration 1785, loss = 0.76969906
Iteration 1786, loss = 0.81200285
Iteration 1787, loss = 0.90274868
Iteration 1788, loss = 0.85654598
Iteration 1789, loss = 0.85807455
Iteration 1790, loss = 0.87208781
Iteration 1791, loss = 0.81847756
Iteration 1792, loss = 0.86685980
Iteration 1793, loss = 0.79101476
Iteration 1794, loss = 0.85277814
Iteration 1795, loss = 0.77597812
Iteration 1796, loss = 0.83720165
Iteration 1797, loss = 0.75748486
Iteration 1798, loss = 0.79671224
Iteration 1799, loss = 0.78311447
Iteration 1800, loss = 0.80730952
Iteration 1801, loss = 0.79555374
Iteration 1802, loss = 0.80940391
Iteration 1803, loss = 0.79221925
Iteration 1804, loss = 0.76489559
Iteration 1805, loss = 0.81009516
Iteration 1806, loss = 0.79558352
Iteration 1807, loss = 0.80741777
Iteration 1808, loss = 0.78402441
Iteration 1809, loss = 0.79620283
Iteration 1810, loss = 0.77552684
Iteration 1811, loss = 0.78799622
Iteration 1812, loss = 0.77085920
Iteration 1813, loss = 0.78224219
Iteration 1814, loss = 0.76826653
Iteration 1815, loss = 0.77855822
Iteration 1816, loss = 0.76790844
Iteration 1817, loss = 0.77627581
Iteration 1818, loss = 0.76702479
Iteration 1819, loss = 0.77288502
Iteration 1820, loss = 0.76520300
Iteration 1821, loss = 0.76898667
Iteration 1822, loss = 0.76271471
Iteration 1823, loss = 0.76506663
Iteration 1824, loss = 0.76030239
Iteration 1825, loss = 0.76129488
Iteration 1826, loss = 0.75635620
Iteration 1827, loss = 0.75549975
Iteration 1828, loss = 0.75221421
Iteration 1829, loss = 0.73765593
Iteration 1830, loss = 0.78917014
Iteration 1831, loss = 0.90319998
Iteration 1832, loss = 0.74624846
Iteration 1833, loss = 1.02774263
Iteration 1834, loss = 0.74621888
Iteration 1835, loss = 1.09148921
Iteration 1836, loss = 0.81668074
Iteration 1837, loss = 0.97533597
Iteration 1838, loss = 0.86982960
Iteration 1839, loss = 0.92204027
Iteration 1840, loss = 0.87312563
Iteration 1841, loss = 0.84954069
Iteration 1842, loss = 0.85586672
Iteration 1843, loss = 0.79509786
Iteration 1844, loss = 0.83881804
Iteration 1845, loss = 0.76986907
Iteration 1846, loss = 0.82710637
Iteration 1847, loss = 0.76573411
Iteration 1848, loss = 0.81761982
Iteration 1849, loss = 0.77031993
Iteration 1850, loss = 0.80743689
Iteration 1851, loss = 0.77515497
Iteration 1852, loss = 0.79474185
Iteration 1853, loss = 0.77672595
Iteration 1854, loss = 0.78114277
Iteration 1855, loss = 0.77417175
Iteration 1856, loss = 0.76310719
Iteration 1857, loss = 0.80026689
Iteration 1858, loss = 0.77286459
Iteration 1859, loss = 0.80292069
Iteration 1860, loss = 0.76019273
Iteration 1861, loss = 0.79424318
Iteration 1862, loss = 0.75468694
Iteration 1863, loss = 0.78241172
Iteration 1864, loss = 0.75496867
Iteration 1865, loss = 0.76853317
Iteration 1866, loss = 0.75598558
Iteration 1867, loss = 0.75643106
Iteration 1868, loss = 0.75448324
Iteration 1869, loss = 0.74274670
Iteration 1870, loss = 0.74015112
Iteration 1871, loss = 0.60791960
Iteration 1872, loss = 0.84073978
Iteration 1873, loss = 0.89997044
Iteration 1874, loss = 0.89484709
Iteration 1875, loss = 0.83024435
Iteration 1876, loss = 0.91306589
Iteration 1877, loss = 0.79064545
Iteration 1878, loss = 0.89329293
Iteration 1879, loss = 0.77519439
Iteration 1880, loss = 0.86195896
Iteration 1881, loss = 0.77976859
Iteration 1882, loss = 0.83038014
Iteration 1883, loss = 0.79048472
Iteration 1884, loss = 0.80274788
Iteration 1885, loss = 0.79870852
Iteration 1886, loss = 0.78239276
Iteration 1887, loss = 0.80199511
Iteration 1888, loss = 0.77064487
Iteration 1889, loss = 0.80080290
Iteration 1890, loss = 0.76538037
Iteration 1891, loss = 0.79523091
Iteration 1892, loss = 0.76356663
Iteration 1893, loss = 0.78585589
Iteration 1894, loss = 0.76143763
Iteration 1895, loss = 0.76737787
Iteration 1896, loss = 0.76723021
Iteration 1897, loss = 0.85953608
Iteration 1898, loss = 0.78341807
Iteration 1899, loss = 0.87396721
Iteration 1900, loss = 0.80925066
Iteration 1901, loss = 0.86026620
Iteration 1902, loss = 0.82219977
Iteration 1903, loss = 0.83507524
Iteration 1904, loss = 0.82084148
Iteration 1905, loss = 0.80672471
Iteration 1906, loss = 0.81360798
Iteration 1907, loss = 0.78647961
Iteration 1908, loss = 0.80551936
Iteration 1909, loss = 0.77578463
Iteration 1910, loss = 0.79916108
Iteration 1911, loss = 0.77278533
Iteration 1912, loss = 0.79449515
Iteration 1913, loss = 0.77412084
Iteration 1914, loss = 0.78993825
Iteration 1915, loss = 0.77581348
Iteration 1916, loss = 0.78417501
Iteration 1917, loss = 0.77527003
Iteration 1918, loss = 0.77794425
Iteration 1919, loss = 0.77481673
Iteration 1920, loss = 0.77360947
Iteration 1921, loss = 0.77377518
Iteration 1922, loss = 0.77074088
Iteration 1923, loss = 0.77207212
Iteration 1924, loss = 0.76886982
Iteration 1925, loss = 0.76933964
Iteration 1926, loss = 0.76599220
Iteration 1927, loss = 0.76647799
Iteration 1928, loss = 0.76347375
Iteration 1929, loss = 0.76320063
Iteration 1930, loss = 0.75877279
Iteration 1931, loss = 0.74729889
Iteration 1932, loss = 0.78513594
Iteration 1933, loss = 0.77230735
Iteration 1934, loss = 0.78702531
Iteration 1935, loss = 0.76804766
Iteration 1936, loss = 0.76606240
Iteration 1937, loss = 0.78107758
Iteration 1938, loss = 0.83482174
Iteration 1939, loss = 0.80361439
Iteration 1940, loss = 0.83401340
Iteration 1941, loss = 0.81686923
Iteration 1942, loss = 0.82432903
Iteration 1943, loss = 0.81511730
Iteration 1944, loss = 0.80818627
Iteration 1945, loss = 0.80700168
Iteration 1946, loss = 0.79322075
Iteration 1947, loss = 0.79750826
Iteration 1948, loss = 0.78180130
Iteration 1949, loss = 0.79045709
Iteration 1950, loss = 0.77501268
Iteration 1951, loss = 0.78572235
Iteration 1952, loss = 0.77133615
Iteration 1953, loss = 0.78252902
Iteration 1954, loss = 0.76939165
Iteration 1955, loss = 0.77974894
Iteration 1956, loss = 0.76930344
Iteration 1957, loss = 0.77270361
Iteration 1958, loss = 0.76751881
Iteration 1959, loss = 0.77184954
Iteration 1960, loss = 0.76689249
Iteration 1961, loss = 0.80243124
Iteration 1962, loss = 0.84351304
Iteration 1963, loss = 0.78292574
Iteration 1964, loss = 0.83714920
Iteration 1965, loss = 0.79664906
Iteration 1966, loss = 0.82889245
Iteration 1967, loss = 0.80059821
Iteration 1968, loss = 0.81417251
Iteration 1969, loss = 0.79515600
Iteration 1970, loss = 0.79738061
Iteration 1971, loss = 0.78771998
Iteration 1972, loss = 0.78482839
Iteration 1973, loss = 0.78331335
Iteration 1974, loss = 0.77835198
Iteration 1975, loss = 0.78203514
Iteration 1976, loss = 0.77550895
Iteration 1977, loss = 0.78132609
Iteration 1978, loss = 0.77337193
Iteration 1979, loss = 0.77945171
Iteration 1980, loss = 0.77066123
Iteration 1981, loss = 0.77648755
Iteration 1982, loss = 0.76783672
Iteration 1983, loss = 0.77342368
Iteration 1984, loss = 0.76562004
Iteration 1985, loss = 0.77097109
Iteration 1986, loss = 0.76422505
Iteration 1987, loss = 0.76912731
Iteration 1988, loss = 0.76331208
Iteration 1989, loss = 0.76751561
Iteration 1990, loss = 0.76238978
Iteration 1991, loss = 0.76578308
Iteration 1992, loss = 0.76127395
Iteration 1993, loss = 0.76394129
Iteration 1994, loss = 0.75993130
Iteration 1995, loss = 0.76216346
Iteration 1996, loss = 0.75900191
Iteration 1997, loss = 0.76070341
Iteration 1998, loss = 0.75797904
Iteration 1999, loss = 0.75950366
Iteration 2000, loss = 0.75722044
Iteration 2001, loss = 0.75827423
Iteration 2002, loss = 0.75646628
Iteration 2003, loss = 0.75723022
Iteration 2004, loss = 0.75552220
Iteration 2005, loss = 0.75586781
Iteration 2006, loss = 0.75459325
Iteration 2007, loss = 0.75495369
Iteration 2008, loss = 0.75362307
Iteration 2009, loss = 0.75364728
Iteration 2010, loss = 0.75286724
Iteration 2011, loss = 0.75281459
Iteration 2012, loss = 0.75166728
Iteration 2013, loss = 0.75218633
Iteration 2014, loss = 0.75142432
Iteration 2015, loss = 0.75083064
Iteration 2016, loss = 0.74964959
Iteration 2017, loss = 0.74903640
Iteration 2018, loss = 0.74848466
Iteration 2019, loss = 0.74853810
Iteration 2020, loss = 0.74700070
Iteration 2021, loss = 0.74279712
Iteration 2022, loss = 0.70825507
Iteration 2023, loss = 0.78224544
Iteration 2024, loss = 0.79129683
Iteration 2025, loss = 0.78253579
Iteration 2026, loss = 0.78526903
Iteration 2027, loss = 0.77098383
Iteration 2028, loss = 0.77412454
Iteration 2029, loss = 0.76205355
Iteration 2030, loss = 0.76974927
Iteration 2031, loss = 0.76070196
Iteration 2032, loss = 0.77032042
Iteration 2033, loss = 0.76085415
Iteration 2034, loss = 0.76904408
Iteration 2035, loss = 0.75848489
Iteration 2036, loss = 0.76535970
Iteration 2037, loss = 0.75529534
Iteration 2038, loss = 0.76237801
Iteration 2039, loss = 0.75383569
Iteration 2040, loss = 0.76090237
Iteration 2041, loss = 0.75342145
Iteration 2042, loss = 0.75970407
Iteration 2043, loss = 0.75279739
Iteration 2044, loss = 0.75799888
Iteration 2045, loss = 0.75175103
Iteration 2046, loss = 0.75615752
Iteration 2047, loss = 0.75089004
Iteration 2048, loss = 0.75471689
Iteration 2049, loss = 0.75037793
Iteration 2050, loss = 0.75351360
Iteration 2051, loss = 0.74985828
Iteration 2052, loss = 0.75224408
Iteration 2053, loss = 0.74919436
Iteration 2054, loss = 0.75098262
Iteration 2055, loss = 0.74814480
Iteration 2056, loss = 0.74841234
Iteration 2057, loss = 0.74918691
Iteration 2058, loss = 0.74974343
Iteration 2059, loss = 0.74921925
Iteration 2060, loss = 0.74848304
Iteration 2061, loss = 0.74754109
Iteration 2062, loss = 0.74719645
Iteration 2063, loss = 0.74686975
Iteration 2064, loss = 0.74680910
Iteration 2065, loss = 0.74641895
Iteration 2066, loss = 0.74607133
Iteration 2067, loss = 0.74541134
Iteration 2068, loss = 0.74486242
Iteration 2069, loss = 0.74428435
Iteration 2070, loss = 0.74406240
Iteration 2071, loss = 0.74366380
Iteration 2072, loss = 0.74333692
Iteration 2073, loss = 0.74280298
Iteration 2074, loss = 0.74235931
Iteration 2075, loss = 0.74170731
Iteration 2076, loss = 0.74115665
Iteration 2077, loss = 0.74061759
Iteration 2078, loss = 0.74009160
Iteration 2079, loss = 0.73948469
Iteration 2080, loss = 0.73900634
Iteration 2081, loss = 0.73853678
Iteration 2082, loss = 0.73780536
Iteration 2083, loss = 0.73664367
Iteration 2084, loss = 0.73566833
Iteration 2085, loss = 0.73470555
Iteration 2086, loss = 0.73339827
Iteration 2087, loss = 0.73271664
Iteration 2088, loss = 0.73190239
Iteration 2089, loss = 0.73025576
Iteration 2090, loss = 0.72877985
Iteration 2091, loss = 0.72745609
Iteration 2092, loss = 0.72586296
Iteration 2093, loss = 0.72339326
Iteration 2094, loss = 0.72005965
Iteration 2095, loss = 0.71521743
Iteration 2096, loss = 0.71107812
Iteration 2097, loss = 0.67454783
Iteration 2098, loss = 0.64359757
Iteration 2099, loss = 1.03611755
Iteration 2100, loss = 0.77094626
Iteration 2101, loss = 1.01482451
Iteration 2102, loss = 0.79332616
Iteration 2103, loss = 0.97947810
Iteration 2104, loss = 0.81250579
Iteration 2105, loss = 0.93778186
Iteration 2106, loss = 0.82283006
Iteration 2107, loss = 0.89853529
Iteration 2108, loss = 0.82392881
Iteration 2109, loss = 0.85985516
Iteration 2110, loss = 0.81690950
Iteration 2111, loss = 0.82853499
Iteration 2112, loss = 0.80890367
Iteration 2113, loss = 0.80530198
Iteration 2114, loss = 0.79541788
Iteration 2115, loss = 0.75445154
Iteration 2116, loss = 1.08252417
Iteration 2117, loss = 0.88722673
Iteration 2118, loss = 1.10582450
Iteration 2119, loss = 0.79385322
Iteration 2120, loss = 1.05618043
Iteration 2121, loss = 0.80058890
Iteration 2122, loss = 1.09031300
Iteration 2123, loss = 0.84072077
Iteration 2124, loss = 0.97451044
Iteration 2125, loss = 0.92593366
Iteration 2126, loss = 0.84497718
Iteration 2127, loss = 0.94655325
Iteration 2128, loss = 0.77488106
Iteration 2129, loss = 0.92812023
Iteration 2130, loss = 0.76794551
Iteration 2131, loss = 0.89217741
Iteration 2132, loss = 0.78742079
Iteration 2133, loss = 0.84503671
Iteration 2134, loss = 0.76331016
Iteration 2135, loss = 0.77072790
Iteration 2136, loss = 0.81641133
Iteration 2137, loss = 0.77234363
Iteration 2138, loss = 0.80993205
Iteration 2139, loss = 0.77026807
Iteration 2140, loss = 0.79599496
Iteration 2141, loss = 0.76917573
Iteration 2142, loss = 0.78442066
Iteration 2143, loss = 0.77134507
Iteration 2144, loss = 0.77727063
Iteration 2145, loss = 0.77477727
Iteration 2146, loss = 0.77217297
Iteration 2147, loss = 0.77556632
Iteration 2148, loss = 0.76681680
Iteration 2149, loss = 0.77058045
Iteration 2150, loss = 0.74917544
Iteration 2151, loss = 0.82214079
Iteration 2152, loss = 0.77732306
Iteration 2153, loss = 0.83127170
Iteration 2154, loss = 0.77121171
Iteration 2155, loss = 0.81994888
Iteration 2156, loss = 0.77083951
Iteration 2157, loss = 0.80170501
Iteration 2158, loss = 0.77578101
Iteration 2159, loss = 0.78448438
Iteration 2160, loss = 0.78080066
Iteration 2161, loss = 0.77266150
Iteration 2162, loss = 0.78272804
Iteration 2163, loss = 0.76469705
Iteration 2164, loss = 0.79522161
Iteration 2165, loss = 0.76396082
Iteration 2166, loss = 0.79031518
Iteration 2167, loss = 0.76041401
Iteration 2168, loss = 0.78259096
Iteration 2169, loss = 0.74043165
Iteration 2170, loss = 0.76205729
Iteration 2171, loss = 0.76258821
Iteration 2172, loss = 0.76305596
Iteration 2173, loss = 0.76142276
Iteration 2174, loss = 0.76124283
Iteration 2175, loss = 0.76054906
Iteration 2176, loss = 0.76117051
Iteration 2177, loss = 0.76106264
Iteration 2178, loss = 0.76198134
Iteration 2179, loss = 0.76197680
Iteration 2180, loss = 0.76250006
Iteration 2181, loss = 0.76213374
Iteration 2182, loss = 0.76198534
Iteration 2183, loss = 0.76106216
Iteration 2184, loss = 0.75976333
Iteration 2185, loss = 0.75791523
Iteration 2186, loss = 0.75540829
Iteration 2187, loss = 0.74981303
Iteration 2188, loss = 0.69677429
Iteration 2189, loss = 0.80138383
Iteration 2190, loss = 0.83512483
Iteration 2191, loss = 0.80815792
Iteration 2192, loss = 0.82569879
Iteration 2193, loss = 0.80234293
Iteration 2194, loss = 0.81257390
Iteration 2195, loss = 0.79299053
Iteration 2196, loss = 0.80005280
Iteration 2197, loss = 0.78644348
Iteration 2198, loss = 0.79385881
Iteration 2199, loss = 0.78381298
Iteration 2200, loss = 0.79004406
Iteration 2201, loss = 0.78150730
Iteration 2202, loss = 0.78648919
Iteration 2203, loss = 0.77891707
Iteration 2204, loss = 0.78306141
Iteration 2205, loss = 0.77648089
Iteration 2206, loss = 0.78016730
Iteration 2207, loss = 0.77417988
Iteration 2208, loss = 0.77700375
Iteration 2209, loss = 0.77068293
Iteration 2210, loss = 0.77244447
Iteration 2211, loss = 0.76630236
Iteration 2212, loss = 0.76803151
Iteration 2213, loss = 0.75201634
Iteration 2214, loss = 0.77797990
Iteration 2215, loss = 0.81530569
Iteration 2216, loss = 0.78312649
Iteration 2217, loss = 0.80689992
Iteration 2218, loss = 0.77500322
Iteration 2219, loss = 0.79487304
Iteration 2220, loss = 0.76919879
Iteration 2221, loss = 0.78838998
Iteration 2222, loss = 0.76969160
Iteration 2223, loss = 0.78637887
Iteration 2224, loss = 0.77115997
Iteration 2225, loss = 0.78294056
Iteration 2226, loss = 0.76994036
Iteration 2227, loss = 0.77803294
Iteration 2228, loss = 0.76811743
Iteration 2229, loss = 0.77368793
Iteration 2230, loss = 0.76706155
Iteration 2231, loss = 0.77112010
Iteration 2232, loss = 0.76684695
Iteration 2233, loss = 0.76879353
Iteration 2234, loss = 0.76596295
Iteration 2235, loss = 0.76644415
Iteration 2236, loss = 0.76482328
Iteration 2237, loss = 0.76411261
Iteration 2238, loss = 0.76314100
Iteration 2239, loss = 0.76166992
Iteration 2240, loss = 0.76131219
Iteration 2241, loss = 0.75944959
Iteration 2242, loss = 0.75876962
Iteration 2243, loss = 0.75428582
Iteration 2244, loss = 0.73890058
Iteration 2245, loss = 0.81361395
Iteration 2246, loss = 0.80581462
Iteration 2247, loss = 0.82178831
Iteration 2248, loss = 0.80583531
Iteration 2249, loss = 0.81603962
Iteration 2250, loss = 0.79352536
Iteration 2251, loss = 0.79927711
Iteration 2252, loss = 0.77613589
Iteration 2253, loss = 0.77609037
Iteration 2254, loss = 0.70491309
Iteration 2255, loss = 0.92387934
Iteration 2256, loss = 0.91719902
Iteration 2257, loss = 0.92752740
Iteration 2258, loss = 0.86548648
Iteration 2259, loss = 0.90290169
Iteration 2260, loss = 0.82349406
Iteration 2261, loss = 0.85839515
Iteration 2262, loss = 0.76852047
Iteration 2263, loss = 0.96763331
Iteration 2264, loss = 0.76948975
Iteration 2265, loss = 0.93086366
Iteration 2266, loss = 0.76838471
Iteration 2267, loss = 0.90442904
Iteration 2268, loss = 0.76913893
Iteration 2269, loss = 0.88436661
Iteration 2270, loss = 0.77125917
Iteration 2271, loss = 0.86825994
Iteration 2272, loss = 0.76962420
Iteration 2273, loss = 0.85143903
Iteration 2274, loss = 0.76770925
Iteration 2275, loss = 0.83759564
Iteration 2276, loss = 0.76560298
Iteration 2277, loss = 0.82446567
Iteration 2278, loss = 0.73496090
Iteration 2279, loss = 0.78210807
Iteration 2280, loss = 0.77557489
Iteration 2281, loss = 0.79329397
Iteration 2282, loss = 0.78396493
Iteration 2283, loss = 0.79198376
Iteration 2284, loss = 0.77878801
Iteration 2285, loss = 0.78076658
Iteration 2286, loss = 0.75466825
Iteration 2287, loss = 0.79093523
Iteration 2288, loss = 0.79366171
Iteration 2289, loss = 0.78851981
Iteration 2290, loss = 0.79691545
Iteration 2291, loss = 0.78308648
Iteration 2292, loss = 0.79339845
Iteration 2293, loss = 0.77780583
Iteration 2294, loss = 0.79033253
Iteration 2295, loss = 0.77742424
Iteration 2296, loss = 0.78949969
Iteration 2297, loss = 0.77991756
Iteration 2298, loss = 0.78861540
Iteration 2299, loss = 0.78192983
Iteration 2300, loss = 0.81783542
Iteration 2301, loss = 0.86327520
Iteration 2302, loss = 0.78704011
Iteration 2303, loss = 0.85921007
Iteration 2304, loss = 0.79126456
Iteration 2305, loss = 0.84819464
Iteration 2306, loss = 0.78922689
Iteration 2307, loss = 0.83017590
Iteration 2308, loss = 0.78642618
Iteration 2309, loss = 0.81387607
Iteration 2310, loss = 0.78699801
Iteration 2311, loss = 0.80234902
Iteration 2312, loss = 0.79032764
Iteration 2313, loss = 0.79453959
Iteration 2314, loss = 0.79316509
Iteration 2315, loss = 0.78815713
Iteration 2316, loss = 0.79340030
Iteration 2317, loss = 0.78265611
Iteration 2318, loss = 0.79150878
Iteration 2319, loss = 0.77880013
Iteration 2320, loss = 0.78870104
Iteration 2321, loss = 0.77683032
Iteration 2322, loss = 0.78566447
Iteration 2323, loss = 0.77627968
Iteration 2324, loss = 0.78257806
Iteration 2325, loss = 0.77616484
Iteration 2326, loss = 0.77833013
Iteration 2327, loss = 0.77710486
Iteration 2328, loss = 0.77743426
Iteration 2329, loss = 0.77743007
Iteration 2330, loss = 0.77478274
Iteration 2331, loss = 0.77591138
Iteration 2332, loss = 0.77228804
Iteration 2333, loss = 0.77428383
Iteration 2334, loss = 0.77100509
Iteration 2335, loss = 0.77305430
Iteration 2336, loss = 0.77020032
Iteration 2337, loss = 0.77152723
Iteration 2338, loss = 0.76942990
Iteration 2339, loss = 0.76992839
Iteration 2340, loss = 0.76866680
Iteration 2341, loss = 0.76836395
Iteration 2342, loss = 0.76781777
Iteration 2343, loss = 0.76696212
Iteration 2344, loss = 0.76691431
Iteration 2345, loss = 0.76576251
Iteration 2346, loss = 0.76593739
Iteration 2347, loss = 0.76475325
Iteration 2348, loss = 0.76493617
Iteration 2349, loss = 0.76387268
Iteration 2350, loss = 0.76385558
Iteration 2351, loss = 0.76297566
Iteration 2352, loss = 0.76273382
Iteration 2353, loss = 0.76212969
Iteration 2354, loss = 0.76172719
Iteration 2355, loss = 0.76133329
Iteration 2356, loss = 0.76076477
Iteration 2357, loss = 0.76045646
Iteration 2358, loss = 0.75980855
Iteration 2359, loss = 0.75955665
Iteration 2360, loss = 0.75894301
Iteration 2361, loss = 0.75868960
Iteration 2362, loss = 0.75812968
Iteration 2363, loss = 0.75780979
Iteration 2364, loss = 0.75731410
Iteration 2365, loss = 0.75693046
Iteration 2366, loss = 0.75650934
Iteration 2367, loss = 0.75608181
Iteration 2368, loss = 0.75571388
Iteration 2369, loss = 0.75526179
Iteration 2370, loss = 0.75491912
Iteration 2371, loss = 0.75446536
Iteration 2372, loss = 0.75412150
Iteration 2373, loss = 0.75362729
Iteration 2374, loss = 0.76704324
Iteration 2375, loss = 0.81555854
Iteration 2376, loss = 0.75426560
Iteration 2377, loss = 0.79269581
Iteration 2378, loss = 0.76785921
Iteration 2379, loss = 0.78601619
Iteration 2380, loss = 0.77725209
Iteration 2381, loss = 0.77515974
Iteration 2382, loss = 0.77710808
Iteration 2383, loss = 0.76190975
Iteration 2384, loss = 0.77198914
Iteration 2385, loss = 0.75342599
Iteration 2386, loss = 0.76749296
Iteration 2387, loss = 0.75135888
Iteration 2388, loss = 0.76390988
Iteration 2389, loss = 0.75230109
Iteration 2390, loss = 0.75892530
Iteration 2391, loss = 0.75292196
Iteration 2392, loss = 0.75398066
Iteration 2393, loss = 0.75334943
Iteration 2394, loss = 0.75007628
Iteration 2395, loss = 0.75276370
Iteration 2396, loss = 0.74713274
Iteration 2397, loss = 0.75116497
Iteration 2398, loss = 0.74562758
Iteration 2399, loss = 0.74903814
Iteration 2400, loss = 0.74473202
Iteration 2401, loss = 0.74657566
Iteration 2402, loss = 0.74432680
Iteration 2403, loss = 0.74441233
Iteration 2404, loss = 0.74387252
Iteration 2405, loss = 0.74246370
Iteration 2406, loss = 0.74296404
Iteration 2407, loss = 0.74075503
Iteration 2408, loss = 0.74174498
Iteration 2409, loss = 0.73972072
Iteration 2410, loss = 0.74220610
Iteration 2411, loss = 0.74242709
Iteration 2412, loss = 0.73965864
Iteration 2413, loss = 0.74202888
Iteration 2414, loss = 0.73819377
Iteration 2415, loss = 0.73942903
Iteration 2416, loss = 0.73590043
Iteration 2417, loss = 0.73603062
Iteration 2418, loss = 0.73399360
Iteration 2419, loss = 0.73335190
Iteration 2420, loss = 0.73190408
Iteration 2421, loss = 0.73062741
Iteration 2422, loss = 0.72961202
Iteration 2423, loss = 0.72746327
Iteration 2424, loss = 0.72465364
Iteration 2425, loss = 0.72014931
Iteration 2426, loss = 0.71635986
Iteration 2427, loss = 0.70442276
Iteration 2428, loss = 0.84024604
Iteration 2429, loss = 1.36347994
Iteration 2430, loss = 0.89082724
Iteration 2431, loss = 1.33043712
Iteration 2432, loss = 1.15016584
Iteration 2433, loss = 1.11989816
Iteration 2434, loss = 1.21253068
Iteration 2435, loss = 0.92198665
Iteration 2436, loss = 1.13323031
Iteration 2437, loss = 0.83577172
Iteration 2438, loss = 1.04737893
Iteration 2439, loss = 0.79794036
Iteration 2440, loss = 0.98092465
Iteration 2441, loss = 0.77978912
Iteration 2442, loss = 0.93115371
Iteration 2443, loss = 0.76768505
Iteration 2444, loss = 0.89379762
Iteration 2445, loss = 0.75992332
Iteration 2446, loss = 0.86545735
Iteration 2447, loss = 0.75495806
Iteration 2448, loss = 0.84491373
Iteration 2449, loss = 0.75223130
Iteration 2450, loss = 0.82859089
Iteration 2451, loss = 0.75101163
Iteration 2452, loss = 0.81561226
Iteration 2453, loss = 0.75091910
Iteration 2454, loss = 0.80435970
Iteration 2455, loss = 0.75041447
Iteration 2456, loss = 0.79460279
Iteration 2457, loss = 0.75024313
Iteration 2458, loss = 0.78607089
Iteration 2459, loss = 0.75138040
Iteration 2460, loss = 0.77860628
Iteration 2461, loss = 0.75052287
Iteration 2462, loss = 0.86451775
Iteration 2463, loss = 0.76278017
Iteration 2464, loss = 0.85040843
Iteration 2465, loss = 0.76556290
Iteration 2466, loss = 0.83069973
Iteration 2467, loss = 0.75957212
Iteration 2468, loss = 0.80941025
Iteration 2469, loss = 0.75384797
Iteration 2470, loss = 0.79262914
Iteration 2471, loss = 0.75054798
Iteration 2472, loss = 0.77823143
Iteration 2473, loss = 0.74160110
Iteration 2474, loss = 0.72861828
Iteration 2475, loss = 1.14149163
Iteration 2476, loss = 0.99979276
Iteration 2477, loss = 0.97749838
Iteration 2478, loss = 1.02631332
Iteration 2479, loss = 0.90431133
Iteration 2480, loss = 1.02513806
Iteration 2481, loss = 0.85874531
Iteration 2482, loss = 1.00514047
Iteration 2483, loss = 0.74998673
Iteration 2484, loss = 1.71712445
Iteration 2485, loss = 0.81936690
Iteration 2486, loss = 1.73413817
Iteration 2487, loss = 1.16809647
Iteration 2488, loss = 1.59242628
Iteration 2489, loss = 1.56478855
Iteration 2490, loss = 0.99600629
Iteration 2491, loss = 1.36844048
Iteration 2492, loss = 0.80604273
Iteration 2493, loss = 1.21244366
Iteration 2494, loss = 0.77586161
Iteration 2495, loss = 1.14255685
Iteration 2496, loss = 0.78991023
Iteration 2497, loss = 1.11012612
Iteration 2498, loss = 0.81975117
Iteration 2499, loss = 1.09081273
Iteration 2500, loss = 0.85274964
Iteration 2501, loss = 1.06504066
Iteration 2502, loss = 0.87963681
Iteration 2503, loss = 1.02496090
Iteration 2504, loss = 0.89452829
Iteration 2505, loss = 0.97769912
Iteration 2506, loss = 0.88352973
Iteration 2507, loss = 1.21372738
Iteration 2508, loss = 0.85041651
Iteration 2509, loss = 1.19430119
Iteration 2510, loss = 0.94336089
Iteration 2511, loss = 1.13282995
Iteration 2512, loss = 0.99615630
Iteration 2513, loss = 1.03040306
Iteration 2514, loss = 0.99439768
Iteration 2515, loss = 0.94009762
Iteration 2516, loss = 0.96308264
Iteration 2517, loss = 0.88795655
Iteration 2518, loss = 0.92637968
Iteration 2519, loss = 0.86029398
Iteration 2520, loss = 0.88936627
Iteration 2521, loss = 0.84279317
Iteration 2522, loss = 0.85578395
Iteration 2523, loss = 0.83079877
Iteration 2524, loss = 0.82766835
Iteration 2525, loss = 0.82225910
Iteration 2526, loss = 0.80498052
Iteration 2527, loss = 0.80470770
Iteration 2528, loss = 0.78315236
Iteration 2529, loss = 0.77610151
Iteration 2530, loss = 0.78972048
Iteration 2531, loss = 0.77938009
Iteration 2532, loss = 0.77648419
Iteration 2533, loss = 0.66573665
Iteration 2534, loss = 0.83762307
Iteration 2535, loss = 0.96502776
Iteration 2536, loss = 0.84832973
Iteration 2537, loss = 0.94173149
Iteration 2538, loss = 0.84397983
Iteration 2539, loss = 0.91929969
Iteration 2540, loss = 0.83524261
Iteration 2541, loss = 0.89757411
Iteration 2542, loss = 0.82397021
Iteration 2543, loss = 0.88011766
Iteration 2544, loss = 0.81478020
Iteration 2545, loss = 0.86652405
Iteration 2546, loss = 0.80573738
Iteration 2547, loss = 0.85578273
Iteration 2548, loss = 0.79875721
Iteration 2549, loss = 0.84734434
Iteration 2550, loss = 0.79306245
Iteration 2551, loss = 0.83999452
Iteration 2552, loss = 0.78824062
Iteration 2553, loss = 0.83286844
Iteration 2554, loss = 0.78370959
Iteration 2555, loss = 0.82566030
Iteration 2556, loss = 0.77976436
Iteration 2557, loss = 0.81855849
Iteration 2558, loss = 0.77640690
Iteration 2559, loss = 0.81161619
Iteration 2560, loss = 0.77379428
Iteration 2561, loss = 0.80502717
Iteration 2562, loss = 0.77183585
Iteration 2563, loss = 0.79881775
Iteration 2564, loss = 0.77052210
Iteration 2565, loss = 0.79315688
Iteration 2566, loss = 0.76973532
Iteration 2567, loss = 0.78801691
Iteration 2568, loss = 0.76922415
Iteration 2569, loss = 0.78320634
Iteration 2570, loss = 0.76889349
Iteration 2571, loss = 0.77936487
Iteration 2572, loss = 0.76906427
Iteration 2573, loss = 0.77609093
Iteration 2574, loss = 0.76888509
Iteration 2575, loss = 0.77285517
Iteration 2576, loss = 0.76802746
Iteration 2577, loss = 0.76826527
Iteration 2578, loss = 0.74895296
Iteration 2579, loss = 0.79552389
Iteration 2580, loss = 0.77278972
Iteration 2581, loss = 0.79432495
Iteration 2582, loss = 0.77569337
Iteration 2583, loss = 0.78608663
Iteration 2584, loss = 0.77270708
Iteration 2585, loss = 0.77737454
Iteration 2586, loss = 0.77032535
Iteration 2587, loss = 0.77217515
Iteration 2588, loss = 0.77130736
Iteration 2589, loss = 0.77008080
Iteration 2590, loss = 0.77144393
Iteration 2591, loss = 0.76756970
Iteration 2592, loss = 0.77032920
Iteration 2593, loss = 0.76455826
Iteration 2594, loss = 0.76631177
Iteration 2595, loss = 0.75476981
Iteration 2596, loss = 0.75938232
Iteration 2597, loss = 0.76112233
Iteration 2598, loss = 0.76137713
Iteration 2599, loss = 0.76102407
Iteration 2600, loss = 0.75820969
Iteration 2601, loss = 0.75441278
Iteration 2602, loss = 0.74095321
Iteration 2603, loss = 0.76773270
Iteration 2604, loss = 0.77396013
Iteration 2605, loss = 0.76728143
Iteration 2606, loss = 0.77099560
Iteration 2607, loss = 0.76314278
Iteration 2608, loss = 0.76810680
Iteration 2609, loss = 0.75972740
Iteration 2610, loss = 0.76537425
Iteration 2611, loss = 0.75841859
Iteration 2612, loss = 0.76441014
Iteration 2613, loss = 0.75743810
Iteration 2614, loss = 0.76282250
Iteration 2615, loss = 0.75627623
Iteration 2616, loss = 0.76093144
Iteration 2617, loss = 0.75520103
Iteration 2618, loss = 0.75929143
Iteration 2619, loss = 0.75416764
Iteration 2620, loss = 0.75750576
Iteration 2621, loss = 0.75317626
Iteration 2622, loss = 0.75570634
Iteration 2623, loss = 0.75209225
Iteration 2624, loss = 0.75398163
Iteration 2625, loss = 0.75088470
Iteration 2626, loss = 0.75191017
Iteration 2627, loss = 0.74941435
Iteration 2628, loss = 0.74960118
Iteration 2629, loss = 0.74765139
Iteration 2630, loss = 0.74700529
Iteration 2631, loss = 0.74496976
Iteration 2632, loss = 0.74301158
Iteration 2633, loss = 0.77432351
Iteration 2634, loss = 0.84043992
Iteration 2635, loss = 0.76015431
Iteration 2636, loss = 0.84016491
Iteration 2637, loss = 0.76841040
Iteration 2638, loss = 0.82732258
Iteration 2639, loss = 0.76433598
Iteration 2640, loss = 0.80976670
Iteration 2641, loss = 0.75638561
Iteration 2642, loss = 0.79363721
Iteration 2643, loss = 0.75253064
Iteration 2644, loss = 0.78427907
Iteration 2645, loss = 0.75353773
Iteration 2646, loss = 0.77912143
Iteration 2647, loss = 0.75570308
Iteration 2648, loss = 0.77457572
Iteration 2649, loss = 0.75643067
Iteration 2650, loss = 0.76895844
Iteration 2651, loss = 0.75547051
Iteration 2652, loss = 0.76326472
Iteration 2653, loss = 0.75419766
Iteration 2654, loss = 0.75894308
Iteration 2655, loss = 0.75384266
Iteration 2656, loss = 0.75604845
Iteration 2657, loss = 0.75361135
Iteration 2658, loss = 0.75380028
Iteration 2659, loss = 0.75317016
Iteration 2660, loss = 0.75172306
Iteration 2661, loss = 0.75226685
Iteration 2662, loss = 0.75001692
Iteration 2663, loss = 0.75149355
Iteration 2664, loss = 0.74880707
Iteration 2665, loss = 0.75068504
Iteration 2666, loss = 0.74787937
Iteration 2667, loss = 0.74977954
Iteration 2668, loss = 0.74703048
Iteration 2669, loss = 0.74879206
Iteration 2670, loss = 0.74627474
Iteration 2671, loss = 0.74771043
Iteration 2672, loss = 0.74554619
Iteration 2673, loss = 0.74668375
Iteration 2674, loss = 0.74491233
Iteration 2675, loss = 0.74566972
Iteration 2676, loss = 0.74429162
Iteration 2677, loss = 0.74472806
Iteration 2678, loss = 0.74364788
Iteration 2679, loss = 0.74362476
Iteration 2680, loss = 0.74266161
Iteration 2681, loss = 0.74240703
Iteration 2682, loss = 0.74181210
Iteration 2683, loss = 0.74137490
Iteration 2684, loss = 0.74082905
Iteration 2685, loss = 0.74012296
Iteration 2686, loss = 0.73933109
Iteration 2687, loss = 0.73812569
Iteration 2688, loss = 0.73772265
Iteration 2689, loss = 0.73623574
Iteration 2690, loss = 0.73401424
Iteration 2691, loss = 0.73140444
Iteration 2692, loss = 0.72840165
Iteration 2693, loss = 0.72369449
Iteration 2694, loss = 0.71787837
Iteration 2695, loss = 0.72176382
Iteration 2696, loss = 0.63612644
Iteration 2697, loss = 2.12297030
Iteration 2698, loss = 0.98662211
Iteration 2699, loss = 2.08596492
Iteration 2700, loss = 2.11662887
Iteration 2701, loss = 0.84725521
Iteration 2702, loss = 1.87942116
Iteration 2703, loss = 1.26912547
Iteration 2704, loss = 1.47753800
Iteration 2705, loss = 1.63644709
Iteration 2706, loss = 0.83692227
Iteration 2707, loss = 1.45034125
Iteration 2708, loss = 0.85694089
Iteration 2709, loss = 1.35633609
Iteration 2710, loss = 1.10748695
Iteration 2711, loss = 1.10099782
Iteration 2712, loss = 1.18723410
Iteration 2713, loss = 0.86219675
Iteration 2714, loss = 1.11167868
Iteration 2715, loss = 0.78102226
Iteration 2716, loss = 1.04341111
Iteration 2717, loss = 0.77016119
Iteration 2718, loss = 0.99785956
Iteration 2719, loss = 0.77960504
Iteration 2720, loss = 0.96442560
Iteration 2721, loss = 0.79204271
Iteration 2722, loss = 0.93711363
Iteration 2723, loss = 0.80130652
Iteration 2724, loss = 0.91297308
Iteration 2725, loss = 0.80680453
Iteration 2726, loss = 0.89172193
Iteration 2727, loss = 0.80780037
Iteration 2728, loss = 0.87290039
Iteration 2729, loss = 0.80552243
Iteration 2730, loss = 0.85633610
Iteration 2731, loss = 0.80068351
Iteration 2732, loss = 0.84223030
Iteration 2733, loss = 0.79511985
Iteration 2734, loss = 0.83042587
Iteration 2735, loss = 0.78920200
Iteration 2736, loss = 0.82048505
Iteration 2737, loss = 0.78375721
Iteration 2738, loss = 0.81229908
Iteration 2739, loss = 0.77907616
Iteration 2740, loss = 0.80538628
Iteration 2741, loss = 0.77499130
Iteration 2742, loss = 0.79931228
Iteration 2743, loss = 0.77139616
Iteration 2744, loss = 0.79389759
Iteration 2745, loss = 0.76838308
Iteration 2746, loss = 0.78904430
Iteration 2747, loss = 0.76586598
Iteration 2748, loss = 0.78464765
Iteration 2749, loss = 0.76383090
Iteration 2750, loss = 0.78068159
Iteration 2751, loss = 0.76219765
Iteration 2752, loss = 0.77707949
Iteration 2753, loss = 0.76090672
Iteration 2754, loss = 0.77381192
Iteration 2755, loss = 0.75985872
Iteration 2756, loss = 0.77082174
Iteration 2757, loss = 0.75899872
Iteration 2758, loss = 0.76812048
Iteration 2759, loss = 0.75823786
Iteration 2760, loss = 0.75805023
Iteration 2761, loss = 0.75108184
Iteration 2762, loss = 0.76263720
Iteration 2763, loss = 0.74952823
Iteration 2764, loss = 0.79255552
Iteration 2765, loss = 0.81643441
Iteration 2766, loss = 0.78536312
Iteration 2767, loss = 0.79303359
Iteration 2768, loss = 0.76836606
Iteration 2769, loss = 0.78221070
Iteration 2770, loss = 0.76899831
Iteration 2771, loss = 0.78480612
Iteration 2772, loss = 0.77307272
Iteration 2773, loss = 0.78342091
Iteration 2774, loss = 0.77088735
Iteration 2775, loss = 0.77878249
Iteration 2776, loss = 0.76794899
Iteration 2777, loss = 0.77553331
Iteration 2778, loss = 0.76731593
Iteration 2779, loss = 0.77394458
Iteration 2780, loss = 0.76678393
Iteration 2781, loss = 0.77221860
Iteration 2782, loss = 0.76585745
Iteration 2783, loss = 0.77043914
Iteration 2784, loss = 0.76512670
Iteration 2785, loss = 0.76915107
Iteration 2786, loss = 0.76469870
Iteration 2787, loss = 0.76807661
Iteration 2788, loss = 0.76413279
Iteration 2789, loss = 0.76664566
Iteration 2790, loss = 0.76306762
Iteration 2791, loss = 0.76510412
Iteration 2792, loss = 0.76221941
Iteration 2793, loss = 0.76403975
Iteration 2794, loss = 0.76165696
Iteration 2795, loss = 0.76164156
Iteration 2796, loss = 0.76020750
Iteration 2797, loss = 0.76051349
Iteration 2798, loss = 0.75916454
Iteration 2799, loss = 0.75888545
Iteration 2800, loss = 0.75765157
Iteration 2801, loss = 0.75676586
Iteration 2802, loss = 0.75548982
Iteration 2803, loss = 0.75324483
Iteration 2804, loss = 0.75084755
Iteration 2805, loss = 0.70120565
Iteration 2806, loss = 0.77711645
Iteration 2807, loss = 0.80970246
Iteration 2808, loss = 0.78639329
Iteration 2809, loss = 0.80917034
Iteration 2810, loss = 0.78217720
Iteration 2811, loss = 0.79788445
Iteration 2812, loss = 0.77215982
Iteration 2813, loss = 0.78799301
Iteration 2814, loss = 0.76807468
Iteration 2815, loss = 0.78466663
Iteration 2816, loss = 0.76909527
Iteration 2817, loss = 0.78443689
Iteration 2818, loss = 0.77081824
Iteration 2819, loss = 0.78339741
Iteration 2820, loss = 0.76902832
Iteration 2821, loss = 0.79370973
Iteration 2822, loss = 0.77409283
Iteration 2823, loss = 0.78833533
Iteration 2824, loss = 0.77623082
Iteration 2825, loss = 0.78185677
Iteration 2826, loss = 0.77670876
Iteration 2827, loss = 0.77597321
Iteration 2828, loss = 0.77668953
Iteration 2829, loss = 0.77226240
Iteration 2830, loss = 0.77703800
Iteration 2831, loss = 0.77075499
Iteration 2832, loss = 0.77702262
Iteration 2833, loss = 0.77005890
Iteration 2834, loss = 0.77575749
Iteration 2835, loss = 0.76928662
Iteration 2836, loss = 0.77353402
Iteration 2837, loss = 0.76865578
Iteration 2838, loss = 0.77126154
Iteration 2839, loss = 0.76830811
Iteration 2840, loss = 0.76908349
Iteration 2841, loss = 0.76757435
Iteration 2842, loss = 0.76695211
Iteration 2843, loss = 0.76674208
Iteration 2844, loss = 0.76449037
Iteration 2845, loss = 0.76409435
Iteration 2846, loss = 0.76161015
Iteration 2847, loss = 0.76149243
Iteration 2848, loss = 0.75814149
Iteration 2849, loss = 0.75389722
Iteration 2850, loss = 0.66479940
Iteration 2851, loss = 0.77559624
Iteration 2852, loss = 0.86257897
Iteration 2853, loss = 0.78718122
Iteration 2854, loss = 0.84878967
Iteration 2855, loss = 0.79688045
Iteration 2856, loss = 0.82622865
Iteration 2857, loss = 0.80092799
Iteration 2858, loss = 0.80105191
Iteration 2859, loss = 0.80174283
Iteration 2860, loss = 0.78285562
Iteration 2861, loss = 0.80123155
Iteration 2862, loss = 0.77492130
Iteration 2863, loss = 0.79917879
Iteration 2864, loss = 0.77479639
Iteration 2865, loss = 0.79463516
Iteration 2866, loss = 0.77825984
Iteration 2867, loss = 0.78814468
Iteration 2868, loss = 0.78183228
Iteration 2869, loss = 0.78150617
Iteration 2870, loss = 0.78374980
Iteration 2871, loss = 0.77665265
Iteration 2872, loss = 0.78369093
Iteration 2873, loss = 0.77426389
Iteration 2874, loss = 0.78165292
Iteration 2875, loss = 0.77351749
Iteration 2876, loss = 0.77674293
Iteration 2877, loss = 0.77684652
Iteration 2878, loss = 0.77825566
Iteration 2879, loss = 0.77793814
Iteration 2880, loss = 0.77485394
Iteration 2881, loss = 0.77416721
Iteration 2882, loss = 0.77050997
Iteration 2883, loss = 0.77109941
Iteration 2884, loss = 0.76888580
Iteration 2885, loss = 0.76886077
Iteration 2886, loss = 0.76782653
Iteration 2887, loss = 0.76716609
Iteration 2888, loss = 0.76623896
Iteration 2889, loss = 0.76463735
Iteration 2890, loss = 0.76302656
Iteration 2891, loss = 0.76051223
Iteration 2892, loss = 0.75887504
Iteration 2893, loss = 0.75572451
Iteration 2894, loss = 0.74629617
Iteration 2895, loss = 0.76097938
Iteration 2896, loss = 0.86220104
Iteration 2897, loss = 1.06445282
Iteration 2898, loss = 0.80833269
Iteration 2899, loss = 1.07371018
Iteration 2900, loss = 0.83268849
Iteration 2901, loss = 1.02067430
Iteration 2902, loss = 0.83793843
Iteration 2903, loss = 0.93467498
Iteration 2904, loss = 0.84598416
Iteration 2905, loss = 0.85230538
Iteration 2906, loss = 0.86213032
Iteration 2907, loss = 0.79959415
Iteration 2908, loss = 0.86891156
Iteration 2909, loss = 0.78262032
Iteration 2910, loss = 0.85458445
Iteration 2911, loss = 0.78658706
Iteration 2912, loss = 0.82528298
Iteration 2913, loss = 0.79865913
Iteration 2914, loss = 0.75508233
Iteration 2915, loss = 0.99070615
Iteration 2916, loss = 0.83448040
Iteration 2917, loss = 0.92849439
Iteration 2918, loss = 0.84470487
Iteration 2919, loss = 0.87470512
Iteration 2920, loss = 0.85054773
Iteration 2921, loss = 0.83164826
Iteration 2922, loss = 0.85437083
Iteration 2923, loss = 0.80371782
Iteration 2924, loss = 0.85641856
Iteration 2925, loss = 0.79009857
Iteration 2926, loss = 0.85418271
Iteration 2927, loss = 0.78545453
Iteration 2928, loss = 0.84561579
Iteration 2929, loss = 0.78524937
Iteration 2930, loss = 0.83098766
Iteration 2931, loss = 0.78740661
Iteration 2932, loss = 0.81447370
Iteration 2933, loss = 0.79140262
Iteration 2934, loss = 0.80035955
Iteration 2935, loss = 0.79590003
Iteration 2936, loss = 0.78110648
Iteration 2937, loss = 0.83242656
Iteration 2938, loss = 0.79650876
Iteration 2939, loss = 0.84547047
Iteration 2940, loss = 0.80836481
Iteration 2941, loss = 0.83192668
Iteration 2942, loss = 0.81586007
Iteration 2943, loss = 0.82819345
Iteration 2944, loss = 0.81174936
Iteration 2945, loss = 0.81033230
Iteration 2946, loss = 0.80363169
Iteration 2947, loss = 0.79807261
Iteration 2948, loss = 0.80031473
Iteration 2949, loss = 0.79053191
Iteration 2950, loss = 0.79188597
Iteration 2951, loss = 0.79490053
Iteration 2952, loss = 0.79366055
Iteration 2953, loss = 0.79140335
Iteration 2954, loss = 0.78416514
Iteration 2955, loss = 0.80808405
Iteration 2956, loss = 0.80650357
Iteration 2957, loss = 0.80205643
Iteration 2958, loss = 0.80653137
Iteration 2959, loss = 0.79224938
Iteration 2960, loss = 0.82265048
Iteration 2961, loss = 0.79528209
Iteration 2962, loss = 0.81766053
Iteration 2963, loss = 0.79807900
Iteration 2964, loss = 0.80235777
Iteration 2965, loss = 0.81945943
Iteration 2966, loss = 0.79125255
Iteration 2967, loss = 0.81587141
Iteration 2968, loss = 0.79068418
Iteration 2969, loss = 0.80706065
Iteration 2970, loss = 0.79109362
Iteration 2971, loss = 0.80038793
Iteration 2972, loss = 0.79353094
Iteration 2973, loss = 0.79519189
Iteration 2974, loss = 0.79447702
Iteration 2975, loss = 0.79034727
Iteration 2976, loss = 0.79419300
Iteration 2977, loss = 0.78725914
Iteration 2978, loss = 0.79318085
Iteration 2979, loss = 0.78523837
Iteration 2980, loss = 0.78568458
Iteration 2981, loss = 0.78536888
Iteration 2982, loss = 0.78111509
Iteration 2983, loss = 0.77558366
Iteration 2984, loss = 0.80183537
Iteration 2985, loss = 0.80428939
Iteration 2986, loss = 0.80698225
Iteration 2987, loss = 0.80206731
Iteration 2988, loss = 0.79574338
Iteration 2989, loss = 0.79262666
Iteration 2990, loss = 0.78730834
Iteration 2991, loss = 0.78960068
Iteration 2992, loss = 0.78719299
Iteration 2993, loss = 0.79176849
Iteration 2994, loss = 0.78901666
Iteration 2995, loss = 0.79189815
Iteration 2996, loss = 0.78806630
Iteration 2997, loss = 0.78941095
Iteration 2998, loss = 0.78621264
Iteration 2999, loss = 0.78704614
Iteration 3000, loss = 0.78523984
Iteration 3001, loss = 0.78573755
Iteration 3002, loss = 0.78484804
Iteration 3003, loss = 0.78457464
Iteration 3004, loss = 0.78406965
Iteration 3005, loss = 0.78302215
Iteration 3006, loss = 0.78273832
Iteration 3007, loss = 0.78144643
Iteration 3008, loss = 0.80236089
Iteration 3009, loss = 0.90353038
Iteration 3010, loss = 0.79709279
Iteration 3011, loss = 0.90015892
Iteration 3012, loss = 0.81917330
Iteration 3013, loss = 0.88973208
Iteration 3014, loss = 0.82304679
Iteration 3015, loss = 0.86301244
Iteration 3016, loss = 0.81222550
Iteration 3017, loss = 0.83115906
Iteration 3018, loss = 0.80106475
Iteration 3019, loss = 0.80734407
Iteration 3020, loss = 0.79741655
Iteration 3021, loss = 0.79502894
Iteration 3022, loss = 0.79909934
Iteration 3023, loss = 0.78972088
Iteration 3024, loss = 0.80103404
Iteration 3025, loss = 0.78637206
Iteration 3026, loss = 0.79980502
Iteration 3027, loss = 0.78284843
Iteration 3028, loss = 0.79544290
Iteration 3029, loss = 0.77952358
Iteration 3030, loss = 0.79016111
Iteration 3031, loss = 0.77731506
Iteration 3032, loss = 0.78492109
Iteration 3033, loss = 0.77603447
Iteration 3034, loss = 0.78024815
Iteration 3035, loss = 0.77496075
Iteration 3036, loss = 0.77615372
Iteration 3037, loss = 0.77385607
Iteration 3038, loss = 0.77181533
Iteration 3039, loss = 0.77168497
Iteration 3040, loss = 0.76847532
Iteration 3041, loss = 0.76911461
Iteration 3042, loss = 0.76453595
Iteration 3043, loss = 0.76426877
Iteration 3044, loss = 0.75742691
Iteration 3045, loss = 0.72989913
Iteration 3046, loss = 0.80751193
Iteration 3047, loss = 0.86410748
Iteration 3048, loss = 0.80425513
Iteration 3049, loss = 0.85415607
Iteration 3050, loss = 0.78872838
Iteration 3051, loss = 0.83803080
Iteration 3052, loss = 0.77696792
Iteration 3053, loss = 0.82906233
Iteration 3054, loss = 0.77529035
Iteration 3055, loss = 0.82497016
Iteration 3056, loss = 0.77539521
Iteration 3057, loss = 0.81783052
Iteration 3058, loss = 0.77256871
Iteration 3059, loss = 0.80779426
Iteration 3060, loss = 0.76950519
Iteration 3061, loss = 0.79857817
Iteration 3062, loss = 0.76840392
Iteration 3063, loss = 0.79138785
Iteration 3064, loss = 0.76896028
Iteration 3065, loss = 0.78565195
Iteration 3066, loss = 0.76982741
Iteration 3067, loss = 0.78031825
Iteration 3068, loss = 0.76997523
Iteration 3069, loss = 0.77517544
Iteration 3070, loss = 0.76952189
Iteration 3071, loss = 0.77081867
Iteration 3072, loss = 0.76902514
Iteration 3073, loss = 0.76764498
Iteration 3074, loss = 0.76856591
Iteration 3075, loss = 0.76536364
Iteration 3076, loss = 0.76780856
Iteration 3077, loss = 0.76356216
Iteration 3078, loss = 0.76666494
Iteration 3079, loss = 0.76212493
Iteration 3080, loss = 0.76527754
Iteration 3081, loss = 0.76099901
Iteration 3082, loss = 0.76377626
Iteration 3083, loss = 0.76011930
Iteration 3084, loss = 0.76227717
Iteration 3085, loss = 0.75940916
Iteration 3086, loss = 0.76081893
Iteration 3087, loss = 0.75871352
Iteration 3088, loss = 0.75927878
Iteration 3089, loss = 0.75760088
Iteration 3090, loss = 0.75740794
Iteration 3091, loss = 0.75658707
Iteration 3092, loss = 0.75588139
Iteration 3093, loss = 0.75483241
Iteration 3094, loss = 0.75286971
Iteration 3095, loss = 0.75220498
Iteration 3096, loss = 0.75045139
Iteration 3097, loss = 0.74889326
Iteration 3098, loss = 0.74532040
Iteration 3099, loss = 0.73454814
Iteration 3100, loss = 0.85400749
Iteration 3101, loss = 0.89427273
Iteration 3102, loss = 0.83405305
Iteration 3103, loss = 0.89568532
Iteration 3104, loss = 0.80537557
Iteration 3105, loss = 0.87401425
Iteration 3106, loss = 0.76486740
Iteration 3107, loss = 0.75222074
Iteration 3108, loss = 0.97487796
Iteration 3109, loss = 0.76798117
Iteration 3110, loss = 0.94468356
Iteration 3111, loss = 0.77315019
Iteration 3112, loss = 0.92224839
Iteration 3113, loss = 0.77765793
Iteration 3114, loss = 0.90469332
Iteration 3115, loss = 0.78085632
Iteration 3116, loss = 0.88903736
Iteration 3117, loss = 0.77870340
Iteration 3118, loss = 0.86755466
Iteration 3119, loss = 0.75774160
Iteration 3120, loss = 0.79476524
Iteration 3121, loss = 0.77100779
Iteration 3122, loss = 0.79387787
Iteration 3123, loss = 0.76645989
Iteration 3124, loss = 0.78141456
Iteration 3125, loss = 0.76019996
Iteration 3126, loss = 0.77350389
Iteration 3127, loss = 0.75817475
Iteration 3128, loss = 0.77040089
Iteration 3129, loss = 0.75926048
Iteration 3130, loss = 0.76836569
Iteration 3131, loss = 0.75912113
Iteration 3132, loss = 0.76532848
Iteration 3133, loss = 0.75772413
Iteration 3134, loss = 0.76193305
Iteration 3135, loss = 0.75633430
Iteration 3136, loss = 0.75964748
Iteration 3137, loss = 0.75582773
Iteration 3138, loss = 0.75784410
Iteration 3139, loss = 0.75493975
Iteration 3140, loss = 0.75615994
Iteration 3141, loss = 0.75427498
Iteration 3142, loss = 0.75491184
Iteration 3143, loss = 0.75374899
Iteration 3144, loss = 0.75383530
Iteration 3145, loss = 0.75305286
Iteration 3146, loss = 0.75263113
Iteration 3147, loss = 0.75212516
Iteration 3148, loss = 0.75145677
Iteration 3149, loss = 0.75124401
Iteration 3150, loss = 0.75048386
Iteration 3151, loss = 0.75051573
Iteration 3152, loss = 0.74976084
Iteration 3153, loss = 0.74991604
Iteration 3154, loss = 0.74909270
Iteration 3155, loss = 0.74920164
Iteration 3156, loss = 0.74831163
Iteration 3157, loss = 0.74838615
Iteration 3158, loss = 0.74755012
Iteration 3159, loss = 0.74764822
Iteration 3160, loss = 0.74691809
Iteration 3161, loss = 0.74699726
Iteration 3162, loss = 0.74631480
Iteration 3163, loss = 0.74630998
Iteration 3164, loss = 0.74566882
Iteration 3165, loss = 0.74559036
Iteration 3166, loss = 0.74494873
Iteration 3167, loss = 0.73884157
Iteration 3168, loss = 0.75970992
Iteration 3169, loss = 0.79323035
Iteration 3170, loss = 0.76973447
Iteration 3171, loss = 0.76429343
Iteration 3172, loss = 0.78329825
Iteration 3173, loss = 0.76043361
Iteration 3174, loss = 0.75603049
Iteration 3175, loss = 0.76695970
Iteration 3176, loss = 0.74833030
Iteration 3177, loss = 0.76679242
Iteration 3178, loss = 0.84153655
Iteration 3179, loss = 0.77052424
Iteration 3180, loss = 0.79991157
Iteration 3181, loss = 0.80720635
Iteration 3182, loss = 0.76187295
Iteration 3183, loss = 0.80835509
Iteration 3184, loss = 0.75964294
Iteration 3185, loss = 0.78119831
Iteration 3186, loss = 0.77692464
Iteration 3187, loss = 0.75900611
Iteration 3188, loss = 0.78496090
Iteration 3189, loss = 0.75559849
Iteration 3190, loss = 0.77433562
Iteration 3191, loss = 0.76351556
Iteration 3192, loss = 0.75917921
Iteration 3193, loss = 0.76935983
Iteration 3194, loss = 0.75264101
Iteration 3195, loss = 0.76604540
Iteration 3196, loss = 0.75573462
Iteration 3197, loss = 0.75802989
Iteration 3198, loss = 0.76024578
Iteration 3199, loss = 0.75202557
Iteration 3200, loss = 0.75956915
Iteration 3201, loss = 0.75135203
Iteration 3202, loss = 0.75492703
Iteration 3203, loss = 0.75370192
Iteration 3204, loss = 0.75066148
Iteration 3205, loss = 0.75444573
Iteration 3206, loss = 0.74915420
Iteration 3207, loss = 0.75204082
Iteration 3208, loss = 0.74973577
Iteration 3209, loss = 0.74887791
Iteration 3210, loss = 0.75018325
Iteration 3211, loss = 0.74709377
Iteration 3212, loss = 0.74896423
Iteration 3213, loss = 0.74673782
Iteration 3214, loss = 0.74672657
Iteration 3215, loss = 0.74693252
Iteration 3216, loss = 0.74529105
Iteration 3217, loss = 0.74627365
Iteration 3218, loss = 0.74453812
Iteration 3219, loss = 0.74466085
Iteration 3220, loss = 0.74421330
Iteration 3221, loss = 0.74334483
Iteration 3222, loss = 0.74382571
Iteration 3223, loss = 0.74274179
Iteration 3224, loss = 0.74293792
Iteration 3225, loss = 0.74236459
Iteration 3226, loss = 0.74179663
Iteration 3227, loss = 0.74174703
Iteration 3228, loss = 0.74089212
Iteration 3229, loss = 0.74100299
Iteration 3230, loss = 0.74055438
Iteration 3231, loss = 0.74025560
Iteration 3232, loss = 0.74007827
Iteration 3233, loss = 0.73945361
Iteration 3234, loss = 0.73935263
Iteration 3235, loss = 0.73886203
Iteration 3236, loss = 0.73850220
Iteration 3237, loss = 0.73807423
Iteration 3238, loss = 0.73746102
Iteration 3239, loss = 0.73725496
Iteration 3240, loss = 0.73699190
Iteration 3241, loss = 0.73689291
Iteration 3242, loss = 0.73647550
Iteration 3243, loss = 0.73606830
Iteration 3244, loss = 0.73593803
Iteration 3245, loss = 0.73562515
Iteration 3246, loss = 0.73531942
Iteration 3247, loss = 0.73486167
Iteration 3248, loss = 0.73425164
Iteration 3249, loss = 0.73376050
Iteration 3250, loss = 0.73338950
Iteration 3251, loss = 0.73310616
Iteration 3252, loss = 0.73268723
Iteration 3253, loss = 0.73229408
Iteration 3254, loss = 0.73209075
Iteration 3255, loss = 0.73193018
Iteration 3256, loss = 0.73153584
Iteration 3257, loss = 0.73129696
Iteration 3258, loss = 0.73101381
Iteration 3259, loss = 0.73037673
Iteration 3260, loss = 0.72952436
Iteration 3261, loss = 0.72933190
Iteration 3262, loss = 0.72916799
Iteration 3263, loss = 0.72870363
Iteration 3264, loss = 0.72812905
Iteration 3265, loss = 0.72601016
Iteration 3266, loss = 0.72743762
Iteration 3267, loss = 0.73563078
Iteration 3268, loss = 0.73093328
Iteration 3269, loss = 0.73391947
Iteration 3270, loss = 0.73389329
Iteration 3271, loss = 0.72681981
Iteration 3272, loss = 0.72677041
Iteration 3273, loss = 0.72024457
Iteration 3274, loss = 0.69208022
Iteration 3275, loss = 0.98602320
Iteration 3276, loss = 1.20792741
Iteration 3277, loss = 0.87204924
Iteration 3278, loss = 1.33525159
Iteration 3279, loss = 0.87988671
Iteration 3280, loss = 1.42117532
Iteration 3281, loss = 0.98701939
Iteration 3282, loss = 1.43567446
Iteration 3283, loss = 1.16909310
Iteration 3284, loss = 1.21512137
Iteration 3285, loss = 1.22160532
Iteration 3286, loss = 0.99035570
Iteration 3287, loss = 1.11665262
Iteration 3288, loss = 0.89378814
Iteration 3289, loss = 1.00160215
Iteration 3290, loss = 0.86577625
Iteration 3291, loss = 0.90944698
Iteration 3292, loss = 0.86603580
Iteration 3293, loss = 0.84593268
Iteration 3294, loss = 0.87702925
Iteration 3295, loss = 0.80524046
Iteration 3296, loss = 0.88738004
Iteration 3297, loss = 0.78036997
Iteration 3298, loss = 0.89136774
Iteration 3299, loss = 0.76485225
Iteration 3300, loss = 0.88711741
Iteration 3301, loss = 0.75497743
Iteration 3302, loss = 0.87549002
Iteration 3303, loss = 0.74892491
Iteration 3304, loss = 0.85811962
Iteration 3305, loss = 0.74652338
Iteration 3306, loss = 0.83708571
Iteration 3307, loss = 0.74757908
Iteration 3308, loss = 0.81419961
Iteration 3309, loss = 0.75154074
Iteration 3310, loss = 0.79210886
Iteration 3311, loss = 0.75719486
Iteration 3312, loss = 0.77295430
Iteration 3313, loss = 0.76262818
Iteration 3314, loss = 0.75824749
Iteration 3315, loss = 0.76570309
Iteration 3316, loss = 0.74320901
Iteration 3317, loss = 0.74798856
Iteration 3318, loss = 0.74283320
Iteration 3319, loss = 0.74637005
Iteration 3320, loss = 0.74465136
Iteration 3321, loss = 0.74357047
Iteration 3322, loss = 0.74401310
Iteration 3323, loss = 0.73997410
Iteration 3324, loss = 0.77143131
Iteration 3325, loss = 0.76445612
Iteration 3326, loss = 0.75928255
Iteration 3327, loss = 0.77507621
Iteration 3328, loss = 0.74811023
Iteration 3329, loss = 0.77014980
Iteration 3330, loss = 0.73748929
Iteration 3331, loss = 0.76082305
Iteration 3332, loss = 0.73723859
Iteration 3333, loss = 0.75225892
Iteration 3334, loss = 0.73891720
Iteration 3335, loss = 0.74014248
Iteration 3336, loss = 0.73264461
Iteration 3337, loss = 0.78467901
Iteration 3338, loss = 0.79077351
Iteration 3339, loss = 0.77000282
Iteration 3340, loss = 0.79490727
Iteration 3341, loss = 0.75617281
Iteration 3342, loss = 0.79186170
Iteration 3343, loss = 0.74470854
Iteration 3344, loss = 0.78407188
Iteration 3345, loss = 0.74012129
Iteration 3346, loss = 0.77663992
Iteration 3347, loss = 0.74111737
Iteration 3348, loss = 0.76875165
Iteration 3349, loss = 0.74353320
Iteration 3350, loss = 0.75951395
Iteration 3351, loss = 0.74523915
Iteration 3352, loss = 0.75050767
Iteration 3353, loss = 0.74644943
Iteration 3354, loss = 0.74367221
Iteration 3355, loss = 0.74716318
Iteration 3356, loss = 0.73924996
Iteration 3357, loss = 0.74647941
Iteration 3358, loss = 0.73327429
Iteration 3359, loss = 0.75895897
Iteration 3360, loss = 0.74959666
Iteration 3361, loss = 0.75180726
Iteration 3362, loss = 0.75607776
Iteration 3363, loss = 0.73837523
Iteration 3364, loss = 0.75058334
Iteration 3365, loss = 0.73729427
Iteration 3366, loss = 0.74384867
Iteration 3367, loss = 0.74346488
Iteration 3368, loss = 0.73693360
Iteration 3369, loss = 0.74333675
Iteration 3370, loss = 0.73414916
Iteration 3371, loss = 0.73945245
Iteration 3372, loss = 0.73657240
Iteration 3373, loss = 0.73353437
Iteration 3374, loss = 0.73679345
Iteration 3375, loss = 0.73260394
Iteration 3376, loss = 0.73397603
Iteration 3377, loss = 0.73153162
Iteration 3378, loss = 0.71972048
Iteration 3379, loss = 0.74449619
Iteration 3380, loss = 0.74275690
Iteration 3381, loss = 0.73529838
Iteration 3382, loss = 0.74343987
Iteration 3383, loss = 0.73051050
Iteration 3384, loss = 0.73749470
Iteration 3385, loss = 0.73361176
Iteration 3386, loss = 0.73253258
Iteration 3387, loss = 0.73669409
Iteration 3388, loss = 0.72981505
Iteration 3389, loss = 0.73444221
Iteration 3390, loss = 0.73019396
Iteration 3391, loss = 0.73034525
Iteration 3392, loss = 0.73133237
Iteration 3393, loss = 0.72742763
Iteration 3394, loss = 0.72989611
Iteration 3395, loss = 0.72612008
Iteration 3396, loss = 0.72610636
Iteration 3397, loss = 0.72444567
Iteration 3398, loss = 0.72002851
Iteration 3399, loss = 0.69169434
Iteration 3400, loss = 0.73380133
Iteration 3401, loss = 0.77484201
Iteration 3402, loss = 0.74688913
Iteration 3403, loss = 0.76612515
Iteration 3404, loss = 0.75870483
Iteration 3405, loss = 0.75212733
Iteration 3406, loss = 0.76112002
Iteration 3407, loss = 0.74074295
Iteration 3408, loss = 0.75590213
Iteration 3409, loss = 0.73832901
Iteration 3410, loss = 0.74863645
Iteration 3411, loss = 0.74277576
Iteration 3412, loss = 0.74309798
Iteration 3413, loss = 0.74786531
Iteration 3414, loss = 0.74077117
Iteration 3415, loss = 0.74912469
Iteration 3416, loss = 0.74114668
Iteration 3417, loss = 0.74657337
Iteration 3418, loss = 0.74291815
Iteration 3419, loss = 0.74300376
Iteration 3420, loss = 0.74445405
Iteration 3421, loss = 0.74082942
Iteration 3422, loss = 0.74450561
Iteration 3423, loss = 0.74046394
Iteration 3424, loss = 0.74292611
Iteration 3425, loss = 0.74093027
Iteration 3426, loss = 0.74072599
Iteration 3427, loss = 0.74116473
Iteration 3428, loss = 0.73913453
Iteration 3429, loss = 0.74068855
Iteration 3430, loss = 0.73858728
Iteration 3431, loss = 0.73960339
Iteration 3432, loss = 0.73862539
Iteration 3433, loss = 0.73835806
Iteration 3434, loss = 0.73854102
Iteration 3435, loss = 0.73735822
Iteration 3436, loss = 0.73792427
Iteration 3437, loss = 0.73669292
Iteration 3438, loss = 0.73686003
Iteration 3439, loss = 0.73618701
Iteration 3440, loss = 0.73570020
Iteration 3441, loss = 0.73558403
Iteration 3442, loss = 0.73471438
Iteration 3443, loss = 0.73474110
Iteration 3444, loss = 0.73390796
Iteration 3445, loss = 0.73349650
Iteration 3446, loss = 0.73288871
Iteration 3447, loss = 0.73256716
Iteration 3448, loss = 0.73203617
Iteration 3449, loss = 0.73117127
Iteration 3450, loss = 0.73049923
Iteration 3451, loss = 0.73029204
Iteration 3452, loss = 0.72935038
Iteration 3453, loss = 0.72843283
Iteration 3454, loss = 0.72730594
Iteration 3455, loss = 0.72605319
Iteration 3456, loss = 0.72441337
Iteration 3457, loss = 0.72233877
Iteration 3458, loss = 0.71993139
Iteration 3459, loss = 0.71307435
Iteration 3460, loss = 0.76641544
Iteration 3461, loss = 0.79402525
Iteration 3462, loss = 0.74652663
Iteration 3463, loss = 0.79500809
Iteration 3464, loss = 0.71862667
Iteration 3465, loss = 0.89437432
Iteration 3466, loss = 0.94603325
Iteration 3467, loss = 0.80120289
Iteration 3468, loss = 0.97837815
Iteration 3469, loss = 0.81011073
Iteration 3470, loss = 0.97195453
Iteration 3471, loss = 0.79168486
Iteration 3472, loss = 0.94042624
Iteration 3473, loss = 0.76628941
Iteration 3474, loss = 0.90826759
Iteration 3475, loss = 0.74975517
Iteration 3476, loss = 0.88482877
Iteration 3477, loss = 0.74522297
Iteration 3478, loss = 0.86912733
Iteration 3479, loss = 0.74708063
Iteration 3480, loss = 0.85329163
Iteration 3481, loss = 0.74852967
Iteration 3482, loss = 0.83431669
Iteration 3483, loss = 0.74832345
Iteration 3484, loss = 0.81261846
Iteration 3485, loss = 0.74730518
Iteration 3486, loss = 0.79072510
Iteration 3487, loss = 0.74512108
Iteration 3488, loss = 0.76306675
Iteration 3489, loss = 0.78954172
Iteration 3490, loss = 0.74501910
Iteration 3491, loss = 0.78685581
Iteration 3492, loss = 0.74595334
Iteration 3493, loss = 0.77896365
Iteration 3494, loss = 0.74418430
Iteration 3495, loss = 0.76990569
Iteration 3496, loss = 0.74206646
Iteration 3497, loss = 0.76145778
Iteration 3498, loss = 0.74114462
Iteration 3499, loss = 0.75511611
Iteration 3500, loss = 0.74163403
Iteration 3501, loss = 0.75066462
Iteration 3502, loss = 0.74255885
Iteration 3503, loss = 0.74697101
Iteration 3504, loss = 0.74281476
Iteration 3505, loss = 0.74353956
Iteration 3506, loss = 0.74242249
Iteration 3507, loss = 0.74065816
Iteration 3508, loss = 0.74171623
Iteration 3509, loss = 0.73843719
Iteration 3510, loss = 0.74080213
Iteration 3511, loss = 0.73680193
Iteration 3512, loss = 0.73977420
Iteration 3513, loss = 0.73567979
Iteration 3514, loss = 0.73868865
Iteration 3515, loss = 0.73487202
Iteration 3516, loss = 0.73738179
Iteration 3517, loss = 0.73404039
Iteration 3518, loss = 0.73616162
Iteration 3519, loss = 0.73363796
Iteration 3520, loss = 0.73491553
Iteration 3521, loss = 0.73315262
Iteration 3522, loss = 0.73373428
Iteration 3523, loss = 0.73247580
Iteration 3524, loss = 0.73255113
Iteration 3525, loss = 0.73163647
Iteration 3526, loss = 0.73134135
Iteration 3527, loss = 0.73112249
Iteration 3528, loss = 0.73051379
Iteration 3529, loss = 0.73036666
Iteration 3530, loss = 0.72941241
Iteration 3531, loss = 0.72942441
Iteration 3532, loss = 0.72857011
Iteration 3533, loss = 0.72844230
Iteration 3534, loss = 0.72699062
Iteration 3535, loss = 0.72665301
Iteration 3536, loss = 0.72384472
Iteration 3537, loss = 0.70523184
Iteration 3538, loss = 0.76003719
Iteration 3539, loss = 0.78663578
Iteration 3540, loss = 0.75071108
Iteration 3541, loss = 0.78753136
Iteration 3542, loss = 0.73855028
Iteration 3543, loss = 0.77894691
Iteration 3544, loss = 0.73038899
Iteration 3545, loss = 0.76885527
Iteration 3546, loss = 0.72996291
Iteration 3547, loss = 0.76091793
Iteration 3548, loss = 0.73431228
Iteration 3549, loss = 0.75252508
Iteration 3550, loss = 0.73774941
Iteration 3551, loss = 0.74318144
Iteration 3552, loss = 0.73888129
Iteration 3553, loss = 0.73493602
Iteration 3554, loss = 0.73946918
Iteration 3555, loss = 0.73032764
Iteration 3556, loss = 0.73914152
Iteration 3557, loss = 0.72809040
Iteration 3558, loss = 0.73734254
Iteration 3559, loss = 0.72683118
Iteration 3560, loss = 0.73399033
Iteration 3561, loss = 0.72578949
Iteration 3562, loss = 0.72909884
Iteration 3563, loss = 0.72445829
Iteration 3564, loss = 0.72467444
Iteration 3565, loss = 0.72197242
Iteration 3566, loss = 0.72125430
Iteration 3567, loss = 0.71789116
Iteration 3568, loss = 0.67396157
Iteration 3569, loss = 0.80227038
Iteration 3570, loss = 0.84892252
Iteration 3571, loss = 0.77790744
Iteration 3572, loss = 0.85681514
Iteration 3573, loss = 0.75331848
Iteration 3574, loss = 0.84264807
Iteration 3575, loss = 0.73560194
Iteration 3576, loss = 0.82260719
Iteration 3577, loss = 0.73558168
Iteration 3578, loss = 0.80432973
Iteration 3579, loss = 0.74631446
Iteration 3580, loss = 0.78523883
Iteration 3581, loss = 0.75626473
Iteration 3582, loss = 0.76373267
Iteration 3583, loss = 0.76133076
Iteration 3584, loss = 0.74685611
Iteration 3585, loss = 0.76377432
Iteration 3586, loss = 0.73806709
Iteration 3587, loss = 0.76121381
Iteration 3588, loss = 0.73346074
Iteration 3589, loss = 0.75447040
Iteration 3590, loss = 0.73304956
Iteration 3591, loss = 0.74102735
Iteration 3592, loss = 0.71388305
Iteration 3593, loss = 0.79380569
Iteration 3594, loss = 1.09755658
Iteration 3595, loss = 0.79494886
Iteration 3596, loss = 1.11080449
Iteration 3597, loss = 0.83369922
Iteration 3598, loss = 1.09298371
Iteration 3599, loss = 0.84103327
Iteration 3600, loss = 1.05626913
Iteration 3601, loss = 0.84000589
Iteration 3602, loss = 1.02125332
Iteration 3603, loss = 0.84458327
Iteration 3604, loss = 0.99234747
Iteration 3605, loss = 0.85382065
Iteration 3606, loss = 0.96894219
Iteration 3607, loss = 0.85836598
Iteration 3608, loss = 0.94505206
Iteration 3609, loss = 0.85368866
Iteration 3610, loss = 0.92015508
Iteration 3611, loss = 0.84042439
Iteration 3612, loss = 0.89693357
Iteration 3613, loss = 0.82418388
Iteration 3614, loss = 0.87596054
Iteration 3615, loss = 0.79527182
Iteration 3616, loss = 0.73652096
Iteration 3617, loss = 0.76420424
Iteration 3618, loss = 0.79110201
Iteration 3619, loss = 0.76114523
Iteration 3620, loss = 0.73895970
Iteration 3621, loss = 0.77071337
Iteration 3622, loss = 0.72553461
Iteration 3623, loss = 1.52023065
Iteration 3624, loss = 1.75332688
Iteration 3625, loss = 1.18521324
Iteration 3626, loss = 1.59946344
Iteration 3627, loss = 1.62083305
Iteration 3628, loss = 1.04217887
Iteration 3629, loss = 1.47359289
Iteration 3630, loss = 0.89489367
Iteration 3631, loss = 1.36419418
Iteration 3632, loss = 0.90895146
Iteration 3633, loss = 1.30136767
Iteration 3634, loss = 0.96807679
Iteration 3635, loss = 1.22498902
Iteration 3636, loss = 1.02424160
Iteration 3637, loss = 1.10848780
Iteration 3638, loss = 1.03931970
Iteration 3639, loss = 0.98607446
Iteration 3640, loss = 1.00261110
Iteration 3641, loss = 0.89806528
Iteration 3642, loss = 0.94844929
Iteration 3643, loss = 0.84750588
Iteration 3644, loss = 0.89976542
Iteration 3645, loss = 0.82070694
Iteration 3646, loss = 0.86130827
Iteration 3647, loss = 0.80740929
Iteration 3648, loss = 0.83220550
Iteration 3649, loss = 0.80149415
Iteration 3650, loss = 0.81016386
Iteration 3651, loss = 0.79753431
Iteration 3652, loss = 0.79317290
Iteration 3653, loss = 0.79436779
Iteration 3654, loss = 0.77994309
Iteration 3655, loss = 0.79086509
Iteration 3656, loss = 0.76952121
Iteration 3657, loss = 0.78698373
Iteration 3658, loss = 0.76193311
Iteration 3659, loss = 0.78285869
Iteration 3660, loss = 0.75623275
Iteration 3661, loss = 0.77854820
Iteration 3662, loss = 0.75230648
Iteration 3663, loss = 0.77399513
Iteration 3664, loss = 0.74873057
Iteration 3665, loss = 0.76780162
Iteration 3666, loss = 0.74691891
Iteration 3667, loss = 0.76399845
Iteration 3668, loss = 0.74341727
Iteration 3669, loss = 0.75265666
Iteration 3670, loss = 0.63166946
Iteration 3671, loss = 0.85003865
Iteration 3672, loss = 0.86378566
Iteration 3673, loss = 0.84819552
Iteration 3674, loss = 0.83640369
Iteration 3675, loss = 0.83666341
Iteration 3676, loss = 0.81360549
Iteration 3677, loss = 0.82209741
Iteration 3678, loss = 0.79592557
Iteration 3679, loss = 0.79838291
Iteration 3680, loss = 0.80163625
Iteration 3681, loss = 0.78132433
Iteration 3682, loss = 0.80875370
Iteration 3683, loss = 0.76966940
Iteration 3684, loss = 0.80877793
Iteration 3685, loss = 0.76330287
Iteration 3686, loss = 0.80499061
Iteration 3687, loss = 0.76302605
Iteration 3688, loss = 0.79902402
Iteration 3689, loss = 0.76520512
Iteration 3690, loss = 0.78988583
Iteration 3691, loss = 0.76771108
Iteration 3692, loss = 0.78035531
Iteration 3693, loss = 0.76951783
Iteration 3694, loss = 0.76112824
Iteration 3695, loss = 0.76977662
Iteration 3696, loss = 0.80607177
Iteration 3697, loss = 0.77817861
Iteration 3698, loss = 0.79428237
Iteration 3699, loss = 0.77857525
Iteration 3700, loss = 0.77916652
Iteration 3701, loss = 0.78071677
Iteration 3702, loss = 0.77309721
Iteration 3703, loss = 0.78547502
Iteration 3704, loss = 0.77264576
Iteration 3705, loss = 0.78502139
Iteration 3706, loss = 0.77175565
Iteration 3707, loss = 0.77976584
Iteration 3708, loss = 0.77175405
Iteration 3709, loss = 0.77507239
Iteration 3710, loss = 0.77412247
Iteration 3711, loss = 0.77273809
Iteration 3712, loss = 0.77584530
Iteration 3713, loss = 0.77093914
Iteration 3714, loss = 0.77499086
Iteration 3715, loss = 0.76956284
Iteration 3716, loss = 0.77293344
Iteration 3717, loss = 0.76955378
Iteration 3718, loss = 0.77118042
Iteration 3719, loss = 0.77021049
Iteration 3720, loss = 0.76957555
Iteration 3721, loss = 0.77017126
Iteration 3722, loss = 0.76805855
Iteration 3723, loss = 0.76938456
Iteration 3724, loss = 0.76716538
Iteration 3725, loss = 0.76837542
Iteration 3726, loss = 0.76487291
Iteration 3727, loss = 0.77174065
Iteration 3728, loss = 0.78437848
Iteration 3729, loss = 0.78380880
Iteration 3730, loss = 0.78714727
Iteration 3731, loss = 0.77683112
Iteration 3732, loss = 0.77759952
Iteration 3733, loss = 0.77131605
Iteration 3734, loss = 0.77367838
Iteration 3735, loss = 0.77270918
Iteration 3736, loss = 0.77403567
Iteration 3737, loss = 0.77432903
Iteration 3738, loss = 0.77300741
Iteration 3739, loss = 0.77399574
Iteration 3740, loss = 0.77183256
Iteration 3741, loss = 0.77313190
Iteration 3742, loss = 0.77098199
Iteration 3743, loss = 0.77180719
Iteration 3744, loss = 0.77025079
Iteration 3745, loss = 0.77058469
Iteration 3746, loss = 0.76999090
Iteration 3747, loss = 0.76970663
Iteration 3748, loss = 0.76965546
Iteration 3749, loss = 0.76883589
Iteration 3750, loss = 0.76903279
Iteration 3751, loss = 0.76806231
Iteration 3752, loss = 0.76827708
Iteration 3753, loss = 0.76739770
Iteration 3754, loss = 0.76731547
Iteration 3755, loss = 0.76657849
Iteration 3756, loss = 0.76620159
Iteration 3757, loss = 0.76577879
Iteration 3758, loss = 0.76526785
Iteration 3759, loss = 0.76500594
Iteration 3760, loss = 0.76427712
Iteration 3761, loss = 0.76385064
Iteration 3762, loss = 0.76276135
Iteration 3763, loss = 0.76139261
Iteration 3764, loss = 0.75803378
Iteration 3765, loss = 0.75003719
Iteration 3766, loss = 0.71473378
Iteration 3767, loss = 0.88017561
Iteration 3768, loss = 0.77892191
Iteration 3769, loss = 0.86706847
Iteration 3770, loss = 0.79218359
Iteration 3771, loss = 0.83415621
Iteration 3772, loss = 0.79327501
Iteration 3773, loss = 0.79961586
Iteration 3774, loss = 0.79546930
Iteration 3775, loss = 0.77769448
Iteration 3776, loss = 0.79905894
Iteration 3777, loss = 0.76871258
Iteration 3778, loss = 0.79998987
Iteration 3779, loss = 0.76573625
Iteration 3780, loss = 0.79415053
Iteration 3781, loss = 0.76658174
Iteration 3782, loss = 0.78471259
Iteration 3783, loss = 0.76942790
Iteration 3784, loss = 0.77520094
Iteration 3785, loss = 0.77221633
Iteration 3786, loss = 0.76756057
Iteration 3787, loss = 0.77338993
Iteration 3788, loss = 0.76234996
Iteration 3789, loss = 0.77096324
Iteration 3790, loss = 0.75862263
Iteration 3791, loss = 0.76723624
Iteration 3792, loss = 0.75871679
Iteration 3793, loss = 0.76386164
Iteration 3794, loss = 0.76024900
Iteration 3795, loss = 0.76072680
Iteration 3796, loss = 0.76071835
Iteration 3797, loss = 0.75764050
Iteration 3798, loss = 0.76011273
Iteration 3799, loss = 0.75569760
Iteration 3800, loss = 0.75872290
Iteration 3801, loss = 0.75493429
Iteration 3802, loss = 0.75702887
Iteration 3803, loss = 0.75432629
Iteration 3804, loss = 0.75484977
Iteration 3805, loss = 0.75421126
Iteration 3806, loss = 0.75318228
Iteration 3807, loss = 0.75363180
Iteration 3808, loss = 0.75245709
Iteration 3809, loss = 0.75329949
Iteration 3810, loss = 0.75152062
Iteration 3811, loss = 0.75211901
Iteration 3812, loss = 0.75097328
Iteration 3813, loss = 0.75108217
Iteration 3814, loss = 0.75054555
Iteration 3815, loss = 0.75002120
Iteration 3816, loss = 0.74993223
Iteration 3817, loss = 0.74914101
Iteration 3818, loss = 0.74928894
Iteration 3819, loss = 0.74807656
Iteration 3820, loss = 0.75594463
Iteration 3821, loss = 0.75890061
Iteration 3822, loss = 0.75547480
Iteration 3823, loss = 0.76052027
Iteration 3824, loss = 0.75094285
Iteration 3825, loss = 0.75681761
Iteration 3826, loss = 0.74784267
Iteration 3827, loss = 0.75429243
Iteration 3828, loss = 0.74801836
Iteration 3829, loss = 0.75233273
Iteration 3830, loss = 0.74899321
Iteration 3831, loss = 0.74978556
Iteration 3832, loss = 0.74819260
Iteration 3833, loss = 0.74622022
Iteration 3834, loss = 0.74700497
Iteration 3835, loss = 0.74415441
Iteration 3836, loss = 0.74450755
Iteration 3837, loss = 0.73717205
Iteration 3838, loss = 0.71196385
Iteration 3839, loss = 0.83780707
Iteration 3840, loss = 0.83650724
Iteration 3841, loss = 0.82262194
Iteration 3842, loss = 0.84288493
Iteration 3843, loss = 0.79882580
Iteration 3844, loss = 0.83429011
Iteration 3845, loss = 0.77360879
Iteration 3846, loss = 0.82339996
Iteration 3847, loss = 0.75871247
Iteration 3848, loss = 0.81662451
Iteration 3849, loss = 0.75319884
Iteration 3850, loss = 0.81117673
Iteration 3851, loss = 0.75247981
Iteration 3852, loss = 0.80320983
Iteration 3853, loss = 0.75094051
Iteration 3854, loss = 0.79165341
Iteration 3855, loss = 0.74953516
Iteration 3856, loss = 0.77971312
Iteration 3857, loss = 0.74921078
Iteration 3858, loss = 0.76923867
Iteration 3859, loss = 0.75091144
Iteration 3860, loss = 0.76152823
Iteration 3861, loss = 0.75293862
Iteration 3862, loss = 0.75514501
Iteration 3863, loss = 0.75374777
Iteration 3864, loss = 0.74980399
Iteration 3865, loss = 0.75341612
Iteration 3866, loss = 0.74597842
Iteration 3867, loss = 0.75246302
Iteration 3868, loss = 0.74376750
Iteration 3869, loss = 0.75112482
Iteration 3870, loss = 0.74276472
Iteration 3871, loss = 0.74937075
Iteration 3872, loss = 0.74232907
Iteration 3873, loss = 0.74721752
Iteration 3874, loss = 0.74208164
Iteration 3875, loss = 0.74497419
Iteration 3876, loss = 0.74191665
Iteration 3877, loss = 0.74296922
Iteration 3878, loss = 0.74171294
Iteration 3879, loss = 0.74128246
Iteration 3880, loss = 0.74138305
Iteration 3881, loss = 0.73521197
Iteration 3882, loss = 0.74113441
Iteration 3883, loss = 0.74553832
Iteration 3884, loss = 0.74422420
Iteration 3885, loss = 0.74336951
Iteration 3886, loss = 0.72560716
Iteration 3887, loss = 0.74907374
Iteration 3888, loss = 0.75485821
Iteration 3889, loss = 0.75948907
Iteration 3890, loss = 0.75641806
Iteration 3891, loss = 0.75274847
Iteration 3892, loss = 0.74849499
Iteration 3893, loss = 0.74751663
Iteration 3894, loss = 0.74786171
Iteration 3895, loss = 0.74970693
Iteration 3896, loss = 0.74962518
Iteration 3897, loss = 0.74598673
Iteration 3898, loss = 0.74587846
Iteration 3899, loss = 0.74556135
Iteration 3900, loss = 0.74596335
Iteration 3901, loss = 0.74547704
Iteration 3902, loss = 0.74469416
Iteration 3903, loss = 0.74341903
Iteration 3904, loss = 0.74175889
Iteration 3905, loss = 0.74056540
Iteration 3906, loss = 0.73885970
Iteration 3907, loss = 0.73777444
Iteration 3908, loss = 0.73554987
Iteration 3909, loss = 0.73144898
Iteration 3910, loss = 0.72699190
Iteration 3911, loss = 0.72244723
Iteration 3912, loss = 0.69851025
Iteration 3913, loss = 0.97865105
Iteration 3914, loss = 0.98222312
Iteration 3915, loss = 0.96285409
Iteration 3916, loss = 0.94372513
Iteration 3917, loss = 0.92257749
Iteration 3918, loss = 0.91282404
Iteration 3919, loss = 0.87880023
Iteration 3920, loss = 0.89221200
Iteration 3921, loss = 0.84467194
Iteration 3922, loss = 0.88141769
Iteration 3923, loss = 0.82044873
Iteration 3924, loss = 0.87450123
Iteration 3925, loss = 0.80172757
Iteration 3926, loss = 0.87032260
Iteration 3927, loss = 0.78846962
Iteration 3928, loss = 0.86353431
Iteration 3929, loss = 0.77620761
Iteration 3930, loss = 0.85518561
Iteration 3931, loss = 0.76788610
Iteration 3932, loss = 0.84664695
Iteration 3933, loss = 0.76140399
Iteration 3934, loss = 0.83628623
Iteration 3935, loss = 0.75552693
Iteration 3936, loss = 0.82510444
Iteration 3937, loss = 0.75158598
Iteration 3938, loss = 0.81439145
Iteration 3939, loss = 0.74937201
Iteration 3940, loss = 0.80308056
Iteration 3941, loss = 0.74808557
Iteration 3942, loss = 0.79198159
Iteration 3943, loss = 0.74777753
Iteration 3944, loss = 0.78144155
Iteration 3945, loss = 0.74819060
Iteration 3946, loss = 0.77203519
Iteration 3947, loss = 0.74926977
Iteration 3948, loss = 0.76409564
Iteration 3949, loss = 0.75021142
Iteration 3950, loss = 0.75718130
Iteration 3951, loss = 0.75086211
Iteration 3952, loss = 0.75181903
Iteration 3953, loss = 0.75107852
Iteration 3954, loss = 0.74774315
Iteration 3955, loss = 0.75079745
Iteration 3956, loss = 0.74485178
Iteration 3957, loss = 0.74996077
Iteration 3958, loss = 0.74296582
Iteration 3959, loss = 0.74870849
Iteration 3960, loss = 0.74171345
Iteration 3961, loss = 0.74701440
Iteration 3962, loss = 0.74075969
Iteration 3963, loss = 0.74481600
Iteration 3964, loss = 0.73935598
Iteration 3965, loss = 0.74005899
Iteration 3966, loss = 0.74158301
Iteration 3967, loss = 0.73917412
Iteration 3968, loss = 0.74178798
Iteration 3969, loss = 0.73606607
Iteration 3970, loss = 0.72448941
Iteration 3971, loss = 0.76793579
Iteration 3972, loss = 0.74926562
Iteration 3973, loss = 0.76571312
Iteration 3974, loss = 0.74589329
Iteration 3975, loss = 0.75482588
Iteration 3976, loss = 0.74183898
Iteration 3977, loss = 0.74350130
Iteration 3978, loss = 0.74452699
Iteration 3979, loss = 0.78728032
Iteration 3980, loss = 0.74498700
Iteration 3981, loss = 0.77856527
Iteration 3982, loss = 0.74104089
Iteration 3983, loss = 0.76888420
Iteration 3984, loss = 0.74059147
Iteration 3985, loss = 0.76239254
Iteration 3986, loss = 0.74200392
Iteration 3987, loss = 0.75670173
Iteration 3988, loss = 0.74334569
Iteration 3989, loss = 0.75145591
Iteration 3990, loss = 0.74395301
Iteration 3991, loss = 0.74675899
Iteration 3992, loss = 0.74418936
Iteration 3993, loss = 0.74330463
Iteration 3994, loss = 0.74432124
Iteration 3995, loss = 0.74090747
Iteration 3996, loss = 0.74399178
Iteration 3997, loss = 0.73916101
Iteration 3998, loss = 0.74320799
Iteration 3999, loss = 0.73798042
Iteration 4000, loss = 0.74204453
Iteration 4001, loss = 0.73709243
Iteration 4002, loss = 0.74062495
Iteration 4003, loss = 0.73653291
Iteration 4004, loss = 0.73918336
Iteration 4005, loss = 0.73613998
Iteration 4006, loss = 0.73787977
Iteration 4007, loss = 0.73591378
Iteration 4008, loss = 0.73663871
Iteration 4009, loss = 0.73551950
Iteration 4010, loss = 0.73546682
Iteration 4011, loss = 0.73509249
Iteration 4012, loss = 0.73446806
Iteration 4013, loss = 0.73452644
Iteration 4014, loss = 0.73352420
Iteration 4015, loss = 0.73373923
Iteration 4016, loss = 0.73232432
Iteration 4017, loss = 0.73281396
Iteration 4018, loss = 0.73175186
Iteration 4019, loss = 0.73186490
Iteration 4020, loss = 0.73049696
Iteration 4021, loss = 0.73064731
Iteration 4022, loss = 0.72995717
Iteration 4023, loss = 0.73051731
Iteration 4024, loss = 0.72968775
Iteration 4025, loss = 0.72918369
Iteration 4026, loss = 0.72896445
Iteration 4027, loss = 0.72877937
Iteration 4028, loss = 0.72821296
Iteration 4029, loss = 0.72777985
Iteration 4030, loss = 0.72727196
Iteration 4031, loss = 0.72711453
Iteration 4032, loss = 0.72708676
Iteration 4033, loss = 0.72663391
Iteration 4034, loss = 0.72599433
Iteration 4035, loss = 0.72501078
Iteration 4036, loss = 0.72404993
Iteration 4037, loss = 0.72311272
Iteration 4038, loss = 0.72141435
Iteration 4039, loss = 0.71915802
Iteration 4040, loss = 0.71242634
Iteration 4041, loss = 0.73547739
Iteration 4042, loss = 0.90081463
Iteration 4043, loss = 0.76075951
Iteration 4044, loss = 0.90133282
Iteration 4045, loss = 0.77262335
Iteration 4046, loss = 0.87135095
Iteration 4047, loss = 0.75631109
Iteration 4048, loss = 0.82912067
Iteration 4049, loss = 0.74064861
Iteration 4050, loss = 0.79881094
Iteration 4051, loss = 0.73748073
Iteration 4052, loss = 0.78233258
Iteration 4053, loss = 0.74304636
Iteration 4054, loss = 0.77204062
Iteration 4055, loss = 0.74840230
Iteration 4056, loss = 0.76154480
Iteration 4057, loss = 0.75022592
Iteration 4058, loss = 0.75107518
Iteration 4059, loss = 0.74956681
Iteration 4060, loss = 0.74240149
Iteration 4061, loss = 0.74822444
Iteration 4062, loss = 0.73654247
Iteration 4063, loss = 0.74662719
Iteration 4064, loss = 0.73364474
Iteration 4065, loss = 0.74477327
Iteration 4066, loss = 0.73214944
Iteration 4067, loss = 0.74250112
Iteration 4068, loss = 0.73151975
Iteration 4069, loss = 0.73931850
Iteration 4070, loss = 0.73077205
Iteration 4071, loss = 0.73599584
Iteration 4072, loss = 0.73039978
Iteration 4073, loss = 0.73271246
Iteration 4074, loss = 0.72995122
Iteration 4075, loss = 0.73001560
Iteration 4076, loss = 0.72590453
Iteration 4077, loss = 0.64600109
Iteration 4078, loss = 0.75388185
Iteration 4079, loss = 0.76979671
Iteration 4080, loss = 0.74420932
Iteration 4081, loss = 0.76887982
Iteration 4082, loss = 0.73779924
Iteration 4083, loss = 0.76419160
Iteration 4084, loss = 0.73657551
Iteration 4085, loss = 0.75793395
Iteration 4086, loss = 0.73868172
Iteration 4087, loss = 0.75202438
Iteration 4088, loss = 0.74325299
Iteration 4089, loss = 0.74695218
Iteration 4090, loss = 0.74625655
Iteration 4091, loss = 0.74277118
Iteration 4092, loss = 0.74725901
Iteration 4093, loss = 0.73960777
Iteration 4094, loss = 0.74645276
Iteration 4095, loss = 0.73908014
Iteration 4096, loss = 0.74086695
Iteration 4097, loss = 0.73888100
Iteration 4098, loss = 0.73714090
Iteration 4099, loss = 0.73677064
Iteration 4100, loss = 0.73253649
Iteration 4101, loss = 0.73393718
Iteration 4102, loss = 0.73047431
Iteration 4103, loss = 0.72574418
Iteration 4104, loss = 0.71683248
Iteration 4105, loss = 1.23124864
Iteration 4106, loss = 1.95909315
Iteration 4107, loss = 1.54227422
Iteration 4108, loss = 1.30778437
Iteration 4109, loss = 1.69275477
Iteration 4110, loss = 0.86602051
Iteration 4111, loss = 1.53658895
Iteration 4112, loss = 0.95239954
Iteration 4113, loss = 1.45457265
Iteration 4114, loss = 1.19445909
Iteration 4115, loss = 1.17104794
Iteration 4116, loss = 1.23065259
Iteration 4117, loss = 0.90819791
Iteration 4118, loss = 1.11820617
Iteration 4119, loss = 0.80587736
Iteration 4120, loss = 1.00036606
Iteration 4121, loss = 0.78973002
Iteration 4122, loss = 0.95347932
Iteration 4123, loss = 0.79578338
Iteration 4124, loss = 0.91574326
Iteration 4125, loss = 0.79656845
Iteration 4126, loss = 0.86884989
Iteration 4127, loss = 0.78889492
Iteration 4128, loss = 0.84296321
Iteration 4129, loss = 0.78546940
Iteration 4130, loss = 0.82282530
Iteration 4131, loss = 0.78358249
Iteration 4132, loss = 0.80713941
Iteration 4133, loss = 0.78245216
Iteration 4134, loss = 0.79462406
Iteration 4135, loss = 0.78093904
Iteration 4136, loss = 0.78430111
Iteration 4137, loss = 0.77963739
Iteration 4138, loss = 0.77729740
Iteration 4139, loss = 0.77932891
Iteration 4140, loss = 0.77301694
Iteration 4141, loss = 0.77888157
Iteration 4142, loss = 0.76968267
Iteration 4143, loss = 0.77739787
Iteration 4144, loss = 0.76694105
Iteration 4145, loss = 0.77516641
Iteration 4146, loss = 0.76471995
Iteration 4147, loss = 0.77270214
Iteration 4148, loss = 0.76331229
Iteration 4149, loss = 0.77046201
Iteration 4150, loss = 0.76253107
Iteration 4151, loss = 0.76831373
Iteration 4152, loss = 0.76193705
Iteration 4153, loss = 0.76611081
Iteration 4154, loss = 0.76127624
Iteration 4155, loss = 0.76392610
Iteration 4156, loss = 0.76061860
Iteration 4157, loss = 0.76200678
Iteration 4158, loss = 0.76001307
Iteration 4159, loss = 0.76033887
Iteration 4160, loss = 0.75936800
Iteration 4161, loss = 0.75893467
Iteration 4162, loss = 0.75871910
Iteration 4163, loss = 0.75775750
Iteration 4164, loss = 0.75800394
Iteration 4165, loss = 0.75675142
Iteration 4166, loss = 0.75721935
Iteration 4167, loss = 0.75583985
Iteration 4168, loss = 0.75632807
Iteration 4169, loss = 0.75490976
Iteration 4170, loss = 0.75523054
Iteration 4171, loss = 0.75397971
Iteration 4172, loss = 0.75427389
Iteration 4173, loss = 0.75319925
Iteration 4174, loss = 0.75324926
Iteration 4175, loss = 0.75236274
Iteration 4176, loss = 0.75223894
Iteration 4177, loss = 0.75149784
Iteration 4178, loss = 0.75112079
Iteration 4179, loss = 0.75044770
Iteration 4180, loss = 0.74980605
Iteration 4181, loss = 0.74880264
Iteration 4182, loss = 0.74785856
Iteration 4183, loss = 0.74705561
Iteration 4184, loss = 0.74574438
Iteration 4185, loss = 0.74494561
Iteration 4186, loss = 0.74402124
Iteration 4187, loss = 0.74320878
Iteration 4188, loss = 0.74209143
Iteration 4189, loss = 0.73929480
Iteration 4190, loss = 0.73668814
Iteration 4191, loss = 0.72416835
Iteration 4192, loss = 0.79672496
Iteration 4193, loss = 0.82587995
Iteration 4194, loss = 0.78658249
Iteration 4195, loss = 0.83305401
Iteration 4196, loss = 0.77236675
Iteration 4197, loss = 0.82044780
Iteration 4198, loss = 0.72440702
Iteration 4199, loss = 0.75031866
Iteration 4200, loss = 0.86282515
Iteration 4201, loss = 0.75389889
Iteration 4202, loss = 0.84130117
Iteration 4203, loss = 0.75078937
Iteration 4204, loss = 0.82639771
Iteration 4205, loss = 0.75086868
Iteration 4206, loss = 0.81269467
Iteration 4207, loss = 0.75269556
Iteration 4208, loss = 0.80014909
Iteration 4209, loss = 0.75351392
Iteration 4210, loss = 0.78672897
Iteration 4211, loss = 0.75328631
Iteration 4212, loss = 0.77479700
Iteration 4213, loss = 0.75415539
Iteration 4214, loss = 0.76607785
Iteration 4215, loss = 0.75566796
Iteration 4216, loss = 0.75942819
Iteration 4217, loss = 0.75610291
Iteration 4218, loss = 0.75321983
Iteration 4219, loss = 0.75440758
Iteration 4220, loss = 0.74755740
Iteration 4221, loss = 0.75221570
Iteration 4222, loss = 0.74246759
Iteration 4223, loss = 0.74833412
Iteration 4224, loss = 0.73766095
Iteration 4225, loss = 0.73158158
Iteration 4226, loss = 0.83906557
Iteration 4227, loss = 0.81528386
Iteration 4228, loss = 0.83805379
Iteration 4229, loss = 0.80961575
Iteration 4230, loss = 0.81761007
Iteration 4231, loss = 0.79042180
Iteration 4232, loss = 0.79398201
Iteration 4233, loss = 0.77897422
Iteration 4234, loss = 0.78342263
Iteration 4235, loss = 0.77966879
Iteration 4236, loss = 0.77941208
Iteration 4237, loss = 0.77703884
Iteration 4238, loss = 0.77039791
Iteration 4239, loss = 0.77169471
Iteration 4240, loss = 0.76350342
Iteration 4241, loss = 0.77265231
Iteration 4242, loss = 0.75546387
Iteration 4243, loss = 0.77925719
Iteration 4244, loss = 0.77726029
Iteration 4245, loss = 0.79824772
Iteration 4246, loss = 0.79183752
Iteration 4247, loss = 0.80215149
Iteration 4248, loss = 0.78961648
Iteration 4249, loss = 0.79232895
Iteration 4250, loss = 0.77887707
Iteration 4251, loss = 0.77965907
Iteration 4252, loss = 0.76898758
Iteration 4253, loss = 0.77042291
Iteration 4254, loss = 0.76372366
Iteration 4255, loss = 0.76653126
Iteration 4256, loss = 0.76315064
Iteration 4257, loss = 0.76618033
Iteration 4258, loss = 0.76410978
Iteration 4259, loss = 0.76591614
Iteration 4260, loss = 0.76400886
Iteration 4261, loss = 0.76458924
Iteration 4262, loss = 0.76298038
Iteration 4263, loss = 0.76290788
Iteration 4264, loss = 0.76182317
Iteration 4265, loss = 0.76151734
Iteration 4266, loss = 0.76097885
Iteration 4267, loss = 0.76059383
Iteration 4268, loss = 0.76043655
Iteration 4269, loss = 0.75990625
Iteration 4270, loss = 0.75983632
Iteration 4271, loss = 0.75907364
Iteration 4272, loss = 0.75892493
Iteration 4273, loss = 0.75791970
Iteration 4274, loss = 0.75764377
Iteration 4275, loss = 0.75664816
Iteration 4276, loss = 0.75652359
Iteration 4277, loss = 0.75570726
Iteration 4278, loss = 0.75567216
Iteration 4279, loss = 0.75501652
Iteration 4280, loss = 0.75504929
Iteration 4281, loss = 0.75453219
Iteration 4282, loss = 0.75456882
Iteration 4283, loss = 0.75411751
Iteration 4284, loss = 0.75406008
Iteration 4285, loss = 0.75358393
Iteration 4286, loss = 0.75339575
Iteration 4287, loss = 0.75291166
Iteration 4288, loss = 0.75264488
Iteration 4289, loss = 0.75216782
Iteration 4290, loss = 0.75180897
Iteration 4291, loss = 0.75132682
Iteration 4292, loss = 0.75095995
Iteration 4293, loss = 0.75062500
Iteration 4294, loss = 0.76812001
Iteration 4295, loss = 0.76398454
Iteration 4296, loss = 0.78407896
Iteration 4297, loss = 0.78087412
Iteration 4298, loss = 0.79082805
Iteration 4299, loss = 0.78218829
Iteration 4300, loss = 0.78297976
Iteration 4301, loss = 0.77301323
Iteration 4302, loss = 0.77087504
Iteration 4303, loss = 0.76423490
Iteration 4304, loss = 0.76332018
Iteration 4305, loss = 0.76036195
Iteration 4306, loss = 0.76039574
Iteration 4307, loss = 0.76058288
Iteration 4308, loss = 0.76064576
Iteration 4309, loss = 0.76156386
Iteration 4310, loss = 0.76056015
Iteration 4311, loss = 0.76124852
Iteration 4312, loss = 0.75994890
Iteration 4313, loss = 0.76097890
Iteration 4314, loss = 0.75908046
Iteration 4315, loss = 0.75973328
Iteration 4316, loss = 0.75752336
Iteration 4317, loss = 0.75786088
Iteration 4318, loss = 0.75565008
Iteration 4319, loss = 0.75641171
Iteration 4320, loss = 0.75452389
Iteration 4321, loss = 0.75475576
Iteration 4322, loss = 0.75304414
Iteration 4323, loss = 0.75259733
Iteration 4324, loss = 0.75103397
Iteration 4325, loss = 0.75039261
Iteration 4326, loss = 0.74700547
Iteration 4327, loss = 0.73479890
Iteration 4328, loss = 0.84427554
Iteration 4329, loss = 0.84659661
Iteration 4330, loss = 0.82658223
Iteration 4331, loss = 0.85851810
Iteration 4332, loss = 0.80235388
Iteration 4333, loss = 0.84714642
Iteration 4334, loss = 0.76881443
Iteration 4335, loss = 0.80374919
Iteration 4336, loss = 0.81202065
Iteration 4337, loss = 0.76266558
Iteration 4338, loss = 0.80330143
Iteration 4339, loss = 0.76237317
Iteration 4340, loss = 0.78820300
Iteration 4341, loss = 0.76070218
Iteration 4342, loss = 0.77703520
Iteration 4343, loss = 0.76145989
Iteration 4344, loss = 0.77031361
Iteration 4345, loss = 0.76312465
Iteration 4346, loss = 0.76467206
Iteration 4347, loss = 0.76252856
Iteration 4348, loss = 0.75896703
Iteration 4349, loss = 0.76126904
Iteration 4350, loss = 0.75453376
Iteration 4351, loss = 0.75659167
Iteration 4352, loss = 0.66727048
Iteration 4353, loss = 0.77507074
Iteration 4354, loss = 0.77907612
Iteration 4355, loss = 0.78557468
Iteration 4356, loss = 0.77953018
Iteration 4357, loss = 0.77489187
Iteration 4358, loss = 0.76994660
Iteration 4359, loss = 0.76553225
Iteration 4360, loss = 0.76646257
Iteration 4361, loss = 0.76400046
Iteration 4362, loss = 0.76716951
Iteration 4363, loss = 0.76365730
Iteration 4364, loss = 0.76632221
Iteration 4365, loss = 0.76215396
Iteration 4366, loss = 0.76528687
Iteration 4367, loss = 0.76230504
Iteration 4368, loss = 0.76566881
Iteration 4369, loss = 0.76298787
Iteration 4370, loss = 0.76513103
Iteration 4371, loss = 0.76235279
Iteration 4372, loss = 0.76345874
Iteration 4373, loss = 0.76123687
Iteration 4374, loss = 0.76185352
Iteration 4375, loss = 0.76044681
Iteration 4376, loss = 0.76082604
Iteration 4377, loss = 0.76026902
Iteration 4378, loss = 0.76050686
Iteration 4379, loss = 0.76045032
Iteration 4380, loss = 0.76025924
Iteration 4381, loss = 0.76017021
Iteration 4382, loss = 0.75939797
Iteration 4383, loss = 0.75846490
Iteration 4384, loss = 0.76403141
Iteration 4385, loss = 0.76705765
Iteration 4386, loss = 0.76330644
Iteration 4387, loss = 0.76736306
Iteration 4388, loss = 0.76115922
Iteration 4389, loss = 0.76499458
Iteration 4390, loss = 0.75585181
Iteration 4391, loss = 0.75815868
Iteration 4392, loss = 0.73046072
Iteration 4393, loss = 0.79715285
Iteration 4394, loss = 0.77071164
Iteration 4395, loss = 0.78722631
Iteration 4396, loss = 0.77369652
Iteration 4397, loss = 0.77611631
Iteration 4398, loss = 0.77090287
Iteration 4399, loss = 0.76461493
Iteration 4400, loss = 0.76744438
Iteration 4401, loss = 0.75892745
Iteration 4402, loss = 0.76828308
Iteration 4403, loss = 0.75691573
Iteration 4404, loss = 0.76783458
Iteration 4405, loss = 0.75496662
Iteration 4406, loss = 0.76426264
Iteration 4407, loss = 0.75110398
Iteration 4408, loss = 0.75950152
Iteration 4409, loss = 0.74895726
Iteration 4410, loss = 0.75596151
Iteration 4411, loss = 0.74742829
Iteration 4412, loss = 0.75092488
Iteration 4413, loss = 0.74399702
Iteration 4414, loss = 0.74686096
Iteration 4415, loss = 0.74220806
Iteration 4416, loss = 0.74093408
Iteration 4417, loss = 0.73115993
Iteration 4418, loss = 0.70587280
Iteration 4419, loss = 1.03748938
Iteration 4420, loss = 0.87833718
Iteration 4421, loss = 0.98102247
Iteration 4422, loss = 0.83271618
Iteration 4423, loss = 0.90465443
Iteration 4424, loss = 0.76509022
Iteration 4425, loss = 0.82967344
Iteration 4426, loss = 0.80349896
Iteration 4427, loss = 0.85148420
Iteration 4428, loss = 0.79550433
Iteration 4429, loss = 0.82803481
Iteration 4430, loss = 0.78452984
Iteration 4431, loss = 0.80844143
Iteration 4432, loss = 0.77751539
Iteration 4433, loss = 0.79039238
Iteration 4434, loss = 0.77296359
Iteration 4435, loss = 0.77985394
Iteration 4436, loss = 0.77680996
Iteration 4437, loss = 0.77771163
Iteration 4438, loss = 0.78253394
Iteration 4439, loss = 0.77624032
Iteration 4440, loss = 0.78351761
Iteration 4441, loss = 0.77366671
Iteration 4442, loss = 0.78086519
Iteration 4443, loss = 0.77115498
Iteration 4444, loss = 0.77589513
Iteration 4445, loss = 0.76679089
Iteration 4446, loss = 0.76964009
Iteration 4447, loss = 0.78895843
Iteration 4448, loss = 0.77678081
Iteration 4449, loss = 0.79253261
Iteration 4450, loss = 0.77501726
Iteration 4451, loss = 0.78439616
Iteration 4452, loss = 0.76987524
Iteration 4453, loss = 0.77924198
Iteration 4454, loss = 0.76950705
Iteration 4455, loss = 0.77731239
Iteration 4456, loss = 0.76991680
Iteration 4457, loss = 0.77497652
Iteration 4458, loss = 0.76943932
Iteration 4459, loss = 0.77228057
Iteration 4460, loss = 0.76838000
Iteration 4461, loss = 0.76946907
Iteration 4462, loss = 0.76714542
Iteration 4463, loss = 0.76723757
Iteration 4464, loss = 0.76631498
Iteration 4465, loss = 0.76579596
Iteration 4466, loss = 0.76584704
Iteration 4467, loss = 0.76467006
Iteration 4468, loss = 0.76494281
Iteration 4469, loss = 0.76326594
Iteration 4470, loss = 0.76391963
Iteration 4471, loss = 0.76227244
Iteration 4472, loss = 0.76305164
Iteration 4473, loss = 0.76143912
Iteration 4474, loss = 0.76212589
Iteration 4475, loss = 0.76066567
Iteration 4476, loss = 0.76124300
Iteration 4477, loss = 0.75994890
Iteration 4478, loss = 0.76014737
Iteration 4479, loss = 0.75883115
Iteration 4480, loss = 0.75884783
Iteration 4481, loss = 0.75805307
Iteration 4482, loss = 0.75813317
Iteration 4483, loss = 0.75767736
Iteration 4484, loss = 0.75754010
Iteration 4485, loss = 0.75687561
Iteration 4486, loss = 0.75650199
Iteration 4487, loss = 0.75625278
Iteration 4488, loss = 0.75592150
Iteration 4489, loss = 0.75558207
Iteration 4490, loss = 0.75494809
Iteration 4491, loss = 0.75452552
Iteration 4492, loss = 0.75402230
Iteration 4493, loss = 0.75385605
Iteration 4494, loss = 0.75337404
Iteration 4495, loss = 0.75311692
Iteration 4496, loss = 0.75276174
Iteration 4497, loss = 0.75264010
Iteration 4498, loss = 0.75210804
Iteration 4499, loss = 0.75191914
Iteration 4500, loss = 0.75167814
Iteration 4501, loss = 0.75148052
Iteration 4502, loss = 0.75113463
Iteration 4503, loss = 0.75095322
Iteration 4504, loss = 0.75066666
Iteration 4505, loss = 0.75033053
Iteration 4506, loss = 0.75006086
Iteration 4507, loss = 0.74980995
Iteration 4508, loss = 0.74951931
Iteration 4509, loss = 0.74922827
Iteration 4510, loss = 0.74897672
Iteration 4511, loss = 0.74861398
Iteration 4512, loss = 0.74813728
Iteration 4513, loss = 0.74753688
Iteration 4514, loss = 0.74726156
Iteration 4515, loss = 0.74697341
Iteration 4516, loss = 0.74655707
Iteration 4517, loss = 0.74617413
Iteration 4518, loss = 0.74578452
Iteration 4519, loss = 0.74541086
Iteration 4520, loss = 0.74519579
Iteration 4521, loss = 0.74488833
Iteration 4522, loss = 0.74440951
Iteration 4523, loss = 0.74381608
Iteration 4524, loss = 0.74335738
Iteration 4525, loss = 0.74292413
Iteration 4526, loss = 0.74206767
Iteration 4527, loss = 0.74088964
Iteration 4528, loss = 0.74013716
Iteration 4529, loss = 0.73947129
Iteration 4530, loss = 0.73846306
Iteration 4531, loss = 0.73677669
Iteration 4532, loss = 0.73476613
Iteration 4533, loss = 0.73399307
Iteration 4534, loss = 0.72938126
Iteration 4535, loss = 0.71431205
Iteration 4536, loss = 0.90543925
Iteration 4537, loss = 1.38631297
Iteration 4538, loss = 0.93382399
Iteration 4539, loss = 1.30465185
Iteration 4540, loss = 1.21460274
Iteration 4541, loss = 0.99781538
Iteration 4542, loss = 1.19843648
Iteration 4543, loss = 0.81057414
Iteration 4544, loss = 1.09665981
Iteration 4545, loss = 0.75883031
Iteration 4546, loss = 1.02639169
Iteration 4547, loss = 0.76683636
Iteration 4548, loss = 0.98486634
Iteration 4549, loss = 0.79558857
Iteration 4550, loss = 0.94050227
Iteration 4551, loss = 0.82888724
Iteration 4552, loss = 0.89368648
Iteration 4553, loss = 0.84433628
Iteration 4554, loss = 0.84772926
Iteration 4555, loss = 0.84190027
Iteration 4556, loss = 0.81066299
Iteration 4557, loss = 0.81688117
Iteration 4558, loss = 0.79809536
Iteration 4559, loss = 0.81400378
Iteration 4560, loss = 0.78316978
Iteration 4561, loss = 0.80183262
Iteration 4562, loss = 0.76950622
Iteration 4563, loss = 0.79136750
Iteration 4564, loss = 0.76203209
Iteration 4565, loss = 0.77996665
Iteration 4566, loss = 0.75483117
Iteration 4567, loss = 0.77543219
Iteration 4568, loss = 0.75173024
Iteration 4569, loss = 0.77159665
Iteration 4570, loss = 0.74973952
Iteration 4571, loss = 0.76712135
Iteration 4572, loss = 0.74748361
Iteration 4573, loss = 0.76155917
Iteration 4574, loss = 0.74469328
Iteration 4575, loss = 0.75607238
Iteration 4576, loss = 0.74156736
Iteration 4577, loss = 0.78436442
Iteration 4578, loss = 0.75603967
Iteration 4579, loss = 0.77745508
Iteration 4580, loss = 0.74882238
Iteration 4581, loss = 0.76779464
Iteration 4582, loss = 0.74719926
Iteration 4583, loss = 0.76397054
Iteration 4584, loss = 0.74542224
Iteration 4585, loss = 0.75717390
Iteration 4586, loss = 0.74121149
Iteration 4587, loss = 0.73183286
Iteration 4588, loss = 0.77185827
Iteration 4589, loss = 0.75886917
Iteration 4590, loss = 0.76814649
Iteration 4591, loss = 0.75309232
Iteration 4592, loss = 0.75940819
Iteration 4593, loss = 0.74977450
Iteration 4594, loss = 0.75697263
Iteration 4595, loss = 0.75123027
Iteration 4596, loss = 0.75609776
Iteration 4597, loss = 0.75126415
Iteration 4598, loss = 0.75078928
Iteration 4599, loss = 0.75530059
Iteration 4600, loss = 0.76017023
Iteration 4601, loss = 0.76043444
Iteration 4602, loss = 0.76098084
Iteration 4603, loss = 0.75535923
Iteration 4604, loss = 0.75408990
Iteration 4605, loss = 0.74979074
Iteration 4606, loss = 0.75200974
Iteration 4607, loss = 0.75051044
Iteration 4608, loss = 0.75353943
Iteration 4609, loss = 0.75086707
Iteration 4610, loss = 0.75178110
Iteration 4611, loss = 0.74862248
Iteration 4612, loss = 0.74973859
Iteration 4613, loss = 0.74764876
Iteration 4614, loss = 0.74913210
Iteration 4615, loss = 0.74751900
Iteration 4616, loss = 0.74852286
Iteration 4617, loss = 0.74687534
Iteration 4618, loss = 0.74739830
Iteration 4619, loss = 0.74600495
Iteration 4620, loss = 0.74639402
Iteration 4621, loss = 0.74539662
Iteration 4622, loss = 0.74568515
Iteration 4623, loss = 0.74494908
Iteration 4624, loss = 0.74502040
Iteration 4625, loss = 0.74434930
Iteration 4626, loss = 0.74413549
Iteration 4627, loss = 0.74352417
Iteration 4628, loss = 0.74322424
Iteration 4629, loss = 0.74282567
Iteration 4630, loss = 0.74254446
Iteration 4631, loss = 0.74225192
Iteration 4632, loss = 0.74186429
Iteration 4633, loss = 0.74153203
Iteration 4634, loss = 0.74104694
Iteration 4635, loss = 0.74076459
Iteration 4636, loss = 0.74036334
Iteration 4637, loss = 0.74020471
Iteration 4638, loss = 0.73984861
Iteration 4639, loss = 0.73965402
Iteration 4640, loss = 0.73923298
Iteration 4641, loss = 0.73899801
Iteration 4642, loss = 0.73861857
Iteration 4643, loss = 0.73843617
Iteration 4644, loss = 0.73813049
Iteration 4645, loss = 0.73796176
Iteration 4646, loss = 0.73767182
Iteration 4647, loss = 0.73747402
Iteration 4648, loss = 0.73717850
Iteration 4649, loss = 0.73694737
Iteration 4650, loss = 0.73666362
Iteration 4651, loss = 0.73643756
Iteration 4652, loss = 0.73618303
Iteration 4653, loss = 0.73595083
Iteration 4654, loss = 0.73569710
Iteration 4655, loss = 0.73544701
Iteration 4656, loss = 0.73518925
Iteration 4657, loss = 0.73488189
Iteration 4658, loss = 0.73439654
Iteration 4659, loss = 0.73436967
Iteration 4660, loss = 0.73401793
Iteration 4661, loss = 0.73137103
Iteration 4662, loss = 0.73786949
Iteration 4663, loss = 0.74136429
Iteration 4664, loss = 0.73728537
Iteration 4665, loss = 0.74217408
Iteration 4666, loss = 0.73470463
Iteration 4667, loss = 0.74047146
Iteration 4668, loss = 0.73206008
Iteration 4669, loss = 0.73673095
Iteration 4670, loss = 0.72880471
Iteration 4671, loss = 0.72740936
Iteration 4672, loss = 0.74343790
Iteration 4673, loss = 0.77401580
Iteration 4674, loss = 0.74203956
Iteration 4675, loss = 0.77303738
Iteration 4676, loss = 0.73877577
Iteration 4677, loss = 0.76883049
Iteration 4678, loss = 0.73659575
Iteration 4679, loss = 0.76223597
Iteration 4680, loss = 0.73213970
Iteration 4681, loss = 0.75403543
Iteration 4682, loss = 0.73048317
Iteration 4683, loss = 0.74954069
Iteration 4684, loss = 0.73190971
Iteration 4685, loss = 0.74560320
Iteration 4686, loss = 0.73181193
Iteration 4687, loss = 0.74018362
Iteration 4688, loss = 0.73104631
Iteration 4689, loss = 0.73583451
Iteration 4690, loss = 0.73112086
Iteration 4691, loss = 0.73307388
Iteration 4692, loss = 0.73154874
Iteration 4693, loss = 0.73093797
Iteration 4694, loss = 0.73087044
Iteration 4695, loss = 0.72852127
Iteration 4696, loss = 0.73007952
Iteration 4697, loss = 0.72685829
Iteration 4698, loss = 0.72919938
Iteration 4699, loss = 0.72572460
Iteration 4700, loss = 0.72815428
Iteration 4701, loss = 0.72487438
Iteration 4702, loss = 0.72702696
Iteration 4703, loss = 0.72399333
Iteration 4704, loss = 0.72522114
Iteration 4705, loss = 0.72267738
Iteration 4706, loss = 0.72316821
Iteration 4707, loss = 0.72081148
Iteration 4708, loss = 0.71756622
Iteration 4709, loss = 0.69571188
Iteration 4710, loss = 0.79545939
Iteration 4711, loss = 0.83281546
Iteration 4712, loss = 0.77428969
Iteration 4713, loss = 0.84823532
Iteration 4714, loss = 0.75469427
Iteration 4715, loss = 0.84307661
Iteration 4716, loss = 0.73584620
Iteration 4717, loss = 0.82309600
Iteration 4718, loss = 0.72763495
Iteration 4719, loss = 0.80199553
Iteration 4720, loss = 0.73072617
Iteration 4721, loss = 0.78082387
Iteration 4722, loss = 0.74070965
Iteration 4723, loss = 0.76073464
Iteration 4724, loss = 0.74870577
Iteration 4725, loss = 0.74329282
Iteration 4726, loss = 0.75303605
Iteration 4727, loss = 0.73137179
Iteration 4728, loss = 0.75268391
Iteration 4729, loss = 0.72559805
Iteration 4730, loss = 0.74862633
Iteration 4731, loss = 0.72556483
Iteration 4732, loss = 0.74240072
Iteration 4733, loss = 0.72815371
Iteration 4734, loss = 0.73528453
Iteration 4735, loss = 0.73082699
Iteration 4736, loss = 0.72892061
Iteration 4737, loss = 0.73216699
Iteration 4738, loss = 0.72471118
Iteration 4739, loss = 0.73178628
Iteration 4740, loss = 0.72269392
Iteration 4741, loss = 0.72942530
Iteration 4742, loss = 0.72206502
Iteration 4743, loss = 0.72660936
Iteration 4744, loss = 0.72275689
Iteration 4745, loss = 0.72358289
Iteration 4746, loss = 0.72261791
Iteration 4747, loss = 0.71984580
Iteration 4748, loss = 0.72048283
Iteration 4749, loss = 0.71705625
Iteration 4750, loss = 0.71905438
Iteration 4751, loss = 0.71533928
Iteration 4752, loss = 0.71639220
Iteration 4753, loss = 0.71256037
Iteration 4754, loss = 0.71246205
Iteration 4755, loss = 0.71053851
Iteration 4756, loss = 0.70639756
Iteration 4757, loss = 0.69583170
Iteration 4758, loss = 0.95709928
Iteration 4759, loss = 1.31496728
Iteration 4760, loss = 0.76459093
Iteration 4761, loss = 0.98036247
Iteration 4762, loss = 0.79820163
Iteration 4763, loss = 0.97523172
Iteration 4764, loss = 0.80247519
Iteration 4765, loss = 0.92303951
Iteration 4766, loss = 0.78908230
Iteration 4767, loss = 0.85392611
Iteration 4768, loss = 0.77956475
Iteration 4769, loss = 0.79326959
Iteration 4770, loss = 0.78017924
Iteration 4771, loss = 0.75373318
Iteration 4772, loss = 0.78522829
Iteration 4773, loss = 0.73756549
Iteration 4774, loss = 0.78516091
Iteration 4775, loss = 0.73642473
Iteration 4776, loss = 0.77683242
Iteration 4777, loss = 0.74142087
Iteration 4778, loss = 0.76038929
Iteration 4779, loss = 0.74658196
Iteration 4780, loss = 0.74184503
Iteration 4781, loss = 0.70711000
Iteration 4782, loss = 0.75881551
Iteration 4783, loss = 0.76829732
Iteration 4784, loss = 0.76094487
Iteration 4785, loss = 0.76765090
Iteration 4786, loss = 0.75187407
Iteration 4787, loss = 0.75425057
Iteration 4788, loss = 0.74495412
Iteration 4789, loss = 0.74436216
Iteration 4790, loss = 0.74604420
Iteration 4791, loss = 0.74294805
Iteration 4792, loss = 0.74929440
Iteration 4793, loss = 0.74527966
Iteration 4794, loss = 0.74934869
Iteration 4795, loss = 0.74698676
Iteration 4796, loss = 0.74651585
Iteration 4797, loss = 0.74692671
Iteration 4798, loss = 0.74385079
Iteration 4799, loss = 0.74576824
Iteration 4800, loss = 0.74301265
Iteration 4801, loss = 0.74428892
Iteration 4802, loss = 0.74349503
Iteration 4803, loss = 0.74321435
Iteration 4804, loss = 0.74411912
Iteration 4805, loss = 0.74279643
Iteration 4806, loss = 0.74385336
Iteration 4807, loss = 0.74249496
Iteration 4808, loss = 0.74257285
Iteration 4809, loss = 0.74203744
Iteration 4810, loss = 0.74133485
Iteration 4811, loss = 0.74170742
Iteration 4812, loss = 0.74094302
Iteration 4813, loss = 0.74147056
Iteration 4814, loss = 0.74104492
Iteration 4815, loss = 0.74104686
Iteration 4816, loss = 0.74098409
Iteration 4817, loss = 0.74047741
Iteration 4818, loss = 0.74056091
Iteration 4819, loss = 0.73997745
Iteration 4820, loss = 0.73994084
Iteration 4821, loss = 0.73961331
Iteration 4822, loss = 0.73936205
Iteration 4823, loss = 0.73929898
Iteration 4824, loss = 0.73893966
Iteration 4825, loss = 0.73893319
Iteration 4826, loss = 0.73863040
Iteration 4827, loss = 0.73850633
Iteration 4828, loss = 0.73833463
Iteration 4829, loss = 0.73808212
Iteration 4830, loss = 0.73798522
Iteration 4831, loss = 0.73770218
Iteration 4832, loss = 0.73757728
Iteration 4833, loss = 0.73735321
Iteration 4834, loss = 0.73715676
Iteration 4835, loss = 0.73700426
Iteration 4836, loss = 0.73677134
Iteration 4837, loss = 0.73663994
Iteration 4838, loss = 0.73642629
Iteration 4839, loss = 0.73626471
Iteration 4840, loss = 0.73609121
Iteration 4841, loss = 0.73589254
Iteration 4842, loss = 0.73573969
Iteration 4843, loss = 0.73553411
Iteration 4844, loss = 0.73537341
Iteration 4845, loss = 0.73518987
Iteration 4846, loss = 0.73501187
Iteration 4847, loss = 0.73485187
Iteration 4848, loss = 0.73466688
Iteration 4849, loss = 0.73451057
Iteration 4850, loss = 0.73432957
Iteration 4851, loss = 0.73396740
Iteration 4852, loss = 0.73360208
Iteration 4853, loss = 0.73371821
Iteration 4854, loss = 0.73293434
Iteration 4855, loss = 0.73169767
Iteration 4856, loss = 0.73029440
Iteration 4857, loss = 0.72882264
Iteration 4858, loss = 0.72682180
Iteration 4859, loss = 0.71927623
Iteration 4860, loss = 0.74987996
Iteration 4861, loss = 0.76470489
Iteration 4862, loss = 0.73776002
Iteration 4863, loss = 0.75951432
Iteration 4864, loss = 0.75104987
Iteration 4865, loss = 0.85995091
Iteration 4866, loss = 0.75891394
Iteration 4867, loss = 0.81884902
Iteration 4868, loss = 0.77412431
Iteration 4869, loss = 0.76339973
Iteration 4870, loss = 0.79118191
Iteration 4871, loss = 0.73881342
Iteration 4872, loss = 0.79256399
Iteration 4873, loss = 0.74401714
Iteration 4874, loss = 0.77301147
Iteration 4875, loss = 0.75928940
Iteration 4876, loss = 0.74929436
Iteration 4877, loss = 0.76844832
Iteration 4878, loss = 0.74176325
Iteration 4879, loss = 0.74794892
Iteration 4880, loss = 0.74597533
Iteration 4881, loss = 0.74329791
Iteration 4882, loss = 0.74919435
Iteration 4883, loss = 0.74124532
Iteration 4884, loss = 0.74795116
Iteration 4885, loss = 0.74162806
Iteration 4886, loss = 0.74420489
Iteration 4887, loss = 0.74319126
Iteration 4888, loss = 0.74109674
Iteration 4889, loss = 0.74389897
Iteration 4890, loss = 0.73974148
Iteration 4891, loss = 0.74280247
Iteration 4892, loss = 0.73986971
Iteration 4893, loss = 0.74074510
Iteration 4894, loss = 0.74054718
Iteration 4895, loss = 0.73919469
Iteration 4896, loss = 0.74074229
Iteration 4897, loss = 0.73848186
Iteration 4898, loss = 0.73959011
Iteration 4899, loss = 0.73828559
Iteration 4900, loss = 0.73831768
Iteration 4901, loss = 0.73841184
Iteration 4902, loss = 0.73738954
Iteration 4903, loss = 0.73807170
Iteration 4904, loss = 0.73693314
Iteration 4905, loss = 0.73734944
Iteration 4906, loss = 0.73679907
Iteration 4907, loss = 0.73649213
Iteration 4908, loss = 0.73655283
Iteration 4909, loss = 0.73584599
Iteration 4910, loss = 0.73610557
Iteration 4911, loss = 0.73551193
Iteration 4912, loss = 0.73552385
Iteration 4913, loss = 0.73528710
Iteration 4914, loss = 0.73493866
Iteration 4915, loss = 0.73493852
Iteration 4916, loss = 0.73445650
Iteration 4917, loss = 0.73446124
Iteration 4918, loss = 0.73413485
Iteration 4919, loss = 0.73397906
Iteration 4920, loss = 0.73383004
Iteration 4921, loss = 0.73350127
Iteration 4922, loss = 0.73342192
Iteration 4923, loss = 0.73309938
Iteration 4924, loss = 0.73296499
Iteration 4925, loss = 0.73265601
Iteration 4926, loss = 0.73222181
Iteration 4927, loss = 0.73202855
Iteration 4928, loss = 0.73149713
Iteration 4929, loss = 0.72991600
Iteration 4930, loss = 0.73041379
Iteration 4931, loss = 0.73359085
Iteration 4932, loss = 0.73223162
Iteration 4933, loss = 0.72956107
Iteration 4934, loss = 0.73208543
Iteration 4935, loss = 0.72688452
Iteration 4936, loss = 0.72629630
Iteration 4937, loss = 0.72633862
Iteration 4938, loss = 0.72177962
Iteration 4939, loss = 0.72098901
Iteration 4940, loss = 0.71685979
Iteration 4941, loss = 0.69696413
Iteration 4942, loss = 0.85466320
Iteration 4943, loss = 0.91638194
Iteration 4944, loss = 0.79063975
Iteration 4945, loss = 0.95366373
Iteration 4946, loss = 0.75440854
Iteration 4947, loss = 0.95009650
Iteration 4948, loss = 0.73579134
Iteration 4949, loss = 0.91373772
Iteration 4950, loss = 0.73715523
Iteration 4951, loss = 0.86050381
Iteration 4952, loss = 0.75893624
Iteration 4953, loss = 0.80241079
Iteration 4954, loss = 0.78661968
Iteration 4955, loss = 0.75753857
Iteration 4956, loss = 0.80316947
Iteration 4957, loss = 0.72600680
Iteration 4958, loss = 0.76611340
Iteration 4959, loss = 0.76778406
Iteration 4960, loss = 0.98145389
Iteration 4961, loss = 0.76511465
Iteration 4962, loss = 0.97834082
Iteration 4963, loss = 0.75522942
Iteration 4964, loss = 0.96047899
Iteration 4965, loss = 0.74421393
Iteration 4966, loss = 0.93675351
Iteration 4967, loss = 0.73846483
Iteration 4968, loss = 0.90971586
Iteration 4969, loss = 0.73691244
Iteration 4970, loss = 0.87796670
Iteration 4971, loss = 0.73893049
Iteration 4972, loss = 0.84202977
Iteration 4973, loss = 0.74507171
Iteration 4974, loss = 0.80589517
Iteration 4975, loss = 0.75451917
Iteration 4976, loss = 0.77418091
Iteration 4977, loss = 0.76435140
Iteration 4978, loss = 0.75151459
Iteration 4979, loss = 0.77098900
Iteration 4980, loss = 0.73766874
Iteration 4981, loss = 0.77071042
Iteration 4982, loss = 0.73156232
Iteration 4983, loss = 0.76540790
Iteration 4984, loss = 0.73113674
Iteration 4985, loss = 0.75471710
Iteration 4986, loss = 0.73470507
Iteration 4987, loss = 0.74647636
Iteration 4988, loss = 0.73950360
Iteration 4989, loss = 0.73745232
Iteration 4990, loss = 0.73834797
Iteration 4991, loss = 0.72646142
Iteration 4992, loss = 0.73052656
Iteration 4993, loss = 0.69421821
Iteration 4994, loss = 1.03525200
Iteration 4995, loss = 1.96727333
Iteration 4996, loss = 1.53442993
Iteration 4997, loss = 1.23238377
Iteration 4998, loss = 1.69259711
Iteration 4999, loss = 0.84396615
Iteration 5000, loss = 1.57470497
