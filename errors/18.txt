Iteration 1, loss = 0.75895624
Iteration 2, loss = 6.88465522
Iteration 3, loss = 3.24031550
Iteration 4, loss = 0.96276495
Iteration 5, loss = 1.96691322
Iteration 6, loss = 1.99853757
Iteration 7, loss = 1.17049543
Iteration 8, loss = 0.82185300
Iteration 9, loss = 1.25199000
Iteration 10, loss = 1.13114994
Iteration 11, loss = 0.79703553
Iteration 12, loss = 0.79081258
Iteration 13, loss = 0.84978078
Iteration 14, loss = 0.80023316
Iteration 15, loss = 0.75500165
Iteration 16, loss = 0.84117550
Iteration 17, loss = 1.02555996
Iteration 18, loss = 0.82230972
Iteration 19, loss = 0.82755001
Iteration 20, loss = 0.87849833
Iteration 21, loss = 0.90396268
Iteration 22, loss = 2.12344069
Iteration 23, loss = 0.76468351
Iteration 24, loss = 1.69707860
Iteration 25, loss = 0.84934865
Iteration 26, loss = 1.31951881
Iteration 27, loss = 1.02610704
Iteration 28, loss = 1.88753500
Iteration 29, loss = 0.87620686
Iteration 30, loss = 0.69402518
Iteration 31, loss = 0.94968314
Iteration 32, loss = 0.84157359
Iteration 33, loss = 1.17233579
Iteration 34, loss = 0.99323506
Iteration 35, loss = 0.90215521
Iteration 36, loss = 1.03472238
Iteration 37, loss = 1.06766822
Iteration 38, loss = 0.90909506
Iteration 39, loss = 0.86540634
Iteration 40, loss = 0.89206499
Iteration 41, loss = 0.91934111
Iteration 42, loss = 0.89183453
Iteration 43, loss = 0.92021308
Iteration 44, loss = 0.90772072
Iteration 45, loss = 0.85523356
Iteration 46, loss = 0.86219542
Iteration 47, loss = 0.94902416
Iteration 48, loss = 0.95586181
Iteration 49, loss = 0.86037808
Iteration 50, loss = 0.83297487
Iteration 51, loss = 0.89892808
Iteration 52, loss = 0.90470682
Iteration 53, loss = 0.84141117
Iteration 54, loss = 0.82910171
Iteration 55, loss = 0.86557319
Iteration 56, loss = 0.71909195
Iteration 57, loss = 0.89408802
Iteration 58, loss = 0.87439273
Iteration 59, loss = 0.85895914
Iteration 60, loss = 0.88030313
Iteration 61, loss = 0.89142904
Iteration 62, loss = 0.86853156
Iteration 63, loss = 0.84921720
Iteration 64, loss = 0.85498324
Iteration 65, loss = 0.85364149
Iteration 66, loss = 0.81342405
Iteration 67, loss = 0.97764693
Iteration 68, loss = 0.82700553
Iteration 69, loss = 0.86237331
Iteration 70, loss = 0.89119740
Iteration 71, loss = 0.84739651
Iteration 72, loss = 0.99252962
Iteration 73, loss = 0.84343080
Iteration 74, loss = 1.25550525
Iteration 75, loss = 0.83978365
Iteration 76, loss = 0.93108038
Iteration 77, loss = 0.89561140
Iteration 78, loss = 0.86952993
Iteration 79, loss = 0.91905909
Iteration 80, loss = 0.85021347
Iteration 81, loss = 0.87608879
Iteration 82, loss = 0.86556991
Iteration 83, loss = 1.40253286
Iteration 84, loss = 1.22489614
Iteration 85, loss = 1.03087552
Iteration 86, loss = 1.52752879
Iteration 87, loss = 0.84913538
Iteration 88, loss = 0.93500830
Iteration 89, loss = 0.86778665
Iteration 90, loss = 0.88149746
Iteration 91, loss = 0.93388734
Iteration 92, loss = 0.91182374
Iteration 93, loss = 0.92423767
Iteration 94, loss = 0.86401494
Iteration 95, loss = 0.89264514
Iteration 96, loss = 0.91700386
Iteration 97, loss = 0.84219633
Iteration 98, loss = 0.90871887
Iteration 99, loss = 0.86477997
Iteration 100, loss = 0.83745390
Iteration 101, loss = 0.88426023
Iteration 102, loss = 0.83580193
Iteration 103, loss = 0.84441020
Iteration 104, loss = 0.86557130
Iteration 105, loss = 0.82454841
Iteration 106, loss = 0.84551108
Iteration 107, loss = 0.83614320
Iteration 108, loss = 0.88827152
Iteration 109, loss = 0.78193426
Iteration 110, loss = 0.88732796
Iteration 111, loss = 0.84799377
Iteration 112, loss = 0.88359342
Iteration 113, loss = 0.89101594
Iteration 114, loss = 0.85755561
Iteration 115, loss = 0.88264114
Iteration 116, loss = 0.93794030
Iteration 117, loss = 0.85366023
Iteration 118, loss = 0.94315495
Iteration 119, loss = 0.89076892
Iteration 120, loss = 0.84484861
Iteration 121, loss = 0.90707069
Iteration 122, loss = 0.85182206
Iteration 123, loss = 0.83966412
Iteration 124, loss = 0.88068387
Iteration 125, loss = 0.83131660
Iteration 126, loss = 0.84070483
Iteration 127, loss = 0.86049909
Iteration 128, loss = 0.82162673
Iteration 129, loss = 0.84183315
Iteration 130, loss = 0.84280422
Iteration 131, loss = 0.81890083
Iteration 132, loss = 0.84015768
Iteration 133, loss = 0.83106849
Iteration 134, loss = 0.81989259
Iteration 135, loss = 0.83501315
Iteration 136, loss = 0.82105152
Iteration 137, loss = 0.82095479
Iteration 138, loss = 0.82761346
Iteration 139, loss = 0.81343405
Iteration 140, loss = 0.81759211
Iteration 141, loss = 0.81751449
Iteration 142, loss = 0.80851285
Iteration 143, loss = 0.81403119
Iteration 144, loss = 0.80817294
Iteration 145, loss = 0.79735326
Iteration 146, loss = 0.97212572
Iteration 147, loss = 0.82630310
Iteration 148, loss = 1.00815058
Iteration 149, loss = 0.85852381
Iteration 150, loss = 0.88594522
Iteration 151, loss = 0.93914539
Iteration 152, loss = 0.80309920
Iteration 153, loss = 0.90043386
Iteration 154, loss = 0.85290809
Iteration 155, loss = 0.81246965
Iteration 156, loss = 0.85711266
Iteration 157, loss = 0.96303466
Iteration 158, loss = 0.82005301
Iteration 159, loss = 0.87811952
Iteration 160, loss = 0.92800897
Iteration 161, loss = 0.81254216
Iteration 162, loss = 1.03860014
Iteration 163, loss = 0.89176535
Iteration 164, loss = 0.87037306
Iteration 165, loss = 0.97771183
Iteration 166, loss = 0.83067358
Iteration 167, loss = 0.87507558
Iteration 168, loss = 0.91088406
Iteration 169, loss = 0.80095363
Iteration 170, loss = 0.87506848
Iteration 171, loss = 0.85884967
Iteration 172, loss = 0.80156808
Iteration 173, loss = 0.86777601
Iteration 174, loss = 0.82190255
Iteration 175, loss = 0.81176355
Iteration 176, loss = 0.84863216
Iteration 177, loss = 0.79856454
Iteration 178, loss = 0.82215852
Iteration 179, loss = 0.82368633
Iteration 180, loss = 0.78792805
Iteration 181, loss = 0.80003536
Iteration 182, loss = 0.80425307
Iteration 183, loss = 0.80309225
Iteration 184, loss = 0.78642948
Iteration 185, loss = 0.81215884
Iteration 186, loss = 0.80613865
Iteration 187, loss = 0.80205502
Iteration 188, loss = 0.80522876
Iteration 189, loss = 0.79934524
Iteration 190, loss = 0.79913631
Iteration 191, loss = 0.80270764
Iteration 192, loss = 0.87515117
Iteration 193, loss = 0.77297092
Iteration 194, loss = 1.03439697
Iteration 195, loss = 0.87542811
Iteration 196, loss = 0.87452131
Iteration 197, loss = 0.98348687
Iteration 198, loss = 0.85678616
Iteration 199, loss = 0.84222120
Iteration 200, loss = 0.92589984
Iteration 201, loss = 0.83579862
Iteration 202, loss = 0.83003397
Iteration 203, loss = 0.89594926
Iteration 204, loss = 0.82995812
Iteration 205, loss = 0.82869876
Iteration 206, loss = 0.87336752
Iteration 207, loss = 0.82036203
Iteration 208, loss = 0.82243557
Iteration 209, loss = 0.85219160
Iteration 210, loss = 0.81147441
Iteration 211, loss = 0.81835064
Iteration 212, loss = 0.83754016
Iteration 213, loss = 0.80638762
Iteration 214, loss = 0.81546934
Iteration 215, loss = 0.82590091
Iteration 216, loss = 0.80235187
Iteration 217, loss = 0.81203380
Iteration 218, loss = 0.81583854
Iteration 219, loss = 0.79851489
Iteration 220, loss = 0.80765043
Iteration 221, loss = 0.80701916
Iteration 222, loss = 0.79516825
Iteration 223, loss = 0.80312730
Iteration 224, loss = 0.79897674
Iteration 225, loss = 0.79211173
Iteration 226, loss = 0.79695685
Iteration 227, loss = 0.79340493
Iteration 228, loss = 0.78796411
Iteration 229, loss = 0.78845037
Iteration 230, loss = 0.83183440
Iteration 231, loss = 0.81790356
Iteration 232, loss = 0.79071619
Iteration 233, loss = 0.82542586
Iteration 234, loss = 0.81083895
Iteration 235, loss = 0.84489842
Iteration 236, loss = 0.83264143
Iteration 237, loss = 0.81361452
Iteration 238, loss = 0.83167647
Iteration 239, loss = 0.81971294
Iteration 240, loss = 0.80423029
Iteration 241, loss = 0.81872258
Iteration 242, loss = 0.81043329
Iteration 243, loss = 0.80468044
Iteration 244, loss = 0.81686320
Iteration 245, loss = 0.81074240
Iteration 246, loss = 0.80380383
Iteration 247, loss = 0.81113145
Iteration 248, loss = 0.80467780
Iteration 249, loss = 0.79894614
Iteration 250, loss = 0.80333414
Iteration 251, loss = 0.79709732
Iteration 252, loss = 0.79258856
Iteration 253, loss = 0.79523561
Iteration 254, loss = 0.79006071
Iteration 255, loss = 0.78709410
Iteration 256, loss = 0.79420016
Iteration 257, loss = 0.78158353
Iteration 258, loss = 0.78474980
Iteration 259, loss = 0.79528894
Iteration 260, loss = 0.78100303
Iteration 261, loss = 0.78789706
Iteration 262, loss = 0.78555279
Iteration 263, loss = 0.77474759
Iteration 264, loss = 0.78107955
Iteration 265, loss = 0.77871729
Iteration 266, loss = 0.77204052
Iteration 267, loss = 0.77692485
Iteration 268, loss = 0.77338476
Iteration 269, loss = 0.76884083
Iteration 270, loss = 0.77213062
Iteration 271, loss = 0.76819328
Iteration 272, loss = 0.76513414
Iteration 273, loss = 0.76697172
Iteration 274, loss = 0.76198071
Iteration 275, loss = 0.78456189
Iteration 276, loss = 0.77840291
Iteration 277, loss = 0.77195816
Iteration 278, loss = 0.77840594
Iteration 279, loss = 0.76506684
Iteration 280, loss = 0.77522936
Iteration 281, loss = 0.76243325
Iteration 282, loss = 0.77296681
Iteration 283, loss = 0.76159087
Iteration 284, loss = 0.77020988
Iteration 285, loss = 0.75994672
Iteration 286, loss = 0.76668030
Iteration 287, loss = 0.75779465
Iteration 288, loss = 0.76286629
Iteration 289, loss = 0.75508521
Iteration 290, loss = 0.75793544
Iteration 291, loss = 0.75181721
Iteration 292, loss = 0.75133813
Iteration 293, loss = 0.78983742
Iteration 294, loss = 0.77629273
Iteration 295, loss = 0.78248361
Iteration 296, loss = 0.75685133
Iteration 297, loss = 0.79669558
Iteration 298, loss = 0.78351029
Iteration 299, loss = 0.79922332
Iteration 300, loss = 0.77106794
Iteration 301, loss = 0.79611505
Iteration 302, loss = 0.76204364
Iteration 303, loss = 0.78912887
Iteration 304, loss = 0.76009642
Iteration 305, loss = 0.78208743
Iteration 306, loss = 0.76352504
Iteration 307, loss = 0.77465110
Iteration 308, loss = 0.76664341
Iteration 309, loss = 0.76675886
Iteration 310, loss = 0.76809112
Iteration 311, loss = 0.76031509
Iteration 312, loss = 0.76697847
Iteration 313, loss = 0.75500097
Iteration 314, loss = 0.76203154
Iteration 315, loss = 0.74989016
Iteration 316, loss = 0.75320989
Iteration 317, loss = 0.86524677
Iteration 318, loss = 0.94167286
Iteration 319, loss = 0.81840706
Iteration 320, loss = 0.91097349
Iteration 321, loss = 0.89663335
Iteration 322, loss = 0.84000534
Iteration 323, loss = 0.91090257
Iteration 324, loss = 0.79514081
Iteration 325, loss = 0.86916986
Iteration 326, loss = 0.79393425
Iteration 327, loss = 0.82901747
Iteration 328, loss = 0.81662366
Iteration 329, loss = 0.79103733
Iteration 330, loss = 0.82456534
Iteration 331, loss = 0.77755874
Iteration 332, loss = 0.81700762
Iteration 333, loss = 0.79024820
Iteration 334, loss = 0.80315021
Iteration 335, loss = 0.80683419
Iteration 336, loss = 0.79057203
Iteration 337, loss = 0.81001996
Iteration 338, loss = 0.78571904
Iteration 339, loss = 0.80585644
Iteration 340, loss = 0.79404286
Iteration 341, loss = 0.79946428
Iteration 342, loss = 0.80274230
Iteration 343, loss = 0.79080268
Iteration 344, loss = 0.80084360
Iteration 345, loss = 0.78689668
Iteration 346, loss = 0.79615742
Iteration 347, loss = 0.79019833
Iteration 348, loss = 0.79188683
Iteration 349, loss = 0.79359294
Iteration 350, loss = 0.78802140
Iteration 351, loss = 0.79434573
Iteration 352, loss = 0.79333499
Iteration 353, loss = 0.79944967
Iteration 354, loss = 0.79450627
Iteration 355, loss = 0.79159588
Iteration 356, loss = 0.78798116
Iteration 357, loss = 0.78405108
Iteration 358, loss = 0.78421317
Iteration 359, loss = 0.78197794
Iteration 360, loss = 0.78459873
Iteration 361, loss = 0.78134237
Iteration 362, loss = 0.78086359
Iteration 363, loss = 0.77801220
Iteration 364, loss = 0.77665612
Iteration 365, loss = 0.77568583
Iteration 366, loss = 0.77309398
Iteration 367, loss = 0.77211086
Iteration 368, loss = 0.76865935
Iteration 369, loss = 0.77782174
Iteration 370, loss = 0.79417940
Iteration 371, loss = 0.77088855
Iteration 372, loss = 0.78053555
Iteration 373, loss = 0.76433915
Iteration 374, loss = 0.71672589
Iteration 375, loss = 0.91385437
Iteration 376, loss = 0.74861743
Iteration 377, loss = 1.08849933
Iteration 378, loss = 1.03497786
Iteration 379, loss = 0.95404741
Iteration 380, loss = 1.08996982
Iteration 381, loss = 0.85648261
Iteration 382, loss = 1.02012852
Iteration 383, loss = 0.86384580
Iteration 384, loss = 0.90910679
Iteration 385, loss = 0.90611660
Iteration 386, loss = 0.82822032
Iteration 387, loss = 0.92488040
Iteration 388, loss = 0.81606758
Iteration 389, loss = 0.90569212
Iteration 390, loss = 0.84224148
Iteration 391, loss = 0.86237765
Iteration 392, loss = 0.86593043
Iteration 393, loss = 0.82579908
Iteration 394, loss = 0.86993392
Iteration 395, loss = 0.81336154
Iteration 396, loss = 0.85620211
Iteration 397, loss = 0.81959466
Iteration 398, loss = 0.85775389
Iteration 399, loss = 0.81520969
Iteration 400, loss = 0.83964310
Iteration 401, loss = 0.82476382
Iteration 402, loss = 0.81594621
Iteration 403, loss = 0.83125581
Iteration 404, loss = 0.80736438
Iteration 405, loss = 0.82617754
Iteration 406, loss = 0.80582880
Iteration 407, loss = 0.81749486
Iteration 408, loss = 0.80898478
Iteration 409, loss = 0.80882400
Iteration 410, loss = 0.81016151
Iteration 411, loss = 0.80245840
Iteration 412, loss = 0.80950327
Iteration 413, loss = 0.79931126
Iteration 414, loss = 0.80600034
Iteration 415, loss = 0.79757706
Iteration 416, loss = 0.80132694
Iteration 417, loss = 0.79715371
Iteration 418, loss = 0.79382932
Iteration 419, loss = 0.79296120
Iteration 420, loss = 0.79246044
Iteration 421, loss = 0.79223880
Iteration 422, loss = 0.79138924
Iteration 423, loss = 0.79084294
Iteration 424, loss = 0.78966826
Iteration 425, loss = 0.78911756
Iteration 426, loss = 0.78801922
Iteration 427, loss = 0.78744232
Iteration 428, loss = 0.78639080
Iteration 429, loss = 0.78488468
Iteration 430, loss = 0.81073400
Iteration 431, loss = 0.82375568
Iteration 432, loss = 0.80031373
Iteration 433, loss = 0.82773567
Iteration 434, loss = 0.78934656
Iteration 435, loss = 0.81993650
Iteration 436, loss = 0.78712764
Iteration 437, loss = 0.81265359
Iteration 438, loss = 0.79077162
Iteration 439, loss = 0.80365060
Iteration 440, loss = 0.79197391
Iteration 441, loss = 0.79179133
Iteration 442, loss = 0.81195147
Iteration 443, loss = 0.84022484
Iteration 444, loss = 0.83056400
Iteration 445, loss = 0.80678369
Iteration 446, loss = 0.83524502
Iteration 447, loss = 0.79113267
Iteration 448, loss = 0.83399415
Iteration 449, loss = 0.78829319
Iteration 450, loss = 0.82162644
Iteration 451, loss = 0.79178594
Iteration 452, loss = 0.80813306
Iteration 453, loss = 0.79725671
Iteration 454, loss = 0.79473324
Iteration 455, loss = 0.79800215
Iteration 456, loss = 0.78340593
Iteration 457, loss = 0.79610904
Iteration 458, loss = 0.76913104
Iteration 459, loss = 0.78871912
Iteration 460, loss = 0.80761541
Iteration 461, loss = 0.79111420
Iteration 462, loss = 0.79852109
Iteration 463, loss = 0.78651109
Iteration 464, loss = 0.77145888
Iteration 465, loss = 0.82452000
Iteration 466, loss = 0.82121823
Iteration 467, loss = 0.84707099
Iteration 468, loss = 0.80372802
Iteration 469, loss = 0.83612002
Iteration 470, loss = 0.79120129
Iteration 471, loss = 0.82260146
Iteration 472, loss = 0.79963234
Iteration 473, loss = 0.81613848
Iteration 474, loss = 0.81105782
Iteration 475, loss = 0.80604089
Iteration 476, loss = 0.81270827
Iteration 477, loss = 0.79638291
Iteration 478, loss = 0.81008702
Iteration 479, loss = 0.79398212
Iteration 480, loss = 0.80742908
Iteration 481, loss = 0.79562961
Iteration 482, loss = 0.80224772
Iteration 483, loss = 0.79630955
Iteration 484, loss = 0.79596099
Iteration 485, loss = 0.79596169
Iteration 486, loss = 0.79115654
Iteration 487, loss = 0.79468558
Iteration 488, loss = 0.78804351
Iteration 489, loss = 0.79226717
Iteration 490, loss = 0.78607482
Iteration 491, loss = 0.78897230
Iteration 492, loss = 0.78452951
Iteration 493, loss = 0.78530219
Iteration 494, loss = 0.78299764
Iteration 495, loss = 0.78181903
Iteration 496, loss = 0.78117254
Iteration 497, loss = 0.77868504
Iteration 498, loss = 0.77892255
Iteration 499, loss = 0.86942621
Iteration 500, loss = 1.02858714
Iteration 501, loss = 0.86006792
Iteration 502, loss = 0.93509633
Iteration 503, loss = 0.94377443
Iteration 504, loss = 0.81980812
Iteration 505, loss = 0.94026398
Iteration 506, loss = 0.78399458
Iteration 507, loss = 0.90032969
Iteration 508, loss = 0.81952974
Iteration 509, loss = 0.84660813
Iteration 510, loss = 0.85576117
Iteration 511, loss = 0.80065735
Iteration 512, loss = 0.86144342
Iteration 513, loss = 0.78427591
Iteration 514, loss = 0.84357358
Iteration 515, loss = 0.79367362
Iteration 516, loss = 0.81629565
Iteration 517, loss = 0.80758231
Iteration 518, loss = 0.79082571
Iteration 519, loss = 0.81081491
Iteration 520, loss = 0.76970885
Iteration 521, loss = 0.71455716
Iteration 522, loss = 1.02053420
Iteration 523, loss = 0.85820314
Iteration 524, loss = 1.00446598
Iteration 525, loss = 0.81152926
Iteration 526, loss = 0.95924329
Iteration 527, loss = 0.79299926
Iteration 528, loss = 0.91995654
Iteration 529, loss = 0.80672596
Iteration 530, loss = 0.88590681
Iteration 531, loss = 0.82779935
Iteration 532, loss = 0.85005781
Iteration 533, loss = 0.84094128
Iteration 534, loss = 0.81959923
Iteration 535, loss = 0.84459432
Iteration 536, loss = 0.79765577
Iteration 537, loss = 0.83889932
Iteration 538, loss = 0.78615976
Iteration 539, loss = 0.82941821
Iteration 540, loss = 0.78494135
Iteration 541, loss = 0.81882517
Iteration 542, loss = 0.78686516
Iteration 543, loss = 0.80629573
Iteration 544, loss = 0.78820017
Iteration 545, loss = 0.79369000
Iteration 546, loss = 0.78848380
Iteration 547, loss = 0.78403251
Iteration 548, loss = 0.78717893
Iteration 549, loss = 0.77601092
Iteration 550, loss = 0.78390997
Iteration 551, loss = 0.76968285
Iteration 552, loss = 0.77874859
Iteration 553, loss = 0.76520293
Iteration 554, loss = 0.77210884
Iteration 555, loss = 0.76073945
Iteration 556, loss = 0.76099864
Iteration 557, loss = 0.74709944
Iteration 558, loss = 0.95098234
Iteration 559, loss = 0.80328388
Iteration 560, loss = 0.96388878
Iteration 561, loss = 0.79622217
Iteration 562, loss = 0.90133942
Iteration 563, loss = 0.82248922
Iteration 564, loss = 0.81769600
Iteration 565, loss = 0.82470364
Iteration 566, loss = 0.87640854
Iteration 567, loss = 1.14500807
Iteration 568, loss = 1.00547207
Iteration 569, loss = 0.96340903
Iteration 570, loss = 1.02664414
Iteration 571, loss = 0.81505875
Iteration 572, loss = 0.99979910
Iteration 573, loss = 0.77454165
Iteration 574, loss = 0.96072736
Iteration 575, loss = 0.80247950
Iteration 576, loss = 0.90786243
Iteration 577, loss = 0.83974033
Iteration 578, loss = 0.84340121
Iteration 579, loss = 0.85974729
Iteration 580, loss = 0.79352870
Iteration 581, loss = 0.85790637
Iteration 582, loss = 0.76803770
Iteration 583, loss = 0.84129920
Iteration 584, loss = 0.76152247
Iteration 585, loss = 0.82196536
Iteration 586, loss = 0.76926057
Iteration 587, loss = 0.84367729
Iteration 588, loss = 0.78950987
Iteration 589, loss = 0.80593739
Iteration 590, loss = 0.79752883
Iteration 591, loss = 0.76964978
Iteration 592, loss = 0.79806113
Iteration 593, loss = 0.75824691
Iteration 594, loss = 0.78329622
Iteration 595, loss = 0.74813007
Iteration 596, loss = 0.73390325
Iteration 597, loss = 1.47726941
Iteration 598, loss = 1.21910111
Iteration 599, loss = 0.95630198
Iteration 600, loss = 1.36469729
Iteration 601, loss = 0.97176442
Iteration 602, loss = 1.06255425
Iteration 603, loss = 1.18804058
Iteration 604, loss = 0.81184808
Iteration 605, loss = 1.06776310
Iteration 606, loss = 0.96685550
Iteration 607, loss = 0.79447754
Iteration 608, loss = 1.51671725
Iteration 609, loss = 0.91941722
Iteration 610, loss = 1.24373800
Iteration 611, loss = 1.39280789
Iteration 612, loss = 0.83576347
Iteration 613, loss = 1.21617450
Iteration 614, loss = 1.17598401
Iteration 615, loss = 0.80671647
Iteration 616, loss = 1.15664854
Iteration 617, loss = 0.96922309
Iteration 618, loss = 0.88775137
Iteration 619, loss = 1.08119932
Iteration 620, loss = 0.82369513
Iteration 621, loss = 0.95612226
Iteration 622, loss = 0.95515388
Iteration 623, loss = 0.79838019
Iteration 624, loss = 0.95675833
Iteration 625, loss = 0.83078978
Iteration 626, loss = 0.85069245
Iteration 627, loss = 0.89924334
Iteration 628, loss = 0.78357237
Iteration 629, loss = 0.87437354
Iteration 630, loss = 0.80932218
Iteration 631, loss = 1.00822329
Iteration 632, loss = 0.82791241
Iteration 633, loss = 0.91127155
Iteration 634, loss = 0.91381220
Iteration 635, loss = 0.80675655
Iteration 636, loss = 0.92226878
Iteration 637, loss = 0.80127792
Iteration 638, loss = 0.86707261
Iteration 639, loss = 0.84702595
Iteration 640, loss = 0.80498529
Iteration 641, loss = 0.86524920
Iteration 642, loss = 0.78871143
Iteration 643, loss = 0.84363515
Iteration 644, loss = 0.80910799
Iteration 645, loss = 0.80702106
Iteration 646, loss = 0.82648516
Iteration 647, loss = 0.78603905
Iteration 648, loss = 0.82268534
Iteration 649, loss = 0.78877729
Iteration 650, loss = 0.80434413
Iteration 651, loss = 0.79997038
Iteration 652, loss = 0.78721088
Iteration 653, loss = 0.80417036
Iteration 654, loss = 0.78153253
Iteration 655, loss = 0.79829367
Iteration 656, loss = 0.78550502
Iteration 657, loss = 0.78876670
Iteration 658, loss = 0.79040315
Iteration 659, loss = 0.78087279
Iteration 660, loss = 0.79024518
Iteration 661, loss = 0.77907444
Iteration 662, loss = 0.78598546
Iteration 663, loss = 0.78083029
Iteration 664, loss = 0.78039886
Iteration 665, loss = 0.78221339
Iteration 666, loss = 0.77688426
Iteration 667, loss = 0.78162986
Iteration 668, loss = 0.77614364
Iteration 669, loss = 0.77889045
Iteration 670, loss = 0.77661228
Iteration 671, loss = 0.77587103
Iteration 672, loss = 0.77679285
Iteration 673, loss = 0.77381284
Iteration 674, loss = 0.77445169
Iteration 675, loss = 0.77278617
Iteration 676, loss = 0.77541279
Iteration 677, loss = 0.77495973
Iteration 678, loss = 0.77402115
Iteration 679, loss = 0.77193618
Iteration 680, loss = 0.77166258
Iteration 681, loss = 0.77167673
Iteration 682, loss = 0.77154621
Iteration 683, loss = 0.77077797
Iteration 684, loss = 0.76985966
Iteration 685, loss = 0.76949485
Iteration 686, loss = 0.76889194
Iteration 687, loss = 0.76929126
Iteration 688, loss = 0.76910404
Iteration 689, loss = 0.76776955
Iteration 690, loss = 0.76875752
Iteration 691, loss = 0.76696448
Iteration 692, loss = 0.76621392
Iteration 693, loss = 0.76642679
Iteration 694, loss = 0.77748878
Iteration 695, loss = 0.77091837
Iteration 696, loss = 0.77018649
Iteration 697, loss = 0.77433668
Iteration 698, loss = 0.76451919
Iteration 699, loss = 0.77282270
Iteration 700, loss = 0.76401274
Iteration 701, loss = 0.76790255
Iteration 702, loss = 0.76544089
Iteration 703, loss = 0.76306306
Iteration 704, loss = 0.76568820
Iteration 705, loss = 0.75997887
Iteration 706, loss = 0.76345057
Iteration 707, loss = 0.75931684
Iteration 708, loss = 0.75973503
Iteration 709, loss = 0.75884914
Iteration 710, loss = 0.75594866
Iteration 711, loss = 0.75695101
Iteration 712, loss = 0.75267654
Iteration 713, loss = 0.75209951
Iteration 714, loss = 0.74837785
Iteration 715, loss = 0.74310752
Iteration 716, loss = 0.68228797
Iteration 717, loss = 0.80428944
Iteration 718, loss = 1.03054602
Iteration 719, loss = 0.87599239
Iteration 720, loss = 0.96851733
Iteration 721, loss = 0.93338624
Iteration 722, loss = 0.85441897
Iteration 723, loss = 0.92869435
Iteration 724, loss = 0.79749099
Iteration 725, loss = 0.91761349
Iteration 726, loss = 0.80898122
Iteration 727, loss = 0.90530179
Iteration 728, loss = 0.84255150
Iteration 729, loss = 0.87709170
Iteration 730, loss = 0.86327477
Iteration 731, loss = 0.84592176
Iteration 732, loss = 0.87079806
Iteration 733, loss = 0.82650084
Iteration 734, loss = 0.86608043
Iteration 735, loss = 0.81595899
Iteration 736, loss = 1.04587859
Iteration 737, loss = 0.83363018
Iteration 738, loss = 1.01033435
Iteration 739, loss = 0.88986663
Iteration 740, loss = 0.82177725
Iteration 741, loss = 1.01259083
Iteration 742, loss = 0.85759186
Iteration 743, loss = 0.94178377
Iteration 744, loss = 0.90488806
Iteration 745, loss = 0.85258025
Iteration 746, loss = 1.24732043
Iteration 747, loss = 0.87270001
Iteration 748, loss = 1.24397031
Iteration 749, loss = 1.02744069
Iteration 750, loss = 0.97960286
Iteration 751, loss = 1.13007838
Iteration 752, loss = 0.84849078
Iteration 753, loss = 1.04087578
Iteration 754, loss = 0.96049248
Iteration 755, loss = 0.88622514
Iteration 756, loss = 1.01877696
Iteration 757, loss = 0.85276056
Iteration 758, loss = 0.96470351
Iteration 759, loss = 0.91352267
Iteration 760, loss = 0.86762007
Iteration 761, loss = 0.93901215
Iteration 762, loss = 0.83421782
Iteration 763, loss = 0.90807173
Iteration 764, loss = 0.86169997
Iteration 765, loss = 0.84481398
Iteration 766, loss = 0.81252239
Iteration 767, loss = 0.84221148
Iteration 768, loss = 0.94495839
Iteration 769, loss = 0.91011872
Iteration 770, loss = 0.93428163
Iteration 771, loss = 0.95083272
Iteration 772, loss = 0.84636689
Iteration 773, loss = 0.93524648
Iteration 774, loss = 0.82841013
Iteration 775, loss = 0.90637404
Iteration 776, loss = 0.85008615
Iteration 777, loss = 0.85949089
Iteration 778, loss = 0.86711171
Iteration 779, loss = 0.82652652
Iteration 780, loss = 0.86915660
Iteration 781, loss = 0.81511801
Iteration 782, loss = 0.85375442
Iteration 783, loss = 0.81681026
Iteration 784, loss = 0.82910877
Iteration 785, loss = 0.81788800
Iteration 786, loss = 0.77365579
Iteration 787, loss = 0.93210049
Iteration 788, loss = 1.11148320
Iteration 789, loss = 0.88061128
Iteration 790, loss = 1.09955161
Iteration 791, loss = 0.87697390
Iteration 792, loss = 1.04557869
Iteration 793, loss = 0.89391926
Iteration 794, loss = 0.97558606
Iteration 795, loss = 0.91634209
Iteration 796, loss = 0.90975563
Iteration 797, loss = 0.92782811
Iteration 798, loss = 0.85192539
Iteration 799, loss = 0.91786535
Iteration 800, loss = 0.81177700
Iteration 801, loss = 0.89303389
Iteration 802, loss = 0.78686813
Iteration 803, loss = 0.86544921
Iteration 804, loss = 0.73289506
Iteration 805, loss = 1.06184944
Iteration 806, loss = 1.63706715
Iteration 807, loss = 1.38239947
Iteration 808, loss = 1.17928665
Iteration 809, loss = 1.39569347
Iteration 810, loss = 0.86497614
Iteration 811, loss = 1.26925882
Iteration 812, loss = 0.83501492
Iteration 813, loss = 1.22312543
Iteration 814, loss = 0.96473993
Iteration 815, loss = 1.05447757
Iteration 816, loss = 1.08304846
Iteration 817, loss = 0.87232724
Iteration 818, loss = 1.07975445
Iteration 819, loss = 0.81692607
Iteration 820, loss = 1.02477784
Iteration 821, loss = 0.85158014
Iteration 822, loss = 0.94737387
Iteration 823, loss = 0.90030050
Iteration 824, loss = 0.86871206
Iteration 825, loss = 0.92122042
Iteration 826, loss = 0.81746559
Iteration 827, loss = 0.91257955
Iteration 828, loss = 0.80168851
Iteration 829, loss = 0.88429416
Iteration 830, loss = 0.79235064
Iteration 831, loss = 0.93708400
Iteration 832, loss = 0.82020040
Iteration 833, loss = 0.89356192
Iteration 834, loss = 0.85276252
Iteration 835, loss = 0.83732512
Iteration 836, loss = 0.86066457
Iteration 837, loss = 1.09344243
Iteration 838, loss = 0.70629688
Iteration 839, loss = 1.27766544
Iteration 840, loss = 0.88871435
Iteration 841, loss = 1.18642593
Iteration 842, loss = 1.11264428
Iteration 843, loss = 0.90900889
Iteration 844, loss = 1.12280078
Iteration 845, loss = 0.85206748
Iteration 846, loss = 1.00546446
Iteration 847, loss = 0.95966579
Iteration 848, loss = 0.86641572
Iteration 849, loss = 1.00160608
Iteration 850, loss = 0.83774459
Iteration 851, loss = 0.95603879
Iteration 852, loss = 0.89003244
Iteration 853, loss = 0.87399775
Iteration 854, loss = 0.92426433
Iteration 855, loss = 0.83082458
Iteration 856, loss = 0.91306078
Iteration 857, loss = 0.84429322
Iteration 858, loss = 0.87385173
Iteration 859, loss = 0.87037996
Iteration 860, loss = 0.83718011
Iteration 861, loss = 0.87681097
Iteration 862, loss = 0.82614476
Iteration 863, loss = 0.86170461
Iteration 864, loss = 0.83464051
Iteration 865, loss = 0.83840778
Iteration 866, loss = 0.84408379
Iteration 867, loss = 0.82213871
Iteration 868, loss = 0.84315948
Iteration 869, loss = 0.81823454
Iteration 870, loss = 0.83223162
Iteration 871, loss = 0.82044779
Iteration 872, loss = 0.81895236
Iteration 873, loss = 0.82040109
Iteration 874, loss = 0.80611053
Iteration 875, loss = 0.78204970
Iteration 876, loss = 0.90063559
Iteration 877, loss = 0.86609713
Iteration 878, loss = 0.91234545
Iteration 879, loss = 0.83835481
Iteration 880, loss = 0.87614431
Iteration 881, loss = 0.82894111
Iteration 882, loss = 0.85355642
Iteration 883, loss = 0.84500450
Iteration 884, loss = 0.83504381
Iteration 885, loss = 0.75919328
Iteration 886, loss = 0.87100311
Iteration 887, loss = 0.86889996
Iteration 888, loss = 0.89858338
Iteration 889, loss = 0.87242268
Iteration 890, loss = 0.89831649
Iteration 891, loss = 0.86479094
Iteration 892, loss = 0.87752308
Iteration 893, loss = 0.85560557
Iteration 894, loss = 0.85794703
Iteration 895, loss = 0.85567883
Iteration 896, loss = 0.85123723
Iteration 897, loss = 0.86188974
Iteration 898, loss = 0.85278288
Iteration 899, loss = 0.86401032
Iteration 900, loss = 0.84893283
Iteration 901, loss = 0.82554484
Iteration 902, loss = 0.86232201
Iteration 903, loss = 0.86620447
Iteration 904, loss = 0.87019564
Iteration 905, loss = 0.86823314
Iteration 906, loss = 0.86671261
Iteration 907, loss = 0.86455470
Iteration 908, loss = 0.86397368
Iteration 909, loss = 0.86510793
Iteration 910, loss = 0.86560472
Iteration 911, loss = 0.86713138
Iteration 912, loss = 0.86692330
Iteration 913, loss = 0.86760533
Iteration 914, loss = 0.86765049
Iteration 915, loss = 0.86821670
Iteration 916, loss = 0.86859810
Iteration 917, loss = 0.86823681
Iteration 918, loss = 0.86913147
Iteration 919, loss = 0.86825394
Iteration 920, loss = 0.87053726
Iteration 921, loss = 0.86796822
Iteration 922, loss = 0.86841605
Iteration 923, loss = 0.86701969
Iteration 924, loss = 0.86662310
Iteration 925, loss = 0.86671205
Iteration 926, loss = 0.86458557
Iteration 927, loss = 0.86574789
Iteration 928, loss = 0.86412775
Iteration 929, loss = 0.86417282
Iteration 930, loss = 0.86327017
Iteration 931, loss = 0.86280315
Iteration 932, loss = 0.84985056
Iteration 933, loss = 0.86956544
Iteration 934, loss = 0.87299591
Iteration 935, loss = 0.87243072
Iteration 936, loss = 0.86582803
Iteration 937, loss = 0.86508923
Iteration 938, loss = 0.86580125
Iteration 939, loss = 0.86756167
Iteration 940, loss = 0.86920879
Iteration 941, loss = 0.86831774
Iteration 942, loss = 0.86836480
Iteration 943, loss = 0.86724925
Iteration 944, loss = 0.86712539
Iteration 945, loss = 0.86623875
Iteration 946, loss = 0.86631595
Iteration 947, loss = 0.86658170
Iteration 948, loss = 0.86532571
Iteration 949, loss = 0.86366935
Iteration 950, loss = 0.86121892
Iteration 951, loss = 0.85989779
Iteration 952, loss = 0.85810522
Iteration 953, loss = 0.85318140
Iteration 954, loss = 0.88538479
Iteration 955, loss = 0.87612506
Iteration 956, loss = 0.89037266
Iteration 957, loss = 0.86351480
Iteration 958, loss = 0.88279426
Iteration 959, loss = 0.85966273
Iteration 960, loss = 0.87546771
Iteration 961, loss = 0.86341277
Iteration 962, loss = 0.86745399
Iteration 963, loss = 0.86527012
Iteration 964, loss = 0.85865849
Iteration 965, loss = 0.86355840
Iteration 966, loss = 0.85269362
Iteration 967, loss = 0.85971755
Iteration 968, loss = 0.84898271
Iteration 969, loss = 0.85264995
Iteration 970, loss = 0.84443544
Iteration 971, loss = 0.84256944
Iteration 972, loss = 0.83396793
Iteration 973, loss = 0.82629974
Iteration 974, loss = 1.00597442
Iteration 975, loss = 0.88495610
Iteration 976, loss = 0.97016976
Iteration 977, loss = 0.93188960
Iteration 978, loss = 0.89646892
Iteration 979, loss = 0.93538427
Iteration 980, loss = 0.84650525
Iteration 981, loss = 0.91808023
Iteration 982, loss = 0.84535814
Iteration 983, loss = 0.89143949
Iteration 984, loss = 0.85084156
Iteration 985, loss = 0.86354598
Iteration 986, loss = 0.86476967
Iteration 987, loss = 0.85500875
Iteration 988, loss = 0.85980567
Iteration 989, loss = 0.84253753
Iteration 990, loss = 0.85144008
Iteration 991, loss = 0.84463682
Iteration 992, loss = 0.84741603
Iteration 993, loss = 0.84418007
Iteration 994, loss = 0.84013058
Iteration 995, loss = 0.84399766
Iteration 996, loss = 0.83583606
Iteration 997, loss = 0.81644852
Iteration 998, loss = 0.86884986
Iteration 999, loss = 0.86884919
Iteration 1000, loss = 0.87754376
Iteration 1001, loss = 0.84282208
Iteration 1002, loss = 0.87232701
Iteration 1003, loss = 0.83832556
Iteration 1004, loss = 0.86642533
Iteration 1005, loss = 0.84210238
Iteration 1006, loss = 0.85479799
Iteration 1007, loss = 0.84674579
Iteration 1008, loss = 0.84394604
Iteration 1009, loss = 0.84884834
Iteration 1010, loss = 0.83587561
Iteration 1011, loss = 0.84695070
Iteration 1012, loss = 0.83258352
Iteration 1013, loss = 0.84339598
Iteration 1014, loss = 0.83311670
Iteration 1015, loss = 0.83881937
Iteration 1016, loss = 0.83381962
Iteration 1017, loss = 0.83314354
Iteration 1018, loss = 0.83329630
Iteration 1019, loss = 0.82900450
Iteration 1020, loss = 0.83240869
Iteration 1021, loss = 0.82670617
Iteration 1022, loss = 0.84648672
Iteration 1023, loss = 0.85627752
Iteration 1024, loss = 0.87928684
Iteration 1025, loss = 0.87896138
Iteration 1026, loss = 0.87571911
Iteration 1027, loss = 0.86563466
Iteration 1028, loss = 0.85464325
Iteration 1029, loss = 0.85304127
Iteration 1030, loss = 0.84825213
Iteration 1031, loss = 0.85452605
Iteration 1032, loss = 0.85341183
Iteration 1033, loss = 0.85904843
Iteration 1034, loss = 0.85705341
Iteration 1035, loss = 0.85850741
Iteration 1036, loss = 0.85654003
Iteration 1037, loss = 0.85594262
Iteration 1038, loss = 0.85578400
Iteration 1039, loss = 0.85441926
Iteration 1040, loss = 0.85498487
Iteration 1041, loss = 0.85264958
Iteration 1042, loss = 0.85279198
Iteration 1043, loss = 0.85013766
Iteration 1044, loss = 0.84982746
Iteration 1045, loss = 0.84774760
Iteration 1046, loss = 0.84724839
Iteration 1047, loss = 0.84604366
Iteration 1048, loss = 0.84521781
Iteration 1049, loss = 0.84432438
Iteration 1050, loss = 0.84278129
Iteration 1051, loss = 0.84166335
Iteration 1052, loss = 0.83963408
Iteration 1053, loss = 0.83848476
Iteration 1054, loss = 0.83659691
Iteration 1055, loss = 0.83552323
Iteration 1056, loss = 0.83380533
Iteration 1057, loss = 0.83249336
Iteration 1058, loss = 0.83092483
Iteration 1059, loss = 0.82963936
Iteration 1060, loss = 0.82826148
Iteration 1061, loss = 0.82689633
Iteration 1062, loss = 0.82554639
Iteration 1063, loss = 0.82402128
Iteration 1064, loss = 0.82264634
Iteration 1065, loss = 0.82103987
Iteration 1066, loss = 0.81964794
Iteration 1067, loss = 0.81809706
Iteration 1068, loss = 0.81676882
Iteration 1069, loss = 0.81536465
Iteration 1070, loss = 0.81411174
Iteration 1071, loss = 0.81279900
Iteration 1072, loss = 0.81152609
Iteration 1073, loss = 0.81022309
Iteration 1074, loss = 0.80889852
Iteration 1075, loss = 0.80761530
Iteration 1076, loss = 0.80630596
Iteration 1077, loss = 0.80507614
Iteration 1078, loss = 0.80382259
Iteration 1079, loss = 0.80264778
Iteration 1080, loss = 0.80144346
Iteration 1081, loss = 0.80029419
Iteration 1082, loss = 0.79911271
Iteration 1083, loss = 0.79796552
Iteration 1084, loss = 0.79681207
Iteration 1085, loss = 0.79568795
Iteration 1086, loss = 0.79458475
Iteration 1087, loss = 0.79350183
Iteration 1088, loss = 0.79244289
Iteration 1089, loss = 0.79138753
Iteration 1090, loss = 0.79035537
Iteration 1091, loss = 0.78932253
Iteration 1092, loss = 0.78831876
Iteration 1093, loss = 0.78731752
Iteration 1094, loss = 0.78634099
Iteration 1095, loss = 0.78536190
Iteration 1096, loss = 0.78438570
Iteration 1097, loss = 0.78337367
Iteration 1098, loss = 0.78226395
Iteration 1099, loss = 0.78074919
Iteration 1100, loss = 0.77663629
Iteration 1101, loss = 0.79182041
Iteration 1102, loss = 0.86975093
Iteration 1103, loss = 0.80163715
Iteration 1104, loss = 0.85733134
Iteration 1105, loss = 0.81473390
Iteration 1106, loss = 0.82448442
Iteration 1107, loss = 0.81334163
Iteration 1108, loss = 0.79491034
Iteration 1109, loss = 0.81131319
Iteration 1110, loss = 0.78154401
Iteration 1111, loss = 0.81034858
Iteration 1112, loss = 0.77741839
Iteration 1113, loss = 0.80448174
Iteration 1114, loss = 0.77533094
Iteration 1115, loss = 0.79377937
Iteration 1116, loss = 0.77357453
Iteration 1117, loss = 0.78072695
Iteration 1118, loss = 0.77528669
Iteration 1119, loss = 0.77269288
Iteration 1120, loss = 0.77568979
Iteration 1121, loss = 0.76649874
Iteration 1122, loss = 0.77306181
Iteration 1123, loss = 0.76260745
Iteration 1124, loss = 0.76855929
Iteration 1125, loss = 0.76045989
Iteration 1126, loss = 0.76354878
Iteration 1127, loss = 0.75916526
Iteration 1128, loss = 0.75694245
Iteration 1129, loss = 0.75721628
Iteration 1130, loss = 0.75333835
Iteration 1131, loss = 0.74991838
Iteration 1132, loss = 0.70148867
Iteration 1133, loss = 0.80526059
Iteration 1134, loss = 0.83362042
Iteration 1135, loss = 0.86769994
Iteration 1136, loss = 0.79714754
Iteration 1137, loss = 0.85718925
Iteration 1138, loss = 0.77795533
Iteration 1139, loss = 0.81792820
Iteration 1140, loss = 0.79196919
Iteration 1141, loss = 0.79169844
Iteration 1142, loss = 0.80926410
Iteration 1143, loss = 0.77627118
Iteration 1144, loss = 0.80570327
Iteration 1145, loss = 0.76881874
Iteration 1146, loss = 0.78931758
Iteration 1147, loss = 0.77503890
Iteration 1148, loss = 0.77559344
Iteration 1149, loss = 0.78130550
Iteration 1150, loss = 0.76581775
Iteration 1151, loss = 0.77989618
Iteration 1152, loss = 0.76223243
Iteration 1153, loss = 0.77306540
Iteration 1154, loss = 0.76327149
Iteration 1155, loss = 0.76505729
Iteration 1156, loss = 0.76532877
Iteration 1157, loss = 0.75945707
Iteration 1158, loss = 0.76526689
Iteration 1159, loss = 0.75675614
Iteration 1160, loss = 0.76240925
Iteration 1161, loss = 0.75637318
Iteration 1162, loss = 0.75854005
Iteration 1163, loss = 0.75689552
Iteration 1164, loss = 0.75503077
Iteration 1165, loss = 0.75653980
Iteration 1166, loss = 0.75259951
Iteration 1167, loss = 0.75516626
Iteration 1168, loss = 0.75173046
Iteration 1169, loss = 0.75336485
Iteration 1170, loss = 0.75152363
Iteration 1171, loss = 0.75113358
Iteration 1172, loss = 0.75079322
Iteration 1173, loss = 0.74900930
Iteration 1174, loss = 0.74970076
Iteration 1175, loss = 0.74774321
Iteration 1176, loss = 0.74848555
Iteration 1177, loss = 0.74698138
Iteration 1178, loss = 0.74698778
Iteration 1179, loss = 0.74619564
Iteration 1180, loss = 0.74544392
Iteration 1181, loss = 0.74522164
Iteration 1182, loss = 0.74410725
Iteration 1183, loss = 0.74416707
Iteration 1184, loss = 0.74226193
Iteration 1185, loss = 0.76553482
Iteration 1186, loss = 0.76906076
Iteration 1187, loss = 0.77673613
Iteration 1188, loss = 0.76547109
Iteration 1189, loss = 0.75276830
Iteration 1190, loss = 0.75267900
Iteration 1191, loss = 0.75095200
Iteration 1192, loss = 0.75407443
Iteration 1193, loss = 0.75700376
Iteration 1194, loss = 0.75264934
Iteration 1195, loss = 0.75233519
Iteration 1196, loss = 0.74737986
Iteration 1197, loss = 0.74882202
Iteration 1198, loss = 0.74710289
Iteration 1199, loss = 0.74795433
Iteration 1200, loss = 0.74670410
Iteration 1201, loss = 0.74496735
Iteration 1202, loss = 0.74517558
Iteration 1203, loss = 0.74323327
Iteration 1204, loss = 0.74418031
Iteration 1205, loss = 0.74290348
Iteration 1206, loss = 0.74299407
Iteration 1207, loss = 0.74104009
Iteration 1208, loss = 0.74000420
Iteration 1209, loss = 0.73951922
Iteration 1210, loss = 0.73889284
Iteration 1211, loss = 0.73920432
Iteration 1212, loss = 0.73799663
Iteration 1213, loss = 0.73744233
Iteration 1214, loss = 0.73546246
Iteration 1215, loss = 0.73400998
Iteration 1216, loss = 0.73277051
Iteration 1217, loss = 0.72414995
Iteration 1218, loss = 0.81089952
Iteration 1219, loss = 1.09577510
Iteration 1220, loss = 0.84224249
Iteration 1221, loss = 0.95455701
Iteration 1222, loss = 0.88116773
Iteration 1223, loss = 0.93801810
Iteration 1224, loss = 0.85167341
Iteration 1225, loss = 0.84374020
Iteration 1226, loss = 0.84037584
Iteration 1227, loss = 0.79053615
Iteration 1228, loss = 0.83023382
Iteration 1229, loss = 0.81154679
Iteration 1230, loss = 0.81073341
Iteration 1231, loss = 0.83298638
Iteration 1232, loss = 0.80403212
Iteration 1233, loss = 0.82140251
Iteration 1234, loss = 0.81445661
Iteration 1235, loss = 0.80297958
Iteration 1236, loss = 0.81883583
Iteration 1237, loss = 0.80255780
Iteration 1238, loss = 0.80913569
Iteration 1239, loss = 0.80981755
Iteration 1240, loss = 0.79888738
Iteration 1241, loss = 0.80748924
Iteration 1242, loss = 0.79758467
Iteration 1243, loss = 0.79755712
Iteration 1244, loss = 0.79979151
Iteration 1245, loss = 0.79230375
Iteration 1246, loss = 0.79765227
Iteration 1247, loss = 0.79370176
Iteration 1248, loss = 0.79234310
Iteration 1249, loss = 0.79410943
Iteration 1250, loss = 0.78775392
Iteration 1251, loss = 0.78750279
Iteration 1252, loss = 0.78682702
Iteration 1253, loss = 0.78063842
Iteration 1254, loss = 0.78429605
Iteration 1255, loss = 0.89951259
Iteration 1256, loss = 0.88508708
Iteration 1257, loss = 0.85714226
Iteration 1258, loss = 0.90812462
Iteration 1259, loss = 0.82855973
Iteration 1260, loss = 0.84938782
Iteration 1261, loss = 0.84952947
Iteration 1262, loss = 0.81332370
Iteration 1263, loss = 0.85850950
Iteration 1264, loss = 0.82939475
Iteration 1265, loss = 0.83627249
Iteration 1266, loss = 0.85062111
Iteration 1267, loss = 0.82137822
Iteration 1268, loss = 0.84408508
Iteration 1269, loss = 0.82923803
Iteration 1270, loss = 0.82210111
Iteration 1271, loss = 0.80638516
Iteration 1272, loss = 0.86286096
Iteration 1273, loss = 0.84261477
Iteration 1274, loss = 0.86380735
Iteration 1275, loss = 0.84913897
Iteration 1276, loss = 0.84414806
Iteration 1277, loss = 0.85154066
Iteration 1278, loss = 0.83831253
Iteration 1279, loss = 0.85384871
Iteration 1280, loss = 0.84577794
Iteration 1281, loss = 0.84969640
Iteration 1282, loss = 0.85174267
Iteration 1283, loss = 0.84464022
Iteration 1284, loss = 0.85205104
Iteration 1285, loss = 0.84471099
Iteration 1286, loss = 0.84881882
Iteration 1287, loss = 0.84780661
Iteration 1288, loss = 0.84551713
Iteration 1289, loss = 0.84912980
Iteration 1290, loss = 0.84437316
Iteration 1291, loss = 0.84746952
Iteration 1292, loss = 0.84499066
Iteration 1293, loss = 0.84443239
Iteration 1294, loss = 0.84506332
Iteration 1295, loss = 0.84201837
Iteration 1296, loss = 0.84351683
Iteration 1297, loss = 0.84084061
Iteration 1298, loss = 0.84089570
Iteration 1299, loss = 0.84013658
Iteration 1300, loss = 0.83852264
Iteration 1301, loss = 0.83895243
Iteration 1302, loss = 0.83682587
Iteration 1303, loss = 0.83679099
Iteration 1304, loss = 0.83528335
Iteration 1305, loss = 0.83414887
Iteration 1306, loss = 0.83355795
Iteration 1307, loss = 0.83190056
Iteration 1308, loss = 0.83161409
Iteration 1309, loss = 0.83017102
Iteration 1310, loss = 0.82945462
Iteration 1311, loss = 0.82847795
Iteration 1312, loss = 0.82720040
Iteration 1313, loss = 0.82649020
Iteration 1314, loss = 0.82508635
Iteration 1315, loss = 0.82434302
Iteration 1316, loss = 0.82320919
Iteration 1317, loss = 0.82222596
Iteration 1318, loss = 0.82135018
Iteration 1319, loss = 0.82016999
Iteration 1320, loss = 0.81935692
Iteration 1321, loss = 0.81820747
Iteration 1322, loss = 0.81730835
Iteration 1323, loss = 0.81632032
Iteration 1324, loss = 0.81530300
Iteration 1325, loss = 0.81443263
Iteration 1326, loss = 0.81337802
Iteration 1327, loss = 0.81251281
Iteration 1328, loss = 0.81151057
Iteration 1329, loss = 0.81058472
Iteration 1330, loss = 0.80967165
Iteration 1331, loss = 0.80871015
Iteration 1332, loss = 0.80785230
Iteration 1333, loss = 0.80690091
Iteration 1334, loss = 0.80603536
Iteration 1335, loss = 0.80512588
Iteration 1336, loss = 0.80421351
Iteration 1337, loss = 0.80694570
Iteration 1338, loss = 0.80489121
Iteration 1339, loss = 0.80558629
Iteration 1340, loss = 0.80447674
Iteration 1341, loss = 0.80403685
Iteration 1342, loss = 0.80213813
Iteration 1343, loss = 0.80059361
Iteration 1344, loss = 0.79927787
Iteration 1345, loss = 0.79339685
Iteration 1346, loss = 0.81351306
Iteration 1347, loss = 0.79982598
Iteration 1348, loss = 0.81204845
Iteration 1349, loss = 0.80013125
Iteration 1350, loss = 0.80291407
Iteration 1351, loss = 0.80198838
Iteration 1352, loss = 0.79760563
Iteration 1353, loss = 0.80439729
Iteration 1354, loss = 0.79717186
Iteration 1355, loss = 0.80258755
Iteration 1356, loss = 0.79806569
Iteration 1357, loss = 0.79855536
Iteration 1358, loss = 0.79904537
Iteration 1359, loss = 0.79554863
Iteration 1360, loss = 0.79830458
Iteration 1361, loss = 0.79404484
Iteration 1362, loss = 0.79582989
Iteration 1363, loss = 0.79362227
Iteration 1364, loss = 0.79298289
Iteration 1365, loss = 0.79302157
Iteration 1366, loss = 0.79052630
Iteration 1367, loss = 0.79130172
Iteration 1368, loss = 0.78864223
Iteration 1369, loss = 0.78874047
Iteration 1370, loss = 0.78718586
Iteration 1371, loss = 0.78614695
Iteration 1372, loss = 0.78569874
Iteration 1373, loss = 0.78390512
Iteration 1374, loss = 0.78377536
Iteration 1375, loss = 0.78201388
Iteration 1376, loss = 0.78153527
Iteration 1377, loss = 0.78032541
Iteration 1378, loss = 0.77928955
Iteration 1379, loss = 0.77859947
Iteration 1380, loss = 0.77726218
Iteration 1381, loss = 0.77677189
Iteration 1382, loss = 0.77552223
Iteration 1383, loss = 0.77489067
Iteration 1384, loss = 0.77391428
Iteration 1385, loss = 0.77302410
Iteration 1386, loss = 0.77230925
Iteration 1387, loss = 0.77129844
Iteration 1388, loss = 0.77070036
Iteration 1389, loss = 0.76974210
Iteration 1390, loss = 0.76909288
Iteration 1391, loss = 0.76827256
Iteration 1392, loss = 0.76750548
Iteration 1393, loss = 0.76679067
Iteration 1394, loss = 0.76587631
Iteration 1395, loss = 0.76482456
Iteration 1396, loss = 0.74304105
Iteration 1397, loss = 0.77664272
Iteration 1398, loss = 0.79185732
Iteration 1399, loss = 0.79897078
Iteration 1400, loss = 0.79313669
Iteration 1401, loss = 0.78754890
Iteration 1402, loss = 0.77941040
Iteration 1403, loss = 0.77929464
Iteration 1404, loss = 0.78268088
Iteration 1405, loss = 0.78479952
Iteration 1406, loss = 0.78798013
Iteration 1407, loss = 0.78673358
Iteration 1408, loss = 0.78667870
Iteration 1409, loss = 0.78609737
Iteration 1410, loss = 0.78481540
Iteration 1411, loss = 0.78400166
Iteration 1412, loss = 0.78014751
Iteration 1413, loss = 0.77701315
Iteration 1414, loss = 0.75968902
Iteration 1415, loss = 1.29435174
Iteration 1416, loss = 0.95964625
Iteration 1417, loss = 1.20247106
Iteration 1418, loss = 0.82869580
Iteration 1419, loss = 1.13813443
Iteration 1420, loss = 0.84095158
Iteration 1421, loss = 1.05097462
Iteration 1422, loss = 0.91300059
Iteration 1423, loss = 0.92061740
Iteration 1424, loss = 0.96125958
Iteration 1425, loss = 0.82965736
Iteration 1426, loss = 0.96430327
Iteration 1427, loss = 0.79771278
Iteration 1428, loss = 0.92819786
Iteration 1429, loss = 0.82007946
Iteration 1430, loss = 0.84342089
Iteration 1431, loss = 0.83187998
Iteration 1432, loss = 0.83676763
Iteration 1433, loss = 0.83814712
Iteration 1434, loss = 0.81656296
Iteration 1435, loss = 0.83315908
Iteration 1436, loss = 0.80108635
Iteration 1437, loss = 0.82981091
Iteration 1438, loss = 0.79729244
Iteration 1439, loss = 0.82725034
Iteration 1440, loss = 0.79653687
Iteration 1441, loss = 0.82074340
Iteration 1442, loss = 0.79518041
Iteration 1443, loss = 0.81267068
Iteration 1444, loss = 0.79483384
Iteration 1445, loss = 0.80642233
Iteration 1446, loss = 0.79586274
Iteration 1447, loss = 0.80053144
Iteration 1448, loss = 0.79634311
Iteration 1449, loss = 0.79629669
Iteration 1450, loss = 0.79614040
Iteration 1451, loss = 0.79276796
Iteration 1452, loss = 0.79458732
Iteration 1453, loss = 0.78901216
Iteration 1454, loss = 0.79234995
Iteration 1455, loss = 0.78608237
Iteration 1456, loss = 0.78969397
Iteration 1457, loss = 0.78368783
Iteration 1458, loss = 0.78390277
Iteration 1459, loss = 0.78454207
Iteration 1460, loss = 0.77956338
Iteration 1461, loss = 0.77712427
Iteration 1462, loss = 0.76873920
Iteration 1463, loss = 0.65286592
Iteration 1464, loss = 0.85956867
Iteration 1465, loss = 1.04508635
Iteration 1466, loss = 0.86106190
Iteration 1467, loss = 1.02617203
Iteration 1468, loss = 0.88631952
Iteration 1469, loss = 0.96919119
Iteration 1470, loss = 0.89643015
Iteration 1471, loss = 0.90654659
Iteration 1472, loss = 0.91167551
Iteration 1473, loss = 0.86034567
Iteration 1474, loss = 0.91447546
Iteration 1475, loss = 0.82832399
Iteration 1476, loss = 0.90462849
Iteration 1477, loss = 0.81286393
Iteration 1478, loss = 0.92340787
Iteration 1479, loss = 0.83213806
Iteration 1480, loss = 0.90480049
Iteration 1481, loss = 0.84330816
Iteration 1482, loss = 0.88062552
Iteration 1483, loss = 0.82755017
Iteration 1484, loss = 0.86148537
Iteration 1485, loss = 0.83608681
Iteration 1486, loss = 0.86035830
Iteration 1487, loss = 0.84208931
Iteration 1488, loss = 0.84822778
Iteration 1489, loss = 0.83833155
Iteration 1490, loss = 0.83891075
Iteration 1491, loss = 0.83936145
Iteration 1492, loss = 0.83495396
Iteration 1493, loss = 0.83881203
Iteration 1494, loss = 0.82976371
Iteration 1495, loss = 0.83588321
Iteration 1496, loss = 0.82603434
Iteration 1497, loss = 0.83261860
Iteration 1498, loss = 0.83283768
Iteration 1499, loss = 0.82638942
Iteration 1500, loss = 0.82576296
Iteration 1501, loss = 0.82919607
Iteration 1502, loss = 0.82573389
Iteration 1503, loss = 0.82077207
Iteration 1504, loss = 0.82272843
Iteration 1505, loss = 0.82419172
Iteration 1506, loss = 0.82017479
Iteration 1507, loss = 0.81816909
Iteration 1508, loss = 0.81972369
Iteration 1509, loss = 0.81830229
Iteration 1510, loss = 0.81533927
Iteration 1511, loss = 0.81562607
Iteration 1512, loss = 0.81592380
Iteration 1513, loss = 0.81337458
Iteration 1514, loss = 0.81207243
Iteration 1515, loss = 0.81218976
Iteration 1516, loss = 0.81080032
Iteration 1517, loss = 0.80919974
Iteration 1518, loss = 0.80895373
Iteration 1519, loss = 0.80825844
Iteration 1520, loss = 0.80649634
Iteration 1521, loss = 0.80510604
Iteration 1522, loss = 0.80469837
Iteration 1523, loss = 0.80347794
Iteration 1524, loss = 0.80226810
Iteration 1525, loss = 0.80161441
Iteration 1526, loss = 0.80070494
Iteration 1527, loss = 0.79922606
Iteration 1528, loss = 0.79832615
Iteration 1529, loss = 0.79738505
Iteration 1530, loss = 0.79622277
Iteration 1531, loss = 0.79527417
Iteration 1532, loss = 0.79423739
Iteration 1533, loss = 0.79332032
Iteration 1534, loss = 0.79199226
Iteration 1535, loss = 0.79064793
Iteration 1536, loss = 0.78946359
Iteration 1537, loss = 0.78603858
Iteration 1538, loss = 0.78291476
Iteration 1539, loss = 0.77001108
Iteration 1540, loss = 0.82021594
Iteration 1541, loss = 1.70980548
Iteration 1542, loss = 1.02678195
Iteration 1543, loss = 1.76705354
Iteration 1544, loss = 1.54036644
Iteration 1545, loss = 1.24300085
Iteration 1546, loss = 1.50861155
Iteration 1547, loss = 0.90698660
Iteration 1548, loss = 1.33957534
Iteration 1549, loss = 0.91429830
Iteration 1550, loss = 1.20529295
Iteration 1551, loss = 1.05605233
Iteration 1552, loss = 1.02126628
Iteration 1553, loss = 1.12013282
Iteration 1554, loss = 0.88926820
Iteration 1555, loss = 1.10125002
Iteration 1556, loss = 0.85628447
Iteration 1557, loss = 1.05669792
Iteration 1558, loss = 0.87572632
Iteration 1559, loss = 0.99918210
Iteration 1560, loss = 0.90611769
Iteration 1561, loss = 0.93599645
Iteration 1562, loss = 0.92464283
Iteration 1563, loss = 0.88325934
Iteration 1564, loss = 0.92755285
Iteration 1565, loss = 0.85169935
Iteration 1566, loss = 0.92015717
Iteration 1567, loss = 0.83869269
Iteration 1568, loss = 0.90691022
Iteration 1569, loss = 0.83675327
Iteration 1570, loss = 0.88931190
Iteration 1571, loss = 0.83849726
Iteration 1572, loss = 0.87101625
Iteration 1573, loss = 0.84200223
Iteration 1574, loss = 0.85575840
Iteration 1575, loss = 0.84565659
Iteration 1576, loss = 0.84428440
Iteration 1577, loss = 0.84741352
Iteration 1578, loss = 0.83573912
Iteration 1579, loss = 0.84620859
Iteration 1580, loss = 0.82908734
Iteration 1581, loss = 0.84243021
Iteration 1582, loss = 0.82415102
Iteration 1583, loss = 0.83735916
Iteration 1584, loss = 0.82103530
Iteration 1585, loss = 0.83197527
Iteration 1586, loss = 0.81891144
Iteration 1587, loss = 0.82624235
Iteration 1588, loss = 0.81627454
Iteration 1589, loss = 0.81956561
Iteration 1590, loss = 0.81170960
Iteration 1591, loss = 0.80569846
Iteration 1592, loss = 1.04226607
Iteration 1593, loss = 0.88001782
Iteration 1594, loss = 1.02805914
Iteration 1595, loss = 0.90369933
Iteration 1596, loss = 0.94581919
Iteration 1597, loss = 0.90583631
Iteration 1598, loss = 0.88485707
Iteration 1599, loss = 0.92467605
Iteration 1600, loss = 0.86887703
Iteration 1601, loss = 0.93917337
Iteration 1602, loss = 0.86555912
Iteration 1603, loss = 0.92849721
Iteration 1604, loss = 0.85963514
Iteration 1605, loss = 0.90627738
Iteration 1606, loss = 0.86246980
Iteration 1607, loss = 0.89171642
Iteration 1608, loss = 0.87372407
Iteration 1609, loss = 0.88302753
Iteration 1610, loss = 0.88258085
Iteration 1611, loss = 0.87358814
Iteration 1612, loss = 0.88313033
Iteration 1613, loss = 0.86506459
Iteration 1614, loss = 0.88052853
Iteration 1615, loss = 0.86125631
Iteration 1616, loss = 0.87788046
Iteration 1617, loss = 0.86046587
Iteration 1618, loss = 0.87433790
Iteration 1619, loss = 0.86090678
Iteration 1620, loss = 0.87012743
Iteration 1621, loss = 0.86112458
Iteration 1622, loss = 0.86543372
Iteration 1623, loss = 0.86067407
Iteration 1624, loss = 0.86108961
Iteration 1625, loss = 0.85985493
Iteration 1626, loss = 0.85761397
Iteration 1627, loss = 0.85879795
Iteration 1628, loss = 0.85503931
Iteration 1629, loss = 0.85727903
Iteration 1630, loss = 0.85277443
Iteration 1631, loss = 0.85521463
Iteration 1632, loss = 0.85085293
Iteration 1633, loss = 0.85297695
Iteration 1634, loss = 0.84916566
Iteration 1635, loss = 0.85059731
Iteration 1636, loss = 0.84756485
Iteration 1637, loss = 0.84826035
Iteration 1638, loss = 0.84605871
Iteration 1639, loss = 0.84603584
Iteration 1640, loss = 0.84450479
Iteration 1641, loss = 0.84386274
Iteration 1642, loss = 0.84285154
Iteration 1643, loss = 0.84179623
Iteration 1644, loss = 0.84115993
Iteration 1645, loss = 0.83986517
Iteration 1646, loss = 0.83943505
Iteration 1647, loss = 0.83803089
Iteration 1648, loss = 0.83767678
Iteration 1649, loss = 0.83627113
Iteration 1650, loss = 0.83590472
Iteration 1651, loss = 0.83456370
Iteration 1652, loss = 0.83412862
Iteration 1653, loss = 0.83289279
Iteration 1654, loss = 0.83237565
Iteration 1655, loss = 0.83126497
Iteration 1656, loss = 0.83065825
Iteration 1657, loss = 0.82965455
Iteration 1658, loss = 0.82896180
Iteration 1659, loss = 0.82805496
Iteration 1660, loss = 0.82730356
Iteration 1661, loss = 0.82647614
Iteration 1662, loss = 0.82568028
Iteration 1663, loss = 0.82490646
Iteration 1664, loss = 0.82408604
Iteration 1665, loss = 0.82335302
Iteration 1666, loss = 0.82252711
Iteration 1667, loss = 0.82181888
Iteration 1668, loss = 0.82099625
Iteration 1669, loss = 0.82030000
Iteration 1670, loss = 0.81948890
Iteration 1671, loss = 0.81879819
Iteration 1672, loss = 0.81800480
Iteration 1673, loss = 0.81731730
Iteration 1674, loss = 0.81654579
Iteration 1675, loss = 0.81585980
Iteration 1676, loss = 0.81510840
Iteration 1677, loss = 0.81442074
Iteration 1678, loss = 0.81368746
Iteration 1679, loss = 0.81300044
Iteration 1680, loss = 0.81228626
Iteration 1681, loss = 0.81160254
Iteration 1682, loss = 0.81090505
Iteration 1683, loss = 0.81022466
Iteration 1684, loss = 0.80954071
Iteration 1685, loss = 0.80886431
Iteration 1686, loss = 0.80819168
Iteration 1687, loss = 0.80752002
Iteration 1688, loss = 0.80685658
Iteration 1689, loss = 0.80618934
Iteration 1690, loss = 0.80553125
Iteration 1691, loss = 0.80486422
Iteration 1692, loss = 0.80420181
Iteration 1693, loss = 0.80351919
Iteration 1694, loss = 0.80281918
Iteration 1695, loss = 0.80204816
Iteration 1696, loss = 0.80111527
Iteration 1697, loss = 0.79955032
Iteration 1698, loss = 0.78122794
Iteration 1699, loss = 0.80868816
Iteration 1700, loss = 0.81689744
Iteration 1701, loss = 0.82099470
Iteration 1702, loss = 0.81916185
Iteration 1703, loss = 0.81570603
Iteration 1704, loss = 0.81131263
Iteration 1705, loss = 0.81267141
Iteration 1706, loss = 0.81489707
Iteration 1707, loss = 0.81808982
Iteration 1708, loss = 0.82122577
Iteration 1709, loss = 0.82207204
Iteration 1710, loss = 0.82183327
Iteration 1711, loss = 0.82253902
Iteration 1712, loss = 0.82305786
Iteration 1713, loss = 0.82302882
Iteration 1714, loss = 0.82360880
Iteration 1715, loss = 0.82414975
Iteration 1716, loss = 0.82406561
Iteration 1717, loss = 0.82418025
Iteration 1718, loss = 0.82441510
Iteration 1719, loss = 0.82419960
Iteration 1720, loss = 0.82390491
Iteration 1721, loss = 0.82370483
Iteration 1722, loss = 0.82326878
Iteration 1723, loss = 0.82263563
Iteration 1724, loss = 0.82170345
Iteration 1725, loss = 0.82076567
Iteration 1726, loss = 0.81845356
Iteration 1727, loss = 0.81694229
Iteration 1728, loss = 0.81328528
Iteration 1729, loss = 0.79960563
Iteration 1730, loss = 0.97239518
Iteration 1731, loss = 0.91192978
Iteration 1732, loss = 0.99851737
Iteration 1733, loss = 0.84095499
Iteration 1734, loss = 0.97120707
Iteration 1735, loss = 0.83478401
Iteration 1736, loss = 0.94428012
Iteration 1737, loss = 0.86364077
Iteration 1738, loss = 0.90738324
Iteration 1739, loss = 0.88491416
Iteration 1740, loss = 0.86876376
Iteration 1741, loss = 0.89290544
Iteration 1742, loss = 0.84423275
Iteration 1743, loss = 0.89153458
Iteration 1744, loss = 0.83663752
Iteration 1745, loss = 0.88347287
Iteration 1746, loss = 0.83765894
Iteration 1747, loss = 0.86832283
Iteration 1748, loss = 0.83999569
Iteration 1749, loss = 0.85264063
Iteration 1750, loss = 0.84397003
Iteration 1751, loss = 0.84046220
Iteration 1752, loss = 0.84468211
Iteration 1753, loss = 0.83030074
Iteration 1754, loss = 0.84190330
Iteration 1755, loss = 0.82429230
Iteration 1756, loss = 0.83762808
Iteration 1757, loss = 0.82103342
Iteration 1758, loss = 0.83129112
Iteration 1759, loss = 0.81841362
Iteration 1760, loss = 0.82449564
Iteration 1761, loss = 0.81728217
Iteration 1762, loss = 0.81858770
Iteration 1763, loss = 0.81569305
Iteration 1764, loss = 0.81319434
Iteration 1765, loss = 0.81350124
Iteration 1766, loss = 0.80871109
Iteration 1767, loss = 0.81089558
Iteration 1768, loss = 0.80553275
Iteration 1769, loss = 0.80800671
Iteration 1770, loss = 0.80283903
Iteration 1771, loss = 0.80487098
Iteration 1772, loss = 0.80076968
Iteration 1773, loss = 0.80175150
Iteration 1774, loss = 0.79882396
Iteration 1775, loss = 0.79884001
Iteration 1776, loss = 0.79714362
Iteration 1777, loss = 0.79622477
Iteration 1778, loss = 0.79531861
Iteration 1779, loss = 0.79380261
Iteration 1780, loss = 0.79352508
Iteration 1781, loss = 0.79175821
Iteration 1782, loss = 0.79169792
Iteration 1783, loss = 0.78989796
Iteration 1784, loss = 0.78986472
Iteration 1785, loss = 0.78819809
Iteration 1786, loss = 0.78797937
Iteration 1787, loss = 0.78648498
Iteration 1788, loss = 0.78585591
Iteration 1789, loss = 0.78380549
Iteration 1790, loss = 0.75933614
Iteration 1791, loss = 0.79923563
Iteration 1792, loss = 0.80537425
Iteration 1793, loss = 0.81085722
Iteration 1794, loss = 0.81302643
Iteration 1795, loss = 0.80960094
Iteration 1796, loss = 0.80844891
Iteration 1797, loss = 0.80415975
Iteration 1798, loss = 0.80724143
Iteration 1799, loss = 0.80675018
Iteration 1800, loss = 0.81279750
Iteration 1801, loss = 0.81206341
Iteration 1802, loss = 0.81709555
Iteration 1803, loss = 0.81481108
Iteration 1804, loss = 0.81876013
Iteration 1805, loss = 0.81637607
Iteration 1806, loss = 0.82029821
Iteration 1807, loss = 0.81835790
Iteration 1808, loss = 0.82180710
Iteration 1809, loss = 0.81970020
Iteration 1810, loss = 0.82212785
Iteration 1811, loss = 0.81987386
Iteration 1812, loss = 0.82170193
Iteration 1813, loss = 0.81990911
Iteration 1814, loss = 0.82158157
Iteration 1815, loss = 0.82032868
Iteration 1816, loss = 0.82164773
Iteration 1817, loss = 0.82051647
Iteration 1818, loss = 0.82115810
Iteration 1819, loss = 0.81992857
Iteration 1820, loss = 0.81998724
Iteration 1821, loss = 0.81882765
Iteration 1822, loss = 0.81856795
Iteration 1823, loss = 0.81764223
Iteration 1824, loss = 0.81732683
Iteration 1825, loss = 0.81660949
Iteration 1826, loss = 0.81670758
Iteration 1827, loss = 0.81519420
Iteration 1828, loss = 0.80523319
Iteration 1829, loss = 0.86435367
Iteration 1830, loss = 0.99906881
Iteration 1831, loss = 0.84759346
Iteration 1832, loss = 0.88564477
Iteration 1833, loss = 0.92344013
Iteration 1834, loss = 0.82070508
Iteration 1835, loss = 0.90961562
Iteration 1836, loss = 0.85647250
Iteration 1837, loss = 0.84803654
Iteration 1838, loss = 0.89215356
Iteration 1839, loss = 0.82621709
Iteration 1840, loss = 0.87301852
Iteration 1841, loss = 0.84691617
Iteration 1842, loss = 0.83661860
Iteration 1843, loss = 0.86435207
Iteration 1844, loss = 0.82528745
Iteration 1845, loss = 0.85223130
Iteration 1846, loss = 0.83666405
Iteration 1847, loss = 0.82975110
Iteration 1848, loss = 0.84501866
Iteration 1849, loss = 0.82123263
Iteration 1850, loss = 0.83659745
Iteration 1851, loss = 0.82638597
Iteration 1852, loss = 0.82201609
Iteration 1853, loss = 0.83017341
Iteration 1854, loss = 0.81561284
Iteration 1855, loss = 0.82411823
Iteration 1856, loss = 0.81709512
Iteration 1857, loss = 0.81402065
Iteration 1858, loss = 0.81811740
Iteration 1859, loss = 0.80895667
Iteration 1860, loss = 0.81353769
Iteration 1861, loss = 0.80885908
Iteration 1862, loss = 0.80646919
Iteration 1863, loss = 0.80835478
Iteration 1864, loss = 0.80234312
Iteration 1865, loss = 0.80437984
Iteration 1866, loss = 0.80146064
Iteration 1867, loss = 0.79971623
Iteration 1868, loss = 0.80038551
Iteration 1869, loss = 0.79588680
Iteration 1870, loss = 0.79660707
Iteration 1871, loss = 0.79462574
Iteration 1872, loss = 0.79307976
Iteration 1873, loss = 0.79303235
Iteration 1874, loss = 0.78988141
Iteration 1875, loss = 0.78909161
Iteration 1876, loss = 0.78092315
Iteration 1877, loss = 0.79751725
Iteration 1878, loss = 0.88542030
Iteration 1879, loss = 0.83029513
Iteration 1880, loss = 0.80093311
Iteration 1881, loss = 0.81264269
Iteration 1882, loss = 0.84607701
Iteration 1883, loss = 0.79294284
Iteration 1884, loss = 0.82939763
Iteration 1885, loss = 0.80608815
Iteration 1886, loss = 0.82116700
Iteration 1887, loss = 0.81460801
Iteration 1888, loss = 0.80364457
Iteration 1889, loss = 0.81333216
Iteration 1890, loss = 0.79534124
Iteration 1891, loss = 0.81441087
Iteration 1892, loss = 0.79666964
Iteration 1893, loss = 0.80948058
Iteration 1894, loss = 0.79627127
Iteration 1895, loss = 0.80029004
Iteration 1896, loss = 0.79775791
Iteration 1897, loss = 0.79546609
Iteration 1898, loss = 0.80024489
Iteration 1899, loss = 0.79294875
Iteration 1900, loss = 0.79865961
Iteration 1901, loss = 0.78995303
Iteration 1902, loss = 0.79403369
Iteration 1903, loss = 0.78915703
Iteration 1904, loss = 0.79081897
Iteration 1905, loss = 0.78987447
Iteration 1906, loss = 0.78779678
Iteration 1907, loss = 0.78867732
Iteration 1908, loss = 0.78463143
Iteration 1909, loss = 0.78643745
Iteration 1910, loss = 0.78295739
Iteration 1911, loss = 0.78420861
Iteration 1912, loss = 0.78204839
Iteration 1913, loss = 0.78167153
Iteration 1914, loss = 0.78084070
Iteration 1915, loss = 0.77921898
Iteration 1916, loss = 0.77938021
Iteration 1917, loss = 0.77735160
Iteration 1918, loss = 0.77766319
Iteration 1919, loss = 0.77589377
Iteration 1920, loss = 0.77576128
Iteration 1921, loss = 0.77463768
Iteration 1922, loss = 0.77387406
Iteration 1923, loss = 0.77331016
Iteration 1924, loss = 0.77211022
Iteration 1925, loss = 0.77183034
Iteration 1926, loss = 0.77057921
Iteration 1927, loss = 0.77025817
Iteration 1928, loss = 0.76922966
Iteration 1929, loss = 0.76866786
Iteration 1930, loss = 0.76793087
Iteration 1931, loss = 0.76711894
Iteration 1932, loss = 0.76658774
Iteration 1933, loss = 0.76567691
Iteration 1934, loss = 0.76520924
Iteration 1935, loss = 0.76436534
Iteration 1936, loss = 0.76384379
Iteration 1937, loss = 0.76314936
Iteration 1938, loss = 0.76251756
Iteration 1939, loss = 0.76193675
Iteration 1940, loss = 0.76122507
Iteration 1941, loss = 0.76070811
Iteration 1942, loss = 0.76002158
Iteration 1943, loss = 0.75951656
Iteration 1944, loss = 0.75889892
Iteration 1945, loss = 0.75834530
Iteration 1946, loss = 0.75778684
Iteration 1947, loss = 0.75719447
Iteration 1948, loss = 0.75668531
Iteration 1949, loss = 0.75610268
Iteration 1950, loss = 0.75561254
Iteration 1951, loss = 0.75506364
Iteration 1952, loss = 0.75456047
Iteration 1953, loss = 0.75404806
Iteration 1954, loss = 0.75353169
Iteration 1955, loss = 0.75305255
Iteration 1956, loss = 0.75254401
Iteration 1957, loss = 0.75208230
Iteration 1958, loss = 0.75159310
Iteration 1959, loss = 0.75113224
Iteration 1960, loss = 0.75066800
Iteration 1961, loss = 0.75020783
Iteration 1962, loss = 0.74976580
Iteration 1963, loss = 0.74931215
Iteration 1964, loss = 0.74888309
Iteration 1965, loss = 0.74844349
Iteration 1966, loss = 0.74802102
Iteration 1967, loss = 0.74759897
Iteration 1968, loss = 0.74718148
Iteration 1969, loss = 0.74677464
Iteration 1970, loss = 0.74636439
Iteration 1971, loss = 0.74596807
Iteration 1972, loss = 0.74556814
Iteration 1973, loss = 0.74513210
Iteration 1974, loss = 0.74514983
Iteration 1975, loss = 0.75436715
Iteration 1976, loss = 0.89581347
Iteration 1977, loss = 1.11492328
Iteration 1978, loss = 0.76093237
Iteration 1979, loss = 0.94512721
Iteration 1980, loss = 0.87484258
Iteration 1981, loss = 0.76279494
Iteration 1982, loss = 0.91331208
Iteration 1983, loss = 0.79497979
Iteration 1984, loss = 0.79526208
Iteration 1985, loss = 0.84880286
Iteration 1986, loss = 0.75324969
Iteration 1987, loss = 0.83327827
Iteration 1988, loss = 0.78543079
Iteration 1989, loss = 0.77162476
Iteration 1990, loss = 0.81317086
Iteration 1991, loss = 0.75113610
Iteration 1992, loss = 0.79258109
Iteration 1993, loss = 0.77288384
Iteration 1994, loss = 0.75650871
Iteration 1995, loss = 0.78618702
Iteration 1996, loss = 0.74981270
Iteration 1997, loss = 0.77014535
Iteration 1998, loss = 0.76416945
Iteration 1999, loss = 0.74914547
Iteration 2000, loss = 0.76843572
Iteration 2001, loss = 0.74769098
Iteration 2002, loss = 0.75602822
Iteration 2003, loss = 0.75621011
Iteration 2004, loss = 0.74454246
Iteration 2005, loss = 0.75671074
Iteration 2006, loss = 0.74553731
Iteration 2007, loss = 0.74750673
Iteration 2008, loss = 0.74985673
Iteration 2009, loss = 0.74103667
Iteration 2010, loss = 0.74791503
Iteration 2011, loss = 0.74273075
Iteration 2012, loss = 0.74196589
Iteration 2013, loss = 0.74462304
Iteration 2014, loss = 0.73851327
Iteration 2015, loss = 0.74176088
Iteration 2016, loss = 0.73968311
Iteration 2017, loss = 0.73786223
Iteration 2018, loss = 0.74010424
Iteration 2019, loss = 0.73638480
Iteration 2020, loss = 0.73751742
Iteration 2021, loss = 0.73692844
Iteration 2022, loss = 0.73493632
Iteration 2023, loss = 0.73641507
Iteration 2024, loss = 0.73439030
Iteration 2025, loss = 0.73438167
Iteration 2026, loss = 0.73444465
Iteration 2027, loss = 0.73276131
Iteration 2028, loss = 0.73346903
Iteration 2029, loss = 0.73247664
Iteration 2030, loss = 0.73195223
Iteration 2031, loss = 0.73219094
Iteration 2032, loss = 0.73099350
Iteration 2033, loss = 0.73113253
Iteration 2034, loss = 0.73070556
Iteration 2035, loss = 0.73004275
Iteration 2036, loss = 0.73020929
Iteration 2037, loss = 0.72946048
Iteration 2038, loss = 0.72925374
Iteration 2039, loss = 0.72905463
Iteration 2040, loss = 0.72731465
Iteration 2041, loss = 0.76819297
Iteration 2042, loss = 1.24302496
Iteration 2043, loss = 1.00607752
Iteration 2044, loss = 0.78037287
Iteration 2045, loss = 1.18651415
Iteration 2046, loss = 0.73461597
Iteration 2047, loss = 1.03984146
Iteration 2048, loss = 0.83293698
Iteration 2049, loss = 0.81060275
Iteration 2050, loss = 0.96174188
Iteration 2051, loss = 0.72997858
Iteration 2052, loss = 0.93565233
Iteration 2053, loss = 0.76443310
Iteration 2054, loss = 0.80841483
Iteration 2055, loss = 0.84407952
Iteration 2056, loss = 0.73217402
Iteration 2057, loss = 0.85372018
Iteration 2058, loss = 0.74160456
Iteration 2059, loss = 0.78560753
Iteration 2060, loss = 0.78903968
Iteration 2061, loss = 0.73147660
Iteration 2062, loss = 0.80069140
Iteration 2063, loss = 0.73258215
Iteration 2064, loss = 0.76282042
Iteration 2065, loss = 0.76149113
Iteration 2066, loss = 0.72884360
Iteration 2067, loss = 0.76911287
Iteration 2068, loss = 0.72881232
Iteration 2069, loss = 0.74601493
Iteration 2070, loss = 0.74628333
Iteration 2071, loss = 0.72535180
Iteration 2072, loss = 0.74938862
Iteration 2073, loss = 0.72611255
Iteration 2074, loss = 0.73455549
Iteration 2075, loss = 0.73636163
Iteration 2076, loss = 0.72258346
Iteration 2077, loss = 0.73677362
Iteration 2078, loss = 0.72373623
Iteration 2079, loss = 0.72672840
Iteration 2080, loss = 0.72767613
Iteration 2081, loss = 0.71164735
Iteration 2082, loss = 0.84330977
Iteration 2083, loss = 0.84614854
Iteration 2084, loss = 0.77620957
Iteration 2085, loss = 0.88106157
Iteration 2086, loss = 0.73557457
Iteration 2087, loss = 0.87519039
Iteration 2088, loss = 0.72244598
Iteration 2089, loss = 0.84631490
Iteration 2090, loss = 0.73274935
Iteration 2091, loss = 0.80295382
Iteration 2092, loss = 0.75045306
Iteration 2093, loss = 0.75957686
Iteration 2094, loss = 0.76451424
Iteration 2095, loss = 0.71972943
Iteration 2096, loss = 0.94732687
Iteration 2097, loss = 0.74495629
Iteration 2098, loss = 0.90468341
Iteration 2099, loss = 0.73226913
Iteration 2100, loss = 0.86099272
Iteration 2101, loss = 0.72516714
Iteration 2102, loss = 0.83557304
Iteration 2103, loss = 0.72882007
Iteration 2104, loss = 0.81783279
Iteration 2105, loss = 0.72845911
Iteration 2106, loss = 0.79848080
Iteration 2107, loss = 0.72585356
Iteration 2108, loss = 0.78433469
Iteration 2109, loss = 0.72690360
Iteration 2110, loss = 0.77432603
Iteration 2111, loss = 0.72698444
Iteration 2112, loss = 0.76439614
Iteration 2113, loss = 0.72621188
Iteration 2114, loss = 0.75627444
Iteration 2115, loss = 0.72602342
Iteration 2116, loss = 0.74956556
Iteration 2117, loss = 0.72507556
Iteration 2118, loss = 0.74290934
Iteration 2119, loss = 0.72386571
Iteration 2120, loss = 0.73669882
Iteration 2121, loss = 0.72178914
Iteration 2122, loss = 0.73140181
Iteration 2123, loss = 0.72021840
Iteration 2124, loss = 0.72620181
Iteration 2125, loss = 0.71706989
Iteration 2126, loss = 0.72063107
Iteration 2127, loss = 0.71392102
Iteration 2128, loss = 0.71898177
Iteration 2129, loss = 0.71207490
Iteration 2130, loss = 0.66125986
Iteration 2131, loss = 0.75451368
Iteration 2132, loss = 0.91337405
Iteration 2133, loss = 0.77319730
Iteration 2134, loss = 0.88989039
Iteration 2135, loss = 0.75529725
Iteration 2136, loss = 0.85275760
Iteration 2137, loss = 0.74762240
Iteration 2138, loss = 0.83868713
Iteration 2139, loss = 0.75864743
Iteration 2140, loss = 0.83187408
Iteration 2141, loss = 0.76778968
Iteration 2142, loss = 0.82009124
Iteration 2143, loss = 0.77180066
Iteration 2144, loss = 0.80766821
Iteration 2145, loss = 0.77645375
Iteration 2146, loss = 0.79859581
Iteration 2147, loss = 0.78172463
Iteration 2148, loss = 0.79127032
Iteration 2149, loss = 0.78432588
Iteration 2150, loss = 0.78416869
Iteration 2151, loss = 0.78578176
Iteration 2152, loss = 0.77982722
Iteration 2153, loss = 0.78722504
Iteration 2154, loss = 0.77808870
Iteration 2155, loss = 0.78798180
Iteration 2156, loss = 0.77692320
Iteration 2157, loss = 0.78631267
Iteration 2158, loss = 0.77501077
Iteration 2159, loss = 0.78315436
Iteration 2160, loss = 0.77378118
Iteration 2161, loss = 0.78031553
Iteration 2162, loss = 0.77351599
Iteration 2163, loss = 0.77777401
Iteration 2164, loss = 0.77322718
Iteration 2165, loss = 0.77499047
Iteration 2166, loss = 0.77250260
Iteration 2167, loss = 0.77237545
Iteration 2168, loss = 0.77153200
Iteration 2169, loss = 0.76991853
Iteration 2170, loss = 0.77015126
Iteration 2171, loss = 0.76780542
Iteration 2172, loss = 0.76874011
Iteration 2173, loss = 0.76617298
Iteration 2174, loss = 0.76718521
Iteration 2175, loss = 0.76463274
Iteration 2176, loss = 0.76534324
Iteration 2177, loss = 0.76312913
Iteration 2178, loss = 0.76346375
Iteration 2179, loss = 0.76177569
Iteration 2180, loss = 0.76167945
Iteration 2181, loss = 0.76046322
Iteration 2182, loss = 0.75984365
Iteration 2183, loss = 0.75908461
Iteration 2184, loss = 0.75816101
Iteration 2185, loss = 0.75765786
Iteration 2186, loss = 0.75651753
Iteration 2187, loss = 0.75622636
Iteration 2188, loss = 0.75504194
Iteration 2189, loss = 0.75435472
Iteration 2190, loss = 0.75313795
Iteration 2191, loss = 0.75274638
Iteration 2192, loss = 0.75167770
Iteration 2193, loss = 0.75079160
Iteration 2194, loss = 0.74980778
Iteration 2195, loss = 0.74862554
Iteration 2196, loss = 0.74732563
Iteration 2197, loss = 0.74563231
Iteration 2198, loss = 0.73883510
Iteration 2199, loss = 0.65739274
Iteration 2200, loss = 0.76952222
Iteration 2201, loss = 0.80264309
Iteration 2202, loss = 0.76776494
Iteration 2203, loss = 0.79729306
Iteration 2204, loss = 0.76236320
Iteration 2205, loss = 0.78987924
Iteration 2206, loss = 0.75774909
Iteration 2207, loss = 0.78479535
Iteration 2208, loss = 0.75809285
Iteration 2209, loss = 0.78384666
Iteration 2210, loss = 0.76039581
Iteration 2211, loss = 0.78149939
Iteration 2212, loss = 0.76010334
Iteration 2213, loss = 0.77719690
Iteration 2214, loss = 0.75946791
Iteration 2215, loss = 0.77372975
Iteration 2216, loss = 0.75981626
Iteration 2217, loss = 0.77126152
Iteration 2218, loss = 0.76059025
Iteration 2219, loss = 0.76912852
Iteration 2220, loss = 0.76101995
Iteration 2221, loss = 0.76683976
Iteration 2222, loss = 0.76095443
Iteration 2223, loss = 0.76455972
Iteration 2224, loss = 0.76057962
Iteration 2225, loss = 0.76247817
Iteration 2226, loss = 0.76019075
Iteration 2227, loss = 0.76092906
Iteration 2228, loss = 0.75991577
Iteration 2229, loss = 0.75959441
Iteration 2230, loss = 0.75925387
Iteration 2231, loss = 0.75812871
Iteration 2232, loss = 0.75832126
Iteration 2233, loss = 0.75685112
Iteration 2234, loss = 0.75742261
Iteration 2235, loss = 0.75578884
Iteration 2236, loss = 0.75647797
Iteration 2237, loss = 0.75478751
Iteration 2238, loss = 0.75543207
Iteration 2239, loss = 0.75380276
Iteration 2240, loss = 0.75433608
Iteration 2241, loss = 0.75287440
Iteration 2242, loss = 0.75325654
Iteration 2243, loss = 0.75198756
Iteration 2244, loss = 0.75217555
Iteration 2245, loss = 0.75110720
Iteration 2246, loss = 0.75111473
Iteration 2247, loss = 0.75024403
Iteration 2248, loss = 0.75007903
Iteration 2249, loss = 0.74936990
Iteration 2250, loss = 0.74906123
Iteration 2251, loss = 0.74849671
Iteration 2252, loss = 0.74808862
Iteration 2253, loss = 0.74763454
Iteration 2254, loss = 0.74715164
Iteration 2255, loss = 0.74676782
Iteration 2256, loss = 0.74623732
Iteration 2257, loss = 0.74589483
Iteration 2258, loss = 0.74534578
Iteration 2259, loss = 0.74502794
Iteration 2260, loss = 0.74448765
Iteration 2261, loss = 0.74417836
Iteration 2262, loss = 0.74365491
Iteration 2263, loss = 0.74333407
Iteration 2264, loss = 0.74283246
Iteration 2265, loss = 0.74249670
Iteration 2266, loss = 0.74202604
Iteration 2267, loss = 0.74167614
Iteration 2268, loss = 0.74123580
Iteration 2269, loss = 0.74087083
Iteration 2270, loss = 0.74045638
Iteration 2271, loss = 0.74007839
Iteration 2272, loss = 0.73968489
Iteration 2273, loss = 0.73929809
Iteration 2274, loss = 0.73892079
Iteration 2275, loss = 0.73852912
Iteration 2276, loss = 0.73816147
Iteration 2277, loss = 0.73776694
Iteration 2278, loss = 0.73740335
Iteration 2279, loss = 0.73700839
Iteration 2280, loss = 0.73664428
Iteration 2281, loss = 0.73624879
Iteration 2282, loss = 0.73587863
Iteration 2283, loss = 0.73548084
Iteration 2284, loss = 0.73510143
Iteration 2285, loss = 0.73470125
Iteration 2286, loss = 0.73431253
Iteration 2287, loss = 0.73391074
Iteration 2288, loss = 0.73351474
Iteration 2289, loss = 0.73311361
Iteration 2290, loss = 0.73271428
Iteration 2291, loss = 0.73231477
Iteration 2292, loss = 0.73191053
Iteration 2293, loss = 0.73150417
Iteration 2294, loss = 0.73108511
Iteration 2295, loss = 0.73066428
Iteration 2296, loss = 0.73023773
Iteration 2297, loss = 0.72982178
Iteration 2298, loss = 0.72940637
Iteration 2299, loss = 0.72899653
Iteration 2300, loss = 0.72857199
Iteration 2301, loss = 0.72811551
Iteration 2302, loss = 0.72759337
Iteration 2303, loss = 0.72706166
Iteration 2304, loss = 0.72656325
Iteration 2305, loss = 0.72598136
Iteration 2306, loss = 0.72525050
Iteration 2307, loss = 0.72431735
Iteration 2308, loss = 0.72322105
Iteration 2309, loss = 0.72222096
Iteration 2310, loss = 0.72097747
Iteration 2311, loss = 0.71986419
Iteration 2312, loss = 0.71834051
Iteration 2313, loss = 0.71693362
Iteration 2314, loss = 0.71387524
Iteration 2315, loss = 0.71025447
Iteration 2316, loss = 0.63998703
Iteration 2317, loss = 0.79074688
Iteration 2318, loss = 0.87244880
Iteration 2319, loss = 0.82009466
Iteration 2320, loss = 0.83382526
Iteration 2321, loss = 0.79165608
Iteration 2322, loss = 0.78691045
Iteration 2323, loss = 0.77938017
Iteration 2324, loss = 0.77736923
Iteration 2325, loss = 0.79081816
Iteration 2326, loss = 0.78019879
Iteration 2327, loss = 0.79478368
Iteration 2328, loss = 0.77409995
Iteration 2329, loss = 0.78871038
Iteration 2330, loss = 0.76683692
Iteration 2331, loss = 0.78057342
Iteration 2332, loss = 0.76356778
Iteration 2333, loss = 0.77934005
Iteration 2334, loss = 0.76468294
Iteration 2335, loss = 0.77673893
Iteration 2336, loss = 0.76568476
Iteration 2337, loss = 0.77332863
Iteration 2338, loss = 0.76883905
Iteration 2339, loss = 0.77041779
Iteration 2340, loss = 0.77052275
Iteration 2341, loss = 0.76750461
Iteration 2342, loss = 0.77074902
Iteration 2343, loss = 0.76553285
Iteration 2344, loss = 0.76978498
Iteration 2345, loss = 0.76469355
Iteration 2346, loss = 0.76846873
Iteration 2347, loss = 0.76481860
Iteration 2348, loss = 0.76703965
Iteration 2349, loss = 0.76504079
Iteration 2350, loss = 0.76520373
Iteration 2351, loss = 0.76441301
Iteration 2352, loss = 0.76300855
Iteration 2353, loss = 0.76329694
Iteration 2354, loss = 0.76135726
Iteration 2355, loss = 0.76221590
Iteration 2356, loss = 0.76020528
Iteration 2357, loss = 0.76091503
Iteration 2358, loss = 0.75911041
Iteration 2359, loss = 0.75938073
Iteration 2360, loss = 0.75813155
Iteration 2361, loss = 0.75795640
Iteration 2362, loss = 0.75720082
Iteration 2363, loss = 0.75659239
Iteration 2364, loss = 0.75619633
Iteration 2365, loss = 0.75536369
Iteration 2366, loss = 0.75521798
Iteration 2367, loss = 0.75426505
Iteration 2368, loss = 0.75411512
Iteration 2369, loss = 0.75317186
Iteration 2370, loss = 0.75293771
Iteration 2371, loss = 0.75209613
Iteration 2372, loss = 0.75171905
Iteration 2373, loss = 0.75104449
Iteration 2374, loss = 0.75060321
Iteration 2375, loss = 0.75006916
Iteration 2376, loss = 0.74947953
Iteration 2377, loss = 0.74895786
Iteration 2378, loss = 0.74816182
Iteration 2379, loss = 0.74725430
Iteration 2380, loss = 0.74619797
Iteration 2381, loss = 0.74483357
Iteration 2382, loss = 0.74318537
Iteration 2383, loss = 0.74046524
Iteration 2384, loss = 0.73897712
Iteration 2385, loss = 0.73723727
Iteration 2386, loss = 0.69385541
Iteration 2387, loss = 0.79507713
Iteration 2388, loss = 0.84094765
Iteration 2389, loss = 0.80654846
Iteration 2390, loss = 0.81577068
Iteration 2391, loss = 0.79092897
Iteration 2392, loss = 0.79834891
Iteration 2393, loss = 0.79488444
Iteration 2394, loss = 0.80004266
Iteration 2395, loss = 0.80181653
Iteration 2396, loss = 0.79902375
Iteration 2397, loss = 0.80230732
Iteration 2398, loss = 0.79678247
Iteration 2399, loss = 0.80189133
Iteration 2400, loss = 0.79438161
Iteration 2401, loss = 0.79959730
Iteration 2402, loss = 0.79187086
Iteration 2403, loss = 0.79825597
Iteration 2404, loss = 0.79165996
Iteration 2405, loss = 0.79784299
Iteration 2406, loss = 0.79113656
Iteration 2407, loss = 0.79593598
Iteration 2408, loss = 0.78876305
Iteration 2409, loss = 0.79229823
Iteration 2410, loss = 0.78567223
Iteration 2411, loss = 0.78916924
Iteration 2412, loss = 0.78376159
Iteration 2413, loss = 0.78669622
Iteration 2414, loss = 0.78176021
Iteration 2415, loss = 0.78386426
Iteration 2416, loss = 0.77923495
Iteration 2417, loss = 0.78058906
Iteration 2418, loss = 0.77632283
Iteration 2419, loss = 0.77705801
Iteration 2420, loss = 0.77304702
Iteration 2421, loss = 0.77353761
Iteration 2422, loss = 0.77050000
Iteration 2423, loss = 0.77089880
Iteration 2424, loss = 0.76795365
Iteration 2425, loss = 0.76767291
Iteration 2426, loss = 0.76455779
Iteration 2427, loss = 0.76152355
Iteration 2428, loss = 0.76531101
Iteration 2429, loss = 0.77028514
Iteration 2430, loss = 0.76786791
Iteration 2431, loss = 0.76552269
Iteration 2432, loss = 0.76341859
Iteration 2433, loss = 0.75873060
Iteration 2434, loss = 0.75997538
Iteration 2435, loss = 0.75599870
Iteration 2436, loss = 0.75872447
Iteration 2437, loss = 0.75359263
Iteration 2438, loss = 0.75544674
Iteration 2439, loss = 0.75078439
Iteration 2440, loss = 0.75255702
Iteration 2441, loss = 0.74881768
Iteration 2442, loss = 0.74985635
Iteration 2443, loss = 0.74699285
Iteration 2444, loss = 0.74737727
Iteration 2445, loss = 0.74546565
Iteration 2446, loss = 0.74514870
Iteration 2447, loss = 0.74373958
Iteration 2448, loss = 0.74283078
Iteration 2449, loss = 0.74204319
Iteration 2450, loss = 0.74094335
Iteration 2451, loss = 0.74047814
Iteration 2452, loss = 0.73895402
Iteration 2453, loss = 0.73073158
Iteration 2454, loss = 0.75147347
Iteration 2455, loss = 0.76479448
Iteration 2456, loss = 0.76295392
Iteration 2457, loss = 0.75500375
Iteration 2458, loss = 0.75156220
Iteration 2459, loss = 0.74744154
Iteration 2460, loss = 0.75184763
Iteration 2461, loss = 0.75034293
Iteration 2462, loss = 0.75420708
Iteration 2463, loss = 0.75170186
Iteration 2464, loss = 0.75279505
Iteration 2465, loss = 0.75145099
Iteration 2466, loss = 0.75266602
Iteration 2467, loss = 0.75362337
Iteration 2468, loss = 0.75308881
Iteration 2469, loss = 0.75281518
Iteration 2470, loss = 0.75082751
Iteration 2471, loss = 0.75187675
Iteration 2472, loss = 0.75168656
Iteration 2473, loss = 0.75329847
Iteration 2474, loss = 0.75252727
Iteration 2475, loss = 0.75240761
Iteration 2476, loss = 0.75131599
Iteration 2477, loss = 0.75094595
Iteration 2478, loss = 0.75072667
Iteration 2479, loss = 0.75047176
Iteration 2480, loss = 0.75061988
Iteration 2481, loss = 0.75009608
Iteration 2482, loss = 0.75003843
Iteration 2483, loss = 0.74921673
Iteration 2484, loss = 0.74900380
Iteration 2485, loss = 0.74835689
Iteration 2486, loss = 0.74820100
Iteration 2487, loss = 0.74772584
Iteration 2488, loss = 0.74735906
Iteration 2489, loss = 0.74687035
Iteration 2490, loss = 0.74638197
Iteration 2491, loss = 0.74604446
Iteration 2492, loss = 0.74558508
Iteration 2493, loss = 0.74527484
Iteration 2494, loss = 0.74471319
Iteration 2495, loss = 0.74430808
Iteration 2496, loss = 0.74375217
Iteration 2497, loss = 0.74339090
Iteration 2498, loss = 0.74294859
Iteration 2499, loss = 0.74257919
Iteration 2500, loss = 0.74213340
Iteration 2501, loss = 0.74168246
Iteration 2502, loss = 0.74124113
Iteration 2503, loss = 0.74078821
Iteration 2504, loss = 0.74039594
Iteration 2505, loss = 0.73996169
Iteration 2506, loss = 0.73958058
Iteration 2507, loss = 0.73913920
Iteration 2508, loss = 0.73874239
Iteration 2509, loss = 0.73830802
Iteration 2510, loss = 0.73791900
Iteration 2511, loss = 0.73751555
Iteration 2512, loss = 0.73712968
Iteration 2513, loss = 0.73673250
Iteration 2514, loss = 0.73633463
Iteration 2515, loss = 0.73594788
Iteration 2516, loss = 0.73555946
Iteration 2517, loss = 0.73518795
Iteration 2518, loss = 0.73480199
Iteration 2519, loss = 0.73442957
Iteration 2520, loss = 0.73404414
Iteration 2521, loss = 0.73367235
Iteration 2522, loss = 0.73329234
Iteration 2523, loss = 0.73293066
Iteration 2524, loss = 0.73257497
Iteration 2525, loss = 0.73222549
Iteration 2526, loss = 0.73187411
Iteration 2527, loss = 0.73152942
Iteration 2528, loss = 0.73119544
Iteration 2529, loss = 0.73086397
Iteration 2530, loss = 0.73053559
Iteration 2531, loss = 0.73020228
Iteration 2532, loss = 0.72987411
Iteration 2533, loss = 0.72954792
Iteration 2534, loss = 0.72923059
Iteration 2535, loss = 0.72891269
Iteration 2536, loss = 0.72859807
Iteration 2537, loss = 0.72828538
Iteration 2538, loss = 0.72797987
Iteration 2539, loss = 0.72767805
Iteration 2540, loss = 0.72737843
Iteration 2541, loss = 0.72708072
Iteration 2542, loss = 0.72678558
Iteration 2543, loss = 0.72649419
Iteration 2544, loss = 0.72620488
Iteration 2545, loss = 0.72591880
Iteration 2546, loss = 0.72563397
Iteration 2547, loss = 0.72535227
Iteration 2548, loss = 0.72507293
Iteration 2549, loss = 0.72479747
Iteration 2550, loss = 0.72452384
Iteration 2551, loss = 0.72425246
Iteration 2552, loss = 0.72398270
Iteration 2553, loss = 0.72371507
Iteration 2554, loss = 0.72344833
Iteration 2555, loss = 0.72318028
Iteration 2556, loss = 0.72290145
Iteration 2557, loss = 0.72253795
Iteration 2558, loss = 0.72200119
Iteration 2559, loss = 0.72183633
Iteration 2560, loss = 0.72116477
Iteration 2561, loss = 0.72095157
Iteration 2562, loss = 0.72060059
Iteration 2563, loss = 0.72040411
Iteration 2564, loss = 0.71972955
Iteration 2565, loss = 0.71921497
Iteration 2566, loss = 0.71860945
Iteration 2567, loss = 0.71571746
Iteration 2568, loss = 0.69296075
Iteration 2569, loss = 0.79513464
Iteration 2570, loss = 0.74929642
Iteration 2571, loss = 0.81561667
Iteration 2572, loss = 0.73028891
Iteration 2573, loss = 0.79077019
Iteration 2574, loss = 0.74921094
Iteration 2575, loss = 0.75758599
Iteration 2576, loss = 0.77419127
Iteration 2577, loss = 0.73792530
Iteration 2578, loss = 0.77659131
Iteration 2579, loss = 0.73683237
Iteration 2580, loss = 0.76285280
Iteration 2581, loss = 0.75038175
Iteration 2582, loss = 0.74808590
Iteration 2583, loss = 0.75989782
Iteration 2584, loss = 0.73860570
Iteration 2585, loss = 0.75789379
Iteration 2586, loss = 0.73967498
Iteration 2587, loss = 0.75046544
Iteration 2588, loss = 0.74593702
Iteration 2589, loss = 0.74256098
Iteration 2590, loss = 0.74912339
Iteration 2591, loss = 0.73774547
Iteration 2592, loss = 0.74848692
Iteration 2593, loss = 0.73973544
Iteration 2594, loss = 0.74268133
Iteration 2595, loss = 0.73792274
Iteration 2596, loss = 0.72454594
Iteration 2597, loss = 0.84181345
Iteration 2598, loss = 0.74621044
Iteration 2599, loss = 0.81987150
Iteration 2600, loss = 0.77449265
Iteration 2601, loss = 0.76496081
Iteration 2602, loss = 0.79892348
Iteration 2603, loss = 0.74812937
Iteration 2604, loss = 0.76294819
Iteration 2605, loss = 0.77359758
Iteration 2606, loss = 0.74438344
Iteration 2607, loss = 0.77308538
Iteration 2608, loss = 0.75626712
Iteration 2609, loss = 0.74282487
Iteration 2610, loss = 0.76194540
Iteration 2611, loss = 0.75034288
Iteration 2612, loss = 0.74285125
Iteration 2613, loss = 0.75649781
Iteration 2614, loss = 0.74406366
Iteration 2615, loss = 0.74028471
Iteration 2616, loss = 0.74971986
Iteration 2617, loss = 0.73989171
Iteration 2618, loss = 0.73937307
Iteration 2619, loss = 0.74476174
Iteration 2620, loss = 0.73655065
Iteration 2621, loss = 0.73785870
Iteration 2622, loss = 0.74049599
Iteration 2623, loss = 0.73372668
Iteration 2624, loss = 0.73499718
Iteration 2625, loss = 0.73553798
Iteration 2626, loss = 0.73073321
Iteration 2627, loss = 0.73266847
Iteration 2628, loss = 0.73224420
Iteration 2629, loss = 0.72865395
Iteration 2630, loss = 0.73003909
Iteration 2631, loss = 0.72880608
Iteration 2632, loss = 0.72623214
Iteration 2633, loss = 0.72730814
Iteration 2634, loss = 0.72591613
Iteration 2635, loss = 0.72428442
Iteration 2636, loss = 0.72492668
Iteration 2637, loss = 0.72338944
Iteration 2638, loss = 0.72230295
Iteration 2639, loss = 0.72252290
Iteration 2640, loss = 0.72110930
Iteration 2641, loss = 0.72048396
Iteration 2642, loss = 0.72039712
Iteration 2643, loss = 0.71909229
Iteration 2644, loss = 0.71865127
Iteration 2645, loss = 0.71832806
Iteration 2646, loss = 0.71713487
Iteration 2647, loss = 0.71653960
Iteration 2648, loss = 0.71591027
Iteration 2649, loss = 0.71476791
Iteration 2650, loss = 0.71379175
Iteration 2651, loss = 0.71234580
Iteration 2652, loss = 0.71023680
Iteration 2653, loss = 0.70722177
Iteration 2654, loss = 0.70572870
Iteration 2655, loss = 0.77690295
Iteration 2656, loss = 0.84316079
Iteration 2657, loss = 0.85233656
Iteration 2658, loss = 0.78586934
Iteration 2659, loss = 0.83390659
Iteration 2660, loss = 0.78834298
Iteration 2661, loss = 0.73772748
Iteration 2662, loss = 0.79032764
Iteration 2663, loss = 0.76941975
Iteration 2664, loss = 0.75164170
Iteration 2665, loss = 0.78768019
Iteration 2666, loss = 0.68131158
Iteration 2667, loss = 1.13113961
Iteration 2668, loss = 0.78979217
Iteration 2669, loss = 1.07191377
Iteration 2670, loss = 0.77989921
Iteration 2671, loss = 0.97966344
Iteration 2672, loss = 0.86003293
Iteration 2673, loss = 0.85500002
Iteration 2674, loss = 0.91968429
Iteration 2675, loss = 0.76366937
Iteration 2676, loss = 0.90508868
Iteration 2677, loss = 0.77964123
Iteration 2678, loss = 0.83805716
Iteration 2679, loss = 0.82639314
Iteration 2680, loss = 0.76091847
Iteration 2681, loss = 0.82046717
Iteration 2682, loss = 0.81749459
Iteration 2683, loss = 0.76141107
Iteration 2684, loss = 0.75130316
Iteration 2685, loss = 0.89968813
Iteration 2686, loss = 0.82601744
Iteration 2687, loss = 0.95453275
Iteration 2688, loss = 0.77807848
Iteration 2689, loss = 0.87350131
Iteration 2690, loss = 0.84972135
Iteration 2691, loss = 0.77994165
Iteration 2692, loss = 0.87880340
Iteration 2693, loss = 0.78507391
Iteration 2694, loss = 0.82912443
Iteration 2695, loss = 0.83026857
Iteration 2696, loss = 0.77485476
Iteration 2697, loss = 0.83485570
Iteration 2698, loss = 0.78094824
Iteration 2699, loss = 0.79889282
Iteration 2700, loss = 0.80764140
Iteration 2701, loss = 0.77005162
Iteration 2702, loss = 0.80653758
Iteration 2703, loss = 0.77706237
Iteration 2704, loss = 0.78332083
Iteration 2705, loss = 0.79163931
Iteration 2706, loss = 0.76783759
Iteration 2707, loss = 0.78896308
Iteration 2708, loss = 0.77230726
Iteration 2709, loss = 0.77404838
Iteration 2710, loss = 0.77976314
Iteration 2711, loss = 0.76405396
Iteration 2712, loss = 0.77598862
Iteration 2713, loss = 0.76660923
Iteration 2714, loss = 0.76659971
Iteration 2715, loss = 0.77027730
Iteration 2716, loss = 0.76051524
Iteration 2717, loss = 0.76728914
Iteration 2718, loss = 0.76142087
Iteration 2719, loss = 0.76055199
Iteration 2720, loss = 0.76247535
Iteration 2721, loss = 0.75642711
Iteration 2722, loss = 0.75612459
Iteration 2723, loss = 0.76069420
Iteration 2724, loss = 0.77273352
Iteration 2725, loss = 0.77251686
Iteration 2726, loss = 0.76425574
Iteration 2727, loss = 0.75830083
Iteration 2728, loss = 0.75757272
Iteration 2729, loss = 0.75974519
Iteration 2730, loss = 0.76077428
Iteration 2731, loss = 0.75926776
Iteration 2732, loss = 0.75764047
Iteration 2733, loss = 0.75644413
Iteration 2734, loss = 0.75618655
Iteration 2735, loss = 0.75607188
Iteration 2736, loss = 0.75502022
Iteration 2737, loss = 0.75347528
Iteration 2738, loss = 0.75220118
Iteration 2739, loss = 0.75160272
Iteration 2740, loss = 0.75151477
Iteration 2741, loss = 0.75094072
Iteration 2742, loss = 0.74948634
Iteration 2743, loss = 0.74784008
Iteration 2744, loss = 0.74667773
Iteration 2745, loss = 0.74610176
Iteration 2746, loss = 0.74559221
Iteration 2747, loss = 0.74467829
Iteration 2748, loss = 0.74343330
Iteration 2749, loss = 0.74218542
Iteration 2750, loss = 0.74121245
Iteration 2751, loss = 0.74044396
Iteration 2752, loss = 0.73958833
Iteration 2753, loss = 0.73858539
Iteration 2754, loss = 0.73753099
Iteration 2755, loss = 0.73657279
Iteration 2756, loss = 0.73572736
Iteration 2757, loss = 0.73490174
Iteration 2758, loss = 0.73400039
Iteration 2759, loss = 0.73300764
Iteration 2760, loss = 0.73214759
Iteration 2761, loss = 0.73151381
Iteration 2762, loss = 0.73100524
Iteration 2763, loss = 0.73045028
Iteration 2764, loss = 0.72981310
Iteration 2765, loss = 0.72912382
Iteration 2766, loss = 0.72845777
Iteration 2767, loss = 0.72792885
Iteration 2768, loss = 0.72748951
Iteration 2769, loss = 0.72696673
Iteration 2770, loss = 0.72635004
Iteration 2771, loss = 0.72569686
Iteration 2772, loss = 0.72502731
Iteration 2773, loss = 0.72439916
Iteration 2774, loss = 0.72393341
Iteration 2775, loss = 0.72337011
Iteration 2776, loss = 0.72280864
Iteration 2777, loss = 0.72229543
Iteration 2778, loss = 0.72174198
Iteration 2779, loss = 0.72120144
Iteration 2780, loss = 0.72070958
Iteration 2781, loss = 0.72000906
Iteration 2782, loss = 0.71932527
Iteration 2783, loss = 0.71875259
Iteration 2784, loss = 0.71795942
Iteration 2785, loss = 0.71703482
Iteration 2786, loss = 0.71629853
Iteration 2787, loss = 0.71496984
Iteration 2788, loss = 0.71315722
Iteration 2789, loss = 0.71083910
Iteration 2790, loss = 0.70415486
Iteration 2791, loss = 0.73531839
Iteration 2792, loss = 0.72215495
Iteration 2793, loss = 0.74085985
Iteration 2794, loss = 0.71549326
Iteration 2795, loss = 0.71418528
Iteration 2796, loss = 0.75550403
Iteration 2797, loss = 0.73989545
Iteration 2798, loss = 0.75348240
Iteration 2799, loss = 0.72508645
Iteration 2800, loss = 0.74036109
Iteration 2801, loss = 0.72805870
Iteration 2802, loss = 0.73509186
Iteration 2803, loss = 0.73328182
Iteration 2804, loss = 0.72694738
Iteration 2805, loss = 0.73380244
Iteration 2806, loss = 0.72391379
Iteration 2807, loss = 0.73243760
Iteration 2808, loss = 0.72325171
Iteration 2809, loss = 0.72690369
Iteration 2810, loss = 0.72320856
Iteration 2811, loss = 0.72271927
Iteration 2812, loss = 0.72469169
Iteration 2813, loss = 0.72094137
Iteration 2814, loss = 0.72461240
Iteration 2815, loss = 0.71970884
Iteration 2816, loss = 0.72199693
Iteration 2817, loss = 0.71875013
Iteration 2818, loss = 0.71919592
Iteration 2819, loss = 0.71868977
Iteration 2820, loss = 0.71743982
Iteration 2821, loss = 0.71846868
Iteration 2822, loss = 0.71619582
Iteration 2823, loss = 0.71742399
Iteration 2824, loss = 0.71546620
Iteration 2825, loss = 0.71603973
Iteration 2826, loss = 0.71490343
Iteration 2827, loss = 0.71436613
Iteration 2828, loss = 0.71395226
Iteration 2829, loss = 0.71316801
Iteration 2830, loss = 0.71367672
Iteration 2831, loss = 0.71251969
Iteration 2832, loss = 0.71256605
Iteration 2833, loss = 0.71156763
Iteration 2834, loss = 0.71162229
Iteration 2835, loss = 0.71122975
Iteration 2836, loss = 0.71067412
Iteration 2837, loss = 0.71043405
Iteration 2838, loss = 0.70985392
Iteration 2839, loss = 0.70988497
Iteration 2840, loss = 0.70931660
Iteration 2841, loss = 0.70921058
Iteration 2842, loss = 0.70872899
Iteration 2843, loss = 0.70854724
Iteration 2844, loss = 0.70832756
Iteration 2845, loss = 0.70803760
Iteration 2846, loss = 0.70785028
Iteration 2847, loss = 0.70746338
Iteration 2848, loss = 0.70735844
Iteration 2849, loss = 0.70703715
Iteration 2850, loss = 0.70687712
Iteration 2851, loss = 0.70657470
Iteration 2852, loss = 0.70637853
Iteration 2853, loss = 0.70619298
Iteration 2854, loss = 0.70598051
Iteration 2855, loss = 0.70583114
Iteration 2856, loss = 0.70559826
Iteration 2857, loss = 0.70546633
Iteration 2858, loss = 0.70525297
Iteration 2859, loss = 0.70510843
Iteration 2860, loss = 0.70491459
Iteration 2861, loss = 0.70475476
Iteration 2862, loss = 0.70459694
Iteration 2863, loss = 0.70442666
Iteration 2864, loss = 0.70428056
Iteration 2865, loss = 0.70409620
Iteration 2866, loss = 0.70391172
Iteration 2867, loss = 0.70338977
Iteration 2868, loss = 0.70315230
Iteration 2869, loss = 0.70276149
Iteration 2870, loss = 0.70216824
Iteration 2871, loss = 0.70143226
Iteration 2872, loss = 0.70040480
Iteration 2873, loss = 0.68343431
Iteration 2874, loss = 0.80064379
Iteration 2875, loss = 0.73042020
Iteration 2876, loss = 0.82370702
Iteration 2877, loss = 0.72036327
Iteration 2878, loss = 0.77695865
Iteration 2879, loss = 0.75813954
Iteration 2880, loss = 0.72813855
Iteration 2881, loss = 0.78050250
Iteration 2882, loss = 0.72027396
Iteration 2883, loss = 0.76261112
Iteration 2884, loss = 0.74012062
Iteration 2885, loss = 0.73176643
Iteration 2886, loss = 0.75594156
Iteration 2887, loss = 0.72088535
Iteration 2888, loss = 0.75010070
Iteration 2889, loss = 0.73003124
Iteration 2890, loss = 0.73237321
Iteration 2891, loss = 0.74026248
Iteration 2892, loss = 0.72156078
Iteration 2893, loss = 0.73927787
Iteration 2894, loss = 0.72353980
Iteration 2895, loss = 0.72947411
Iteration 2896, loss = 0.72926542
Iteration 2897, loss = 0.72062644
Iteration 2898, loss = 0.72984102
Iteration 2899, loss = 0.71884506
Iteration 2900, loss = 0.72464300
Iteration 2901, loss = 0.72128354
Iteration 2902, loss = 0.71833881
Iteration 2903, loss = 0.72209410
Iteration 2904, loss = 0.71521712
Iteration 2905, loss = 0.71934075
Iteration 2906, loss = 0.71536992
Iteration 2907, loss = 0.71510849
Iteration 2908, loss = 0.71582289
Iteration 2909, loss = 0.71209641
Iteration 2910, loss = 0.71446819
Iteration 2911, loss = 0.71112330
Iteration 2912, loss = 0.71175611
Iteration 2913, loss = 0.71100621
Iteration 2914, loss = 0.70927594
Iteration 2915, loss = 0.71027276
Iteration 2916, loss = 0.70794069
Iteration 2917, loss = 0.70863425
Iteration 2918, loss = 0.70744626
Iteration 2919, loss = 0.70681855
Iteration 2920, loss = 0.70694165
Iteration 2921, loss = 0.70552655
Iteration 2922, loss = 0.70594939
Iteration 2923, loss = 0.70483403
Iteration 2924, loss = 0.70469423
Iteration 2925, loss = 0.70438239
Iteration 2926, loss = 0.70363987
Iteration 2927, loss = 0.70377487
Iteration 2928, loss = 0.70294107
Iteration 2929, loss = 0.70294284
Iteration 2930, loss = 0.70248589
Iteration 2931, loss = 0.70213709
Iteration 2932, loss = 0.70206165
Iteration 2933, loss = 0.70152699
Iteration 2934, loss = 0.70152541
Iteration 2935, loss = 0.70110204
Iteration 2936, loss = 0.70094860
Iteration 2937, loss = 0.70076385
Iteration 2938, loss = 0.70045313
Iteration 2939, loss = 0.70040003
Iteration 2940, loss = 0.70007754
Iteration 2941, loss = 0.69999929
Iteration 2942, loss = 0.69979125
Iteration 2943, loss = 0.69962140
Iteration 2944, loss = 0.69952589
Iteration 2945, loss = 0.69930804
Iteration 2946, loss = 0.69924469
Iteration 2947, loss = 0.69906109
Iteration 2948, loss = 0.69896356
Iteration 2949, loss = 0.69885012
Iteration 2950, loss = 0.69871214
Iteration 2951, loss = 0.69864418
Iteration 2952, loss = 0.69850337
Iteration 2953, loss = 0.69843644
Iteration 2954, loss = 0.69832734
Iteration 2955, loss = 0.69823869
Iteration 2956, loss = 0.69816516
Iteration 2957, loss = 0.69806389
Iteration 2958, loss = 0.69800627
Iteration 2959, loss = 0.69791389
Iteration 2960, loss = 0.69785151
Iteration 2961, loss = 0.69777932
Iteration 2962, loss = 0.69770672
Iteration 2963, loss = 0.69765064
Iteration 2964, loss = 0.69757652
Iteration 2965, loss = 0.69752480
Iteration 2966, loss = 0.69745861
Iteration 2967, loss = 0.69740202
Iteration 2968, loss = 0.69734457
Iteration 2969, loss = 0.69727880
Iteration 2970, loss = 0.69721380
Iteration 2971, loss = 0.69712373
Iteration 2972, loss = 0.69706374
Iteration 2973, loss = 0.69701864
Iteration 2974, loss = 0.69695664
Iteration 2975, loss = 0.69688103
Iteration 2976, loss = 0.69681229
Iteration 2977, loss = 0.69676321
Iteration 2978, loss = 0.69669352
Iteration 2979, loss = 0.69661876
Iteration 2980, loss = 0.69647033
Iteration 2981, loss = 0.69648437
Iteration 2982, loss = 0.69638754
Iteration 2983, loss = 0.69623698
Iteration 2984, loss = 0.69590217
Iteration 2985, loss = 0.69576998
Iteration 2986, loss = 0.69554084
Iteration 2987, loss = 0.69469388
Iteration 2988, loss = 0.69224708
Iteration 2989, loss = 0.70844053
Iteration 2990, loss = 0.71537159
Iteration 2991, loss = 0.71342746
Iteration 2992, loss = 0.72447569
Iteration 2993, loss = 0.71796861
Iteration 2994, loss = 0.71600509
Iteration 2995, loss = 0.70680231
Iteration 2996, loss = 0.70744856
Iteration 2997, loss = 0.70494907
Iteration 2998, loss = 0.70769712
Iteration 2999, loss = 0.70926605
Iteration 3000, loss = 0.71078702
Iteration 3001, loss = 0.71279447
Iteration 3002, loss = 0.71121881
Iteration 3003, loss = 0.71120264
Iteration 3004, loss = 0.70798565
Iteration 3005, loss = 0.70825808
Iteration 3006, loss = 0.70693931
Iteration 3007, loss = 0.70881580
Iteration 3008, loss = 0.70923168
Iteration 3009, loss = 0.71014071
Iteration 3010, loss = 0.70998792
Iteration 3011, loss = 0.70929235
Iteration 3012, loss = 0.70881008
Iteration 3013, loss = 0.70773976
Iteration 3014, loss = 0.70790482
Iteration 3015, loss = 0.70763910
Iteration 3016, loss = 0.70847657
Iteration 3017, loss = 0.70828283
Iteration 3018, loss = 0.70827610
Iteration 3019, loss = 0.70913247
Iteration 3020, loss = 0.70520989
Iteration 3021, loss = 0.70907727
Iteration 3022, loss = 0.70376660
Iteration 3023, loss = 0.70240396
Iteration 3024, loss = 0.67921359
Iteration 3025, loss = 0.71290158
Iteration 3026, loss = 0.76577317
Iteration 3027, loss = 0.72972764
Iteration 3028, loss = 0.74798771
Iteration 3029, loss = 0.71675429
Iteration 3030, loss = 0.73445536
Iteration 3031, loss = 0.72323965
Iteration 3032, loss = 0.73289696
Iteration 3033, loss = 0.73102055
Iteration 3034, loss = 0.72734602
Iteration 3035, loss = 0.73201581
Iteration 3036, loss = 0.72246731
Iteration 3037, loss = 0.73053133
Iteration 3038, loss = 0.71993999
Iteration 3039, loss = 0.72829608
Iteration 3040, loss = 0.71950569
Iteration 3041, loss = 0.72548689
Iteration 3042, loss = 0.72125729
Iteration 3043, loss = 0.72388922
Iteration 3044, loss = 0.72262083
Iteration 3045, loss = 0.72090106
Iteration 3046, loss = 0.72135130
Iteration 3047, loss = 0.71783009
Iteration 3048, loss = 0.72055861
Iteration 3049, loss = 0.71760657
Iteration 3050, loss = 0.72035763
Iteration 3051, loss = 0.71709184
Iteration 3052, loss = 0.71837844
Iteration 3053, loss = 0.71610510
Iteration 3054, loss = 0.71658512
Iteration 3055, loss = 0.71562671
Iteration 3056, loss = 0.71522507
Iteration 3057, loss = 0.71507088
Iteration 3058, loss = 0.71399451
Iteration 3059, loss = 0.71433749
Iteration 3060, loss = 0.71297458
Iteration 3061, loss = 0.71334152
Iteration 3062, loss = 0.71196706
Iteration 3063, loss = 0.71220804
Iteration 3064, loss = 0.71117413
Iteration 3065, loss = 0.71122894
Iteration 3066, loss = 0.71054100
Iteration 3067, loss = 0.71027970
Iteration 3068, loss = 0.70968831
Iteration 3069, loss = 0.70952019
Iteration 3070, loss = 0.70919849
Iteration 3071, loss = 0.70913016
Iteration 3072, loss = 0.70857060
Iteration 3073, loss = 0.70833352
Iteration 3074, loss = 0.70783360
Iteration 3075, loss = 0.70763093
Iteration 3076, loss = 0.70712546
Iteration 3077, loss = 0.70689313
Iteration 3078, loss = 0.70647433
Iteration 3079, loss = 0.70617805
Iteration 3080, loss = 0.70573544
Iteration 3081, loss = 0.70555269
Iteration 3082, loss = 0.70509070
Iteration 3083, loss = 0.70483040
Iteration 3084, loss = 0.70445442
Iteration 3085, loss = 0.70417087
Iteration 3086, loss = 0.70389463
Iteration 3087, loss = 0.70357350
Iteration 3088, loss = 0.70324081
Iteration 3089, loss = 0.70297007
Iteration 3090, loss = 0.70269362
Iteration 3091, loss = 0.70249945
Iteration 3092, loss = 0.70223511
Iteration 3093, loss = 0.70192940
Iteration 3094, loss = 0.70178253
Iteration 3095, loss = 0.70145782
Iteration 3096, loss = 0.70123768
Iteration 3097, loss = 0.70173128
Iteration 3098, loss = 0.70153875
Iteration 3099, loss = 0.70058176
Iteration 3100, loss = 0.69984065
Iteration 3101, loss = 0.69876687
Iteration 3102, loss = 0.69597872
Iteration 3103, loss = 0.70605055
Iteration 3104, loss = 0.77627363
Iteration 3105, loss = 0.72335900
Iteration 3106, loss = 0.77230117
Iteration 3107, loss = 0.71192073
Iteration 3108, loss = 0.74775128
Iteration 3109, loss = 0.70463959
Iteration 3110, loss = 0.74216580
Iteration 3111, loss = 0.71126308
Iteration 3112, loss = 0.73918440
Iteration 3113, loss = 0.70883933
Iteration 3114, loss = 0.72875365
Iteration 3115, loss = 0.70564900
Iteration 3116, loss = 0.72437399
Iteration 3117, loss = 0.70679560
Iteration 3118, loss = 0.72147988
Iteration 3119, loss = 0.70593784
Iteration 3120, loss = 0.71735983
Iteration 3121, loss = 0.70517034
Iteration 3122, loss = 0.71506127
Iteration 3123, loss = 0.70502486
Iteration 3124, loss = 0.71267828
Iteration 3125, loss = 0.70411590
Iteration 3126, loss = 0.71047178
Iteration 3127, loss = 0.70386576
Iteration 3128, loss = 0.70929496
Iteration 3129, loss = 0.70304793
Iteration 3130, loss = 0.70931545
Iteration 3131, loss = 0.71411982
Iteration 3132, loss = 0.71127833
Iteration 3133, loss = 0.70699814
Iteration 3134, loss = 0.70285641
Iteration 3135, loss = 0.70606332
Iteration 3136, loss = 0.70580782
Iteration 3137, loss = 0.70631226
Iteration 3138, loss = 0.70464301
Iteration 3139, loss = 0.70483006
Iteration 3140, loss = 0.70430940
Iteration 3141, loss = 0.70387872
Iteration 3142, loss = 0.70281645
Iteration 3143, loss = 0.70264426
Iteration 3144, loss = 0.70293126
Iteration 3145, loss = 0.70292547
Iteration 3146, loss = 0.70212896
Iteration 3147, loss = 0.70142193
Iteration 3148, loss = 0.70166645
Iteration 3149, loss = 0.70135019
Iteration 3150, loss = 0.70107533
Iteration 3151, loss = 0.70034152
Iteration 3152, loss = 0.70046587
Iteration 3153, loss = 0.70026106
Iteration 3154, loss = 0.70015766
Iteration 3155, loss = 0.69956183
Iteration 3156, loss = 0.69936138
Iteration 3157, loss = 0.69908653
Iteration 3158, loss = 0.69925706
Iteration 3159, loss = 0.69891059
Iteration 3160, loss = 0.69851267
Iteration 3161, loss = 0.69810639
Iteration 3162, loss = 0.69804867
Iteration 3163, loss = 0.69784443
Iteration 3164, loss = 0.69773552
Iteration 3165, loss = 0.69745147
Iteration 3166, loss = 0.69732090
Iteration 3167, loss = 0.69724114
Iteration 3168, loss = 0.69712540
Iteration 3169, loss = 0.69689937
Iteration 3170, loss = 0.69667668
Iteration 3171, loss = 0.69649779
Iteration 3172, loss = 0.69631463
Iteration 3173, loss = 0.69614985
Iteration 3174, loss = 0.69598518
Iteration 3175, loss = 0.69583246
Iteration 3176, loss = 0.69567922
Iteration 3177, loss = 0.69556549
Iteration 3178, loss = 0.69541884
Iteration 3179, loss = 0.69530570
Iteration 3180, loss = 0.69514559
Iteration 3181, loss = 0.69499869
Iteration 3182, loss = 0.69484201
Iteration 3183, loss = 0.69471111
Iteration 3184, loss = 0.69458178
Iteration 3185, loss = 0.69445932
Iteration 3186, loss = 0.69430088
Iteration 3187, loss = 0.69414671
Iteration 3188, loss = 0.69391993
Iteration 3189, loss = 0.69350189
Iteration 3190, loss = 0.69299624
Iteration 3191, loss = 0.69255334
Iteration 3192, loss = 0.69112539
Iteration 3193, loss = 0.68949944
Iteration 3194, loss = 0.68708838
Iteration 3195, loss = 0.68086125
Iteration 3196, loss = 0.64121262
Iteration 3197, loss = 0.77692833
Iteration 3198, loss = 0.81574920
Iteration 3199, loss = 0.77891677
Iteration 3200, loss = 0.78574415
Iteration 3201, loss = 0.75679388
Iteration 3202, loss = 0.76732156
Iteration 3203, loss = 0.75851832
Iteration 3204, loss = 0.76863299
Iteration 3205, loss = 0.76287330
Iteration 3206, loss = 0.76364656
Iteration 3207, loss = 0.75923012
Iteration 3208, loss = 0.75787744
Iteration 3209, loss = 0.75641929
Iteration 3210, loss = 0.75455808
Iteration 3211, loss = 0.75514943
Iteration 3212, loss = 0.75286696
Iteration 3213, loss = 0.75432777
Iteration 3214, loss = 0.75160635
Iteration 3215, loss = 0.75293260
Iteration 3216, loss = 0.74938733
Iteration 3217, loss = 0.75036163
Iteration 3218, loss = 0.74708022
Iteration 3219, loss = 0.74825750
Iteration 3220, loss = 0.74533582
Iteration 3221, loss = 0.74623908
Iteration 3222, loss = 0.74348494
Iteration 3223, loss = 0.74397557
Iteration 3224, loss = 0.74146568
Iteration 3225, loss = 0.74168773
Iteration 3226, loss = 0.73939510
Iteration 3227, loss = 0.73931428
Iteration 3228, loss = 0.73728165
Iteration 3229, loss = 0.73702204
Iteration 3230, loss = 0.73524285
Iteration 3231, loss = 0.73483164
Iteration 3232, loss = 0.73328892
Iteration 3233, loss = 0.73272719
Iteration 3234, loss = 0.73131087
Iteration 3235, loss = 0.73057686
Iteration 3236, loss = 0.72930333
Iteration 3237, loss = 0.72850970
Iteration 3238, loss = 0.72739900
Iteration 3239, loss = 0.72657489
Iteration 3240, loss = 0.72560392
Iteration 3241, loss = 0.72474627
Iteration 3242, loss = 0.72385678
Iteration 3243, loss = 0.72296184
Iteration 3244, loss = 0.72213213
Iteration 3245, loss = 0.72122245
Iteration 3246, loss = 0.72047279
Iteration 3247, loss = 0.71960528
Iteration 3248, loss = 0.71894703
Iteration 3249, loss = 0.71810970
Iteration 3250, loss = 0.71748764
Iteration 3251, loss = 0.71665218
Iteration 3252, loss = 0.71605656
Iteration 3253, loss = 0.71525140
Iteration 3254, loss = 0.71470489
Iteration 3255, loss = 0.71395244
Iteration 3256, loss = 0.71345456
Iteration 3257, loss = 0.71274581
Iteration 3258, loss = 0.71226964
Iteration 3259, loss = 0.71158372
Iteration 3260, loss = 0.71112009
Iteration 3261, loss = 0.71047090
Iteration 3262, loss = 0.71003918
Iteration 3263, loss = 0.70944053
Iteration 3264, loss = 0.70903674
Iteration 3265, loss = 0.70847300
Iteration 3266, loss = 0.70807877
Iteration 3267, loss = 0.70753959
Iteration 3268, loss = 0.70714809
Iteration 3269, loss = 0.70615372
Iteration 3270, loss = 0.74531974
Iteration 3271, loss = 0.72835553
Iteration 3272, loss = 0.74905426
Iteration 3273, loss = 0.71628996
Iteration 3274, loss = 0.74689360
Iteration 3275, loss = 0.70841846
Iteration 3276, loss = 0.74102556
Iteration 3277, loss = 0.70692787
Iteration 3278, loss = 0.73495768
Iteration 3279, loss = 0.70823496
Iteration 3280, loss = 0.72786130
Iteration 3281, loss = 0.71010791
Iteration 3282, loss = 0.72101045
Iteration 3283, loss = 0.71213838
Iteration 3284, loss = 0.71541571
Iteration 3285, loss = 0.71315663
Iteration 3286, loss = 0.71068538
Iteration 3287, loss = 0.71334554
Iteration 3288, loss = 0.70775597
Iteration 3289, loss = 0.71303858
Iteration 3290, loss = 0.70578298
Iteration 3291, loss = 0.71168294
Iteration 3292, loss = 0.70445121
Iteration 3293, loss = 0.71008169
Iteration 3294, loss = 0.70393433
Iteration 3295, loss = 0.70840865
Iteration 3296, loss = 0.70363238
Iteration 3297, loss = 0.70664531
Iteration 3298, loss = 0.70342063
Iteration 3299, loss = 0.70502161
Iteration 3300, loss = 0.70318231
Iteration 3301, loss = 0.70363678
Iteration 3302, loss = 0.70292377
Iteration 3303, loss = 0.70247565
Iteration 3304, loss = 0.70249390
Iteration 3305, loss = 0.70150555
Iteration 3306, loss = 0.70201793
Iteration 3307, loss = 0.70077529
Iteration 3308, loss = 0.70146554
Iteration 3309, loss = 0.70014685
Iteration 3310, loss = 0.70084689
Iteration 3311, loss = 0.69965320
Iteration 3312, loss = 0.70026779
Iteration 3313, loss = 0.69925545
Iteration 3314, loss = 0.69967755
Iteration 3315, loss = 0.69886919
Iteration 3316, loss = 0.69911572
Iteration 3317, loss = 0.69853863
Iteration 3318, loss = 0.69862079
Iteration 3319, loss = 0.69822326
Iteration 3320, loss = 0.69815813
Iteration 3321, loss = 0.69790741
Iteration 3322, loss = 0.69774638
Iteration 3323, loss = 0.69760867
Iteration 3324, loss = 0.69738514
Iteration 3325, loss = 0.69731402
Iteration 3326, loss = 0.69705712
Iteration 3327, loss = 0.69702726
Iteration 3328, loss = 0.69676746
Iteration 3329, loss = 0.69675317
Iteration 3330, loss = 0.69650278
Iteration 3331, loss = 0.69648790
Iteration 3332, loss = 0.69626061
Iteration 3333, loss = 0.69623592
Iteration 3334, loss = 0.69603320
Iteration 3335, loss = 0.69599017
Iteration 3336, loss = 0.69580804
Iteration 3337, loss = 0.69573477
Iteration 3338, loss = 0.69554073
Iteration 3339, loss = 0.69533458
Iteration 3340, loss = 0.69447017
Iteration 3341, loss = 0.69455160
Iteration 3342, loss = 0.70715840
Iteration 3343, loss = 0.70023574
Iteration 3344, loss = 0.70885860
Iteration 3345, loss = 0.70006528
Iteration 3346, loss = 0.70327488
Iteration 3347, loss = 0.69795325
Iteration 3348, loss = 0.70073716
Iteration 3349, loss = 0.69851759
Iteration 3350, loss = 0.69931228
Iteration 3351, loss = 0.69837538
Iteration 3352, loss = 0.69768232
Iteration 3353, loss = 0.69794515
Iteration 3354, loss = 0.69656017
Iteration 3355, loss = 0.69750436
Iteration 3356, loss = 0.69556246
Iteration 3357, loss = 0.69667489
Iteration 3358, loss = 0.69472754
Iteration 3359, loss = 0.69629595
Iteration 3360, loss = 0.69452573
Iteration 3361, loss = 0.69571263
Iteration 3362, loss = 0.69384798
Iteration 3363, loss = 0.69476993
Iteration 3364, loss = 0.69324853
Iteration 3365, loss = 0.69421163
Iteration 3366, loss = 0.69298867
Iteration 3367, loss = 0.69339578
Iteration 3368, loss = 0.69264282
Iteration 3369, loss = 0.69295440
Iteration 3370, loss = 0.69217125
Iteration 3371, loss = 0.69216456
Iteration 3372, loss = 0.69150696
Iteration 3373, loss = 0.69105938
Iteration 3374, loss = 0.69113015
Iteration 3375, loss = 0.69155209
Iteration 3376, loss = 0.68946055
Iteration 3377, loss = 0.69465969
Iteration 3378, loss = 0.76255603
Iteration 3379, loss = 0.71621271
Iteration 3380, loss = 0.76044043
Iteration 3381, loss = 0.71025927
Iteration 3382, loss = 0.73290111
Iteration 3383, loss = 0.70351141
Iteration 3384, loss = 0.72124903
Iteration 3385, loss = 0.71119853
Iteration 3386, loss = 0.71631090
Iteration 3387, loss = 0.71204753
Iteration 3388, loss = 0.70306748
Iteration 3389, loss = 0.69890065
Iteration 3390, loss = 0.83382432
Iteration 3391, loss = 0.72541490
Iteration 3392, loss = 0.83065989
Iteration 3393, loss = 0.73650208
Iteration 3394, loss = 0.78073779
Iteration 3395, loss = 0.75293705
Iteration 3396, loss = 0.73411728
Iteration 3397, loss = 0.76933192
Iteration 3398, loss = 0.71653836
Iteration 3399, loss = 0.75546025
Iteration 3400, loss = 0.74170259
Iteration 3401, loss = 0.72864984
Iteration 3402, loss = 0.73736506
Iteration 3403, loss = 0.72450986
Iteration 3404, loss = 0.72621384
Iteration 3405, loss = 0.72373379
Iteration 3406, loss = 0.72534906
Iteration 3407, loss = 0.72805527
Iteration 3408, loss = 0.72383664
Iteration 3409, loss = 0.72574890
Iteration 3410, loss = 0.71949803
Iteration 3411, loss = 0.72442273
Iteration 3412, loss = 0.71913336
Iteration 3413, loss = 0.72432442
Iteration 3414, loss = 0.71800601
Iteration 3415, loss = 0.72111805
Iteration 3416, loss = 0.71633579
Iteration 3417, loss = 0.71969031
Iteration 3418, loss = 0.71608349
Iteration 3419, loss = 0.71843075
Iteration 3420, loss = 0.71425895
Iteration 3421, loss = 0.70192400
Iteration 3422, loss = 0.81548090
Iteration 3423, loss = 0.76557326
Iteration 3424, loss = 0.83722201
Iteration 3425, loss = 0.72332731
Iteration 3426, loss = 0.81235345
Iteration 3427, loss = 0.73496104
Iteration 3428, loss = 0.77987334
Iteration 3429, loss = 0.76178968
Iteration 3430, loss = 0.74167145
Iteration 3431, loss = 0.77162624
Iteration 3432, loss = 0.72209041
Iteration 3433, loss = 0.76748273
Iteration 3434, loss = 0.72459110
Iteration 3435, loss = 0.75060147
Iteration 3436, loss = 0.73252601
Iteration 3437, loss = 0.73148672
Iteration 3438, loss = 0.74019000
Iteration 3439, loss = 0.72126052
Iteration 3440, loss = 0.74070381
Iteration 3441, loss = 0.71779070
Iteration 3442, loss = 0.73323346
Iteration 3443, loss = 0.71987016
Iteration 3444, loss = 0.72490360
Iteration 3445, loss = 0.72389018
Iteration 3446, loss = 0.71808270
Iteration 3447, loss = 0.72449218
Iteration 3448, loss = 0.71407574
Iteration 3449, loss = 0.72220234
Iteration 3450, loss = 0.71386838
Iteration 3451, loss = 0.71849538
Iteration 3452, loss = 0.71476786
Iteration 3453, loss = 0.71421274
Iteration 3454, loss = 0.71510763
Iteration 3455, loss = 0.71134864
Iteration 3456, loss = 0.71460364
Iteration 3457, loss = 0.71009165
Iteration 3458, loss = 0.71281719
Iteration 3459, loss = 0.70959961
Iteration 3460, loss = 0.71051387
Iteration 3461, loss = 0.70954970
Iteration 3462, loss = 0.70863736
Iteration 3463, loss = 0.70926962
Iteration 3464, loss = 0.70723678
Iteration 3465, loss = 0.70836649
Iteration 3466, loss = 0.70638689
Iteration 3467, loss = 0.70719683
Iteration 3468, loss = 0.70598750
Iteration 3469, loss = 0.70599223
Iteration 3470, loss = 0.70560197
Iteration 3471, loss = 0.70488270
Iteration 3472, loss = 0.70505897
Iteration 3473, loss = 0.70406286
Iteration 3474, loss = 0.70439484
Iteration 3475, loss = 0.70350340
Iteration 3476, loss = 0.70362894
Iteration 3477, loss = 0.70305169
Iteration 3478, loss = 0.70285837
Iteration 3479, loss = 0.70262106
Iteration 3480, loss = 0.70218643
Iteration 3481, loss = 0.70215757
Iteration 3482, loss = 0.70163853
Iteration 3483, loss = 0.70164993
Iteration 3484, loss = 0.70119275
Iteration 3485, loss = 0.70112284
Iteration 3486, loss = 0.70080024
Iteration 3487, loss = 0.70061234
Iteration 3488, loss = 0.70042554
Iteration 3489, loss = 0.70015534
Iteration 3490, loss = 0.70005289
Iteration 3491, loss = 0.69975870
Iteration 3492, loss = 0.69967307
Iteration 3493, loss = 0.69940691
Iteration 3494, loss = 0.69929457
Iteration 3495, loss = 0.69908655
Iteration 3496, loss = 0.69893639
Iteration 3497, loss = 0.69878607
Iteration 3498, loss = 0.69860799
Iteration 3499, loss = 0.69849328
Iteration 3500, loss = 0.69830794
Iteration 3501, loss = 0.69820538
Iteration 3502, loss = 0.69803484
Iteration 3503, loss = 0.69792865
Iteration 3504, loss = 0.69778339
Iteration 3505, loss = 0.69766588
Iteration 3506, loss = 0.69754509
Iteration 3507, loss = 0.69741971
Iteration 3508, loss = 0.69731772
Iteration 3509, loss = 0.69719270
Iteration 3510, loss = 0.69710004
Iteration 3511, loss = 0.69698182
Iteration 3512, loss = 0.69689111
Iteration 3513, loss = 0.69678468
Iteration 3514, loss = 0.69669379
Iteration 3515, loss = 0.69660037
Iteration 3516, loss = 0.69650929
Iteration 3517, loss = 0.69642557
Iteration 3518, loss = 0.69633516
Iteration 3519, loss = 0.69625673
Iteration 3520, loss = 0.69616978
Iteration 3521, loss = 0.69609571
Iteration 3522, loss = 0.69601643
Iteration 3523, loss = 0.69594574
Iteration 3524, loss = 0.69587292
Iteration 3525, loss = 0.69580287
Iteration 3526, loss = 0.69573513
Iteration 3527, loss = 0.69566762
Iteration 3528, loss = 0.69560567
Iteration 3529, loss = 0.69554180
Iteration 3530, loss = 0.69548303
Iteration 3531, loss = 0.69542216
Iteration 3532, loss = 0.69536596
Iteration 3533, loss = 0.69530956
Iteration 3534, loss = 0.69525608
Iteration 3535, loss = 0.69520335
Iteration 3536, loss = 0.69515170
Iteration 3537, loss = 0.69510224
Iteration 3538, loss = 0.69505327
Iteration 3539, loss = 0.69500695
Iteration 3540, loss = 0.69496046
Iteration 3541, loss = 0.69491632
Iteration 3542, loss = 0.69487238
Iteration 3543, loss = 0.69483054
Iteration 3544, loss = 0.69478937
Iteration 3545, loss = 0.69474948
Iteration 3546, loss = 0.69471057
Iteration 3547, loss = 0.69467253
Iteration 3548, loss = 0.69463590
Iteration 3549, loss = 0.69459989
Iteration 3550, loss = 0.69456522
Iteration 3551, loss = 0.69453102
Iteration 3552, loss = 0.69449810
Iteration 3553, loss = 0.69446579
Iteration 3554, loss = 0.69443456
Iteration 3555, loss = 0.69440401
Iteration 3556, loss = 0.69437429
Iteration 3557, loss = 0.69434537
Iteration 3558, loss = 0.69431716
Iteration 3559, loss = 0.69428981
Iteration 3560, loss = 0.69426303
Iteration 3561, loss = 0.69423707
Iteration 3562, loss = 0.69421165
Iteration 3563, loss = 0.69418702
Iteration 3564, loss = 0.69416295
Iteration 3565, loss = 0.69413955
Iteration 3566, loss = 0.69411671
Iteration 3567, loss = 0.69409447
Iteration 3568, loss = 0.69407281
Iteration 3569, loss = 0.69405169
Iteration 3570, loss = 0.69403115
Iteration 3571, loss = 0.69401108
Iteration 3572, loss = 0.69399156
Iteration 3573, loss = 0.69397249
Iteration 3574, loss = 0.69395395
Iteration 3575, loss = 0.69393585
Iteration 3576, loss = 0.69391823
Iteration 3577, loss = 0.69390103
Iteration 3578, loss = 0.69388427
Iteration 3579, loss = 0.69386794
Iteration 3580, loss = 0.69385201
Iteration 3581, loss = 0.69383648
Iteration 3582, loss = 0.69382133
Iteration 3583, loss = 0.69380656
Iteration 3584, loss = 0.69379215
Iteration 3585, loss = 0.69377811
Iteration 3586, loss = 0.69376440
Iteration 3587, loss = 0.69375104
Iteration 3588, loss = 0.69373800
Iteration 3589, loss = 0.69372528
Iteration 3590, loss = 0.69371287
Iteration 3591, loss = 0.69370077
Iteration 3592, loss = 0.69368896
Iteration 3593, loss = 0.69367743
Iteration 3594, loss = 0.69366619
Iteration 3595, loss = 0.69365521
Iteration 3596, loss = 0.69364451
Iteration 3597, loss = 0.69363405
Iteration 3598, loss = 0.69362386
Iteration 3599, loss = 0.69361390
Iteration 3600, loss = 0.69360418
Iteration 3601, loss = 0.69359469
Iteration 3602, loss = 0.69358543
Iteration 3603, loss = 0.69357639
Iteration 3604, loss = 0.69356756
Iteration 3605, loss = 0.69355894
Iteration 3606, loss = 0.69355052
Iteration 3607, loss = 0.69354230
Iteration 3608, loss = 0.69353427
Iteration 3609, loss = 0.69352643
Iteration 3610, loss = 0.69351877
Iteration 3611, loss = 0.69351129
Iteration 3612, loss = 0.69350398
Iteration 3613, loss = 0.69349684
Iteration 3614, loss = 0.69348986
Iteration 3615, loss = 0.69348304
Iteration 3616, loss = 0.69347637
Iteration 3617, loss = 0.69346986
Iteration 3618, loss = 0.69346348
Iteration 3619, loss = 0.69345725
Iteration 3620, loss = 0.69345114
Iteration 3621, loss = 0.69344516
Iteration 3622, loss = 0.69343930
Iteration 3623, loss = 0.69343355
Iteration 3624, loss = 0.69342789
Iteration 3625, loss = 0.69342229
Iteration 3626, loss = 0.69341670
Iteration 3627, loss = 0.69341098
Iteration 3628, loss = 0.69340465
Iteration 3629, loss = 0.69339400
Iteration 3630, loss = 0.69305567
Iteration 3631, loss = 0.69375101
Iteration 3632, loss = 0.69459698
Iteration 3633, loss = 0.69511012
Iteration 3634, loss = 0.69485841
Iteration 3635, loss = 0.69431574
Iteration 3636, loss = 0.69392601
Iteration 3637, loss = 0.69410423
Iteration 3638, loss = 0.69428558
Iteration 3639, loss = 0.69432802
Iteration 3640, loss = 0.69420823
Iteration 3641, loss = 0.69393758
Iteration 3642, loss = 0.69391952
Iteration 3643, loss = 0.69389817
Iteration 3644, loss = 0.69388540
Iteration 3645, loss = 0.69378683
Iteration 3646, loss = 0.69370522
Iteration 3647, loss = 0.69371145
Iteration 3648, loss = 0.69373160
Iteration 3649, loss = 0.69378682
Iteration 3650, loss = 0.69372904
Iteration 3651, loss = 0.69366280
Iteration 3652, loss = 0.69362343
Iteration 3653, loss = 0.69365009
Iteration 3654, loss = 0.69368645
Iteration 3655, loss = 0.69364904
Iteration 3656, loss = 0.69361636
Iteration 3657, loss = 0.69358937
Iteration 3658, loss = 0.69359834
Iteration 3659, loss = 0.69358783
Iteration 3660, loss = 0.69356038
Iteration 3661, loss = 0.69353809
Iteration 3662, loss = 0.69352423
Iteration 3663, loss = 0.69352645
Iteration 3664, loss = 0.69350495
Iteration 3665, loss = 0.69348130
Iteration 3666, loss = 0.69345883
Iteration 3667, loss = 0.69345088
Iteration 3668, loss = 0.69344551
Iteration 3669, loss = 0.69342666
Iteration 3670, loss = 0.69340521
Iteration 3671, loss = 0.69338566
Iteration 3672, loss = 0.69338157
Iteration 3673, loss = 0.69337192
Iteration 3674, loss = 0.69335521
Iteration 3675, loss = 0.69334020
Iteration 3676, loss = 0.69333258
Iteration 3677, loss = 0.69333023
Iteration 3678, loss = 0.69332211
Iteration 3679, loss = 0.69331405
Iteration 3680, loss = 0.69330410
Iteration 3681, loss = 0.69329530
Iteration 3682, loss = 0.69328705
Iteration 3683, loss = 0.69327631
Iteration 3684, loss = 0.69325812
Iteration 3685, loss = 0.69321745
Iteration 3686, loss = 0.69312189
Iteration 3687, loss = 0.69311585
Iteration 3688, loss = 0.69312352
Iteration 3689, loss = 0.69303909
Iteration 3690, loss = 0.69298305
Iteration 3691, loss = 0.69299820
Iteration 3692, loss = 0.69290419
Iteration 3693, loss = 0.69286038
Iteration 3694, loss = 0.69259922
Iteration 3695, loss = 0.69251793
Iteration 3696, loss = 0.69231260
Iteration 3697, loss = 0.69201105
Iteration 3698, loss = 0.69151576
Iteration 3699, loss = 0.68995239
Iteration 3700, loss = 0.63947583
Iteration 3701, loss = 0.72276369
Iteration 3702, loss = 0.73242108
Iteration 3703, loss = 0.73791574
Iteration 3704, loss = 0.72390816
Iteration 3705, loss = 0.72843100
Iteration 3706, loss = 0.70764445
Iteration 3707, loss = 0.80300652
Iteration 3708, loss = 0.77183281
Iteration 3709, loss = 0.80324842
Iteration 3710, loss = 0.76954932
Iteration 3711, loss = 0.78034860
Iteration 3712, loss = 0.81504134
Iteration 3713, loss = 0.77568509
Iteration 3714, loss = 0.80951102
Iteration 3715, loss = 0.79091934
Iteration 3716, loss = 0.78226923
Iteration 3717, loss = 0.79207863
Iteration 3718, loss = 0.78708100
Iteration 3719, loss = 0.77887095
Iteration 3720, loss = 0.78771884
Iteration 3721, loss = 0.79618295
Iteration 3722, loss = 0.78520241
Iteration 3723, loss = 0.78408499
Iteration 3724, loss = 0.77175151
Iteration 3725, loss = 0.77930757
Iteration 3726, loss = 0.77615008
Iteration 3727, loss = 0.78448936
Iteration 3728, loss = 0.77940031
Iteration 3729, loss = 0.78079819
Iteration 3730, loss = 0.77580576
Iteration 3731, loss = 0.77672055
Iteration 3732, loss = 0.77606022
Iteration 3733, loss = 0.77617876
Iteration 3734, loss = 0.77605697
Iteration 3735, loss = 0.77373590
Iteration 3736, loss = 0.77386728
Iteration 3737, loss = 0.77145419
Iteration 3738, loss = 0.77259977
Iteration 3739, loss = 0.77050873
Iteration 3740, loss = 0.77132496
Iteration 3741, loss = 0.76895049
Iteration 3742, loss = 0.76891393
Iteration 3743, loss = 0.76674938
Iteration 3744, loss = 0.76644329
Iteration 3745, loss = 0.76513538
Iteration 3746, loss = 0.76482041
Iteration 3747, loss = 0.76398575
Iteration 3748, loss = 0.76305903
Iteration 3749, loss = 0.76203153
Iteration 3750, loss = 0.76061295
Iteration 3751, loss = 0.75983538
Iteration 3752, loss = 0.75867788
Iteration 3753, loss = 0.75828161
Iteration 3754, loss = 0.75717269
Iteration 3755, loss = 0.75656331
Iteration 3756, loss = 0.75524527
Iteration 3757, loss = 0.75446516
Iteration 3758, loss = 0.75331866
Iteration 3759, loss = 0.75265399
Iteration 3760, loss = 0.75172531
Iteration 3761, loss = 0.75097853
Iteration 3762, loss = 0.75002888
Iteration 3763, loss = 0.74913708
Iteration 3764, loss = 0.74824371
Iteration 3765, loss = 0.74736861
Iteration 3766, loss = 0.74657942
Iteration 3767, loss = 0.74570692
Iteration 3768, loss = 0.74492729
Iteration 3769, loss = 0.74402521
Iteration 3770, loss = 0.74324686
Iteration 3771, loss = 0.74236784
Iteration 3772, loss = 0.74161580
Iteration 3773, loss = 0.74077221
Iteration 3774, loss = 0.74001972
Iteration 3775, loss = 0.73918869
Iteration 3776, loss = 0.73841930
Iteration 3777, loss = 0.73760231
Iteration 3778, loss = 0.73683056
Iteration 3779, loss = 0.73604675
Iteration 3780, loss = 0.73529325
Iteration 3781, loss = 0.73453892
Iteration 3782, loss = 0.73376639
Iteration 3783, loss = 0.73294715
Iteration 3784, loss = 0.73203836
Iteration 3785, loss = 0.73114070
Iteration 3786, loss = 0.73013451
Iteration 3787, loss = 0.72875358
Iteration 3788, loss = 0.72708732
Iteration 3789, loss = 0.72542340
Iteration 3790, loss = 0.72325943
Iteration 3791, loss = 0.72136494
Iteration 3792, loss = 0.71593118
Iteration 3793, loss = 0.79489257
Iteration 3794, loss = 0.76990091
Iteration 3795, loss = 0.94016843
Iteration 3796, loss = 0.82315301
Iteration 3797, loss = 0.96050891
Iteration 3798, loss = 0.73812078
Iteration 3799, loss = 0.91228603
Iteration 3800, loss = 0.75991073
Iteration 3801, loss = 0.85996800
Iteration 3802, loss = 0.81687098
Iteration 3803, loss = 0.79696380
Iteration 3804, loss = 0.83869142
Iteration 3805, loss = 0.74904589
Iteration 3806, loss = 0.83023363
Iteration 3807, loss = 0.73987072
Iteration 3808, loss = 0.80816557
Iteration 3809, loss = 0.75652315
Iteration 3810, loss = 0.77918013
Iteration 3811, loss = 0.77143296
Iteration 3812, loss = 0.75368587
Iteration 3813, loss = 0.77805988
Iteration 3814, loss = 0.73842237
Iteration 3815, loss = 0.77231113
Iteration 3816, loss = 0.73791233
Iteration 3817, loss = 0.76309536
Iteration 3818, loss = 0.74196212
Iteration 3819, loss = 0.74986828
Iteration 3820, loss = 0.74730993
Iteration 3821, loss = 0.73966039
Iteration 3822, loss = 0.74832320
Iteration 3823, loss = 0.73305134
Iteration 3824, loss = 0.74659120
Iteration 3825, loss = 0.73182876
Iteration 3826, loss = 0.74194856
Iteration 3827, loss = 0.73267571
Iteration 3828, loss = 0.73642566
Iteration 3829, loss = 0.73342966
Iteration 3830, loss = 0.73117893
Iteration 3831, loss = 0.73338195
Iteration 3832, loss = 0.72812406
Iteration 3833, loss = 0.73261751
Iteration 3834, loss = 0.72644082
Iteration 3835, loss = 0.73023692
Iteration 3836, loss = 0.72568134
Iteration 3837, loss = 0.72751833
Iteration 3838, loss = 0.72532495
Iteration 3839, loss = 0.72502528
Iteration 3840, loss = 0.72498719
Iteration 3841, loss = 0.72312698
Iteration 3842, loss = 0.72412371
Iteration 3843, loss = 0.72158296
Iteration 3844, loss = 0.72280234
Iteration 3845, loss = 0.72062963
Iteration 3846, loss = 0.72140736
Iteration 3847, loss = 0.71996814
Iteration 3848, loss = 0.71994635
Iteration 3849, loss = 0.71927639
Iteration 3850, loss = 0.71859180
Iteration 3851, loss = 0.71851877
Iteration 3852, loss = 0.71747897
Iteration 3853, loss = 0.71765313
Iteration 3854, loss = 0.71656564
Iteration 3855, loss = 0.71670515
Iteration 3856, loss = 0.71580300
Iteration 3857, loss = 0.71572909
Iteration 3858, loss = 0.71509680
Iteration 3859, loss = 0.71477628
Iteration 3860, loss = 0.71440346
Iteration 3861, loss = 0.71390883
Iteration 3862, loss = 0.71370680
Iteration 3863, loss = 0.71313400
Iteration 3864, loss = 0.71298735
Iteration 3865, loss = 0.71242690
Iteration 3866, loss = 0.71225340
Iteration 3867, loss = 0.71177081
Iteration 3868, loss = 0.71153352
Iteration 3869, loss = 0.71115192
Iteration 3870, loss = 0.71084901
Iteration 3871, loss = 0.71055301
Iteration 3872, loss = 0.71020277
Iteration 3873, loss = 0.70995778
Iteration 3874, loss = 0.70959164
Iteration 3875, loss = 0.70936858
Iteration 3876, loss = 0.70901940
Iteration 3877, loss = 0.70879622
Iteration 3878, loss = 0.70847914
Iteration 3879, loss = 0.70824006
Iteration 3880, loss = 0.70795742
Iteration 3881, loss = 0.70770251
Iteration 3882, loss = 0.70745226
Iteration 3883, loss = 0.70719016
Iteration 3884, loss = 0.70696306
Iteration 3885, loss = 0.70670194
Iteration 3886, loss = 0.70648709
Iteration 3887, loss = 0.70623484
Iteration 3888, loss = 0.70602486
Iteration 3889, loss = 0.70578670
Iteration 3890, loss = 0.70557778
Iteration 3891, loss = 0.70535561
Iteration 3892, loss = 0.70514737
Iteration 3893, loss = 0.70494006
Iteration 3894, loss = 0.70473360
Iteration 3895, loss = 0.70453788
Iteration 3896, loss = 0.70433541
Iteration 3897, loss = 0.70414858
Iteration 3898, loss = 0.70395286
Iteration 3899, loss = 0.70377263
Iteration 3900, loss = 0.70358498
Iteration 3901, loss = 0.70340944
Iteration 3902, loss = 0.70323026
Iteration 3903, loss = 0.70305889
Iteration 3904, loss = 0.70288812
Iteration 3905, loss = 0.70272108
Iteration 3906, loss = 0.70255790
Iteration 3907, loss = 0.70239553
Iteration 3908, loss = 0.70223893
Iteration 3909, loss = 0.70208178
Iteration 3910, loss = 0.70193092
Iteration 3911, loss = 0.70177937
Iteration 3912, loss = 0.70163353
Iteration 3913, loss = 0.70148770
Iteration 3914, loss = 0.70134648
Iteration 3915, loss = 0.70120633
Iteration 3916, loss = 0.70106952
Iteration 3917, loss = 0.70093476
Iteration 3918, loss = 0.70080228
Iteration 3919, loss = 0.70067256
Iteration 3920, loss = 0.70054445
Iteration 3921, loss = 0.70041944
Iteration 3922, loss = 0.70029571
Iteration 3923, loss = 0.70017506
Iteration 3924, loss = 0.70005565
Iteration 3925, loss = 0.69993910
Iteration 3926, loss = 0.69982394
Iteration 3927, loss = 0.69971131
Iteration 3928, loss = 0.69960029
Iteration 3929, loss = 0.69949142
Iteration 3930, loss = 0.69938435
Iteration 3931, loss = 0.69927913
Iteration 3932, loss = 0.69917584
Iteration 3933, loss = 0.69907418
Iteration 3934, loss = 0.69897450
Iteration 3935, loss = 0.69887632
Iteration 3936, loss = 0.69878007
Iteration 3937, loss = 0.69868526
Iteration 3938, loss = 0.69859230
Iteration 3939, loss = 0.69850077
Iteration 3940, loss = 0.69841097
Iteration 3941, loss = 0.69832261
Iteration 3942, loss = 0.69823584
Iteration 3943, loss = 0.69815053
Iteration 3944, loss = 0.69806671
Iteration 3945, loss = 0.69798434
Iteration 3946, loss = 0.69790335
Iteration 3947, loss = 0.69782380
Iteration 3948, loss = 0.69774556
Iteration 3949, loss = 0.69766872
Iteration 3950, loss = 0.69759314
Iteration 3951, loss = 0.69751891
Iteration 3952, loss = 0.69744591
Iteration 3953, loss = 0.69737419
Iteration 3954, loss = 0.69730366
Iteration 3955, loss = 0.69723437
Iteration 3956, loss = 0.69716623
Iteration 3957, loss = 0.69709928
Iteration 3958, loss = 0.69703345
Iteration 3959, loss = 0.69696875
Iteration 3960, loss = 0.69690514
Iteration 3961, loss = 0.69684261
Iteration 3962, loss = 0.69678115
Iteration 3963, loss = 0.69672071
Iteration 3964, loss = 0.69666129
Iteration 3965, loss = 0.69660285
Iteration 3966, loss = 0.69654537
Iteration 3967, loss = 0.69648877
Iteration 3968, loss = 0.69643289
Iteration 3969, loss = 0.69637708
Iteration 3970, loss = 0.69631463
Iteration 3971, loss = 0.69551359
Iteration 3972, loss = 0.69364696
Iteration 3973, loss = 0.70128732
Iteration 3974, loss = 0.70171954
Iteration 3975, loss = 0.70322611
Iteration 3976, loss = 0.69886391
Iteration 3977, loss = 0.69200126
Iteration 3978, loss = 0.70778051
Iteration 3979, loss = 0.69266301
Iteration 3980, loss = 0.71021477
Iteration 3981, loss = 0.69433723
Iteration 3982, loss = 0.70385034
Iteration 3983, loss = 0.69960692
Iteration 3984, loss = 0.69622685
Iteration 3985, loss = 0.70116749
Iteration 3986, loss = 0.69116307
Iteration 3987, loss = 0.69724713
Iteration 3988, loss = 0.68754256
Iteration 3989, loss = 0.68662771
Iteration 3990, loss = 0.64304738
Iteration 3991, loss = 0.79805230
Iteration 3992, loss = 0.86342025
Iteration 3993, loss = 0.87287798
Iteration 3994, loss = 0.76208037
Iteration 3995, loss = 0.86801792
Iteration 3996, loss = 0.71607974
Iteration 3997, loss = 0.80813752
Iteration 3998, loss = 0.74630904
Iteration 3999, loss = 0.81975973
Iteration 4000, loss = 0.84568251
Iteration 4001, loss = 0.84760352
Iteration 4002, loss = 0.85317797
Iteration 4003, loss = 0.81070510
Iteration 4004, loss = 0.81152767
Iteration 4005, loss = 0.79076382
Iteration 4006, loss = 0.79256153
Iteration 4007, loss = 0.80363200
Iteration 4008, loss = 0.79946281
Iteration 4009, loss = 0.81695312
Iteration 4010, loss = 0.81083983
Iteration 4011, loss = 0.81711869
Iteration 4012, loss = 0.81643017
Iteration 4013, loss = 0.81135997
Iteration 4014, loss = 0.81667540
Iteration 4015, loss = 0.81051655
Iteration 4016, loss = 0.81625741
Iteration 4017, loss = 0.81508278
Iteration 4018, loss = 0.81526348
Iteration 4019, loss = 0.81716438
Iteration 4020, loss = 0.81263551
Iteration 4021, loss = 0.81467627
Iteration 4022, loss = 0.81127414
Iteration 4023, loss = 0.81197167
Iteration 4024, loss = 0.81238873
Iteration 4025, loss = 0.81142388
Iteration 4026, loss = 0.81348820
Iteration 4027, loss = 0.81150180
Iteration 4028, loss = 0.81200433
Iteration 4029, loss = 0.81022716
Iteration 4030, loss = 0.80860361
Iteration 4031, loss = 0.80794220
Iteration 4032, loss = 0.80581687
Iteration 4033, loss = 0.80590590
Iteration 4034, loss = 0.80457208
Iteration 4035, loss = 0.80425567
Iteration 4036, loss = 0.80360685
Iteration 4037, loss = 0.80429697
Iteration 4038, loss = 0.80638612
Iteration 4039, loss = 0.81306619
Iteration 4040, loss = 0.81338055
Iteration 4041, loss = 0.80768901
Iteration 4042, loss = 0.80118907
Iteration 4043, loss = 0.79941582
Iteration 4044, loss = 0.80031322
Iteration 4045, loss = 0.80067132
Iteration 4046, loss = 0.79902485
Iteration 4047, loss = 0.79632565
Iteration 4048, loss = 0.79474732
Iteration 4049, loss = 0.79388242
Iteration 4050, loss = 0.79333723
Iteration 4051, loss = 0.79208896
Iteration 4052, loss = 0.79045576
Iteration 4053, loss = 0.78903146
Iteration 4054, loss = 0.78788211
Iteration 4055, loss = 0.78732629
Iteration 4056, loss = 0.78661120
Iteration 4057, loss = 0.78557925
Iteration 4058, loss = 0.78415748
Iteration 4059, loss = 0.78274032
Iteration 4060, loss = 0.78187691
Iteration 4061, loss = 0.78130276
Iteration 4062, loss = 0.78076864
Iteration 4063, loss = 0.77983046
Iteration 4064, loss = 0.77866012
Iteration 4065, loss = 0.77757249
Iteration 4066, loss = 0.77667540
Iteration 4067, loss = 0.77599383
Iteration 4068, loss = 0.77527048
Iteration 4069, loss = 0.77450379
Iteration 4070, loss = 0.77365332
Iteration 4071, loss = 0.77278043
Iteration 4072, loss = 0.77195915
Iteration 4073, loss = 0.77117396
Iteration 4074, loss = 0.77047463
Iteration 4075, loss = 0.76977752
Iteration 4076, loss = 0.76905320
Iteration 4077, loss = 0.76827915
Iteration 4078, loss = 0.76750194
Iteration 4079, loss = 0.76679428
Iteration 4080, loss = 0.76612934
Iteration 4081, loss = 0.76548314
Iteration 4082, loss = 0.76479407
Iteration 4083, loss = 0.76408251
Iteration 4084, loss = 0.76339236
Iteration 4085, loss = 0.76274146
Iteration 4086, loss = 0.76212271
Iteration 4087, loss = 0.76148933
Iteration 4088, loss = 0.76084399
Iteration 4089, loss = 0.76019732
Iteration 4090, loss = 0.75957061
Iteration 4091, loss = 0.75896307
Iteration 4092, loss = 0.75835513
Iteration 4093, loss = 0.75774544
Iteration 4094, loss = 0.75713185
Iteration 4095, loss = 0.75652670
Iteration 4096, loss = 0.75592611
Iteration 4097, loss = 0.75525303
Iteration 4098, loss = 0.75447680
Iteration 4099, loss = 0.75377084
Iteration 4100, loss = 0.75303710
Iteration 4101, loss = 0.75219896
Iteration 4102, loss = 0.75132707
Iteration 4103, loss = 0.75029923
Iteration 4104, loss = 0.74929437
Iteration 4105, loss = 0.74800998
Iteration 4106, loss = 0.74632964
Iteration 4107, loss = 0.74435218
Iteration 4108, loss = 0.74079666
Iteration 4109, loss = 0.71720662
Iteration 4110, loss = 0.76554681
Iteration 4111, loss = 0.72159344
Iteration 4112, loss = 0.88164860
Iteration 4113, loss = 0.78904280
Iteration 4114, loss = 0.84586230
Iteration 4115, loss = 0.82372653
Iteration 4116, loss = 0.79472467
Iteration 4117, loss = 0.84544564
Iteration 4118, loss = 0.79029378
Iteration 4119, loss = 0.84435707
Iteration 4120, loss = 0.81698026
Iteration 4121, loss = 0.82435736
Iteration 4122, loss = 0.84068572
Iteration 4123, loss = 0.81392741
Iteration 4124, loss = 0.84659083
Iteration 4125, loss = 0.82008691
Iteration 4126, loss = 0.83665658
Iteration 4127, loss = 0.83407328
Iteration 4128, loss = 0.82718319
Iteration 4129, loss = 0.84290015
Iteration 4130, loss = 0.82682213
Iteration 4131, loss = 0.84162781
Iteration 4132, loss = 0.83224987
Iteration 4133, loss = 0.83398065
Iteration 4134, loss = 0.83651812
Iteration 4135, loss = 0.82849868
Iteration 4136, loss = 0.83704469
Iteration 4137, loss = 0.82884170
Iteration 4138, loss = 0.83372535
Iteration 4139, loss = 0.83083737
Iteration 4140, loss = 0.82847117
Iteration 4141, loss = 0.83071336
Iteration 4142, loss = 0.82499389
Iteration 4143, loss = 0.82829102
Iteration 4144, loss = 0.82404454
Iteration 4145, loss = 0.82445967
Iteration 4146, loss = 0.82343321
Iteration 4147, loss = 0.82065973
Iteration 4148, loss = 0.82164020
Iteration 4149, loss = 0.81800785
Iteration 4150, loss = 0.81858936
Iteration 4151, loss = 0.81616848
Iteration 4152, loss = 0.81505237
Iteration 4153, loss = 0.81431348
Iteration 4154, loss = 0.81198374
Iteration 4155, loss = 0.81192683
Iteration 4156, loss = 0.80954117
Iteration 4157, loss = 0.80896574
Iteration 4158, loss = 0.80736964
Iteration 4159, loss = 0.80596328
Iteration 4160, loss = 0.80515658
Iteration 4161, loss = 0.80330956
Iteration 4162, loss = 0.80266545
Iteration 4163, loss = 0.80095708
Iteration 4164, loss = 0.79999265
Iteration 4165, loss = 0.79875657
Iteration 4166, loss = 0.79742302
Iteration 4167, loss = 0.79652953
Iteration 4168, loss = 0.79505640
Iteration 4169, loss = 0.79418494
Iteration 4170, loss = 0.79286020
Iteration 4171, loss = 0.79182603
Iteration 4172, loss = 0.79075481
Iteration 4173, loss = 0.78956420
Iteration 4174, loss = 0.78864429
Iteration 4175, loss = 0.78743603
Iteration 4176, loss = 0.78652303
Iteration 4177, loss = 0.78542560
Iteration 4178, loss = 0.78443688
Iteration 4179, loss = 0.78346942
Iteration 4180, loss = 0.78242320
Iteration 4181, loss = 0.78153172
Iteration 4182, loss = 0.78050521
Iteration 4183, loss = 0.77962181
Iteration 4184, loss = 0.77866781
Iteration 4185, loss = 0.77775883
Iteration 4186, loss = 0.77687995
Iteration 4187, loss = 0.77595955
Iteration 4188, loss = 0.77512189
Iteration 4189, loss = 0.77422194
Iteration 4190, loss = 0.77339365
Iteration 4191, loss = 0.77254444
Iteration 4192, loss = 0.77171955
Iteration 4193, loss = 0.77091773
Iteration 4194, loss = 0.77009590
Iteration 4195, loss = 0.76931984
Iteration 4196, loss = 0.76852102
Iteration 4197, loss = 0.76776147
Iteration 4198, loss = 0.76699632
Iteration 4199, loss = 0.76624436
Iteration 4200, loss = 0.76551004
Iteration 4201, loss = 0.76477196
Iteration 4202, loss = 0.76406098
Iteration 4203, loss = 0.76334230
Iteration 4204, loss = 0.76264584
Iteration 4205, loss = 0.76195115
Iteration 4206, loss = 0.76126588
Iteration 4207, loss = 0.76059152
Iteration 4208, loss = 0.75991866
Iteration 4209, loss = 0.75926395
Iteration 4210, loss = 0.75861078
Iteration 4211, loss = 0.75797211
Iteration 4212, loss = 0.75733705
Iteration 4213, loss = 0.75670980
Iteration 4214, loss = 0.75609143
Iteration 4215, loss = 0.75547790
Iteration 4216, loss = 0.75487662
Iteration 4217, loss = 0.75427900
Iteration 4218, loss = 0.75369099
Iteration 4219, loss = 0.75310741
Iteration 4220, loss = 0.75253138
Iteration 4221, loss = 0.75196329
Iteration 4222, loss = 0.75140065
Iteration 4223, loss = 0.75084602
Iteration 4224, loss = 0.75029564
Iteration 4225, loss = 0.74975324
Iteration 4226, loss = 0.74921628
Iteration 4227, loss = 0.74868582
Iteration 4228, loss = 0.74816132
Iteration 4229, loss = 0.74764207
Iteration 4230, loss = 0.74712951
Iteration 4231, loss = 0.74662183
Iteration 4232, loss = 0.74612047
Iteration 4233, loss = 0.74562403
Iteration 4234, loss = 0.74513335
Iteration 4235, loss = 0.74464803
Iteration 4236, loss = 0.74416774
Iteration 4237, loss = 0.74369288
Iteration 4238, loss = 0.74322261
Iteration 4239, loss = 0.74275740
Iteration 4240, loss = 0.74229154
Iteration 4241, loss = 0.74173117
Iteration 4242, loss = 0.74216208
Iteration 4243, loss = 0.74177561
Iteration 4244, loss = 0.74070239
Iteration 4245, loss = 0.74030666
Iteration 4246, loss = 0.74027966
Iteration 4247, loss = 0.73955415
Iteration 4248, loss = 0.73917608
Iteration 4249, loss = 0.73883205
Iteration 4250, loss = 0.73825996
Iteration 4251, loss = 0.73785399
Iteration 4252, loss = 0.73749581
Iteration 4253, loss = 0.73699624
Iteration 4254, loss = 0.73658985
Iteration 4255, loss = 0.73621879
Iteration 4256, loss = 0.73579566
Iteration 4257, loss = 0.73514795
Iteration 4258, loss = 0.73552339
Iteration 4259, loss = 0.73580807
Iteration 4260, loss = 0.73570835
Iteration 4261, loss = 0.73501935
Iteration 4262, loss = 0.73410127
Iteration 4263, loss = 0.73335907
Iteration 4264, loss = 0.73294967
Iteration 4265, loss = 0.73283299
Iteration 4266, loss = 0.73263379
Iteration 4267, loss = 0.73229397
Iteration 4268, loss = 0.73179421
Iteration 4269, loss = 0.73131854
Iteration 4270, loss = 0.73092884
Iteration 4271, loss = 0.73058673
Iteration 4272, loss = 0.73025474
Iteration 4273, loss = 0.72989953
Iteration 4274, loss = 0.72958970
Iteration 4275, loss = 0.72925533
Iteration 4276, loss = 0.72891504
Iteration 4277, loss = 0.72856515
Iteration 4278, loss = 0.72821317
Iteration 4279, loss = 0.72787128
Iteration 4280, loss = 0.72755553
Iteration 4281, loss = 0.72727246
Iteration 4282, loss = 0.72696610
Iteration 4283, loss = 0.72664688
Iteration 4284, loss = 0.72632283
Iteration 4285, loss = 0.72601363
Iteration 4286, loss = 0.72571050
Iteration 4287, loss = 0.72541891
Iteration 4288, loss = 0.72513522
Iteration 4289, loss = 0.72483663
Iteration 4290, loss = 0.72453934
Iteration 4291, loss = 0.72425054
Iteration 4292, loss = 0.72397492
Iteration 4293, loss = 0.72369684
Iteration 4294, loss = 0.72341910
Iteration 4295, loss = 0.72314288
Iteration 4296, loss = 0.72286514
Iteration 4297, loss = 0.72259433
Iteration 4298, loss = 0.72233035
Iteration 4299, loss = 0.72207178
Iteration 4300, loss = 0.72181020
Iteration 4301, loss = 0.72154884
Iteration 4302, loss = 0.72129013
Iteration 4303, loss = 0.72103489
Iteration 4304, loss = 0.72078398
Iteration 4305, loss = 0.72053683
Iteration 4306, loss = 0.72029210
Iteration 4307, loss = 0.72004677
Iteration 4308, loss = 0.71980364
Iteration 4309, loss = 0.71956328
Iteration 4310, loss = 0.71932615
Iteration 4311, loss = 0.71909138
Iteration 4312, loss = 0.71885900
Iteration 4313, loss = 0.71862855
Iteration 4314, loss = 0.71839961
Iteration 4315, loss = 0.71817322
Iteration 4316, loss = 0.71794887
Iteration 4317, loss = 0.71772691
Iteration 4318, loss = 0.71750688
Iteration 4319, loss = 0.71728901
Iteration 4320, loss = 0.71707304
Iteration 4321, loss = 0.71685906
Iteration 4322, loss = 0.71664726
Iteration 4323, loss = 0.71643724
Iteration 4324, loss = 0.71622919
Iteration 4325, loss = 0.71602308
Iteration 4326, loss = 0.71581905
Iteration 4327, loss = 0.71561672
Iteration 4328, loss = 0.71541628
Iteration 4329, loss = 0.71521772
Iteration 4330, loss = 0.71502093
Iteration 4331, loss = 0.71482598
Iteration 4332, loss = 0.71463287
Iteration 4333, loss = 0.71444158
Iteration 4334, loss = 0.71425193
Iteration 4335, loss = 0.71406405
Iteration 4336, loss = 0.71387786
Iteration 4337, loss = 0.71369341
Iteration 4338, loss = 0.71351072
Iteration 4339, loss = 0.71332978
Iteration 4340, loss = 0.71315056
Iteration 4341, loss = 0.71297307
Iteration 4342, loss = 0.71279738
Iteration 4343, loss = 0.71262342
Iteration 4344, loss = 0.71245098
Iteration 4345, loss = 0.71227960
Iteration 4346, loss = 0.71210892
Iteration 4347, loss = 0.71193929
Iteration 4348, loss = 0.71177166
Iteration 4349, loss = 0.71160652
Iteration 4350, loss = 0.71144338
Iteration 4351, loss = 0.71128136
Iteration 4352, loss = 0.71112004
Iteration 4353, loss = 0.71095991
Iteration 4354, loss = 0.71080170
Iteration 4355, loss = 0.71064549
Iteration 4356, loss = 0.71049067
Iteration 4357, loss = 0.71033679
Iteration 4358, loss = 0.71018407
Iteration 4359, loss = 0.71003304
Iteration 4360, loss = 0.70988383
Iteration 4361, loss = 0.70973609
Iteration 4362, loss = 0.70958950
Iteration 4363, loss = 0.70944406
Iteration 4364, loss = 0.70929982
Iteration 4365, loss = 0.70915653
Iteration 4366, loss = 0.70901397
Iteration 4367, loss = 0.70887248
Iteration 4368, loss = 0.70873276
Iteration 4369, loss = 0.70859503
Iteration 4370, loss = 0.70845884
Iteration 4371, loss = 0.70832348
Iteration 4372, loss = 0.70818873
Iteration 4373, loss = 0.70805505
Iteration 4374, loss = 0.70792301
Iteration 4375, loss = 0.70779270
Iteration 4376, loss = 0.70766374
Iteration 4377, loss = 0.70753585
Iteration 4378, loss = 0.70740920
Iteration 4379, loss = 0.70728407
Iteration 4380, loss = 0.70716019
Iteration 4381, loss = 0.70703655
Iteration 4382, loss = 0.70691255
Iteration 4383, loss = 0.70678915
Iteration 4384, loss = 0.70666771
Iteration 4385, loss = 0.70654828
Iteration 4386, loss = 0.70642984
Iteration 4387, loss = 0.70631173
Iteration 4388, loss = 0.70619459
Iteration 4389, loss = 0.70607941
Iteration 4390, loss = 0.70596583
Iteration 4391, loss = 0.70585265
Iteration 4392, loss = 0.70573967
Iteration 4393, loss = 0.70562798
Iteration 4394, loss = 0.70551840
Iteration 4395, loss = 0.70541024
Iteration 4396, loss = 0.70530236
Iteration 4397, loss = 0.70519458
Iteration 4398, loss = 0.70508761
Iteration 4399, loss = 0.70498197
Iteration 4400, loss = 0.70487763
Iteration 4401, loss = 0.70477454
Iteration 4402, loss = 0.70467285
Iteration 4403, loss = 0.70457253
Iteration 4404, loss = 0.70447245
Iteration 4405, loss = 0.70437077
Iteration 4406, loss = 0.70426809
Iteration 4407, loss = 0.70416838
Iteration 4408, loss = 0.70407287
Iteration 4409, loss = 0.70397782
Iteration 4410, loss = 0.70388037
Iteration 4411, loss = 0.70378317
Iteration 4412, loss = 0.70368968
Iteration 4413, loss = 0.70359809
Iteration 4414, loss = 0.70350520
Iteration 4415, loss = 0.70341224
Iteration 4416, loss = 0.70332169
Iteration 4417, loss = 0.70323235
Iteration 4418, loss = 0.70314256
Iteration 4419, loss = 0.70305368
Iteration 4420, loss = 0.70296673
Iteration 4421, loss = 0.70288013
Iteration 4422, loss = 0.70279330
Iteration 4423, loss = 0.70270775
Iteration 4424, loss = 0.70262374
Iteration 4425, loss = 0.70254001
Iteration 4426, loss = 0.70245658
Iteration 4427, loss = 0.70237432
Iteration 4428, loss = 0.70229291
Iteration 4429, loss = 0.70221186
Iteration 4430, loss = 0.70213168
Iteration 4431, loss = 0.70205261
Iteration 4432, loss = 0.70197409
Iteration 4433, loss = 0.70189606
Iteration 4434, loss = 0.70181906
Iteration 4435, loss = 0.70174305
Iteration 4436, loss = 0.70166762
Iteration 4437, loss = 0.70159287
Iteration 4438, loss = 0.70151895
Iteration 4439, loss = 0.70144558
Iteration 4440, loss = 0.70137224
Iteration 4441, loss = 0.70129849
Iteration 4442, loss = 0.70122465
Iteration 4443, loss = 0.70115216
Iteration 4444, loss = 0.70108195
Iteration 4445, loss = 0.70101299
Iteration 4446, loss = 0.70094345
Iteration 4447, loss = 0.70087315
Iteration 4448, loss = 0.70080387
Iteration 4449, loss = 0.70073668
Iteration 4450, loss = 0.70067042
Iteration 4451, loss = 0.70060372
Iteration 4452, loss = 0.70053696
Iteration 4453, loss = 0.70047136
Iteration 4454, loss = 0.70040698
Iteration 4455, loss = 0.70034291
Iteration 4456, loss = 0.70027893
Iteration 4457, loss = 0.70021569
Iteration 4458, loss = 0.70015346
Iteration 4459, loss = 0.70009173
Iteration 4460, loss = 0.70003023
Iteration 4461, loss = 0.69996939
Iteration 4462, loss = 0.69990966
Iteration 4463, loss = 0.69985078
Iteration 4464, loss = 0.69979235
Iteration 4465, loss = 0.69973446
Iteration 4466, loss = 0.69967728
Iteration 4467, loss = 0.69962049
Iteration 4468, loss = 0.69956347
Iteration 4469, loss = 0.69950600
Iteration 4470, loss = 0.69944902
Iteration 4471, loss = 0.69939342
Iteration 4472, loss = 0.69933823
Iteration 4473, loss = 0.69928223
Iteration 4474, loss = 0.69922612
Iteration 4475, loss = 0.69917162
Iteration 4476, loss = 0.69911915
Iteration 4477, loss = 0.69906712
Iteration 4478, loss = 0.69901408
Iteration 4479, loss = 0.69896092
Iteration 4480, loss = 0.69890927
Iteration 4481, loss = 0.69885894
Iteration 4482, loss = 0.69880850
Iteration 4483, loss = 0.69875775
Iteration 4484, loss = 0.69870787
Iteration 4485, loss = 0.69865919
Iteration 4486, loss = 0.69861078
Iteration 4487, loss = 0.69856226
Iteration 4488, loss = 0.69851442
Iteration 4489, loss = 0.69846758
Iteration 4490, loss = 0.69842081
Iteration 4491, loss = 0.69837342
Iteration 4492, loss = 0.69832606
Iteration 4493, loss = 0.69827969
Iteration 4494, loss = 0.69823439
Iteration 4495, loss = 0.69818976
Iteration 4496, loss = 0.69814585
Iteration 4497, loss = 0.69810302
Iteration 4498, loss = 0.69806135
Iteration 4499, loss = 0.69802012
Iteration 4500, loss = 0.69797693
Iteration 4501, loss = 0.69793021
Iteration 4502, loss = 0.69788459
Iteration 4503, loss = 0.69784428
Iteration 4504, loss = 0.69780505
Iteration 4505, loss = 0.69776186
Iteration 4506, loss = 0.69771838
Iteration 4507, loss = 0.69767926
Iteration 4508, loss = 0.69764055
Iteration 4509, loss = 0.69759894
Iteration 4510, loss = 0.69755866
Iteration 4511, loss = 0.69752112
Iteration 4512, loss = 0.69748236
Iteration 4513, loss = 0.69744292
Iteration 4514, loss = 0.69740563
Iteration 4515, loss = 0.69736548
Iteration 4516, loss = 0.69714435
Iteration 4517, loss = 0.69749907
Iteration 4518, loss = 0.69778378
Iteration 4519, loss = 0.69798716
Iteration 4520, loss = 0.69798154
Iteration 4521, loss = 0.69780032
Iteration 4522, loss = 0.69770055
Iteration 4523, loss = 0.69747197
Iteration 4524, loss = 0.69746576
Iteration 4525, loss = 0.69729203
Iteration 4526, loss = 0.69727219
Iteration 4527, loss = 0.69690767
Iteration 4528, loss = 0.69642171
Iteration 4529, loss = 0.69457379
Iteration 4530, loss = 0.69933871
Iteration 4531, loss = 0.69954010
Iteration 4532, loss = 0.69930881
Iteration 4533, loss = 0.69846993
Iteration 4534, loss = 0.69712236
Iteration 4535, loss = 0.69590324
Iteration 4536, loss = 0.69216745
Iteration 4537, loss = 0.73076732
Iteration 4538, loss = 0.72494301
Iteration 4539, loss = 0.74573379
Iteration 4540, loss = 0.71378111
Iteration 4541, loss = 0.73566597
Iteration 4542, loss = 0.69956661
Iteration 4543, loss = 0.72927713
Iteration 4544, loss = 0.70209937
Iteration 4545, loss = 0.72643782
Iteration 4546, loss = 0.70028927
Iteration 4547, loss = 0.71583735
Iteration 4548, loss = 0.70157164
Iteration 4549, loss = 0.71038636
Iteration 4550, loss = 0.70357983
Iteration 4551, loss = 0.70367749
Iteration 4552, loss = 0.70257114
Iteration 4553, loss = 0.69837556
Iteration 4554, loss = 0.70192704
Iteration 4555, loss = 0.69490637
Iteration 4556, loss = 0.69762443
Iteration 4557, loss = 0.68742840
Iteration 4558, loss = 0.69134787
Iteration 4559, loss = 0.61738709
Iteration 4560, loss = 0.81482721
Iteration 4561, loss = 0.95213845
Iteration 4562, loss = 0.84511427
Iteration 4563, loss = 0.91869621
Iteration 4564, loss = 0.83484251
Iteration 4565, loss = 0.86108411
Iteration 4566, loss = 0.82330135
Iteration 4567, loss = 0.82057550
Iteration 4568, loss = 0.82606839
Iteration 4569, loss = 0.80155960
Iteration 4570, loss = 0.83030185
Iteration 4571, loss = 0.78584139
Iteration 4572, loss = 0.82322778
Iteration 4573, loss = 0.76860329
Iteration 4574, loss = 0.81032085
Iteration 4575, loss = 0.75693421
Iteration 4576, loss = 0.80178339
Iteration 4577, loss = 0.75470492
Iteration 4578, loss = 0.79775187
Iteration 4579, loss = 0.75621687
Iteration 4580, loss = 0.79205913
Iteration 4581, loss = 0.75501254
Iteration 4582, loss = 0.78422603
Iteration 4583, loss = 0.75310725
Iteration 4584, loss = 0.77712688
Iteration 4585, loss = 0.75334287
Iteration 4586, loss = 0.77283492
Iteration 4587, loss = 0.75451241
Iteration 4588, loss = 0.76861282
Iteration 4589, loss = 0.75402411
Iteration 4590, loss = 0.76356239
Iteration 4591, loss = 0.75264507
Iteration 4592, loss = 0.75917860
Iteration 4593, loss = 0.75160845
Iteration 4594, loss = 0.75586076
Iteration 4595, loss = 0.75072023
Iteration 4596, loss = 0.75297648
Iteration 4597, loss = 0.74940662
Iteration 4598, loss = 0.75002573
Iteration 4599, loss = 0.74757576
Iteration 4600, loss = 0.74715919
Iteration 4601, loss = 0.74570626
Iteration 4602, loss = 0.74477736
Iteration 4603, loss = 0.74407041
Iteration 4604, loss = 0.74276903
Iteration 4605, loss = 0.74241060
Iteration 4606, loss = 0.74077764
Iteration 4607, loss = 0.74055893
Iteration 4608, loss = 0.73877870
Iteration 4609, loss = 0.73869366
Iteration 4610, loss = 0.73695546
Iteration 4611, loss = 0.73696957
Iteration 4612, loss = 0.73531291
Iteration 4613, loss = 0.73532212
Iteration 4614, loss = 0.73373100
Iteration 4615, loss = 0.73367935
Iteration 4616, loss = 0.73217314
Iteration 4617, loss = 0.73206071
Iteration 4618, loss = 0.73067031
Iteration 4619, loss = 0.73051833
Iteration 4620, loss = 0.72925637
Iteration 4621, loss = 0.72905020
Iteration 4622, loss = 0.72788845
Iteration 4623, loss = 0.72763033
Iteration 4624, loss = 0.72657199
Iteration 4625, loss = 0.72626687
Iteration 4626, loss = 0.72529226
Iteration 4627, loss = 0.72494913
Iteration 4628, loss = 0.72406005
Iteration 4629, loss = 0.72369348
Iteration 4630, loss = 0.72288173
Iteration 4631, loss = 0.72249314
Iteration 4632, loss = 0.72173692
Iteration 4633, loss = 0.72132670
Iteration 4634, loss = 0.72063005
Iteration 4635, loss = 0.72021612
Iteration 4636, loss = 0.71957018
Iteration 4637, loss = 0.71915305
Iteration 4638, loss = 0.71855294
Iteration 4639, loss = 0.71813243
Iteration 4640, loss = 0.71756465
Iteration 4641, loss = 0.71714501
Iteration 4642, loss = 0.71661350
Iteration 4643, loss = 0.71620086
Iteration 4644, loss = 0.71570144
Iteration 4645, loss = 0.71529877
Iteration 4646, loss = 0.71482781
Iteration 4647, loss = 0.71443282
Iteration 4648, loss = 0.71398544
Iteration 4649, loss = 0.71360001
Iteration 4650, loss = 0.71317284
Iteration 4651, loss = 0.71279331
Iteration 4652, loss = 0.71238361
Iteration 4653, loss = 0.71201790
Iteration 4654, loss = 0.71163145
Iteration 4655, loss = 0.71127756
Iteration 4656, loss = 0.71090602
Iteration 4657, loss = 0.71056380
Iteration 4658, loss = 0.71021054
Iteration 4659, loss = 0.70987617
Iteration 4660, loss = 0.70938908
Iteration 4661, loss = 0.71020652
Iteration 4662, loss = 0.71007877
Iteration 4663, loss = 0.70889392
Iteration 4664, loss = 0.70873798
Iteration 4665, loss = 0.70863374
Iteration 4666, loss = 0.70853412
Iteration 4667, loss = 0.70765632
Iteration 4668, loss = 0.70726755
Iteration 4669, loss = 0.70745930
Iteration 4670, loss = 0.70669156
Iteration 4671, loss = 0.70645599
Iteration 4672, loss = 0.70628049
Iteration 4673, loss = 0.70590182
Iteration 4674, loss = 0.70548319
Iteration 4675, loss = 0.70533095
Iteration 4676, loss = 0.70495907
Iteration 4677, loss = 0.70465030
Iteration 4678, loss = 0.70449020
Iteration 4679, loss = 0.70423852
Iteration 4680, loss = 0.70391487
Iteration 4681, loss = 0.70369109
Iteration 4682, loss = 0.70350915
Iteration 4683, loss = 0.70328066
Iteration 4684, loss = 0.70301519
Iteration 4685, loss = 0.70280215
Iteration 4686, loss = 0.70264598
Iteration 4687, loss = 0.70243312
Iteration 4688, loss = 0.70220390
Iteration 4689, loss = 0.70203912
Iteration 4690, loss = 0.70187055
Iteration 4691, loss = 0.70167646
Iteration 4692, loss = 0.70150052
Iteration 4693, loss = 0.70133794
Iteration 4694, loss = 0.70117637
Iteration 4695, loss = 0.70100777
Iteration 4696, loss = 0.70084295
Iteration 4697, loss = 0.70069928
Iteration 4698, loss = 0.70054930
Iteration 4699, loss = 0.70038653
Iteration 4700, loss = 0.70024217
Iteration 4701, loss = 0.70010668
Iteration 4702, loss = 0.69996210
Iteration 4703, loss = 0.69982011
Iteration 4704, loss = 0.69968524
Iteration 4705, loss = 0.69955303
Iteration 4706, loss = 0.69942031
Iteration 4707, loss = 0.69928751
Iteration 4708, loss = 0.69916294
Iteration 4709, loss = 0.69904388
Iteration 4710, loss = 0.69892184
Iteration 4711, loss = 0.69880138
Iteration 4712, loss = 0.69868565
Iteration 4713, loss = 0.69857224
Iteration 4714, loss = 0.69846224
Iteration 4715, loss = 0.69835453
Iteration 4716, loss = 0.69824855
Iteration 4717, loss = 0.69814635
Iteration 4718, loss = 0.69804609
Iteration 4719, loss = 0.69794718
Iteration 4720, loss = 0.69785129
Iteration 4721, loss = 0.69775720
Iteration 4722, loss = 0.69766450
Iteration 4723, loss = 0.69757386
Iteration 4724, loss = 0.69748498
Iteration 4725, loss = 0.69739800
Iteration 4726, loss = 0.69731273
Iteration 4727, loss = 0.69722935
Iteration 4728, loss = 0.69714850
Iteration 4729, loss = 0.69706894
Iteration 4730, loss = 0.69698978
Iteration 4731, loss = 0.69691176
Iteration 4732, loss = 0.69683524
Iteration 4733, loss = 0.69676073
Iteration 4734, loss = 0.69668864
Iteration 4735, loss = 0.69661827
Iteration 4736, loss = 0.69654880
Iteration 4737, loss = 0.69648035
Iteration 4738, loss = 0.69641349
Iteration 4739, loss = 0.69634833
Iteration 4740, loss = 0.69628441
Iteration 4741, loss = 0.69622172
Iteration 4742, loss = 0.69616046
Iteration 4743, loss = 0.69610050
Iteration 4744, loss = 0.69604182
Iteration 4745, loss = 0.69598464
Iteration 4746, loss = 0.69592931
Iteration 4747, loss = 0.69587641
Iteration 4748, loss = 0.69582649
Iteration 4749, loss = 0.69577793
Iteration 4750, loss = 0.69572456
Iteration 4751, loss = 0.69566526
Iteration 4752, loss = 0.69561191
Iteration 4753, loss = 0.69556707
Iteration 4754, loss = 0.69551919
Iteration 4755, loss = 0.69546809
Iteration 4756, loss = 0.69542348
Iteration 4757, loss = 0.69537994
Iteration 4758, loss = 0.69533177
Iteration 4759, loss = 0.69528787
Iteration 4760, loss = 0.69524802
Iteration 4761, loss = 0.69520462
Iteration 4762, loss = 0.69516252
Iteration 4763, loss = 0.69512379
Iteration 4764, loss = 0.69508338
Iteration 4765, loss = 0.69504448
Iteration 4766, loss = 0.69500823
Iteration 4767, loss = 0.69497023
Iteration 4768, loss = 0.69493316
Iteration 4769, loss = 0.69489810
Iteration 4770, loss = 0.69485921
Iteration 4771, loss = 0.69461636
Iteration 4772, loss = 0.69636596
Iteration 4773, loss = 0.69693304
Iteration 4774, loss = 0.69565301
Iteration 4775, loss = 0.69456687
Iteration 4776, loss = 0.69668773
Iteration 4777, loss = 0.69868712
Iteration 4778, loss = 0.69734801
Iteration 4779, loss = 0.69798489
Iteration 4780, loss = 0.69643486
Iteration 4781, loss = 0.69656622
Iteration 4782, loss = 0.69622715
Iteration 4783, loss = 0.69674270
Iteration 4784, loss = 0.69703254
Iteration 4785, loss = 0.69633084
Iteration 4786, loss = 0.69674014
Iteration 4787, loss = 0.69620046
Iteration 4788, loss = 0.69630887
Iteration 4789, loss = 0.69617901
Iteration 4790, loss = 0.69608141
Iteration 4791, loss = 0.69590052
Iteration 4792, loss = 0.69539154
Iteration 4793, loss = 0.69551946
Iteration 4794, loss = 0.69523212
Iteration 4795, loss = 0.69509067
Iteration 4796, loss = 0.69473411
Iteration 4797, loss = 0.69439965
Iteration 4798, loss = 0.69424622
Iteration 4799, loss = 0.69402045
Iteration 4800, loss = 0.69410401
Iteration 4801, loss = 0.69398854
Iteration 4802, loss = 0.69391697
Iteration 4803, loss = 0.69373249
Iteration 4804, loss = 0.69349266
Iteration 4805, loss = 0.69338383
Iteration 4806, loss = 0.69323451
Iteration 4807, loss = 0.69321664
Iteration 4808, loss = 0.69312253
Iteration 4809, loss = 0.69305586
Iteration 4810, loss = 0.69294887
Iteration 4811, loss = 0.69276670
Iteration 4812, loss = 0.69264310
Iteration 4813, loss = 0.69249581
Iteration 4814, loss = 0.69240452
Iteration 4815, loss = 0.69226791
Iteration 4816, loss = 0.69213358
Iteration 4817, loss = 0.69202278
Iteration 4818, loss = 0.69189400
Iteration 4819, loss = 0.69180832
Iteration 4820, loss = 0.69171032
Iteration 4821, loss = 0.69162272
Iteration 4822, loss = 0.69145445
Iteration 4823, loss = 0.69119398
Iteration 4824, loss = 0.68965731
Iteration 4825, loss = 0.66056119
Iteration 4826, loss = 0.78602399
Iteration 4827, loss = 0.81470695
Iteration 4828, loss = 0.72390856
Iteration 4829, loss = 0.75298242
Iteration 4830, loss = 0.76936615
Iteration 4831, loss = 0.72113475
Iteration 4832, loss = 0.75765167
Iteration 4833, loss = 0.76436742
Iteration 4834, loss = 0.72373674
Iteration 4835, loss = 0.75010543
Iteration 4836, loss = 0.74192507
Iteration 4837, loss = 0.72943000
Iteration 4838, loss = 0.72285414
Iteration 4839, loss = 0.72009017
Iteration 4840, loss = 1.19825095
Iteration 4841, loss = 1.30404284
Iteration 4842, loss = 0.95049557
Iteration 4843, loss = 1.49232606
Iteration 4844, loss = 1.01483955
Iteration 4845, loss = 1.50756477
Iteration 4846, loss = 1.24620684
Iteration 4847, loss = 1.22189543
Iteration 4848, loss = 1.30478530
Iteration 4849, loss = 0.94060304
Iteration 4850, loss = 1.14313392
Iteration 4851, loss = 0.79879058
Iteration 4852, loss = 1.04744333
Iteration 4853, loss = 0.77496975
Iteration 4854, loss = 0.97952461
Iteration 4855, loss = 0.76086848
Iteration 4856, loss = 0.92601527
Iteration 4857, loss = 0.75288656
Iteration 4858, loss = 0.89025966
Iteration 4859, loss = 0.75241337
Iteration 4860, loss = 0.86360010
Iteration 4861, loss = 0.74827691
Iteration 4862, loss = 0.83827661
Iteration 4863, loss = 0.74571771
Iteration 4864, loss = 0.81993490
Iteration 4865, loss = 0.74420687
Iteration 4866, loss = 0.80378804
Iteration 4867, loss = 0.74159245
Iteration 4868, loss = 0.78878447
Iteration 4869, loss = 0.73843068
Iteration 4870, loss = 0.77643004
Iteration 4871, loss = 0.73687661
Iteration 4872, loss = 0.76679329
Iteration 4873, loss = 0.73518872
Iteration 4874, loss = 0.75753035
Iteration 4875, loss = 0.73286652
Iteration 4876, loss = 0.74963844
Iteration 4877, loss = 0.73125837
Iteration 4878, loss = 0.74347573
Iteration 4879, loss = 0.72986941
Iteration 4880, loss = 0.73796071
Iteration 4881, loss = 0.72811892
Iteration 4882, loss = 0.73315564
Iteration 4883, loss = 0.72657675
Iteration 4884, loss = 0.72934370
Iteration 4885, loss = 0.72516316
Iteration 4886, loss = 0.72598659
Iteration 4887, loss = 0.72352338
Iteration 4888, loss = 0.72308264
Iteration 4889, loss = 0.72206684
Iteration 4890, loss = 0.72080790
Iteration 4891, loss = 0.72067134
Iteration 4892, loss = 0.71875607
Iteration 4893, loss = 0.71913436
Iteration 4894, loss = 0.71692930
Iteration 4895, loss = 0.71770909
Iteration 4896, loss = 0.71545603
Iteration 4897, loss = 0.71636097
Iteration 4898, loss = 0.71409283
Iteration 4899, loss = 0.71499749
Iteration 4900, loss = 0.71289896
Iteration 4901, loss = 0.71367232
Iteration 4902, loss = 0.71185120
Iteration 4903, loss = 0.71252424
Iteration 4904, loss = 0.71094283
Iteration 4905, loss = 0.71147388
Iteration 4906, loss = 0.71009022
Iteration 4907, loss = 0.71042078
Iteration 4908, loss = 0.70927263
Iteration 4909, loss = 0.70943591
Iteration 4910, loss = 0.70853889
Iteration 4911, loss = 0.70855721
Iteration 4912, loss = 0.70785966
Iteration 4913, loss = 0.70775067
Iteration 4914, loss = 0.70719501
Iteration 4915, loss = 0.70699313
Iteration 4916, loss = 0.70655851
Iteration 4917, loss = 0.70628728
Iteration 4918, loss = 0.70595588
Iteration 4919, loss = 0.70561471
Iteration 4920, loss = 0.70532354
Iteration 4921, loss = 0.70473276
Iteration 4922, loss = 0.70395507
Iteration 4923, loss = 0.70320970
Iteration 4924, loss = 0.70128679
Iteration 4925, loss = 0.69238917
Iteration 4926, loss = 0.79365260
Iteration 4927, loss = 0.76537488
Iteration 4928, loss = 0.80428672
Iteration 4929, loss = 0.72214035
Iteration 4930, loss = 0.78817999
Iteration 4931, loss = 0.71363099
Iteration 4932, loss = 0.78503462
Iteration 4933, loss = 0.71783188
Iteration 4934, loss = 0.76575740
Iteration 4935, loss = 0.71952270
Iteration 4936, loss = 0.74861474
Iteration 4937, loss = 0.72896119
Iteration 4938, loss = 0.73774453
Iteration 4939, loss = 0.73427422
Iteration 4940, loss = 0.72471173
Iteration 4941, loss = 0.73361465
Iteration 4942, loss = 0.71724462
Iteration 4943, loss = 0.73395985
Iteration 4944, loss = 0.71456725
Iteration 4945, loss = 0.73085630
Iteration 4946, loss = 0.71205025
Iteration 4947, loss = 0.72583565
Iteration 4948, loss = 0.71166824
Iteration 4949, loss = 0.72169939
Iteration 4950, loss = 0.71249587
Iteration 4951, loss = 0.71747300
Iteration 4952, loss = 0.71227511
Iteration 4953, loss = 0.71301149
Iteration 4954, loss = 0.71184682
Iteration 4955, loss = 0.71022207
Iteration 4956, loss = 0.71162225
Iteration 4957, loss = 0.70787838
Iteration 4958, loss = 0.71016435
Iteration 4959, loss = 0.70580050
Iteration 4960, loss = 0.70878526
Iteration 4961, loss = 0.70480779
Iteration 4962, loss = 0.70741813
Iteration 4963, loss = 0.70384870
Iteration 4964, loss = 0.70567121
Iteration 4965, loss = 0.70302864
Iteration 4966, loss = 0.70421359
Iteration 4967, loss = 0.70253709
Iteration 4968, loss = 0.70294662
Iteration 4969, loss = 0.70193601
Iteration 4970, loss = 0.70169519
Iteration 4971, loss = 0.70130911
Iteration 4972, loss = 0.70074553
Iteration 4973, loss = 0.70078735
Iteration 4974, loss = 0.69996506
Iteration 4975, loss = 0.70016640
Iteration 4976, loss = 0.69926361
Iteration 4977, loss = 0.69957164
Iteration 4978, loss = 0.69874402
Iteration 4979, loss = 0.69903349
Iteration 4980, loss = 0.69829981
Iteration 4981, loss = 0.69849613
Iteration 4982, loss = 0.69790377
Iteration 4983, loss = 0.69800875
Iteration 4984, loss = 0.69757371
Iteration 4985, loss = 0.69758336
Iteration 4986, loss = 0.69727541
Iteration 4987, loss = 0.69719488
Iteration 4988, loss = 0.69699276
Iteration 4989, loss = 0.69685820
Iteration 4990, loss = 0.69674403
Iteration 4991, loss = 0.69657646
Iteration 4992, loss = 0.69651085
Iteration 4993, loss = 0.69631924
Iteration 4994, loss = 0.69627944
Iteration 4995, loss = 0.69609220
Iteration 4996, loss = 0.69607348
Iteration 4997, loss = 0.69590254
Iteration 4998, loss = 0.69588329
Iteration 4999, loss = 0.69572770
Iteration 5000, loss = 0.69570377
