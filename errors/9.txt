Iteration 1, loss = 0.71725278
Iteration 2, loss = 0.84337430
Iteration 3, loss = 2.64798719
Iteration 4, loss = 1.27414129
Iteration 5, loss = 0.72194049
Iteration 6, loss = 1.05651250
Iteration 7, loss = 0.98661606
Iteration 8, loss = 1.11751841
Iteration 9, loss = 0.77957420
Iteration 10, loss = 0.76771979
Iteration 11, loss = 0.75363275
Iteration 12, loss = 0.80206827
Iteration 13, loss = 0.76946462
Iteration 14, loss = 0.76422970
Iteration 15, loss = 0.78145940
Iteration 16, loss = 0.77669129
Iteration 17, loss = 0.77763684
Iteration 18, loss = 0.63340429
Iteration 19, loss = 1.43366839
Iteration 20, loss = 1.19495951
Iteration 21, loss = 0.73784337
Iteration 22, loss = 0.98339723
Iteration 23, loss = 0.91397153
Iteration 24, loss = 0.57968896
Iteration 25, loss = 1.17637954
Iteration 26, loss = 0.89568697
Iteration 27, loss = 0.96552838
Iteration 28, loss = 0.79584516
Iteration 29, loss = 0.80387760
Iteration 30, loss = 0.80552461
Iteration 31, loss = 0.95521703
Iteration 32, loss = 0.76353820
Iteration 33, loss = 0.80524599
Iteration 34, loss = 0.83144427
Iteration 35, loss = 0.83727231
Iteration 36, loss = 0.83410959
Iteration 37, loss = 1.17603731
Iteration 38, loss = 0.59725647
Iteration 39, loss = 1.18614527
Iteration 40, loss = 1.09009079
Iteration 41, loss = 0.85390596
Iteration 42, loss = 1.00168064
Iteration 43, loss = 1.10055940
Iteration 44, loss = 0.92483130
Iteration 45, loss = 0.84673635
Iteration 46, loss = 0.98134650
Iteration 47, loss = 0.94889122
Iteration 48, loss = 0.80791340
Iteration 49, loss = 0.84897331
Iteration 50, loss = 0.91007896
Iteration 51, loss = 0.82410879
Iteration 52, loss = 0.77928757
Iteration 53, loss = 0.84754097
Iteration 54, loss = 0.83319213
Iteration 55, loss = 0.76688007
Iteration 56, loss = 0.79617484
Iteration 57, loss = 0.82399190
Iteration 58, loss = 0.77610111
Iteration 59, loss = 0.76719365
Iteration 60, loss = 0.80221381
Iteration 61, loss = 0.78196115
Iteration 62, loss = 0.75573335
Iteration 63, loss = 0.77931568
Iteration 64, loss = 0.77937661
Iteration 65, loss = 0.75280681
Iteration 66, loss = 0.76206621
Iteration 67, loss = 0.77174981
Iteration 68, loss = 0.75222410
Iteration 69, loss = 0.75125481
Iteration 70, loss = 0.76278378
Iteration 71, loss = 0.75112403
Iteration 72, loss = 0.74522104
Iteration 73, loss = 0.75485935
Iteration 74, loss = 0.74915592
Iteration 75, loss = 0.74193099
Iteration 76, loss = 0.74876405
Iteration 77, loss = 0.74669692
Iteration 78, loss = 0.73980794
Iteration 79, loss = 0.74361557
Iteration 80, loss = 0.74275999
Iteration 81, loss = 0.73628739
Iteration 82, loss = 0.73071582
Iteration 83, loss = 0.82531605
Iteration 84, loss = 0.74608220
Iteration 85, loss = 0.78418707
Iteration 86, loss = 0.81785944
Iteration 87, loss = 0.75629475
Iteration 88, loss = 0.75476083
Iteration 89, loss = 0.80647565
Iteration 90, loss = 0.76380182
Iteration 91, loss = 0.74100325
Iteration 92, loss = 0.78119618
Iteration 93, loss = 0.77308970
Iteration 94, loss = 0.73946613
Iteration 95, loss = 0.75935640
Iteration 96, loss = 0.77083967
Iteration 97, loss = 0.74295582
Iteration 98, loss = 0.74331341
Iteration 99, loss = 0.76045999
Iteration 100, loss = 0.74551229
Iteration 101, loss = 0.73616107
Iteration 102, loss = 0.75057833
Iteration 103, loss = 0.74643622
Iteration 104, loss = 0.73418825
Iteration 105, loss = 0.74211155
Iteration 106, loss = 0.74386711
Iteration 107, loss = 0.73300423
Iteration 108, loss = 0.73545589
Iteration 109, loss = 0.73944431
Iteration 110, loss = 0.73129960
Iteration 111, loss = 0.73317108
Iteration 112, loss = 0.73221883
Iteration 113, loss = 0.72930096
Iteration 114, loss = 0.72762896
Iteration 115, loss = 0.70626465
Iteration 116, loss = 0.84237058
Iteration 117, loss = 0.74978754
Iteration 118, loss = 0.86228742
Iteration 119, loss = 0.76501855
Iteration 120, loss = 0.77510406
Iteration 121, loss = 0.80829123
Iteration 122, loss = 0.72577868
Iteration 123, loss = 0.77175380
Iteration 124, loss = 0.75604796
Iteration 125, loss = 0.79952545
Iteration 126, loss = 0.79734713
Iteration 127, loss = 0.91568478
Iteration 128, loss = 0.79285773
Iteration 129, loss = 0.77308207
Iteration 130, loss = 0.86003094
Iteration 131, loss = 0.77530773
Iteration 132, loss = 0.75350189
Iteration 133, loss = 0.82514646
Iteration 134, loss = 0.77127933
Iteration 135, loss = 0.74894426
Iteration 136, loss = 0.80285764
Iteration 137, loss = 0.76563771
Iteration 138, loss = 0.74258429
Iteration 139, loss = 0.78138974
Iteration 140, loss = 0.75607365
Iteration 141, loss = 0.73694299
Iteration 142, loss = 0.76645879
Iteration 143, loss = 0.74928545
Iteration 144, loss = 0.73303561
Iteration 145, loss = 0.74466989
Iteration 146, loss = 0.73803111
Iteration 147, loss = 0.73944217
Iteration 148, loss = 0.72908754
Iteration 149, loss = 0.76282038
Iteration 150, loss = 0.74490468
Iteration 151, loss = 0.75375770
Iteration 152, loss = 0.75697466
Iteration 153, loss = 0.74209199
Iteration 154, loss = 0.74981177
Iteration 155, loss = 0.75242099
Iteration 156, loss = 0.74354024
Iteration 157, loss = 0.75106874
Iteration 158, loss = 0.75144819
Iteration 159, loss = 0.74430794
Iteration 160, loss = 0.74927271
Iteration 161, loss = 0.74770900
Iteration 162, loss = 0.74316553
Iteration 163, loss = 0.74768736
Iteration 164, loss = 0.74595252
Iteration 165, loss = 0.74317752
Iteration 166, loss = 0.74598395
Iteration 167, loss = 0.74320671
Iteration 168, loss = 0.74131427
Iteration 169, loss = 0.74303361
Iteration 170, loss = 0.74039286
Iteration 171, loss = 0.73933681
Iteration 172, loss = 0.73948907
Iteration 173, loss = 0.73527394
Iteration 174, loss = 0.73107710
Iteration 175, loss = 0.71840460
Iteration 176, loss = 0.92891814
Iteration 177, loss = 0.75029878
Iteration 178, loss = 0.94926915
Iteration 179, loss = 0.82236041
Iteration 180, loss = 0.78397703
Iteration 181, loss = 0.89882907
Iteration 182, loss = 0.76077450
Iteration 183, loss = 0.80581776
Iteration 184, loss = 0.84191902
Iteration 185, loss = 0.73623942
Iteration 186, loss = 0.80721895
Iteration 187, loss = 0.78913922
Iteration 188, loss = 0.73144388
Iteration 189, loss = 0.79014560
Iteration 190, loss = 0.73940795
Iteration 191, loss = 1.00252558
Iteration 192, loss = 0.80023661
Iteration 193, loss = 0.67286665
Iteration 194, loss = 1.56833572
Iteration 195, loss = 1.17076138
Iteration 196, loss = 0.79070545
Iteration 197, loss = 1.16348904
Iteration 198, loss = 1.05447469
Iteration 199, loss = 0.78141812
Iteration 200, loss = 1.05264985
Iteration 201, loss = 0.93475366
Iteration 202, loss = 0.77799905
Iteration 203, loss = 0.97977621
Iteration 204, loss = 0.85564042
Iteration 205, loss = 0.78330762
Iteration 206, loss = 0.92111854
Iteration 207, loss = 0.80006072
Iteration 208, loss = 0.79222094
Iteration 209, loss = 0.87752160
Iteration 210, loss = 0.77076572
Iteration 211, loss = 0.80002503
Iteration 212, loss = 0.83969316
Iteration 213, loss = 0.75643853
Iteration 214, loss = 0.80254896
Iteration 215, loss = 0.80774054
Iteration 216, loss = 0.75246912
Iteration 217, loss = 0.79814876
Iteration 218, loss = 0.78062277
Iteration 219, loss = 0.75328617
Iteration 220, loss = 0.78925892
Iteration 221, loss = 0.76205517
Iteration 222, loss = 0.75692990
Iteration 223, loss = 0.77809923
Iteration 224, loss = 0.75119086
Iteration 225, loss = 0.75952760
Iteration 226, loss = 0.76622839
Iteration 227, loss = 0.74638032
Iteration 228, loss = 0.75943523
Iteration 229, loss = 0.75540916
Iteration 230, loss = 0.74507649
Iteration 231, loss = 0.75634110
Iteration 232, loss = 0.74714974
Iteration 233, loss = 0.74526906
Iteration 234, loss = 0.74439517
Iteration 235, loss = 0.74462880
Iteration 236, loss = 0.74962208
Iteration 237, loss = 0.74895655
Iteration 238, loss = 0.75359954
Iteration 239, loss = 0.74994670
Iteration 240, loss = 0.75194253
Iteration 241, loss = 0.74684378
Iteration 242, loss = 0.74739661
Iteration 243, loss = 0.74323905
Iteration 244, loss = 0.74403103
Iteration 245, loss = 0.74223833
Iteration 246, loss = 0.74318229
Iteration 247, loss = 0.74270854
Iteration 248, loss = 0.74261405
Iteration 249, loss = 0.74229886
Iteration 250, loss = 0.74134558
Iteration 251, loss = 0.74119353
Iteration 252, loss = 0.73982158
Iteration 253, loss = 0.73976220
Iteration 254, loss = 0.73831333
Iteration 255, loss = 0.73832957
Iteration 256, loss = 0.73706668
Iteration 257, loss = 0.73712723
Iteration 258, loss = 0.73593964
Iteration 259, loss = 0.73560831
Iteration 260, loss = 0.73430323
Iteration 261, loss = 0.73379117
Iteration 262, loss = 0.73290851
Iteration 263, loss = 0.73272769
Iteration 264, loss = 0.73204179
Iteration 265, loss = 0.73135134
Iteration 266, loss = 0.73050415
Iteration 267, loss = 0.72999777
Iteration 268, loss = 0.72958465
Iteration 269, loss = 0.72887665
Iteration 270, loss = 0.72784160
Iteration 271, loss = 0.72691511
Iteration 272, loss = 0.72612636
Iteration 273, loss = 0.72413020
Iteration 274, loss = 0.72261146
Iteration 275, loss = 0.71942520
Iteration 276, loss = 0.71786678
Iteration 277, loss = 0.69737817
Iteration 278, loss = 0.80447003
Iteration 279, loss = 0.81679846
Iteration 280, loss = 0.81276681
Iteration 281, loss = 0.78086120
Iteration 282, loss = 0.80928505
Iteration 283, loss = 0.74841365
Iteration 284, loss = 0.80057799
Iteration 285, loss = 0.73459106
Iteration 286, loss = 0.79221462
Iteration 287, loss = 0.73649624
Iteration 288, loss = 0.78193180
Iteration 289, loss = 0.74378815
Iteration 290, loss = 0.76825301
Iteration 291, loss = 0.75019059
Iteration 292, loss = 0.75436279
Iteration 293, loss = 0.75404961
Iteration 294, loss = 0.74367669
Iteration 295, loss = 0.75489304
Iteration 296, loss = 0.73718754
Iteration 297, loss = 0.75308645
Iteration 298, loss = 0.73460099
Iteration 299, loss = 0.74887550
Iteration 300, loss = 0.73155971
Iteration 301, loss = 0.76282593
Iteration 302, loss = 0.77581034
Iteration 303, loss = 0.78204618
Iteration 304, loss = 0.78225486
Iteration 305, loss = 0.78729948
Iteration 306, loss = 0.76259287
Iteration 307, loss = 0.77166583
Iteration 308, loss = 0.74573101
Iteration 309, loss = 0.76134942
Iteration 310, loss = 0.74437367
Iteration 311, loss = 0.76054401
Iteration 312, loss = 0.75070981
Iteration 313, loss = 0.75961991
Iteration 314, loss = 0.75383692
Iteration 315, loss = 0.75473675
Iteration 316, loss = 0.75273985
Iteration 317, loss = 0.74901038
Iteration 318, loss = 0.75117343
Iteration 319, loss = 0.74619207
Iteration 320, loss = 0.75079555
Iteration 321, loss = 0.74560699
Iteration 322, loss = 0.75010136
Iteration 323, loss = 0.74502176
Iteration 324, loss = 0.74823131
Iteration 325, loss = 0.74417241
Iteration 326, loss = 0.74610493
Iteration 327, loss = 0.74360362
Iteration 328, loss = 0.74451541
Iteration 329, loss = 0.74345416
Iteration 330, loss = 0.74339578
Iteration 331, loss = 0.74312006
Iteration 332, loss = 0.74214992
Iteration 333, loss = 0.74224679
Iteration 334, loss = 0.74077455
Iteration 335, loss = 0.74111186
Iteration 336, loss = 0.73961464
Iteration 337, loss = 0.74016367
Iteration 338, loss = 0.73891372
Iteration 339, loss = 0.73948171
Iteration 340, loss = 0.73840046
Iteration 341, loss = 0.73869210
Iteration 342, loss = 0.73765057
Iteration 343, loss = 0.73761723
Iteration 344, loss = 0.73672248
Iteration 345, loss = 0.73656293
Iteration 346, loss = 0.73594452
Iteration 347, loss = 0.73574409
Iteration 348, loss = 0.73511024
Iteration 349, loss = 0.73639468
Iteration 350, loss = 0.73510364
Iteration 351, loss = 0.73545938
Iteration 352, loss = 0.73474390
Iteration 353, loss = 0.73434737
Iteration 354, loss = 0.73404521
Iteration 355, loss = 0.73330195
Iteration 356, loss = 0.73340167
Iteration 357, loss = 0.73257247
Iteration 358, loss = 0.73284165
Iteration 359, loss = 0.73199269
Iteration 360, loss = 0.73216226
Iteration 361, loss = 0.73139580
Iteration 362, loss = 0.73138129
Iteration 363, loss = 0.73081656
Iteration 364, loss = 0.73062563
Iteration 365, loss = 0.73027404
Iteration 366, loss = 0.72992074
Iteration 367, loss = 0.72970992
Iteration 368, loss = 0.72924671
Iteration 369, loss = 0.72908901
Iteration 370, loss = 0.72858266
Iteration 371, loss = 0.72839363
Iteration 372, loss = 0.72787369
Iteration 373, loss = 0.72739441
Iteration 374, loss = 0.72701485
Iteration 375, loss = 0.72666668
Iteration 376, loss = 0.72604277
Iteration 377, loss = 0.72573509
Iteration 378, loss = 0.72484903
Iteration 379, loss = 0.72386541
Iteration 380, loss = 0.72154364
Iteration 381, loss = 0.72846382
Iteration 382, loss = 0.77181396
Iteration 383, loss = 0.73371493
Iteration 384, loss = 0.76381180
Iteration 385, loss = 0.74234131
Iteration 386, loss = 0.75007677
Iteration 387, loss = 0.74464112
Iteration 388, loss = 0.73648734
Iteration 389, loss = 0.74554898
Iteration 390, loss = 0.72966305
Iteration 391, loss = 0.74527223
Iteration 392, loss = 0.72877898
Iteration 393, loss = 0.74384681
Iteration 394, loss = 0.73841634
Iteration 395, loss = 0.73019555
Iteration 396, loss = 0.70666052
Iteration 397, loss = 0.80705483
Iteration 398, loss = 0.84866881
Iteration 399, loss = 1.10054763
Iteration 400, loss = 0.91808294
Iteration 401, loss = 1.13715532
Iteration 402, loss = 0.76819384
Iteration 403, loss = 1.06787124
Iteration 404, loss = 0.83354246
Iteration 405, loss = 0.94168330
Iteration 406, loss = 0.93950128
Iteration 407, loss = 0.81174252
Iteration 408, loss = 0.96203541
Iteration 409, loss = 0.77454132
Iteration 410, loss = 0.91861085
Iteration 411, loss = 0.81148871
Iteration 412, loss = 0.84459514
Iteration 413, loss = 0.85519362
Iteration 414, loss = 0.78739040
Iteration 415, loss = 0.86568935
Iteration 416, loss = 0.77336176
Iteration 417, loss = 0.84518405
Iteration 418, loss = 0.78921883
Iteration 419, loss = 0.80944067
Iteration 420, loss = 0.80806498
Iteration 421, loss = 0.78033553
Iteration 422, loss = 0.81438647
Iteration 423, loss = 0.76977739
Iteration 424, loss = 0.80630258
Iteration 425, loss = 0.77368761
Iteration 426, loss = 0.78987991
Iteration 427, loss = 0.78109636
Iteration 428, loss = 0.77365541
Iteration 429, loss = 0.78368246
Iteration 430, loss = 0.76278854
Iteration 431, loss = 0.77147742
Iteration 432, loss = 0.77731890
Iteration 433, loss = 0.78640518
Iteration 434, loss = 0.79532857
Iteration 435, loss = 0.76830693
Iteration 436, loss = 0.79162153
Iteration 437, loss = 0.76891281
Iteration 438, loss = 0.77694322
Iteration 439, loss = 0.77885052
Iteration 440, loss = 0.76692292
Iteration 441, loss = 0.78150363
Iteration 442, loss = 0.76685278
Iteration 443, loss = 0.77405744
Iteration 444, loss = 0.77119905
Iteration 445, loss = 0.76578037
Iteration 446, loss = 0.77263312
Iteration 447, loss = 0.76314755
Iteration 448, loss = 0.76882743
Iteration 449, loss = 0.76479234
Iteration 450, loss = 0.76349886
Iteration 451, loss = 0.76592176
Iteration 452, loss = 0.76027544
Iteration 453, loss = 0.76374576
Iteration 454, loss = 0.75952945
Iteration 455, loss = 0.75968984
Iteration 456, loss = 0.75940348
Iteration 457, loss = 0.75642182
Iteration 458, loss = 0.75814307
Iteration 459, loss = 0.75488094
Iteration 460, loss = 0.75551133
Iteration 461, loss = 0.75402068
Iteration 462, loss = 0.75255155
Iteration 463, loss = 0.75274313
Iteration 464, loss = 0.75041264
Iteration 465, loss = 0.75078340
Iteration 466, loss = 0.74906162
Iteration 467, loss = 0.74843503
Iteration 468, loss = 0.74759985
Iteration 469, loss = 0.77819827
Iteration 470, loss = 0.78857082
Iteration 471, loss = 0.77145636
Iteration 472, loss = 0.77996108
Iteration 473, loss = 0.78902264
Iteration 474, loss = 0.75840039
Iteration 475, loss = 0.77559164
Iteration 476, loss = 0.74913281
Iteration 477, loss = 0.75852235
Iteration 478, loss = 0.75680948
Iteration 479, loss = 0.74991268
Iteration 480, loss = 0.76211689
Iteration 481, loss = 0.74688047
Iteration 482, loss = 0.75605528
Iteration 483, loss = 0.74725462
Iteration 484, loss = 0.75847679
Iteration 485, loss = 0.74824605
Iteration 486, loss = 0.76560895
Iteration 487, loss = 0.77139136
Iteration 488, loss = 0.77415438
Iteration 489, loss = 0.76712746
Iteration 490, loss = 0.75747469
Iteration 491, loss = 0.75258711
Iteration 492, loss = 0.74803035
Iteration 493, loss = 0.75121598
Iteration 494, loss = 0.75238671
Iteration 495, loss = 0.75486682
Iteration 496, loss = 0.75526122
Iteration 497, loss = 0.75328579
Iteration 498, loss = 0.75257414
Iteration 499, loss = 0.74990074
Iteration 500, loss = 0.74980569
Iteration 501, loss = 0.74881926
Iteration 502, loss = 0.74864809
Iteration 503, loss = 0.74842116
Iteration 504, loss = 0.74717319
Iteration 505, loss = 0.74664299
Iteration 506, loss = 0.74472938
Iteration 507, loss = 0.74350475
Iteration 508, loss = 0.74132855
Iteration 509, loss = 0.73885919
Iteration 510, loss = 0.73287634
Iteration 511, loss = 0.78181476
Iteration 512, loss = 0.74458943
Iteration 513, loss = 0.85253455
Iteration 514, loss = 0.77291681
Iteration 515, loss = 0.83541993
Iteration 516, loss = 0.77248175
Iteration 517, loss = 0.80170831
Iteration 518, loss = 0.79569789
Iteration 519, loss = 0.75564295
Iteration 520, loss = 0.79149402
Iteration 521, loss = 0.75829931
Iteration 522, loss = 0.76809630
Iteration 523, loss = 0.78053692
Iteration 524, loss = 0.75619901
Iteration 525, loss = 0.77989556
Iteration 526, loss = 0.76439489
Iteration 527, loss = 0.76276044
Iteration 528, loss = 0.77264727
Iteration 529, loss = 0.75539588
Iteration 530, loss = 0.76781903
Iteration 531, loss = 0.76129974
Iteration 532, loss = 0.75778541
Iteration 533, loss = 0.76538903
Iteration 534, loss = 0.75467909
Iteration 535, loss = 0.76075971
Iteration 536, loss = 0.75777824
Iteration 537, loss = 0.75413350
Iteration 538, loss = 0.75904119
Iteration 539, loss = 0.75266111
Iteration 540, loss = 0.75576953
Iteration 541, loss = 0.75453995
Iteration 542, loss = 0.75168783
Iteration 543, loss = 0.75442943
Iteration 544, loss = 0.75023480
Iteration 545, loss = 0.75138289
Iteration 546, loss = 0.75048373
Iteration 547, loss = 0.74832627
Iteration 548, loss = 0.74981314
Iteration 549, loss = 0.74721437
Iteration 550, loss = 0.74769395
Iteration 551, loss = 0.74705988
Iteration 552, loss = 0.74551452
Iteration 553, loss = 0.74613052
Iteration 554, loss = 0.74428970
Iteration 555, loss = 0.74427734
Iteration 556, loss = 0.74363533
Iteration 557, loss = 0.74249948
Iteration 558, loss = 0.74265427
Iteration 559, loss = 0.74135161
Iteration 560, loss = 0.74115253
Iteration 561, loss = 0.74052093
Iteration 562, loss = 0.73964382
Iteration 563, loss = 0.73950143
Iteration 564, loss = 0.73850562
Iteration 565, loss = 0.73820706
Iteration 566, loss = 0.73760405
Iteration 567, loss = 0.73691660
Iteration 568, loss = 0.73662404
Iteration 569, loss = 0.73582871
Iteration 570, loss = 0.73546664
Iteration 571, loss = 0.73487506
Iteration 572, loss = 0.73428631
Iteration 573, loss = 0.73390033
Iteration 574, loss = 0.73323641
Iteration 575, loss = 0.73284800
Iteration 576, loss = 0.73226926
Iteration 577, loss = 0.73111004
Iteration 578, loss = 0.73276983
Iteration 579, loss = 0.73264992
Iteration 580, loss = 0.73223322
Iteration 581, loss = 0.73229421
Iteration 582, loss = 0.73091998
Iteration 583, loss = 0.73114084
Iteration 584, loss = 0.73002907
Iteration 585, loss = 0.72928559
Iteration 586, loss = 0.72892073
Iteration 587, loss = 0.72799822
Iteration 588, loss = 0.72800643
Iteration 589, loss = 0.72719223
Iteration 590, loss = 0.72681827
Iteration 591, loss = 0.72640263
Iteration 592, loss = 0.72572815
Iteration 593, loss = 0.72555757
Iteration 594, loss = 0.72491988
Iteration 595, loss = 0.72464181
Iteration 596, loss = 0.72415435
Iteration 597, loss = 0.72358551
Iteration 598, loss = 0.72325870
Iteration 599, loss = 0.72269172
Iteration 600, loss = 0.72237809
Iteration 601, loss = 0.72187669
Iteration 602, loss = 0.72142616
Iteration 603, loss = 0.72105531
Iteration 604, loss = 0.72056238
Iteration 605, loss = 0.72022167
Iteration 606, loss = 0.71974763
Iteration 607, loss = 0.71936148
Iteration 608, loss = 0.71897846
Iteration 609, loss = 0.71855826
Iteration 610, loss = 0.71820996
Iteration 611, loss = 0.71776514
Iteration 612, loss = 0.71737264
Iteration 613, loss = 0.71692119
Iteration 614, loss = 0.71644017
Iteration 615, loss = 0.71596087
Iteration 616, loss = 0.71544359
Iteration 617, loss = 0.71497194
Iteration 618, loss = 0.71439067
Iteration 619, loss = 0.71361860
Iteration 620, loss = 0.71263062
Iteration 621, loss = 0.71163150
Iteration 622, loss = 0.71067237
Iteration 623, loss = 0.70941563
Iteration 624, loss = 0.70754860
Iteration 625, loss = 0.70563324
Iteration 626, loss = 0.70328890
Iteration 627, loss = 0.69571443
Iteration 628, loss = 0.78701744
Iteration 629, loss = 0.72675666
Iteration 630, loss = 0.80259415
Iteration 631, loss = 0.73709042
Iteration 632, loss = 0.75503961
Iteration 633, loss = 0.77224337
Iteration 634, loss = 0.72021158
Iteration 635, loss = 0.76381472
Iteration 636, loss = 0.73273216
Iteration 637, loss = 0.72894606
Iteration 638, loss = 0.74883286
Iteration 639, loss = 0.71511467
Iteration 640, loss = 0.73921961
Iteration 641, loss = 0.72787719
Iteration 642, loss = 0.71987943
Iteration 643, loss = 0.73615199
Iteration 644, loss = 0.71577030
Iteration 645, loss = 0.72750892
Iteration 646, loss = 0.72362884
Iteration 647, loss = 0.71535546
Iteration 648, loss = 0.72576212
Iteration 649, loss = 0.71346253
Iteration 650, loss = 0.71846279
Iteration 651, loss = 0.71707111
Iteration 652, loss = 0.70956716
Iteration 653, loss = 0.70536228
Iteration 654, loss = 0.72820015
Iteration 655, loss = 0.70756026
Iteration 656, loss = 0.71353134
Iteration 657, loss = 0.80923578
Iteration 658, loss = 0.73153608
Iteration 659, loss = 0.83008639
Iteration 660, loss = 0.74675611
Iteration 661, loss = 0.75895079
Iteration 662, loss = 0.78330231
Iteration 663, loss = 0.71699884
Iteration 664, loss = 0.76810559
Iteration 665, loss = 0.75341933
Iteration 666, loss = 0.71779753
Iteration 667, loss = 0.75986953
Iteration 668, loss = 0.72766663
Iteration 669, loss = 0.72540122
Iteration 670, loss = 0.74724574
Iteration 671, loss = 0.71590110
Iteration 672, loss = 0.72985419
Iteration 673, loss = 0.73222455
Iteration 674, loss = 0.71206628
Iteration 675, loss = 0.72976931
Iteration 676, loss = 0.71989208
Iteration 677, loss = 0.71385703
Iteration 678, loss = 0.72574226
Iteration 679, loss = 0.71238162
Iteration 680, loss = 0.71533006
Iteration 681, loss = 0.71835198
Iteration 682, loss = 0.70873354
Iteration 683, loss = 0.71542730
Iteration 684, loss = 0.71248897
Iteration 685, loss = 0.70841132
Iteration 686, loss = 0.71323592
Iteration 687, loss = 0.70780241
Iteration 688, loss = 0.70818451
Iteration 689, loss = 0.71004903
Iteration 690, loss = 0.70521360
Iteration 691, loss = 0.70774470
Iteration 692, loss = 0.70671864
Iteration 693, loss = 0.70434542
Iteration 694, loss = 0.70597855
Iteration 695, loss = 0.70385498
Iteration 696, loss = 0.70412515
Iteration 697, loss = 0.70492493
Iteration 698, loss = 0.70228850
Iteration 699, loss = 0.70179975
Iteration 700, loss = 0.70090157
Iteration 701, loss = 0.69932799
Iteration 702, loss = 0.69816673
Iteration 703, loss = 0.69473126
Iteration 704, loss = 0.69138735
Iteration 705, loss = 0.68996971
Iteration 706, loss = 0.67778952
Iteration 707, loss = 0.83140779
Iteration 708, loss = 1.19638778
Iteration 709, loss = 0.92086221
Iteration 710, loss = 0.94949759
Iteration 711, loss = 1.14143964
Iteration 712, loss = 0.83520848
Iteration 713, loss = 0.95430070
Iteration 714, loss = 0.98925797
Iteration 715, loss = 0.74840248
Iteration 716, loss = 0.91255555
Iteration 717, loss = 0.85820075
Iteration 718, loss = 0.75344467
Iteration 719, loss = 0.89897469
Iteration 720, loss = 0.79503863
Iteration 721, loss = 0.77265537
Iteration 722, loss = 0.86291029
Iteration 723, loss = 0.78809343
Iteration 724, loss = 0.77592778
Iteration 725, loss = 0.82979181
Iteration 726, loss = 0.76265556
Iteration 727, loss = 0.77518569
Iteration 728, loss = 0.80165224
Iteration 729, loss = 0.74770001
Iteration 730, loss = 0.77243585
Iteration 731, loss = 0.77853586
Iteration 732, loss = 0.74808174
Iteration 733, loss = 0.75348241
Iteration 734, loss = 0.95000727
Iteration 735, loss = 0.75948115
Iteration 736, loss = 0.92222871
Iteration 737, loss = 0.87254336
Iteration 738, loss = 0.75848647
Iteration 739, loss = 0.88196686
Iteration 740, loss = 0.80090495
Iteration 741, loss = 0.77106147
Iteration 742, loss = 0.85397441
Iteration 743, loss = 0.76657501
Iteration 744, loss = 0.78496980
Iteration 745, loss = 0.81691503
Iteration 746, loss = 0.74554689
Iteration 747, loss = 0.78692340
Iteration 748, loss = 0.78349241
Iteration 749, loss = 0.74233995
Iteration 750, loss = 0.78294487
Iteration 751, loss = 0.75899377
Iteration 752, loss = 0.74604054
Iteration 753, loss = 0.77245174
Iteration 754, loss = 0.74333945
Iteration 755, loss = 0.74955405
Iteration 756, loss = 0.75883516
Iteration 757, loss = 0.73606919
Iteration 758, loss = 0.75005224
Iteration 759, loss = 0.74610592
Iteration 760, loss = 0.73433523
Iteration 761, loss = 0.74703693
Iteration 762, loss = 0.73704499
Iteration 763, loss = 0.73540543
Iteration 764, loss = 0.74207053
Iteration 765, loss = 0.73167195
Iteration 766, loss = 0.73549643
Iteration 767, loss = 0.73608317
Iteration 768, loss = 0.72948800
Iteration 769, loss = 0.73453550
Iteration 770, loss = 0.73105633
Iteration 771, loss = 0.72843371
Iteration 772, loss = 0.73155758
Iteration 773, loss = 0.72672351
Iteration 774, loss = 0.72641419
Iteration 775, loss = 0.72605025
Iteration 776, loss = 0.71965937
Iteration 777, loss = 0.71506356
Iteration 778, loss = 0.76732267
Iteration 779, loss = 0.73808358
Iteration 780, loss = 0.77712658
Iteration 781, loss = 0.74104353
Iteration 782, loss = 0.75263820
Iteration 783, loss = 0.75778426
Iteration 784, loss = 0.73510008
Iteration 785, loss = 0.75906381
Iteration 786, loss = 0.74062537
Iteration 787, loss = 0.74425362
Iteration 788, loss = 0.75072338
Iteration 789, loss = 0.73566809
Iteration 790, loss = 0.74980860
Iteration 791, loss = 0.74045049
Iteration 792, loss = 0.74117859
Iteration 793, loss = 0.74642073
Iteration 794, loss = 0.73680914
Iteration 795, loss = 0.74629186
Iteration 796, loss = 0.74016010
Iteration 797, loss = 0.74574865
Iteration 798, loss = 0.74713093
Iteration 799, loss = 0.74041836
Iteration 800, loss = 0.74242356
Iteration 801, loss = 0.73771727
Iteration 802, loss = 0.73918026
Iteration 803, loss = 0.74039795
Iteration 804, loss = 0.73753377
Iteration 805, loss = 0.73957208
Iteration 806, loss = 0.73667244
Iteration 807, loss = 0.73670217
Iteration 808, loss = 0.73679059
Iteration 809, loss = 0.73470604
Iteration 810, loss = 0.73570552
Iteration 811, loss = 0.73376206
Iteration 812, loss = 0.73350714
Iteration 813, loss = 0.73312304
Iteration 814, loss = 0.73122332
Iteration 815, loss = 0.73173559
Iteration 816, loss = 0.73002321
Iteration 817, loss = 0.72868311
Iteration 818, loss = 0.72810764
Iteration 819, loss = 0.72712647
Iteration 820, loss = 0.72646531
Iteration 821, loss = 0.72454676
Iteration 822, loss = 0.72205663
Iteration 823, loss = 0.71053672
Iteration 824, loss = 0.90991979
Iteration 825, loss = 0.74968710
Iteration 826, loss = 0.92872024
Iteration 827, loss = 0.76616486
Iteration 828, loss = 0.83359281
Iteration 829, loss = 0.83286461
Iteration 830, loss = 0.73732486
Iteration 831, loss = 0.84211421
Iteration 832, loss = 0.73779086
Iteration 833, loss = 0.79439771
Iteration 834, loss = 0.77891977
Iteration 835, loss = 0.73907538
Iteration 836, loss = 0.79320606
Iteration 837, loss = 0.72413085
Iteration 838, loss = 0.76967432
Iteration 839, loss = 0.74397057
Iteration 840, loss = 0.73720262
Iteration 841, loss = 0.75925647
Iteration 842, loss = 0.72132928
Iteration 843, loss = 0.75280966
Iteration 844, loss = 0.72637685
Iteration 845, loss = 0.73410443
Iteration 846, loss = 0.73678570
Iteration 847, loss = 0.72032321
Iteration 848, loss = 0.73795245
Iteration 849, loss = 0.71859107
Iteration 850, loss = 0.73026849
Iteration 851, loss = 0.72372671
Iteration 852, loss = 0.72032973
Iteration 853, loss = 0.72702529
Iteration 854, loss = 0.71583076
Iteration 855, loss = 0.72474710
Iteration 856, loss = 0.71683900
Iteration 857, loss = 0.71936457
Iteration 858, loss = 0.71937923
Iteration 859, loss = 0.71492849
Iteration 860, loss = 0.71929947
Iteration 861, loss = 0.71142589
Iteration 862, loss = 0.72009623
Iteration 863, loss = 0.71659573
Iteration 864, loss = 0.71674383
Iteration 865, loss = 0.71792487
Iteration 866, loss = 0.71339393
Iteration 867, loss = 0.71660279
Iteration 868, loss = 0.71260147
Iteration 869, loss = 0.71463610
Iteration 870, loss = 0.71366826
Iteration 871, loss = 0.71281423
Iteration 872, loss = 0.71410359
Iteration 873, loss = 0.71169623
Iteration 874, loss = 0.71326755
Iteration 875, loss = 0.71139663
Iteration 876, loss = 0.71170430
Iteration 877, loss = 0.71135671
Iteration 878, loss = 0.71036046
Iteration 879, loss = 0.71094519
Iteration 880, loss = 0.70934457
Iteration 881, loss = 0.70946554
Iteration 882, loss = 0.70844339
Iteration 883, loss = 0.70822077
Iteration 884, loss = 0.70801305
Iteration 885, loss = 0.70721433
Iteration 886, loss = 0.70729498
Iteration 887, loss = 0.70640512
Iteration 888, loss = 0.70634077
Iteration 889, loss = 0.70574882
Iteration 890, loss = 0.70536819
Iteration 891, loss = 0.70508739
Iteration 892, loss = 0.70416997
Iteration 893, loss = 0.70363551
Iteration 894, loss = 0.70261356
Iteration 895, loss = 0.70187289
Iteration 896, loss = 0.70096492
Iteration 897, loss = 0.70006226
Iteration 898, loss = 0.69948680
Iteration 899, loss = 0.69797969
Iteration 900, loss = 0.69739607
Iteration 901, loss = 0.69692788
Iteration 902, loss = 0.69550433
Iteration 903, loss = 0.69251190
Iteration 904, loss = 0.68977181
Iteration 905, loss = 0.68818651
Iteration 906, loss = 0.68281950
Iteration 907, loss = 0.62911733
Iteration 908, loss = 0.88475321
Iteration 909, loss = 0.76116399
Iteration 910, loss = 0.77578008
Iteration 911, loss = 0.76395597
Iteration 912, loss = 0.86701046
Iteration 913, loss = 0.80883823
Iteration 914, loss = 0.95554801
Iteration 915, loss = 0.75205901
Iteration 916, loss = 0.85111750
Iteration 917, loss = 0.84536045
Iteration 918, loss = 0.73907232
Iteration 919, loss = 0.86303905
Iteration 920, loss = 0.76673052
Iteration 921, loss = 0.78579576
Iteration 922, loss = 0.82047623
Iteration 923, loss = 0.73359758
Iteration 924, loss = 0.80279049
Iteration 925, loss = 0.75826898
Iteration 926, loss = 0.74813981
Iteration 927, loss = 0.78304509
Iteration 928, loss = 0.72936776
Iteration 929, loss = 0.76797802
Iteration 930, loss = 0.75090009
Iteration 931, loss = 0.73687371
Iteration 932, loss = 0.76254832
Iteration 933, loss = 0.72957982
Iteration 934, loss = 0.74838819
Iteration 935, loss = 0.74120856
Iteration 936, loss = 0.72988893
Iteration 937, loss = 0.74686183
Iteration 938, loss = 0.72782868
Iteration 939, loss = 0.73793737
Iteration 940, loss = 0.73492570
Iteration 941, loss = 0.72662593
Iteration 942, loss = 0.73640612
Iteration 943, loss = 0.72450933
Iteration 944, loss = 0.72956808
Iteration 945, loss = 0.72776477
Iteration 946, loss = 0.72118789
Iteration 947, loss = 0.71091702
Iteration 948, loss = 0.76925104
Iteration 949, loss = 0.76827177
Iteration 950, loss = 0.77833015
Iteration 951, loss = 0.74608327
Iteration 952, loss = 0.76384232
Iteration 953, loss = 0.73083911
Iteration 954, loss = 0.76233825
Iteration 955, loss = 0.73107542
Iteration 956, loss = 0.75954672
Iteration 957, loss = 0.72824918
Iteration 958, loss = 0.75160421
Iteration 959, loss = 0.72648377
Iteration 960, loss = 0.74512717
Iteration 961, loss = 0.72773809
Iteration 962, loss = 0.73986866
Iteration 963, loss = 0.72881131
Iteration 964, loss = 0.73508526
Iteration 965, loss = 0.72882352
Iteration 966, loss = 0.77218862
Iteration 967, loss = 0.73578274
Iteration 968, loss = 0.73214555
Iteration 969, loss = 0.74084105
Iteration 970, loss = 0.74268609
Iteration 971, loss = 0.73853234
Iteration 972, loss = 0.73238361
Iteration 973, loss = 0.72784497
Iteration 974, loss = 0.72632272
Iteration 975, loss = 0.72776140
Iteration 976, loss = 0.72992009
Iteration 977, loss = 0.73125560
Iteration 978, loss = 0.73101603
Iteration 979, loss = 0.72985378
Iteration 980, loss = 0.72845167
Iteration 981, loss = 0.72741892
Iteration 982, loss = 0.72688946
Iteration 983, loss = 0.72660353
Iteration 984, loss = 0.72641484
Iteration 985, loss = 0.72616161
Iteration 986, loss = 0.72586594
Iteration 987, loss = 0.71962242
Iteration 988, loss = 0.73077334
Iteration 989, loss = 0.73323921
Iteration 990, loss = 0.73734325
Iteration 991, loss = 0.73654581
Iteration 992, loss = 0.73564170
Iteration 993, loss = 0.73389592
Iteration 994, loss = 0.73173293
Iteration 995, loss = 0.73076409
Iteration 996, loss = 0.72836721
Iteration 997, loss = 0.72803487
Iteration 998, loss = 0.72714022
Iteration 999, loss = 0.72851373
Iteration 1000, loss = 0.72839477
Iteration 1001, loss = 0.72900377
Iteration 1002, loss = 0.72837233
Iteration 1003, loss = 0.72795231
Iteration 1004, loss = 0.72739935
Iteration 1005, loss = 0.72691437
Iteration 1006, loss = 0.72670476
Iteration 1007, loss = 0.72608636
Iteration 1008, loss = 0.72596149
Iteration 1009, loss = 0.72520726
Iteration 1010, loss = 0.72495046
Iteration 1011, loss = 0.72432652
Iteration 1012, loss = 0.72419848
Iteration 1013, loss = 0.72383976
Iteration 1014, loss = 0.72367828
Iteration 1015, loss = 0.72335567
Iteration 1016, loss = 0.72301673
Iteration 1017, loss = 0.72268133
Iteration 1018, loss = 0.72224151
Iteration 1019, loss = 0.72190032
Iteration 1020, loss = 0.72140399
Iteration 1021, loss = 0.72106488
Iteration 1022, loss = 0.72061197
Iteration 1023, loss = 0.72034471
Iteration 1024, loss = 0.72002477
Iteration 1025, loss = 0.71981460
Iteration 1026, loss = 0.71950924
Iteration 1027, loss = 0.71920049
Iteration 1028, loss = 0.71883853
Iteration 1029, loss = 0.71847633
Iteration 1030, loss = 0.71815539
Iteration 1031, loss = 0.71784209
Iteration 1032, loss = 0.71758044
Iteration 1033, loss = 0.71728379
Iteration 1034, loss = 0.71701176
Iteration 1035, loss = 0.71668493
Iteration 1036, loss = 0.71638469
Iteration 1037, loss = 0.71605265
Iteration 1038, loss = 0.71573444
Iteration 1039, loss = 0.71537592
Iteration 1040, loss = 0.71500694
Iteration 1041, loss = 0.71464280
Iteration 1042, loss = 0.71431594
Iteration 1043, loss = 0.71397737
Iteration 1044, loss = 0.71356958
Iteration 1045, loss = 0.71307041
Iteration 1046, loss = 0.71250153
Iteration 1047, loss = 0.71221706
Iteration 1048, loss = 0.71201476
Iteration 1049, loss = 0.71169619
Iteration 1050, loss = 0.71131543
Iteration 1051, loss = 0.71101922
Iteration 1052, loss = 0.71077443
Iteration 1053, loss = 0.71042394
Iteration 1054, loss = 0.70998780
Iteration 1055, loss = 0.70972795
Iteration 1056, loss = 0.70948145
Iteration 1057, loss = 0.70907715
Iteration 1058, loss = 0.70859848
Iteration 1059, loss = 0.70813807
Iteration 1060, loss = 0.70763199
Iteration 1061, loss = 0.70702627
Iteration 1062, loss = 0.70627931
Iteration 1063, loss = 0.70509049
Iteration 1064, loss = 0.70346362
Iteration 1065, loss = 0.70007884
Iteration 1066, loss = 0.69441042
Iteration 1067, loss = 0.66742322
Iteration 1068, loss = 0.95281599
Iteration 1069, loss = 0.76544529
Iteration 1070, loss = 0.99089698
Iteration 1071, loss = 0.76121134
Iteration 1072, loss = 0.86582676
Iteration 1073, loss = 0.86623296
Iteration 1074, loss = 0.72786384
Iteration 1075, loss = 0.87593967
Iteration 1076, loss = 0.75181269
Iteration 1077, loss = 0.79597736
Iteration 1078, loss = 0.82059367
Iteration 1079, loss = 0.72787815
Iteration 1080, loss = 0.81701771
Iteration 1081, loss = 0.74645211
Iteration 1082, loss = 0.76101646
Iteration 1083, loss = 0.78364555
Iteration 1084, loss = 0.72516940
Iteration 1085, loss = 0.77871148
Iteration 1086, loss = 0.73945036
Iteration 1087, loss = 0.74479159
Iteration 1088, loss = 0.76105370
Iteration 1089, loss = 0.72539892
Iteration 1090, loss = 0.75708674
Iteration 1091, loss = 0.73421313
Iteration 1092, loss = 0.73630388
Iteration 1093, loss = 0.74596505
Iteration 1094, loss = 0.72402522
Iteration 1095, loss = 0.74233600
Iteration 1096, loss = 0.72836991
Iteration 1097, loss = 0.72997147
Iteration 1098, loss = 0.73573212
Iteration 1099, loss = 0.72309208
Iteration 1100, loss = 0.73399632
Iteration 1101, loss = 0.72503479
Iteration 1102, loss = 0.72599504
Iteration 1103, loss = 0.72856441
Iteration 1104, loss = 0.72108551
Iteration 1105, loss = 0.72754222
Iteration 1106, loss = 0.72190352
Iteration 1107, loss = 0.72289937
Iteration 1108, loss = 0.72386964
Iteration 1109, loss = 0.71948794
Iteration 1110, loss = 0.72311606
Iteration 1111, loss = 0.71936787
Iteration 1112, loss = 0.72019970
Iteration 1113, loss = 0.72030917
Iteration 1114, loss = 0.71780576
Iteration 1115, loss = 0.71976919
Iteration 1116, loss = 0.71723768
Iteration 1117, loss = 0.71784124
Iteration 1118, loss = 0.71752028
Iteration 1119, loss = 0.71613203
Iteration 1120, loss = 0.71697160
Iteration 1121, loss = 0.71586233
Iteration 1122, loss = 0.71565764
Iteration 1123, loss = 0.71576347
Iteration 1124, loss = 0.71498453
Iteration 1125, loss = 0.71461557
Iteration 1126, loss = 0.71422362
Iteration 1127, loss = 0.71369780
Iteration 1128, loss = 0.71364268
Iteration 1129, loss = 0.71328866
Iteration 1130, loss = 0.71289305
Iteration 1131, loss = 0.71274380
Iteration 1132, loss = 0.71231777
Iteration 1133, loss = 0.71197951
Iteration 1134, loss = 0.71170473
Iteration 1135, loss = 0.71123529
Iteration 1136, loss = 0.71088199
Iteration 1137, loss = 0.71044545
Iteration 1138, loss = 0.70982554
Iteration 1139, loss = 0.70916886
Iteration 1140, loss = 0.70806136
Iteration 1141, loss = 0.70585842
Iteration 1142, loss = 0.69905632
Iteration 1143, loss = 0.71903349
Iteration 1144, loss = 0.75393500
Iteration 1145, loss = 0.68520503
Iteration 1146, loss = 0.74228234
Iteration 1147, loss = 0.76188617
Iteration 1148, loss = 0.73908472
Iteration 1149, loss = 0.76131926
Iteration 1150, loss = 0.72188881
Iteration 1151, loss = 0.74541493
Iteration 1152, loss = 0.71944518
Iteration 1153, loss = 0.73684928
Iteration 1154, loss = 0.72184088
Iteration 1155, loss = 0.73250500
Iteration 1156, loss = 0.72454863
Iteration 1157, loss = 0.72392486
Iteration 1158, loss = 0.71736552
Iteration 1159, loss = 0.87743793
Iteration 1160, loss = 0.75165180
Iteration 1161, loss = 0.77594073
Iteration 1162, loss = 0.78790815
Iteration 1163, loss = 0.80102048
Iteration 1164, loss = 0.77785548
Iteration 1165, loss = 0.76273007
Iteration 1166, loss = 0.75321885
Iteration 1167, loss = 0.74469995
Iteration 1168, loss = 0.75713233
Iteration 1169, loss = 0.75802412
Iteration 1170, loss = 0.76578683
Iteration 1171, loss = 0.76922316
Iteration 1172, loss = 0.76518582
Iteration 1173, loss = 0.76888126
Iteration 1174, loss = 0.76446336
Iteration 1175, loss = 0.76555648
Iteration 1176, loss = 0.76588090
Iteration 1177, loss = 0.76473037
Iteration 1178, loss = 0.76732789
Iteration 1179, loss = 0.76596309
Iteration 1180, loss = 0.76732110
Iteration 1181, loss = 0.76756052
Iteration 1182, loss = 0.76644643
Iteration 1183, loss = 0.76761028
Iteration 1184, loss = 0.76683222
Iteration 1185, loss = 0.76675347
Iteration 1186, loss = 0.76728392
Iteration 1187, loss = 0.76615950
Iteration 1188, loss = 0.76583684
Iteration 1189, loss = 0.76460801
Iteration 1190, loss = 0.76326166
Iteration 1191, loss = 0.76295480
Iteration 1192, loss = 0.76174273
Iteration 1193, loss = 0.76083731
Iteration 1194, loss = 0.75989586
Iteration 1195, loss = 0.75823676
Iteration 1196, loss = 0.75515509
Iteration 1197, loss = 0.79815356
Iteration 1198, loss = 0.77242241
Iteration 1199, loss = 0.80160233
Iteration 1200, loss = 0.77249764
Iteration 1201, loss = 0.78435173
Iteration 1202, loss = 0.78182258
Iteration 1203, loss = 0.76840977
Iteration 1204, loss = 0.78434908
Iteration 1205, loss = 0.76669677
Iteration 1206, loss = 0.77667089
Iteration 1207, loss = 0.77283867
Iteration 1208, loss = 0.76738204
Iteration 1209, loss = 0.77562083
Iteration 1210, loss = 0.76476630
Iteration 1211, loss = 0.77174593
Iteration 1212, loss = 0.76735489
Iteration 1213, loss = 0.76549866
Iteration 1214, loss = 0.76880124
Iteration 1215, loss = 0.76213844
Iteration 1216, loss = 0.76643406
Iteration 1217, loss = 0.76240665
Iteration 1218, loss = 0.76227896
Iteration 1219, loss = 0.76308871
Iteration 1220, loss = 0.75936008
Iteration 1221, loss = 0.76179871
Iteration 1222, loss = 0.75862508
Iteration 1223, loss = 0.75907961
Iteration 1224, loss = 0.75861171
Iteration 1225, loss = 0.75659091
Iteration 1226, loss = 0.75764151
Iteration 1227, loss = 0.75525915
Iteration 1228, loss = 0.75566338
Iteration 1229, loss = 0.75465764
Iteration 1230, loss = 0.75360633
Iteration 1231, loss = 0.75380918
Iteration 1232, loss = 0.75216839
Iteration 1233, loss = 0.75238189
Iteration 1234, loss = 0.75130752
Iteration 1235, loss = 0.75076173
Iteration 1236, loss = 0.75049372
Iteration 1237, loss = 0.74940639
Iteration 1238, loss = 0.74938184
Iteration 1239, loss = 0.74841434
Iteration 1240, loss = 0.74806275
Iteration 1241, loss = 0.74755729
Iteration 1242, loss = 0.74682417
Iteration 1243, loss = 0.74660224
Iteration 1244, loss = 0.74581150
Iteration 1245, loss = 0.74551866
Iteration 1246, loss = 0.74495284
Iteration 1247, loss = 0.74444151
Iteration 1248, loss = 0.74410316
Iteration 1249, loss = 0.74348671
Iteration 1250, loss = 0.74318827
Iteration 1251, loss = 0.74263853
Iteration 1252, loss = 0.74204501
Iteration 1253, loss = 0.74215393
Iteration 1254, loss = 0.74185959
Iteration 1255, loss = 0.74177474
Iteration 1256, loss = 0.74117177
Iteration 1257, loss = 0.74058103
Iteration 1258, loss = 0.73999971
Iteration 1259, loss = 0.73945145
Iteration 1260, loss = 0.73920863
Iteration 1261, loss = 0.73882900
Iteration 1262, loss = 0.73856836
Iteration 1263, loss = 0.73816553
Iteration 1264, loss = 0.73773871
Iteration 1265, loss = 0.73737099
Iteration 1266, loss = 0.73693613
Iteration 1267, loss = 0.73662354
Iteration 1268, loss = 0.73624219
Iteration 1269, loss = 0.73591404
Iteration 1270, loss = 0.73558249
Iteration 1271, loss = 0.73522856
Iteration 1272, loss = 0.73492268
Iteration 1273, loss = 0.73456308
Iteration 1274, loss = 0.73424843
Iteration 1275, loss = 0.73390991
Iteration 1276, loss = 0.73358591
Iteration 1277, loss = 0.73328024
Iteration 1278, loss = 0.73295645
Iteration 1279, loss = 0.73266271
Iteration 1280, loss = 0.73234570
Iteration 1281, loss = 0.73204766
Iteration 1282, loss = 0.73174627
Iteration 1283, loss = 0.73144452
Iteration 1284, loss = 0.73115620
Iteration 1285, loss = 0.73085629
Iteration 1286, loss = 0.73057278
Iteration 1287, loss = 0.73028238
Iteration 1288, loss = 0.73000046
Iteration 1289, loss = 0.72972179
Iteration 1290, loss = 0.72944093
Iteration 1291, loss = 0.72916850
Iteration 1292, loss = 0.72889023
Iteration 1293, loss = 0.72861995
Iteration 1294, loss = 0.72834867
Iteration 1295, loss = 0.72808148
Iteration 1296, loss = 0.72781866
Iteration 1297, loss = 0.72755503
Iteration 1298, loss = 0.72729675
Iteration 1299, loss = 0.72703635
Iteration 1300, loss = 0.72678001
Iteration 1301, loss = 0.72652448
Iteration 1302, loss = 0.72627116
Iteration 1303, loss = 0.72602138
Iteration 1304, loss = 0.72577194
Iteration 1305, loss = 0.72552616
Iteration 1306, loss = 0.72528036
Iteration 1307, loss = 0.72503714
Iteration 1308, loss = 0.72479530
Iteration 1309, loss = 0.72455508
Iteration 1310, loss = 0.72431751
Iteration 1311, loss = 0.72408088
Iteration 1312, loss = 0.72384689
Iteration 1313, loss = 0.72361382
Iteration 1314, loss = 0.72338273
Iteration 1315, loss = 0.72315319
Iteration 1316, loss = 0.72292510
Iteration 1317, loss = 0.72269910
Iteration 1318, loss = 0.72247430
Iteration 1319, loss = 0.72225154
Iteration 1320, loss = 0.72203001
Iteration 1321, loss = 0.72181012
Iteration 1322, loss = 0.72159171
Iteration 1323, loss = 0.72137468
Iteration 1324, loss = 0.72115936
Iteration 1325, loss = 0.72094532
Iteration 1326, loss = 0.72073295
Iteration 1327, loss = 0.72052186
Iteration 1328, loss = 0.72031225
Iteration 1329, loss = 0.72010406
Iteration 1330, loss = 0.71989725
Iteration 1331, loss = 0.71969200
Iteration 1332, loss = 0.71948808
Iteration 1333, loss = 0.71928568
Iteration 1334, loss = 0.71908462
Iteration 1335, loss = 0.71888498
Iteration 1336, loss = 0.71868673
Iteration 1337, loss = 0.71848984
Iteration 1338, loss = 0.71829437
Iteration 1339, loss = 0.71810020
Iteration 1340, loss = 0.71790741
Iteration 1341, loss = 0.71771587
Iteration 1342, loss = 0.71752562
Iteration 1343, loss = 0.71733662
Iteration 1344, loss = 0.71714884
Iteration 1345, loss = 0.71696226
Iteration 1346, loss = 0.71677682
Iteration 1347, loss = 0.71659253
Iteration 1348, loss = 0.71640932
Iteration 1349, loss = 0.71622716
Iteration 1350, loss = 0.71604600
Iteration 1351, loss = 0.71586578
Iteration 1352, loss = 0.71568646
Iteration 1353, loss = 0.71550795
Iteration 1354, loss = 0.71533018
Iteration 1355, loss = 0.71515303
Iteration 1356, loss = 0.71497636
Iteration 1357, loss = 0.71480000
Iteration 1358, loss = 0.71462373
Iteration 1359, loss = 0.71444726
Iteration 1360, loss = 0.71427020
Iteration 1361, loss = 0.71409209
Iteration 1362, loss = 0.71391233
Iteration 1363, loss = 0.71373025
Iteration 1364, loss = 0.71354522
Iteration 1365, loss = 0.71335687
Iteration 1366, loss = 0.71316540
Iteration 1367, loss = 0.71297156
Iteration 1368, loss = 0.71277600
Iteration 1369, loss = 0.71257820
Iteration 1370, loss = 0.71237609
Iteration 1371, loss = 0.71216651
Iteration 1372, loss = 0.71194467
Iteration 1373, loss = 0.71170342
Iteration 1374, loss = 0.71144147
Iteration 1375, loss = 0.71119179
Iteration 1376, loss = 0.71098606
Iteration 1377, loss = 0.71077463
Iteration 1378, loss = 0.71051989
Iteration 1379, loss = 0.71024728
Iteration 1380, loss = 0.70999129
Iteration 1381, loss = 0.70975185
Iteration 1382, loss = 0.70950950
Iteration 1383, loss = 0.70926337
Iteration 1384, loss = 0.70902387
Iteration 1385, loss = 0.70879286
Iteration 1386, loss = 0.70857397
Iteration 1387, loss = 0.70834410
Iteration 1388, loss = 0.70799562
Iteration 1389, loss = 0.70764613
Iteration 1390, loss = 0.70740950
Iteration 1391, loss = 0.70709089
Iteration 1392, loss = 0.70683708
Iteration 1393, loss = 0.70646833
Iteration 1394, loss = 0.70593191
Iteration 1395, loss = 0.70570061
Iteration 1396, loss = 0.70541579
Iteration 1397, loss = 0.70482857
Iteration 1398, loss = 0.70511089
Iteration 1399, loss = 0.70533810
Iteration 1400, loss = 0.70559513
Iteration 1401, loss = 0.70519800
Iteration 1402, loss = 0.70992756
Iteration 1403, loss = 0.70328926
Iteration 1404, loss = 0.71055455
Iteration 1405, loss = 0.70292526
Iteration 1406, loss = 0.71041087
Iteration 1407, loss = 0.70304622
Iteration 1408, loss = 0.70667113
Iteration 1409, loss = 0.70268307
Iteration 1410, loss = 0.70160269
Iteration 1411, loss = 0.70084528
Iteration 1412, loss = 0.67799025
Iteration 1413, loss = 0.71647772
Iteration 1414, loss = 0.73746404
Iteration 1415, loss = 0.74063013
Iteration 1416, loss = 0.74040071
Iteration 1417, loss = 0.73978599
Iteration 1418, loss = 0.72533237
Iteration 1419, loss = 0.73161154
Iteration 1420, loss = 0.71346334
Iteration 1421, loss = 0.70761954
Iteration 1422, loss = 0.98496316
Iteration 1423, loss = 1.04265131
Iteration 1424, loss = 1.00737261
Iteration 1425, loss = 0.72537136
Iteration 1426, loss = 0.79622880
Iteration 1427, loss = 0.86262257
Iteration 1428, loss = 0.82419618
Iteration 1429, loss = 0.83627347
Iteration 1430, loss = 0.82033618
Iteration 1431, loss = 0.80000913
Iteration 1432, loss = 0.81586311
Iteration 1433, loss = 0.78675424
Iteration 1434, loss = 0.81683022
Iteration 1435, loss = 0.74725480
Iteration 1436, loss = 0.82804793
Iteration 1437, loss = 0.87588520
Iteration 1438, loss = 0.86683997
Iteration 1439, loss = 0.83483708
Iteration 1440, loss = 0.87211334
Iteration 1441, loss = 0.81867893
Iteration 1442, loss = 0.85492519
Iteration 1443, loss = 0.82222006
Iteration 1444, loss = 0.83403320
Iteration 1445, loss = 0.83457782
Iteration 1446, loss = 0.81811474
Iteration 1447, loss = 0.83987219
Iteration 1448, loss = 0.81375054
Iteration 1449, loss = 0.83245257
Iteration 1450, loss = 0.81587309
Iteration 1451, loss = 0.81962323
Iteration 1452, loss = 0.81996178
Iteration 1453, loss = 0.81061239
Iteration 1454, loss = 0.82006181
Iteration 1455, loss = 0.80587140
Iteration 1456, loss = 0.81316274
Iteration 1457, loss = 0.80344946
Iteration 1458, loss = 0.80275786
Iteration 1459, loss = 0.75596823
Iteration 1460, loss = 0.81218547
Iteration 1461, loss = 0.81959642
Iteration 1462, loss = 0.82665839
Iteration 1463, loss = 0.82077657
Iteration 1464, loss = 0.81334070
Iteration 1465, loss = 0.80636658
Iteration 1466, loss = 0.80005842
Iteration 1467, loss = 0.80094180
Iteration 1468, loss = 0.80156088
Iteration 1469, loss = 0.80361911
Iteration 1470, loss = 0.80328645
Iteration 1471, loss = 0.80038929
Iteration 1472, loss = 0.79860732
Iteration 1473, loss = 0.79642210
Iteration 1474, loss = 0.79568479
Iteration 1475, loss = 0.79468122
Iteration 1476, loss = 0.79293293
Iteration 1477, loss = 0.79209486
Iteration 1478, loss = 0.79042514
Iteration 1479, loss = 0.78960660
Iteration 1480, loss = 0.78866123
Iteration 1481, loss = 0.78741346
Iteration 1482, loss = 0.78662141
Iteration 1483, loss = 0.78517876
Iteration 1484, loss = 0.78413591
Iteration 1485, loss = 0.78291004
Iteration 1486, loss = 0.78159011
Iteration 1487, loss = 0.78060378
Iteration 1488, loss = 0.77934953
Iteration 1489, loss = 0.77846578
Iteration 1490, loss = 0.77751068
Iteration 1491, loss = 0.77653631
Iteration 1492, loss = 0.77565737
Iteration 1493, loss = 0.77451774
Iteration 1494, loss = 0.77353445
Iteration 1495, loss = 0.77248598
Iteration 1496, loss = 0.77152153
Iteration 1497, loss = 0.77068121
Iteration 1498, loss = 0.76973180
Iteration 1499, loss = 0.76886627
Iteration 1500, loss = 0.76799385
Iteration 1501, loss = 0.76716688
Iteration 1502, loss = 0.76631432
Iteration 1503, loss = 0.76538271
Iteration 1504, loss = 0.76457634
Iteration 1505, loss = 0.76382399
Iteration 1506, loss = 0.76312032
Iteration 1507, loss = 0.76238064
Iteration 1508, loss = 0.76158047
Iteration 1509, loss = 0.76083993
Iteration 1510, loss = 0.76011410
Iteration 1511, loss = 0.75943027
Iteration 1512, loss = 0.75875272
Iteration 1513, loss = 0.75807796
Iteration 1514, loss = 0.75744361
Iteration 1515, loss = 0.75679577
Iteration 1516, loss = 0.75614935
Iteration 1517, loss = 0.75547748
Iteration 1518, loss = 0.75475148
Iteration 1519, loss = 0.75357177
Iteration 1520, loss = 0.75390252
Iteration 1521, loss = 0.76198416
Iteration 1522, loss = 0.75848767
Iteration 1523, loss = 0.75999890
Iteration 1524, loss = 0.76147639
Iteration 1525, loss = 0.75333519
Iteration 1526, loss = 0.75642832
Iteration 1527, loss = 0.74985159
Iteration 1528, loss = 0.74953638
Iteration 1529, loss = 0.74687405
Iteration 1530, loss = 0.73620804
Iteration 1531, loss = 0.77839031
Iteration 1532, loss = 0.98867662
Iteration 1533, loss = 0.88438246
Iteration 1534, loss = 0.89543535
Iteration 1535, loss = 1.00662942
Iteration 1536, loss = 0.84178787
Iteration 1537, loss = 0.93659617
Iteration 1538, loss = 0.88425018
Iteration 1539, loss = 0.80912308
Iteration 1540, loss = 0.88839277
Iteration 1541, loss = 0.79392371
Iteration 1542, loss = 0.83580682
Iteration 1543, loss = 0.84453495
Iteration 1544, loss = 0.79303448
Iteration 1545, loss = 0.85374951
Iteration 1546, loss = 0.80831429
Iteration 1547, loss = 0.81974113
Iteration 1548, loss = 0.83576639
Iteration 1549, loss = 0.79708759
Iteration 1550, loss = 0.83060935
Iteration 1551, loss = 0.80665257
Iteration 1552, loss = 0.80455883
Iteration 1553, loss = 0.81767896
Iteration 1554, loss = 0.79180245
Iteration 1555, loss = 0.81002186
Iteration 1556, loss = 0.79898160
Iteration 1557, loss = 0.79503519
Iteration 1558, loss = 0.80567562
Iteration 1559, loss = 0.79052165
Iteration 1560, loss = 0.80048281
Iteration 1561, loss = 0.79575840
Iteration 1562, loss = 0.79168580
Iteration 1563, loss = 0.79771265
Iteration 1564, loss = 0.78678329
Iteration 1565, loss = 0.78747115
Iteration 1566, loss = 0.88131086
Iteration 1567, loss = 0.79769258
Iteration 1568, loss = 0.89127763
Iteration 1569, loss = 0.76054499
Iteration 1570, loss = 0.80605213
Iteration 1571, loss = 0.90209852
Iteration 1572, loss = 0.88219163
Iteration 1573, loss = 0.80479515
Iteration 1574, loss = 0.89393079
Iteration 1575, loss = 0.81849630
Iteration 1576, loss = 0.83709292
Iteration 1577, loss = 0.86741408
Iteration 1578, loss = 0.80425952
Iteration 1579, loss = 0.85723284
Iteration 1580, loss = 0.82902673
Iteration 1581, loss = 0.81028789
Iteration 1582, loss = 0.85025358
Iteration 1583, loss = 0.82451939
Iteration 1584, loss = 0.81837891
Iteration 1585, loss = 0.84096218
Iteration 1586, loss = 0.81391344
Iteration 1587, loss = 0.82283824
Iteration 1588, loss = 0.83152472
Iteration 1589, loss = 0.81140618
Iteration 1590, loss = 0.82486090
Iteration 1591, loss = 0.82220948
Iteration 1592, loss = 0.81109318
Iteration 1593, loss = 0.82268967
Iteration 1594, loss = 0.81406828
Iteration 1595, loss = 0.81059305
Iteration 1596, loss = 0.81741444
Iteration 1597, loss = 0.80818615
Iteration 1598, loss = 0.80991986
Iteration 1599, loss = 0.81170451
Iteration 1600, loss = 0.80436068
Iteration 1601, loss = 0.80773257
Iteration 1602, loss = 0.80578565
Iteration 1603, loss = 0.80144245
Iteration 1604, loss = 0.80413214
Iteration 1605, loss = 0.80026946
Iteration 1606, loss = 0.79854577
Iteration 1607, loss = 0.79968619
Iteration 1608, loss = 0.79582374
Iteration 1609, loss = 0.79579654
Iteration 1610, loss = 0.79529176
Iteration 1611, loss = 0.79218072
Iteration 1612, loss = 0.79245874
Iteration 1613, loss = 0.79074385
Iteration 1614, loss = 0.78880431
Iteration 1615, loss = 0.78892772
Iteration 1616, loss = 0.78685514
Iteration 1617, loss = 0.78579241
Iteration 1618, loss = 0.78530316
Iteration 1619, loss = 0.78333732
Iteration 1620, loss = 0.78275220
Iteration 1621, loss = 0.78175977
Iteration 1622, loss = 0.78021468
Iteration 1623, loss = 0.77973774
Iteration 1624, loss = 0.77846474
Iteration 1625, loss = 0.77734242
Iteration 1626, loss = 0.77673764
Iteration 1627, loss = 0.77544411
Iteration 1628, loss = 0.77463414
Iteration 1629, loss = 0.77385062
Iteration 1630, loss = 0.77269916
Iteration 1631, loss = 0.77202936
Iteration 1632, loss = 0.77111413
Iteration 1633, loss = 0.77015191
Iteration 1634, loss = 0.76949583
Iteration 1635, loss = 0.76855948
Iteration 1636, loss = 0.76777491
Iteration 1637, loss = 0.76707783
Iteration 1638, loss = 0.76619078
Iteration 1639, loss = 0.76550786
Iteration 1640, loss = 0.76477140
Iteration 1641, loss = 0.76398074
Iteration 1642, loss = 0.76334400
Iteration 1643, loss = 0.76260181
Iteration 1644, loss = 0.76190424
Iteration 1645, loss = 0.76127515
Iteration 1646, loss = 0.76056298
Iteration 1647, loss = 0.75993588
Iteration 1648, loss = 0.75930747
Iteration 1649, loss = 0.75864752
Iteration 1650, loss = 0.75806183
Iteration 1651, loss = 0.75744168
Iteration 1652, loss = 0.75683611
Iteration 1653, loss = 0.75627212
Iteration 1654, loss = 0.75567578
Iteration 1655, loss = 0.75511650
Iteration 1656, loss = 0.75456650
Iteration 1657, loss = 0.75400315
Iteration 1658, loss = 0.75347609
Iteration 1659, loss = 0.75294062
Iteration 1660, loss = 0.75241235
Iteration 1661, loss = 0.75190783
Iteration 1662, loss = 0.75139287
Iteration 1663, loss = 0.75089578
Iteration 1664, loss = 0.75040765
Iteration 1665, loss = 0.74991626
Iteration 1666, loss = 0.74944396
Iteration 1667, loss = 0.74897202
Iteration 1668, loss = 0.74850530
Iteration 1669, loss = 0.74805219
Iteration 1670, loss = 0.74759756
Iteration 1671, loss = 0.74715323
Iteration 1672, loss = 0.74671595
Iteration 1673, loss = 0.74627972
Iteration 1674, loss = 0.74585413
Iteration 1675, loss = 0.74543003
Iteration 1676, loss = 0.74498344
Iteration 1677, loss = 0.74431334
Iteration 1678, loss = 0.74341829
Iteration 1679, loss = 0.73817116
Iteration 1680, loss = 0.74605037
Iteration 1681, loss = 0.74688423
Iteration 1682, loss = 0.74744220
Iteration 1683, loss = 0.74630858
Iteration 1684, loss = 0.74458178
Iteration 1685, loss = 0.74423141
Iteration 1686, loss = 0.74403467
Iteration 1687, loss = 0.74446555
Iteration 1688, loss = 0.74485183
Iteration 1689, loss = 0.74455129
Iteration 1690, loss = 0.74447406
Iteration 1691, loss = 0.74416849
Iteration 1692, loss = 0.74383295
Iteration 1693, loss = 0.74374489
Iteration 1694, loss = 0.74337186
Iteration 1695, loss = 0.74314564
Iteration 1696, loss = 0.74297996
Iteration 1697, loss = 0.74269776
Iteration 1698, loss = 0.74258804
Iteration 1699, loss = 0.74230907
Iteration 1700, loss = 0.74193031
Iteration 1701, loss = 0.74158891
Iteration 1702, loss = 0.74113961
Iteration 1703, loss = 0.74081758
Iteration 1704, loss = 0.74053444
Iteration 1705, loss = 0.74019042
Iteration 1706, loss = 0.73988695
Iteration 1707, loss = 0.73949386
Iteration 1708, loss = 0.73909170
Iteration 1709, loss = 0.73872119
Iteration 1710, loss = 0.73830265
Iteration 1711, loss = 0.73792962
Iteration 1712, loss = 0.73756068
Iteration 1713, loss = 0.73718124
Iteration 1714, loss = 0.73681324
Iteration 1715, loss = 0.73555902
Iteration 1716, loss = 0.73830365
Iteration 1717, loss = 0.74055159
Iteration 1718, loss = 0.74005537
Iteration 1719, loss = 0.73762390
Iteration 1720, loss = 0.73568396
Iteration 1721, loss = 0.73548310
Iteration 1722, loss = 0.73597210
Iteration 1723, loss = 0.73572463
Iteration 1724, loss = 0.73503242
Iteration 1725, loss = 0.73451138
Iteration 1726, loss = 0.73412199
Iteration 1727, loss = 0.73351577
Iteration 1728, loss = 0.73292590
Iteration 1729, loss = 0.73255622
Iteration 1730, loss = 0.73231139
Iteration 1731, loss = 0.73201659
Iteration 1732, loss = 0.73149268
Iteration 1733, loss = 0.73080424
Iteration 1734, loss = 0.73034872
Iteration 1735, loss = 0.73021388
Iteration 1736, loss = 0.73005959
Iteration 1737, loss = 0.72962641
Iteration 1738, loss = 0.72905743
Iteration 1739, loss = 0.72867429
Iteration 1740, loss = 0.72842801
Iteration 1741, loss = 0.72805479
Iteration 1742, loss = 0.72770481
Iteration 1743, loss = 0.72730418
Iteration 1744, loss = 0.72697093
Iteration 1745, loss = 0.72681377
Iteration 1746, loss = 0.72640365
Iteration 1747, loss = 0.72603631
Iteration 1748, loss = 0.72576835
Iteration 1749, loss = 0.72547049
Iteration 1750, loss = 0.72521077
Iteration 1751, loss = 0.72492434
Iteration 1752, loss = 0.72456531
Iteration 1753, loss = 0.72430356
Iteration 1754, loss = 0.72402463
Iteration 1755, loss = 0.72375286
Iteration 1756, loss = 0.72352888
Iteration 1757, loss = 0.72322985
Iteration 1758, loss = 0.72295308
Iteration 1759, loss = 0.72267278
Iteration 1760, loss = 0.72213389
Iteration 1761, loss = 0.72188284
Iteration 1762, loss = 0.72163285
Iteration 1763, loss = 0.72131264
Iteration 1764, loss = 0.72104903
Iteration 1765, loss = 0.72083261
Iteration 1766, loss = 0.72074905
Iteration 1767, loss = 0.72051183
Iteration 1768, loss = 0.72006878
Iteration 1769, loss = 0.71997586
Iteration 1770, loss = 0.71955912
Iteration 1771, loss = 0.71992017
Iteration 1772, loss = 0.71913652
Iteration 1773, loss = 0.71849503
Iteration 1774, loss = 0.71783578
Iteration 1775, loss = 0.71732527
Iteration 1776, loss = 0.71671258
Iteration 1777, loss = 0.71606326
Iteration 1778, loss = 0.71523288
Iteration 1779, loss = 0.71466547
Iteration 1780, loss = 0.71321703
Iteration 1781, loss = 0.71041995
Iteration 1782, loss = 0.70040002
Iteration 1783, loss = 0.58882767
Iteration 1784, loss = 0.79071811
Iteration 1785, loss = 0.76141047
Iteration 1786, loss = 0.81921432
Iteration 1787, loss = 0.72797034
Iteration 1788, loss = 0.79726323
Iteration 1789, loss = 0.72580311
Iteration 1790, loss = 0.79295250
Iteration 1791, loss = 0.78757153
Iteration 1792, loss = 0.75547699
Iteration 1793, loss = 0.79171786
Iteration 1794, loss = 0.75225558
Iteration 1795, loss = 0.76078781
Iteration 1796, loss = 0.77876373
Iteration 1797, loss = 0.75167011
Iteration 1798, loss = 0.77478652
Iteration 1799, loss = 0.76441522
Iteration 1800, loss = 0.75443544
Iteration 1801, loss = 0.77172280
Iteration 1802, loss = 0.75580824
Iteration 1803, loss = 0.76402875
Iteration 1804, loss = 0.76697917
Iteration 1805, loss = 0.75428178
Iteration 1806, loss = 0.76530472
Iteration 1807, loss = 0.75968529
Iteration 1808, loss = 0.75766678
Iteration 1809, loss = 0.76146310
Iteration 1810, loss = 0.70033311
Iteration 1811, loss = 0.79599679
Iteration 1812, loss = 0.80896430
Iteration 1813, loss = 0.83655132
Iteration 1814, loss = 0.77484598
Iteration 1815, loss = 0.81648153
Iteration 1816, loss = 0.77110648
Iteration 1817, loss = 0.78262797
Iteration 1818, loss = 0.83211265
Iteration 1819, loss = 0.86036216
Iteration 1820, loss = 0.79156140
Iteration 1821, loss = 0.84810832
Iteration 1822, loss = 0.82138466
Iteration 1823, loss = 0.79685841
Iteration 1824, loss = 0.83932819
Iteration 1825, loss = 0.79886146
Iteration 1826, loss = 0.81178270
Iteration 1827, loss = 0.82314951
Iteration 1828, loss = 0.79136615
Iteration 1829, loss = 0.81504253
Iteration 1830, loss = 0.80277771
Iteration 1831, loss = 0.79008672
Iteration 1832, loss = 0.80402720
Iteration 1833, loss = 0.78090375
Iteration 1834, loss = 0.73883092
Iteration 1835, loss = 1.20591130
Iteration 1836, loss = 0.83201384
Iteration 1837, loss = 1.20137893
Iteration 1838, loss = 1.03510987
Iteration 1839, loss = 0.86408868
Iteration 1840, loss = 1.10386718
Iteration 1841, loss = 0.87584783
Iteration 1842, loss = 0.91166836
Iteration 1843, loss = 1.01379529
Iteration 1844, loss = 0.81034768
Iteration 1845, loss = 0.94370646
Iteration 1846, loss = 0.91894734
Iteration 1847, loss = 0.81357036
Iteration 1848, loss = 0.93563132
Iteration 1849, loss = 0.84078623
Iteration 1850, loss = 0.84503393
Iteration 1851, loss = 0.89513897
Iteration 1852, loss = 0.80172787
Iteration 1853, loss = 0.86062473
Iteration 1854, loss = 0.84112328
Iteration 1855, loss = 0.80240551
Iteration 1856, loss = 0.85447549
Iteration 1857, loss = 0.80557754
Iteration 1858, loss = 0.81944593
Iteration 1859, loss = 0.83193945
Iteration 1860, loss = 0.79407648
Iteration 1861, loss = 0.82422919
Iteration 1862, loss = 0.80486410
Iteration 1863, loss = 0.79735783
Iteration 1864, loss = 0.81464208
Iteration 1865, loss = 0.78979008
Iteration 1866, loss = 0.80227375
Iteration 1867, loss = 0.79890306
Iteration 1868, loss = 0.78661258
Iteration 1869, loss = 0.79953319
Iteration 1870, loss = 0.78627129
Iteration 1871, loss = 0.78873361
Iteration 1872, loss = 0.79150958
Iteration 1873, loss = 0.78117001
Iteration 1874, loss = 0.78831402
Iteration 1875, loss = 0.78223883
Iteration 1876, loss = 0.77995691
Iteration 1877, loss = 0.78313470
Iteration 1878, loss = 0.77551732
Iteration 1879, loss = 0.77791581
Iteration 1880, loss = 0.77126884
Iteration 1881, loss = 0.70723074
Iteration 1882, loss = 0.82333938
Iteration 1883, loss = 0.79964657
Iteration 1884, loss = 0.80292026
Iteration 1885, loss = 0.82063086
Iteration 1886, loss = 0.79210460
Iteration 1887, loss = 0.81074613
Iteration 1888, loss = 0.80004223
Iteration 1889, loss = 0.78950757
Iteration 1890, loss = 0.80382684
Iteration 1891, loss = 0.78740873
Iteration 1892, loss = 0.79497380
Iteration 1893, loss = 0.79523280
Iteration 1894, loss = 0.78554690
Iteration 1895, loss = 0.79536560
Iteration 1896, loss = 0.78727961
Iteration 1897, loss = 0.78856662
Iteration 1898, loss = 0.79195413
Iteration 1899, loss = 0.78486031
Iteration 1900, loss = 0.79024227
Iteration 1901, loss = 0.78695763
Iteration 1902, loss = 0.78570983
Iteration 1903, loss = 0.78889244
Iteration 1904, loss = 0.78426423
Iteration 1905, loss = 0.78651433
Iteration 1906, loss = 0.78527314
Iteration 1907, loss = 0.78312274
Iteration 1908, loss = 0.78506914
Iteration 1909, loss = 0.78210842
Iteration 1910, loss = 0.78253559
Iteration 1911, loss = 0.78207404
Iteration 1912, loss = 0.77998157
Iteration 1913, loss = 0.78090533
Iteration 1914, loss = 0.77911068
Iteration 1915, loss = 0.77879274
Iteration 1916, loss = 0.77866807
Iteration 1917, loss = 0.77705054
Iteration 1918, loss = 0.77738530
Iteration 1919, loss = 0.77634520
Iteration 1920, loss = 0.77577709
Iteration 1921, loss = 0.77569656
Iteration 1922, loss = 0.77446511
Iteration 1923, loss = 0.77431101
Iteration 1924, loss = 0.77348812
Iteration 1925, loss = 0.77271059
Iteration 1926, loss = 0.77245555
Iteration 1927, loss = 0.77148732
Iteration 1928, loss = 0.77111946
Iteration 1929, loss = 0.77047826
Iteration 1930, loss = 0.76972688
Iteration 1931, loss = 0.76937408
Iteration 1932, loss = 0.76859761
Iteration 1933, loss = 0.76814114
Iteration 1934, loss = 0.76760492
Iteration 1935, loss = 0.76693119
Iteration 1936, loss = 0.76652244
Iteration 1937, loss = 0.76586458
Iteration 1938, loss = 0.76535967
Iteration 1939, loss = 0.76485071
Iteration 1940, loss = 0.76422443
Iteration 1941, loss = 0.76376567
Iteration 1942, loss = 0.76317038
Iteration 1943, loss = 0.76264915
Iteration 1944, loss = 0.76215735
Iteration 1945, loss = 0.76158792
Iteration 1946, loss = 0.76112543
Iteration 1947, loss = 0.76059168
Iteration 1948, loss = 0.76008738
Iteration 1949, loss = 0.75953953
Iteration 1950, loss = 0.76122870
Iteration 1951, loss = 0.75664126
Iteration 1952, loss = 0.76058438
Iteration 1953, loss = 0.75538925
Iteration 1954, loss = 0.75747664
Iteration 1955, loss = 0.75152201
Iteration 1956, loss = 0.73147315
Iteration 1957, loss = 0.77519007
Iteration 1958, loss = 0.77238569
Iteration 1959, loss = 0.77753087
Iteration 1960, loss = 0.78094762
Iteration 1961, loss = 0.77380497
Iteration 1962, loss = 0.78221282
Iteration 1963, loss = 0.77507996
Iteration 1964, loss = 0.78587048
Iteration 1965, loss = 0.78375762
Iteration 1966, loss = 0.79064564
Iteration 1967, loss = 0.79335693
Iteration 1968, loss = 0.79446220
Iteration 1969, loss = 0.79948956
Iteration 1970, loss = 0.79713570
Iteration 1971, loss = 0.80220074
Iteration 1972, loss = 0.79974552
Iteration 1973, loss = 0.80310851
Iteration 1974, loss = 0.80287974
Iteration 1975, loss = 0.80447077
Iteration 1976, loss = 0.80622748
Iteration 1977, loss = 0.80592991
Iteration 1978, loss = 0.80817747
Iteration 1979, loss = 0.80683478
Iteration 1980, loss = 0.80840010
Iteration 1981, loss = 0.80718058
Iteration 1982, loss = 0.80777607
Iteration 1983, loss = 0.80745547
Iteration 1984, loss = 0.80728998
Iteration 1985, loss = 0.80771247
Iteration 1986, loss = 0.80696042
Iteration 1987, loss = 0.80740762
Iteration 1988, loss = 0.80635691
Iteration 1989, loss = 0.80639603
Iteration 1990, loss = 0.80547664
Iteration 1991, loss = 0.80511096
Iteration 1992, loss = 0.80455663
Iteration 1993, loss = 0.80410119
Iteration 1994, loss = 0.80240615
Iteration 1995, loss = 0.80476770
Iteration 1996, loss = 0.80698297
Iteration 1997, loss = 0.80762486
Iteration 1998, loss = 0.80372250
Iteration 1999, loss = 0.80126084
Iteration 2000, loss = 0.79873505
Iteration 2001, loss = 0.79751644
Iteration 2002, loss = 0.79728320
Iteration 2003, loss = 0.79566831
Iteration 2004, loss = 0.79416663
Iteration 2005, loss = 0.79130369
Iteration 2006, loss = 0.78892135
Iteration 2007, loss = 0.78538190
Iteration 2008, loss = 0.77761634
Iteration 2009, loss = 0.85030252
Iteration 2010, loss = 0.82190799
Iteration 2011, loss = 0.86662730
Iteration 2012, loss = 0.80371450
Iteration 2013, loss = 0.84987752
Iteration 2014, loss = 0.80071250
Iteration 2015, loss = 0.82388466
Iteration 2016, loss = 0.81066818
Iteration 2017, loss = 0.80531216
Iteration 2018, loss = 0.81995802
Iteration 2019, loss = 0.79549251
Iteration 2020, loss = 0.81827734
Iteration 2021, loss = 0.79215370
Iteration 2022, loss = 0.80827759
Iteration 2023, loss = 0.79404953
Iteration 2024, loss = 0.79767304
Iteration 2025, loss = 0.79757350
Iteration 2026, loss = 0.79000730
Iteration 2027, loss = 0.79798339
Iteration 2028, loss = 0.78590748
Iteration 2029, loss = 0.79479286
Iteration 2030, loss = 0.78496225
Iteration 2031, loss = 0.78987314
Iteration 2032, loss = 0.78562142
Iteration 2033, loss = 0.78501138
Iteration 2034, loss = 0.78574916
Iteration 2035, loss = 0.78126773
Iteration 2036, loss = 0.78444793
Iteration 2037, loss = 0.77901503
Iteration 2038, loss = 0.78198755
Iteration 2039, loss = 0.77800942
Iteration 2040, loss = 0.77909180
Iteration 2041, loss = 0.77735255
Iteration 2042, loss = 0.77628084
Iteration 2043, loss = 0.77638669
Iteration 2044, loss = 0.77399769
Iteration 2045, loss = 0.77490944
Iteration 2046, loss = 0.77235743
Iteration 2047, loss = 0.77305453
Iteration 2048, loss = 0.77112682
Iteration 2049, loss = 0.77104909
Iteration 2050, loss = 0.77001727
Iteration 2051, loss = 0.76913204
Iteration 2052, loss = 0.76879957
Iteration 2053, loss = 0.76745722
Iteration 2054, loss = 0.76743320
Iteration 2055, loss = 0.76605751
Iteration 2056, loss = 0.76595629
Iteration 2057, loss = 0.76483385
Iteration 2058, loss = 0.76443929
Iteration 2059, loss = 0.76366030
Iteration 2060, loss = 0.76296556
Iteration 2061, loss = 0.76246646
Iteration 2062, loss = 0.76160537
Iteration 2063, loss = 0.76124551
Iteration 2064, loss = 0.76037352
Iteration 2065, loss = 0.76000482
Iteration 2066, loss = 0.75922783
Iteration 2067, loss = 0.75876255
Iteration 2068, loss = 0.75811872
Iteration 2069, loss = 0.75754497
Iteration 2070, loss = 0.75701713
Iteration 2071, loss = 0.75638044
Iteration 2072, loss = 0.75592326
Iteration 2073, loss = 0.75528183
Iteration 2074, loss = 0.75483863
Iteration 2075, loss = 0.75423111
Iteration 2076, loss = 0.75376284
Iteration 2077, loss = 0.75320782
Iteration 2078, loss = 0.75270605
Iteration 2079, loss = 0.75220321
Iteration 2080, loss = 0.75168051
Iteration 2081, loss = 0.75121511
Iteration 2082, loss = 0.75069015
Iteration 2083, loss = 0.75024107
Iteration 2084, loss = 0.74972918
Iteration 2085, loss = 0.74928041
Iteration 2086, loss = 0.74879132
Iteration 2087, loss = 0.74833723
Iteration 2088, loss = 0.74787355
Iteration 2089, loss = 0.74741576
Iteration 2090, loss = 0.74697342
Iteration 2091, loss = 0.74651126
Iteration 2092, loss = 0.74624048
Iteration 2093, loss = 0.74763064
Iteration 2094, loss = 0.74764939
Iteration 2095, loss = 0.74608721
Iteration 2096, loss = 0.74522423
Iteration 2097, loss = 0.74535954
Iteration 2098, loss = 0.74438029
Iteration 2099, loss = 0.73729464
Iteration 2100, loss = 0.74826185
Iteration 2101, loss = 0.75011301
Iteration 2102, loss = 0.75080532
Iteration 2103, loss = 0.74817261
Iteration 2104, loss = 0.74832414
Iteration 2105, loss = 0.74780437
Iteration 2106, loss = 0.74955349
Iteration 2107, loss = 0.74986119
Iteration 2108, loss = 0.75072777
Iteration 2109, loss = 0.75076224
Iteration 2110, loss = 0.75102994
Iteration 2111, loss = 0.75117798
Iteration 2112, loss = 0.75089314
Iteration 2113, loss = 0.75113317
Iteration 2114, loss = 0.75079903
Iteration 2115, loss = 0.75104611
Iteration 2116, loss = 0.75077406
Iteration 2117, loss = 0.75096580
Iteration 2118, loss = 0.75049320
Iteration 2119, loss = 0.75011116
Iteration 2120, loss = 0.74954208
Iteration 2121, loss = 0.74915215
Iteration 2122, loss = 0.74883737
Iteration 2123, loss = 0.74838617
Iteration 2124, loss = 0.74801798
Iteration 2125, loss = 0.74740590
Iteration 2126, loss = 0.74692092
Iteration 2127, loss = 0.74622940
Iteration 2128, loss = 0.74572052
Iteration 2129, loss = 0.74509631
Iteration 2130, loss = 0.74458554
Iteration 2131, loss = 0.74400648
Iteration 2132, loss = 0.74343120
Iteration 2133, loss = 0.74282580
Iteration 2134, loss = 0.74219744
Iteration 2135, loss = 0.74161397
Iteration 2136, loss = 0.74099052
Iteration 2137, loss = 0.74044114
Iteration 2138, loss = 0.73984434
Iteration 2139, loss = 0.73929223
Iteration 2140, loss = 0.73868917
Iteration 2141, loss = 0.73813261
Iteration 2142, loss = 0.73756270
Iteration 2143, loss = 0.73701360
Iteration 2144, loss = 0.73645784
Iteration 2145, loss = 0.73591339
Iteration 2146, loss = 0.73539001
Iteration 2147, loss = 0.73486314
Iteration 2148, loss = 0.73435555
Iteration 2149, loss = 0.73383774
Iteration 2150, loss = 0.73334101
Iteration 2151, loss = 0.73283783
Iteration 2152, loss = 0.73236006
Iteration 2153, loss = 0.73188177
Iteration 2154, loss = 0.73141859
Iteration 2155, loss = 0.73095656
Iteration 2156, loss = 0.73050539
Iteration 2157, loss = 0.73006548
Iteration 2158, loss = 0.72967421
Iteration 2159, loss = 0.72928237
Iteration 2160, loss = 0.72882007
Iteration 2161, loss = 0.72837951
Iteration 2162, loss = 0.72798295
Iteration 2163, loss = 0.72759599
Iteration 2164, loss = 0.72719534
Iteration 2165, loss = 0.72680652
Iteration 2166, loss = 0.72642607
Iteration 2167, loss = 0.72605330
Iteration 2168, loss = 0.72568264
Iteration 2169, loss = 0.72532734
Iteration 2170, loss = 0.72498047
Iteration 2171, loss = 0.72463287
Iteration 2172, loss = 0.72428838
Iteration 2173, loss = 0.72395293
Iteration 2174, loss = 0.72362749
Iteration 2175, loss = 0.72330829
Iteration 2176, loss = 0.72299279
Iteration 2177, loss = 0.72267723
Iteration 2178, loss = 0.72237137
Iteration 2179, loss = 0.72207383
Iteration 2180, loss = 0.72177950
Iteration 2181, loss = 0.72148709
Iteration 2182, loss = 0.72120155
Iteration 2183, loss = 0.72092094
Iteration 2184, loss = 0.72064478
Iteration 2185, loss = 0.72037323
Iteration 2186, loss = 0.72010588
Iteration 2187, loss = 0.71984264
Iteration 2188, loss = 0.71958320
Iteration 2189, loss = 0.71932813
Iteration 2190, loss = 0.71907710
Iteration 2191, loss = 0.71883006
Iteration 2192, loss = 0.71858628
Iteration 2193, loss = 0.71834663
Iteration 2194, loss = 0.71811017
Iteration 2195, loss = 0.71787711
Iteration 2196, loss = 0.71764769
Iteration 2197, loss = 0.71742178
Iteration 2198, loss = 0.71719870
Iteration 2199, loss = 0.71697889
Iteration 2200, loss = 0.71676223
Iteration 2201, loss = 0.71654843
Iteration 2202, loss = 0.71633773
Iteration 2203, loss = 0.71612995
Iteration 2204, loss = 0.71592479
Iteration 2205, loss = 0.71572224
Iteration 2206, loss = 0.71552260
Iteration 2207, loss = 0.71532563
Iteration 2208, loss = 0.71513113
Iteration 2209, loss = 0.71493895
Iteration 2210, loss = 0.71474933
Iteration 2211, loss = 0.71456214
Iteration 2212, loss = 0.71437724
Iteration 2213, loss = 0.71419461
Iteration 2214, loss = 0.71401427
Iteration 2215, loss = 0.71383605
Iteration 2216, loss = 0.71365992
Iteration 2217, loss = 0.71348597
Iteration 2218, loss = 0.71331411
Iteration 2219, loss = 0.71314420
Iteration 2220, loss = 0.71297621
Iteration 2221, loss = 0.71281018
Iteration 2222, loss = 0.71264609
Iteration 2223, loss = 0.71248386
Iteration 2224, loss = 0.71232338
Iteration 2225, loss = 0.71216470
Iteration 2226, loss = 0.71200779
Iteration 2227, loss = 0.71185261
Iteration 2228, loss = 0.71169909
Iteration 2229, loss = 0.71154723
Iteration 2230, loss = 0.71139700
Iteration 2231, loss = 0.71124835
Iteration 2232, loss = 0.71110128
Iteration 2233, loss = 0.71095575
Iteration 2234, loss = 0.71081173
Iteration 2235, loss = 0.71066919
Iteration 2236, loss = 0.71052811
Iteration 2237, loss = 0.71038847
Iteration 2238, loss = 0.71025025
Iteration 2239, loss = 0.71011341
Iteration 2240, loss = 0.70997793
Iteration 2241, loss = 0.70984380
Iteration 2242, loss = 0.70971099
Iteration 2243, loss = 0.70957948
Iteration 2244, loss = 0.70944926
Iteration 2245, loss = 0.70932029
Iteration 2246, loss = 0.70919256
Iteration 2247, loss = 0.70906606
Iteration 2248, loss = 0.70894076
Iteration 2249, loss = 0.70881665
Iteration 2250, loss = 0.70869370
Iteration 2251, loss = 0.70857191
Iteration 2252, loss = 0.70845126
Iteration 2253, loss = 0.70833172
Iteration 2254, loss = 0.70821328
Iteration 2255, loss = 0.70809594
Iteration 2256, loss = 0.70797966
Iteration 2257, loss = 0.70786445
Iteration 2258, loss = 0.70775027
Iteration 2259, loss = 0.70763713
Iteration 2260, loss = 0.70752500
Iteration 2261, loss = 0.70741387
Iteration 2262, loss = 0.70730374
Iteration 2263, loss = 0.70719458
Iteration 2264, loss = 0.70708638
Iteration 2265, loss = 0.70697913
Iteration 2266, loss = 0.70687282
Iteration 2267, loss = 0.70676744
Iteration 2268, loss = 0.70666298
Iteration 2269, loss = 0.70655942
Iteration 2270, loss = 0.70645675
Iteration 2271, loss = 0.70635497
Iteration 2272, loss = 0.70625406
Iteration 2273, loss = 0.70615401
Iteration 2274, loss = 0.70605481
Iteration 2275, loss = 0.70595645
Iteration 2276, loss = 0.70585892
Iteration 2277, loss = 0.70576221
Iteration 2278, loss = 0.70566632
Iteration 2279, loss = 0.70557123
Iteration 2280, loss = 0.70547693
Iteration 2281, loss = 0.70538342
Iteration 2282, loss = 0.70529068
Iteration 2283, loss = 0.70519871
Iteration 2284, loss = 0.70510750
Iteration 2285, loss = 0.70501703
Iteration 2286, loss = 0.70492731
Iteration 2287, loss = 0.70483833
Iteration 2288, loss = 0.70475006
Iteration 2289, loss = 0.70466252
Iteration 2290, loss = 0.70457568
Iteration 2291, loss = 0.70448954
Iteration 2292, loss = 0.70440410
Iteration 2293, loss = 0.70431935
Iteration 2294, loss = 0.70423527
Iteration 2295, loss = 0.70415187
Iteration 2296, loss = 0.70406913
Iteration 2297, loss = 0.70398704
Iteration 2298, loss = 0.70390561
Iteration 2299, loss = 0.70382482
Iteration 2300, loss = 0.70374466
Iteration 2301, loss = 0.70366513
Iteration 2302, loss = 0.70358622
Iteration 2303, loss = 0.70350792
Iteration 2304, loss = 0.70343023
Iteration 2305, loss = 0.70335314
Iteration 2306, loss = 0.70327664
Iteration 2307, loss = 0.70320073
Iteration 2308, loss = 0.70312539
Iteration 2309, loss = 0.70305062
Iteration 2310, loss = 0.70297641
Iteration 2311, loss = 0.70290274
Iteration 2312, loss = 0.70282962
Iteration 2313, loss = 0.70275703
Iteration 2314, loss = 0.70268496
Iteration 2315, loss = 0.70261340
Iteration 2316, loss = 0.70254232
Iteration 2317, loss = 0.70247172
Iteration 2318, loss = 0.70240156
Iteration 2319, loss = 0.70233180
Iteration 2320, loss = 0.70226240
Iteration 2321, loss = 0.70219327
Iteration 2322, loss = 0.70212427
Iteration 2323, loss = 0.70205511
Iteration 2324, loss = 0.70198515
Iteration 2325, loss = 0.70191270
Iteration 2326, loss = 0.70183202
Iteration 2327, loss = 0.70171771
Iteration 2328, loss = 0.70148606
Iteration 2329, loss = 0.70135178
Iteration 2330, loss = 0.70134780
Iteration 2331, loss = 0.70127694
Iteration 2332, loss = 0.70110540
Iteration 2333, loss = 0.70093300
Iteration 2334, loss = 0.70090177
Iteration 2335, loss = 0.70081074
Iteration 2336, loss = 0.70063025
Iteration 2337, loss = 0.70056165
Iteration 2338, loss = 0.70046956
Iteration 2339, loss = 0.70022201
Iteration 2340, loss = 0.70020945
Iteration 2341, loss = 0.70001983
Iteration 2342, loss = 0.69991659
Iteration 2343, loss = 0.69945100
Iteration 2344, loss = 0.69962131
Iteration 2345, loss = 0.69910951
Iteration 2346, loss = 0.69907853
Iteration 2347, loss = 0.69920499
Iteration 2348, loss = 0.69855041
Iteration 2349, loss = 0.69698333
Iteration 2350, loss = 0.69586359
Iteration 2351, loss = 0.69437494
Iteration 2352, loss = 0.68862191
Iteration 2353, loss = 0.64076560
Iteration 2354, loss = 0.95627959
Iteration 2355, loss = 1.11008674
Iteration 2356, loss = 0.87807000
Iteration 2357, loss = 1.14217159
Iteration 2358, loss = 0.89314974
Iteration 2359, loss = 1.09398867
Iteration 2360, loss = 0.93170541
Iteration 2361, loss = 0.98725069
Iteration 2362, loss = 0.95016603
Iteration 2363, loss = 0.87380521
Iteration 2364, loss = 0.93768291
Iteration 2365, loss = 0.79756928
Iteration 2366, loss = 0.91162453
Iteration 2367, loss = 0.75618613
Iteration 2368, loss = 0.88082362
Iteration 2369, loss = 0.73640665
Iteration 2370, loss = 0.85174247
Iteration 2371, loss = 0.72704412
Iteration 2372, loss = 0.82702574
Iteration 2373, loss = 0.72711594
Iteration 2374, loss = 0.80904346
Iteration 2375, loss = 0.73146761
Iteration 2376, loss = 0.79479445
Iteration 2377, loss = 0.73612204
Iteration 2378, loss = 0.78194087
Iteration 2379, loss = 0.73883834
Iteration 2380, loss = 0.76970808
Iteration 2381, loss = 0.73951768
Iteration 2382, loss = 0.75902289
Iteration 2383, loss = 0.73960234
Iteration 2384, loss = 0.75082684
Iteration 2385, loss = 0.73971642
Iteration 2386, loss = 0.74491106
Iteration 2387, loss = 0.73959726
Iteration 2388, loss = 0.74026320
Iteration 2389, loss = 0.73867986
Iteration 2390, loss = 0.73626191
Iteration 2391, loss = 0.73712179
Iteration 2392, loss = 0.73294166
Iteration 2393, loss = 0.73543462
Iteration 2394, loss = 0.73048946
Iteration 2395, loss = 0.73394492
Iteration 2396, loss = 0.72878868
Iteration 2397, loss = 0.73262261
Iteration 2398, loss = 0.72752622
Iteration 2399, loss = 0.73128776
Iteration 2400, loss = 0.72641243
Iteration 2401, loss = 0.72988701
Iteration 2402, loss = 0.72540380
Iteration 2403, loss = 0.72853785
Iteration 2404, loss = 0.72456744
Iteration 2405, loss = 0.72735471
Iteration 2406, loss = 0.72391680
Iteration 2407, loss = 0.72632268
Iteration 2408, loss = 0.72335419
Iteration 2409, loss = 0.72535702
Iteration 2410, loss = 0.72279858
Iteration 2411, loss = 0.72443004
Iteration 2412, loss = 0.72224950
Iteration 2413, loss = 0.72356689
Iteration 2414, loss = 0.72172915
Iteration 2415, loss = 0.72278235
Iteration 2416, loss = 0.72124255
Iteration 2417, loss = 0.72206944
Iteration 2418, loss = 0.72077614
Iteration 2419, loss = 0.72140631
Iteration 2420, loss = 0.72031423
Iteration 2421, loss = 0.72077881
Iteration 2422, loss = 0.71985247
Iteration 2423, loss = 0.72018142
Iteration 2424, loss = 0.71939316
Iteration 2425, loss = 0.71961522
Iteration 2426, loss = 0.71894391
Iteration 2427, loss = 0.71908310
Iteration 2428, loss = 0.71850792
Iteration 2429, loss = 0.71857912
Iteration 2430, loss = 0.71807845
Iteration 2431, loss = 0.71809230
Iteration 2432, loss = 0.71761652
Iteration 2433, loss = 0.71673157
Iteration 2434, loss = 0.71692458
Iteration 2435, loss = 0.71667078
Iteration 2436, loss = 0.71636125
Iteration 2437, loss = 0.71616820
Iteration 2438, loss = 0.71575336
Iteration 2439, loss = 0.71566776
Iteration 2440, loss = 0.71500424
Iteration 2441, loss = 0.71476046
Iteration 2442, loss = 0.71372282
Iteration 2443, loss = 0.71369444
Iteration 2444, loss = 0.71267716
Iteration 2445, loss = 0.71458207
Iteration 2446, loss = 0.71084646
Iteration 2447, loss = 0.71239699
Iteration 2448, loss = 0.70760348
Iteration 2449, loss = 0.77118947
Iteration 2450, loss = 0.73844725
Iteration 2451, loss = 0.76929170
Iteration 2452, loss = 0.71969156
Iteration 2453, loss = 0.75768057
Iteration 2454, loss = 0.72335171
Iteration 2455, loss = 0.75450469
Iteration 2456, loss = 0.72487093
Iteration 2457, loss = 0.74105134
Iteration 2458, loss = 0.72550802
Iteration 2459, loss = 0.73346861
Iteration 2460, loss = 0.73009391
Iteration 2461, loss = 0.72757497
Iteration 2462, loss = 0.72982793
Iteration 2463, loss = 0.72094880
Iteration 2464, loss = 0.72846117
Iteration 2465, loss = 0.71847121
Iteration 2466, loss = 0.72743362
Iteration 2467, loss = 0.71695185
Iteration 2468, loss = 0.72407730
Iteration 2469, loss = 0.71521442
Iteration 2470, loss = 0.72069392
Iteration 2471, loss = 0.71510313
Iteration 2472, loss = 0.71811077
Iteration 2473, loss = 0.71461121
Iteration 2474, loss = 0.71504529
Iteration 2475, loss = 0.71395292
Iteration 2476, loss = 0.71297693
Iteration 2477, loss = 0.71331753
Iteration 2478, loss = 0.71113565
Iteration 2479, loss = 0.71234330
Iteration 2480, loss = 0.70987577
Iteration 2481, loss = 0.71126450
Iteration 2482, loss = 0.70870735
Iteration 2483, loss = 0.70994081
Iteration 2484, loss = 0.70785693
Iteration 2485, loss = 0.70866684
Iteration 2486, loss = 0.70686837
Iteration 2487, loss = 0.70712941
Iteration 2488, loss = 0.70558612
Iteration 2489, loss = 0.70437701
Iteration 2490, loss = 0.70254941
Iteration 2491, loss = 0.69981455
Iteration 2492, loss = 0.69627976
Iteration 2493, loss = 0.78061065
Iteration 2494, loss = 0.78308046
Iteration 2495, loss = 0.78529180
Iteration 2496, loss = 0.75972867
Iteration 2497, loss = 0.77940133
Iteration 2498, loss = 0.73839771
Iteration 2499, loss = 0.76824381
Iteration 2500, loss = 0.72365446
Iteration 2501, loss = 0.75694801
Iteration 2502, loss = 0.71443283
Iteration 2503, loss = 0.74976997
Iteration 2504, loss = 0.70935786
Iteration 2505, loss = 0.74083202
Iteration 2506, loss = 0.69978680
Iteration 2507, loss = 0.92090704
Iteration 2508, loss = 0.81332449
Iteration 2509, loss = 1.00086960
Iteration 2510, loss = 0.80137370
Iteration 2511, loss = 0.94414559
Iteration 2512, loss = 0.80665754
Iteration 2513, loss = 0.84349452
Iteration 2514, loss = 0.83931162
Iteration 2515, loss = 0.78670051
Iteration 2516, loss = 0.86807643
Iteration 2517, loss = 0.77684064
Iteration 2518, loss = 0.86240884
Iteration 2519, loss = 0.78966621
Iteration 2520, loss = 0.83224220
Iteration 2521, loss = 0.80845404
Iteration 2522, loss = 0.80069107
Iteration 2523, loss = 0.82010308
Iteration 2524, loss = 0.78287630
Iteration 2525, loss = 0.81995986
Iteration 2526, loss = 0.77880768
Iteration 2527, loss = 0.80873990
Iteration 2528, loss = 0.78302574
Iteration 2529, loss = 0.79409681
Iteration 2530, loss = 0.78936705
Iteration 2531, loss = 0.78220309
Iteration 2532, loss = 0.79204285
Iteration 2533, loss = 0.77427991
Iteration 2534, loss = 0.78764145
Iteration 2535, loss = 0.76958305
Iteration 2536, loss = 0.77943996
Iteration 2537, loss = 0.76862529
Iteration 2538, loss = 0.77154650
Iteration 2539, loss = 0.76905089
Iteration 2540, loss = 0.76496073
Iteration 2541, loss = 0.76758959
Iteration 2542, loss = 0.75942625
Iteration 2543, loss = 0.76354150
Iteration 2544, loss = 0.75548351
Iteration 2545, loss = 0.75853767
Iteration 2546, loss = 0.75322482
Iteration 2547, loss = 0.75364936
Iteration 2548, loss = 0.75134336
Iteration 2549, loss = 0.74900147
Iteration 2550, loss = 0.74878215
Iteration 2551, loss = 0.74492292
Iteration 2552, loss = 0.74568877
Iteration 2553, loss = 0.74187662
Iteration 2554, loss = 0.74248901
Iteration 2555, loss = 0.73952775
Iteration 2556, loss = 0.73914869
Iteration 2557, loss = 0.73723543
Iteration 2558, loss = 0.73583540
Iteration 2559, loss = 0.73489088
Iteration 2560, loss = 0.73295173
Iteration 2561, loss = 0.73258863
Iteration 2562, loss = 0.73057244
Iteration 2563, loss = 0.73027431
Iteration 2564, loss = 0.72849318
Iteration 2565, loss = 0.72792961
Iteration 2566, loss = 0.72655136
Iteration 2567, loss = 0.72565774
Iteration 2568, loss = 0.72469795
Iteration 2569, loss = 0.72358955
Iteration 2570, loss = 0.72293490
Iteration 2571, loss = 0.72176790
Iteration 2572, loss = 0.72123505
Iteration 2573, loss = 0.72013005
Iteration 2574, loss = 0.71957046
Iteration 2575, loss = 0.71861132
Iteration 2576, loss = 0.71797248
Iteration 2577, loss = 0.71719541
Iteration 2578, loss = 0.71649223
Iteration 2579, loss = 0.71587193
Iteration 2580, loss = 0.71514201
Iteration 2581, loss = 0.71461535
Iteration 2582, loss = 0.71390087
Iteration 2583, loss = 0.71341089
Iteration 2584, loss = 0.71275302
Iteration 2585, loss = 0.71226979
Iteration 2586, loss = 0.71169178
Iteration 2587, loss = 0.71120361
Iteration 2588, loss = 0.71069962
Iteration 2589, loss = 0.71015139
Iteration 2590, loss = 0.70905138
Iteration 2591, loss = 0.70375547
Iteration 2592, loss = 0.71260162
Iteration 2593, loss = 0.71339480
Iteration 2594, loss = 0.71322957
Iteration 2595, loss = 0.71095012
Iteration 2596, loss = 0.71027543
Iteration 2597, loss = 0.71005073
Iteration 2598, loss = 0.71060930
Iteration 2599, loss = 0.71089787
Iteration 2600, loss = 0.71073131
Iteration 2601, loss = 0.71074977
Iteration 2602, loss = 0.71036656
Iteration 2603, loss = 0.71036822
Iteration 2604, loss = 0.70983315
Iteration 2605, loss = 0.70978283
Iteration 2606, loss = 0.70960315
Iteration 2607, loss = 0.70980525
Iteration 2608, loss = 0.70963476
Iteration 2609, loss = 0.70930230
Iteration 2610, loss = 0.70887663
Iteration 2611, loss = 0.70854972
Iteration 2612, loss = 0.70842208
Iteration 2613, loss = 0.70817417
Iteration 2614, loss = 0.70801105
Iteration 2615, loss = 0.70767095
Iteration 2616, loss = 0.70742460
Iteration 2617, loss = 0.70702926
Iteration 2618, loss = 0.70673339
Iteration 2619, loss = 0.70641249
Iteration 2620, loss = 0.70617181
Iteration 2621, loss = 0.70590907
Iteration 2622, loss = 0.70561853
Iteration 2623, loss = 0.70531397
Iteration 2624, loss = 0.70497106
Iteration 2625, loss = 0.70468726
Iteration 2626, loss = 0.70439566
Iteration 2627, loss = 0.70415588
Iteration 2628, loss = 0.70386895
Iteration 2629, loss = 0.70360740
Iteration 2630, loss = 0.70332507
Iteration 2631, loss = 0.70307015
Iteration 2632, loss = 0.70280761
Iteration 2633, loss = 0.70255903
Iteration 2634, loss = 0.70232235
Iteration 2635, loss = 0.70208941
Iteration 2636, loss = 0.70186494
Iteration 2637, loss = 0.70163211
Iteration 2638, loss = 0.70141767
Iteration 2639, loss = 0.70120113
Iteration 2640, loss = 0.70100155
Iteration 2641, loss = 0.70079761
Iteration 2642, loss = 0.70060820
Iteration 2643, loss = 0.70041980
Iteration 2644, loss = 0.70024102
Iteration 2645, loss = 0.70006337
Iteration 2646, loss = 0.69989097
Iteration 2647, loss = 0.69972515
Iteration 2648, loss = 0.69956518
Iteration 2649, loss = 0.69941349
Iteration 2650, loss = 0.69926297
Iteration 2651, loss = 0.69911840
Iteration 2652, loss = 0.69897544
Iteration 2653, loss = 0.69884115
Iteration 2654, loss = 0.69870968
Iteration 2655, loss = 0.69858379
Iteration 2656, loss = 0.69845944
Iteration 2657, loss = 0.69834040
Iteration 2658, loss = 0.69822542
Iteration 2659, loss = 0.69811487
Iteration 2660, loss = 0.69800737
Iteration 2661, loss = 0.69790237
Iteration 2662, loss = 0.69780107
Iteration 2663, loss = 0.69770295
Iteration 2664, loss = 0.69760920
Iteration 2665, loss = 0.69751775
Iteration 2666, loss = 0.69742937
Iteration 2667, loss = 0.69734272
Iteration 2668, loss = 0.69725943
Iteration 2669, loss = 0.69717864
Iteration 2670, loss = 0.69710083
Iteration 2671, loss = 0.69702503
Iteration 2672, loss = 0.69695158
Iteration 2673, loss = 0.69688027
Iteration 2674, loss = 0.69681109
Iteration 2675, loss = 0.69674396
Iteration 2676, loss = 0.69667872
Iteration 2677, loss = 0.69661558
Iteration 2678, loss = 0.69655419
Iteration 2679, loss = 0.69649467
Iteration 2680, loss = 0.69643662
Iteration 2681, loss = 0.69638029
Iteration 2682, loss = 0.69632540
Iteration 2683, loss = 0.69627217
Iteration 2684, loss = 0.69622035
Iteration 2685, loss = 0.69616999
Iteration 2686, loss = 0.69612088
Iteration 2687, loss = 0.69607305
Iteration 2688, loss = 0.69602645
Iteration 2689, loss = 0.69598107
Iteration 2690, loss = 0.69593687
Iteration 2691, loss = 0.69589375
Iteration 2692, loss = 0.69585171
Iteration 2693, loss = 0.69581067
Iteration 2694, loss = 0.69577065
Iteration 2695, loss = 0.69573155
Iteration 2696, loss = 0.69569339
Iteration 2697, loss = 0.69565609
Iteration 2698, loss = 0.69561968
Iteration 2699, loss = 0.69558408
Iteration 2700, loss = 0.69554928
Iteration 2701, loss = 0.69551522
Iteration 2702, loss = 0.69548192
Iteration 2703, loss = 0.69544932
Iteration 2704, loss = 0.69541742
Iteration 2705, loss = 0.69538618
Iteration 2706, loss = 0.69535558
Iteration 2707, loss = 0.69532560
Iteration 2708, loss = 0.69529622
Iteration 2709, loss = 0.69526742
Iteration 2710, loss = 0.69523917
Iteration 2711, loss = 0.69521147
Iteration 2712, loss = 0.69518429
Iteration 2713, loss = 0.69515762
Iteration 2714, loss = 0.69513143
Iteration 2715, loss = 0.69510572
Iteration 2716, loss = 0.69508046
Iteration 2717, loss = 0.69505564
Iteration 2718, loss = 0.69503125
Iteration 2719, loss = 0.69500728
Iteration 2720, loss = 0.69498370
Iteration 2721, loss = 0.69496051
Iteration 2722, loss = 0.69493770
Iteration 2723, loss = 0.69491524
Iteration 2724, loss = 0.69489313
Iteration 2725, loss = 0.69487135
Iteration 2726, loss = 0.69484989
Iteration 2727, loss = 0.69482873
Iteration 2728, loss = 0.69480786
Iteration 2729, loss = 0.69478725
Iteration 2730, loss = 0.69476688
Iteration 2731, loss = 0.69474671
Iteration 2732, loss = 0.69472669
Iteration 2733, loss = 0.69470673
Iteration 2734, loss = 0.69468664
Iteration 2735, loss = 0.69466597
Iteration 2736, loss = 0.69464324
Iteration 2737, loss = 0.69460830
Iteration 2738, loss = 0.69056096
Iteration 2739, loss = 0.71189456
Iteration 2740, loss = 0.73569549
Iteration 2741, loss = 0.74423045
Iteration 2742, loss = 0.75579839
Iteration 2743, loss = 0.74374633
Iteration 2744, loss = 0.73914876
Iteration 2745, loss = 0.72116622
Iteration 2746, loss = 0.71940049
Iteration 2747, loss = 0.70903937
Iteration 2748, loss = 0.71507713
Iteration 2749, loss = 0.71120942
Iteration 2750, loss = 0.71901693
Iteration 2751, loss = 0.71446245
Iteration 2752, loss = 0.71895053
Iteration 2753, loss = 0.71241457
Iteration 2754, loss = 0.71487053
Iteration 2755, loss = 0.70899454
Iteration 2756, loss = 0.71232436
Iteration 2757, loss = 0.70807799
Iteration 2758, loss = 0.71139095
Iteration 2759, loss = 0.70772444
Iteration 2760, loss = 0.70994784
Iteration 2761, loss = 0.70603800
Iteration 2762, loss = 0.70752218
Iteration 2763, loss = 0.70436299
Iteration 2764, loss = 0.70609712
Iteration 2765, loss = 0.70402979
Iteration 2766, loss = 0.70581634
Iteration 2767, loss = 0.70416865
Iteration 2768, loss = 0.70534649
Iteration 2769, loss = 0.70355790
Iteration 2770, loss = 0.70399584
Iteration 2771, loss = 0.70223210
Iteration 2772, loss = 0.70246195
Iteration 2773, loss = 0.70123393
Iteration 2774, loss = 0.70165783
Iteration 2775, loss = 0.70095553
Iteration 2776, loss = 0.70133518
Iteration 2777, loss = 0.70073036
Iteration 2778, loss = 0.70079629
Iteration 2779, loss = 0.70016298
Iteration 2780, loss = 0.70003463
Iteration 2781, loss = 0.69951503
Iteration 2782, loss = 0.69935662
Iteration 2783, loss = 0.69898379
Iteration 2784, loss = 0.69881034
Iteration 2785, loss = 0.69854730
Iteration 2786, loss = 0.69837843
Iteration 2787, loss = 0.69820826
Iteration 2788, loss = 0.69803308
Iteration 2789, loss = 0.69789008
Iteration 2790, loss = 0.69766678
Iteration 2791, loss = 0.69751243
Iteration 2792, loss = 0.69726300
Iteration 2793, loss = 0.69713076
Iteration 2794, loss = 0.69690926
Iteration 2795, loss = 0.69682118
Iteration 2796, loss = 0.69663484
Iteration 2797, loss = 0.69656762
Iteration 2798, loss = 0.69639334
Iteration 2799, loss = 0.69632128
Iteration 2800, loss = 0.69615090
Iteration 2801, loss = 0.69607454
Iteration 2802, loss = 0.69591918
Iteration 2803, loss = 0.69584719
Iteration 2804, loss = 0.69571152
Iteration 2805, loss = 0.69564237
Iteration 2806, loss = 0.69552253
Iteration 2807, loss = 0.69545434
Iteration 2808, loss = 0.69535015
Iteration 2809, loss = 0.69528532
Iteration 2810, loss = 0.69519656
Iteration 2811, loss = 0.69513412
Iteration 2812, loss = 0.69505557
Iteration 2813, loss = 0.69499171
Iteration 2814, loss = 0.69491932
Iteration 2815, loss = 0.69485548
Iteration 2816, loss = 0.69479187
Iteration 2817, loss = 0.69473354
Iteration 2818, loss = 0.69468053
Iteration 2819, loss = 0.69462781
Iteration 2820, loss = 0.69458106
Iteration 2821, loss = 0.69453030
Iteration 2822, loss = 0.69448615
Iteration 2823, loss = 0.69443717
Iteration 2824, loss = 0.69439632
Iteration 2825, loss = 0.69435132
Iteration 2826, loss = 0.69431464
Iteration 2827, loss = 0.69427407
Iteration 2828, loss = 0.69424072
Iteration 2829, loss = 0.69420383
Iteration 2830, loss = 0.69417281
Iteration 2831, loss = 0.69413897
Iteration 2832, loss = 0.69410970
Iteration 2833, loss = 0.69407850
Iteration 2834, loss = 0.69405078
Iteration 2835, loss = 0.69402216
Iteration 2836, loss = 0.69399614
Iteration 2837, loss = 0.69397010
Iteration 2838, loss = 0.69394579
Iteration 2839, loss = 0.69392197
Iteration 2840, loss = 0.69389912
Iteration 2841, loss = 0.69387719
Iteration 2842, loss = 0.69385585
Iteration 2843, loss = 0.69383586
Iteration 2844, loss = 0.69381634
Iteration 2845, loss = 0.69379840
Iteration 2846, loss = 0.69378078
Iteration 2847, loss = 0.69376464
Iteration 2848, loss = 0.69374859
Iteration 2849, loss = 0.69373375
Iteration 2850, loss = 0.69371892
Iteration 2851, loss = 0.69370510
Iteration 2852, loss = 0.69369128
Iteration 2853, loss = 0.69367822
Iteration 2854, loss = 0.69366509
Iteration 2855, loss = 0.69365235
Iteration 2856, loss = 0.69363940
Iteration 2857, loss = 0.69362647
Iteration 2858, loss = 0.69361321
Iteration 2859, loss = 0.69359956
Iteration 2860, loss = 0.69358515
Iteration 2861, loss = 0.69356931
Iteration 2862, loss = 0.69355076
Iteration 2863, loss = 0.69352616
Iteration 2864, loss = 0.69348583
Iteration 2865, loss = 0.69338109
Iteration 2866, loss = 0.69164761
Iteration 2867, loss = 0.69740445
Iteration 2868, loss = 0.69933392
Iteration 2869, loss = 0.69978921
Iteration 2870, loss = 0.69753534
Iteration 2871, loss = 0.69726900
Iteration 2872, loss = 0.69618758
Iteration 2873, loss = 0.69776797
Iteration 2874, loss = 0.69677015
Iteration 2875, loss = 0.69908193
Iteration 2876, loss = 0.70250447
Iteration 2877, loss = 0.70413873
Iteration 2878, loss = 0.70279896
Iteration 2879, loss = 0.70042040
Iteration 2880, loss = 0.69829069
Iteration 2881, loss = 0.69824347
Iteration 2882, loss = 0.69861772
Iteration 2883, loss = 0.69940743
Iteration 2884, loss = 0.69893056
Iteration 2885, loss = 0.69757538
Iteration 2886, loss = 0.63618386
Iteration 2887, loss = 0.70705347
Iteration 2888, loss = 0.72689161
Iteration 2889, loss = 0.72624158
Iteration 2890, loss = 0.73341213
Iteration 2891, loss = 0.73586602
Iteration 2892, loss = 0.73256703
Iteration 2893, loss = 0.73967860
Iteration 2894, loss = 0.73350350
Iteration 2895, loss = 0.74357957
Iteration 2896, loss = 0.73865091
Iteration 2897, loss = 0.74873310
Iteration 2898, loss = 0.74654854
Iteration 2899, loss = 0.75441958
Iteration 2900, loss = 0.75474427
Iteration 2901, loss = 0.75840886
Iteration 2902, loss = 0.75989702
Iteration 2903, loss = 0.76079684
Iteration 2904, loss = 0.76391949
Iteration 2905, loss = 0.76341210
Iteration 2906, loss = 0.76690857
Iteration 2907, loss = 0.76540308
Iteration 2908, loss = 0.76816861
Iteration 2909, loss = 0.76671808
Iteration 2910, loss = 0.76867576
Iteration 2911, loss = 0.76783930
Iteration 2912, loss = 0.76905308
Iteration 2913, loss = 0.76913393
Iteration 2914, loss = 0.76952831
Iteration 2915, loss = 0.76971794
Iteration 2916, loss = 0.76928137
Iteration 2917, loss = 0.76964478
Iteration 2918, loss = 0.76872751
Iteration 2919, loss = 0.76896066
Iteration 2920, loss = 0.76796074
Iteration 2921, loss = 0.76815267
Iteration 2922, loss = 0.76731483
Iteration 2923, loss = 0.76724750
Iteration 2924, loss = 0.76656000
Iteration 2925, loss = 0.76621690
Iteration 2926, loss = 0.76530120
Iteration 2927, loss = 0.76478331
Iteration 2928, loss = 0.76424882
Iteration 2929, loss = 0.76345034
Iteration 2930, loss = 0.76317535
Iteration 2931, loss = 0.76237595
Iteration 2932, loss = 0.76186675
Iteration 2933, loss = 0.76196425
Iteration 2934, loss = 0.76196129
Iteration 2935, loss = 0.76083542
Iteration 2936, loss = 0.75910034
Iteration 2937, loss = 0.75779118
Iteration 2938, loss = 0.75739013
Iteration 2939, loss = 0.75656280
Iteration 2940, loss = 0.75542747
Iteration 2941, loss = 0.75424878
Iteration 2942, loss = 0.75227661
Iteration 2943, loss = 0.75060802
Iteration 2944, loss = 0.74015326
Iteration 2945, loss = 0.69795259
Iteration 2946, loss = 0.83859606
Iteration 2947, loss = 0.78958080
Iteration 2948, loss = 0.86646697
Iteration 2949, loss = 0.76874973
Iteration 2950, loss = 0.83659820
Iteration 2951, loss = 0.78900841
Iteration 2952, loss = 0.78818672
Iteration 2953, loss = 0.80811208
Iteration 2954, loss = 0.75875007
Iteration 2955, loss = 0.80534961
Iteration 2956, loss = 0.76259342
Iteration 2957, loss = 0.78601411
Iteration 2958, loss = 0.77756205
Iteration 2959, loss = 0.76265977
Iteration 2960, loss = 0.78259920
Iteration 2961, loss = 0.75509545
Iteration 2962, loss = 0.77711302
Iteration 2963, loss = 0.76050322
Iteration 2964, loss = 0.76446598
Iteration 2965, loss = 0.76637714
Iteration 2966, loss = 0.75440851
Iteration 2967, loss = 0.76628763
Iteration 2968, loss = 0.75225115
Iteration 2969, loss = 0.76066130
Iteration 2970, loss = 0.75503768
Iteration 2971, loss = 0.75391759
Iteration 2972, loss = 0.75723609
Iteration 2973, loss = 0.74986000
Iteration 2974, loss = 0.75574142
Iteration 2975, loss = 0.74907106
Iteration 2976, loss = 0.75169947
Iteration 2977, loss = 0.74997079
Iteration 2978, loss = 0.74801343
Iteration 2979, loss = 0.75020170
Iteration 2980, loss = 0.74601083
Iteration 2981, loss = 0.74853402
Iteration 2982, loss = 0.74539243
Iteration 2983, loss = 0.74584369
Iteration 2984, loss = 0.74525706
Iteration 2985, loss = 0.74361173
Iteration 2986, loss = 0.74469416
Iteration 2987, loss = 0.74240476
Iteration 2988, loss = 0.74334476
Iteration 2989, loss = 0.74180452
Iteration 2990, loss = 0.74154125
Iteration 2991, loss = 0.74117964
Iteration 2992, loss = 0.73994903
Iteration 2993, loss = 0.74027493
Iteration 2994, loss = 0.73893044
Iteration 2995, loss = 0.73911514
Iteration 2996, loss = 0.73825088
Iteration 2997, loss = 0.73783172
Iteration 2998, loss = 0.73751765
Iteration 2999, loss = 0.73665391
Iteration 3000, loss = 0.73659763
Iteration 3001, loss = 0.73572228
Iteration 3002, loss = 0.73555922
Iteration 3003, loss = 0.73495683
Iteration 3004, loss = 0.73451931
Iteration 3005, loss = 0.73419316
Iteration 3006, loss = 0.73356572
Iteration 3007, loss = 0.73334090
Iteration 3008, loss = 0.73271765
Iteration 3009, loss = 0.73242521
Iteration 3010, loss = 0.73194277
Iteration 3011, loss = 0.73152672
Iteration 3012, loss = 0.73118344
Iteration 3013, loss = 0.73068861
Iteration 3014, loss = 0.73039284
Iteration 3015, loss = 0.72990685
Iteration 3016, loss = 0.72957777
Iteration 3017, loss = 0.72916139
Iteration 3018, loss = 0.72877455
Iteration 3019, loss = 0.72842646
Iteration 3020, loss = 0.72800762
Iteration 3021, loss = 0.72768797
Iteration 3022, loss = 0.72727975
Iteration 3023, loss = 0.72694900
Iteration 3024, loss = 0.72657671
Iteration 3025, loss = 0.72622109
Iteration 3026, loss = 0.72588424
Iteration 3027, loss = 0.72551660
Iteration 3028, loss = 0.72519780
Iteration 3029, loss = 0.72483810
Iteration 3030, loss = 0.72451778
Iteration 3031, loss = 0.72417426
Iteration 3032, loss = 0.72376086
Iteration 3033, loss = 0.72379066
Iteration 3034, loss = 0.72372320
Iteration 3035, loss = 0.72329528
Iteration 3036, loss = 0.72274601
Iteration 3037, loss = 0.72236658
Iteration 3038, loss = 0.72212699
Iteration 3039, loss = 0.72186458
Iteration 3040, loss = 0.72153961
Iteration 3041, loss = 0.72120917
Iteration 3042, loss = 0.72090069
Iteration 3043, loss = 0.72060637
Iteration 3044, loss = 0.72029340
Iteration 3045, loss = 0.71997913
Iteration 3046, loss = 0.71970740
Iteration 3047, loss = 0.71945220
Iteration 3048, loss = 0.71916665
Iteration 3049, loss = 0.71885727
Iteration 3050, loss = 0.71857220
Iteration 3051, loss = 0.71831021
Iteration 3052, loss = 0.71804597
Iteration 3053, loss = 0.71778037
Iteration 3054, loss = 0.71751900
Iteration 3055, loss = 0.71725575
Iteration 3056, loss = 0.71698712
Iteration 3057, loss = 0.71672824
Iteration 3058, loss = 0.71648239
Iteration 3059, loss = 0.71623936
Iteration 3060, loss = 0.71599175
Iteration 3061, loss = 0.71574134
Iteration 3062, loss = 0.71549557
Iteration 3063, loss = 0.71525759
Iteration 3064, loss = 0.71502541
Iteration 3065, loss = 0.71479211
Iteration 3066, loss = 0.71455794
Iteration 3067, loss = 0.71432794
Iteration 3068, loss = 0.71410246
Iteration 3069, loss = 0.71387834
Iteration 3070, loss = 0.71365545
Iteration 3071, loss = 0.71343679
Iteration 3072, loss = 0.71322095
Iteration 3073, loss = 0.71300594
Iteration 3074, loss = 0.71279258
Iteration 3075, loss = 0.71258254
Iteration 3076, loss = 0.71237531
Iteration 3077, loss = 0.71216974
Iteration 3078, loss = 0.71196627
Iteration 3079, loss = 0.71176509
Iteration 3080, loss = 0.71156616
Iteration 3081, loss = 0.71136917
Iteration 3082, loss = 0.71117420
Iteration 3083, loss = 0.71098146
Iteration 3084, loss = 0.71079099
Iteration 3085, loss = 0.71060256
Iteration 3086, loss = 0.71041573
Iteration 3087, loss = 0.71023082
Iteration 3088, loss = 0.71004823
Iteration 3089, loss = 0.70986778
Iteration 3090, loss = 0.70968891
Iteration 3091, loss = 0.70951170
Iteration 3092, loss = 0.70933660
Iteration 3093, loss = 0.70916358
Iteration 3094, loss = 0.70899230
Iteration 3095, loss = 0.70882258
Iteration 3096, loss = 0.70865464
Iteration 3097, loss = 0.70848861
Iteration 3098, loss = 0.70832443
Iteration 3099, loss = 0.70816192
Iteration 3100, loss = 0.70800096
Iteration 3101, loss = 0.70784168
Iteration 3102, loss = 0.70768414
Iteration 3103, loss = 0.70752829
Iteration 3104, loss = 0.70737401
Iteration 3105, loss = 0.70722129
Iteration 3106, loss = 0.70707016
Iteration 3107, loss = 0.70692058
Iteration 3108, loss = 0.70677251
Iteration 3109, loss = 0.70662595
Iteration 3110, loss = 0.70648089
Iteration 3111, loss = 0.70633726
Iteration 3112, loss = 0.70619503
Iteration 3113, loss = 0.70605415
Iteration 3114, loss = 0.70591457
Iteration 3115, loss = 0.70577621
Iteration 3116, loss = 0.70563890
Iteration 3117, loss = 0.70550225
Iteration 3118, loss = 0.70536517
Iteration 3119, loss = 0.70522303
Iteration 3120, loss = 0.70503973
Iteration 3121, loss = 0.70468373
Iteration 3122, loss = 0.70461565
Iteration 3123, loss = 0.70439757
Iteration 3124, loss = 0.70423842
Iteration 3125, loss = 0.70402478
Iteration 3126, loss = 0.70388557
Iteration 3127, loss = 0.70374690
Iteration 3128, loss = 0.70357631
Iteration 3129, loss = 0.70347912
Iteration 3130, loss = 0.70327317
Iteration 3131, loss = 0.70303441
Iteration 3132, loss = 0.70331300
Iteration 3133, loss = 0.70410335
Iteration 3134, loss = 0.70310022
Iteration 3135, loss = 0.70235507
Iteration 3136, loss = 0.70163455
Iteration 3137, loss = 0.70195117
Iteration 3138, loss = 0.70142793
Iteration 3139, loss = 0.70049131
Iteration 3140, loss = 0.69884167
Iteration 3141, loss = 0.69421056
Iteration 3142, loss = 0.60088621
Iteration 3143, loss = 0.76996818
Iteration 3144, loss = 0.78803755
Iteration 3145, loss = 0.78647748
Iteration 3146, loss = 0.75901870
Iteration 3147, loss = 0.78056046
Iteration 3148, loss = 0.73755202
Iteration 3149, loss = 0.78027294
Iteration 3150, loss = 0.73586965
Iteration 3151, loss = 0.78429807
Iteration 3152, loss = 0.73969753
Iteration 3153, loss = 0.78201518
Iteration 3154, loss = 0.74138282
Iteration 3155, loss = 0.77579831
Iteration 3156, loss = 0.74487294
Iteration 3157, loss = 0.77207506
Iteration 3158, loss = 0.75153688
Iteration 3159, loss = 0.77008703
Iteration 3160, loss = 0.75715055
Iteration 3161, loss = 0.76679134
Iteration 3162, loss = 0.75991469
Iteration 3163, loss = 0.76320555
Iteration 3164, loss = 0.76180181
Iteration 3165, loss = 0.76114328
Iteration 3166, loss = 0.76356377
Iteration 3167, loss = 0.76015896
Iteration 3168, loss = 0.76438891
Iteration 3169, loss = 0.75915347
Iteration 3170, loss = 0.76395689
Iteration 3171, loss = 0.75813386
Iteration 3172, loss = 0.76306255
Iteration 3173, loss = 0.75763873
Iteration 3174, loss = 0.76222382
Iteration 3175, loss = 0.75743684
Iteration 3176, loss = 0.76101568
Iteration 3177, loss = 0.75723384
Iteration 3178, loss = 0.75868764
Iteration 3179, loss = 0.75724457
Iteration 3180, loss = 0.75657709
Iteration 3181, loss = 0.75697238
Iteration 3182, loss = 0.75518133
Iteration 3183, loss = 0.75608520
Iteration 3184, loss = 0.75465857
Iteration 3185, loss = 0.75434399
Iteration 3186, loss = 0.75410738
Iteration 3187, loss = 0.75284651
Iteration 3188, loss = 0.75302834
Iteration 3189, loss = 0.75174930
Iteration 3190, loss = 0.75147044
Iteration 3191, loss = 0.75090092
Iteration 3192, loss = 0.74991532
Iteration 3193, loss = 0.74964894
Iteration 3194, loss = 0.74851736
Iteration 3195, loss = 0.74808856
Iteration 3196, loss = 0.74743861
Iteration 3197, loss = 0.74676309
Iteration 3198, loss = 0.74632214
Iteration 3199, loss = 0.74516913
Iteration 3200, loss = 0.74462752
Iteration 3201, loss = 0.74372972
Iteration 3202, loss = 0.74207114
Iteration 3203, loss = 0.74002695
Iteration 3204, loss = 0.73735831
Iteration 3205, loss = 0.73690134
Iteration 3206, loss = 0.67967130
Iteration 3207, loss = 0.78884307
Iteration 3208, loss = 0.89885559
Iteration 3209, loss = 0.84059150
Iteration 3210, loss = 0.86770219
Iteration 3211, loss = 0.82830383
Iteration 3212, loss = 0.81969920
Iteration 3213, loss = 0.82452351
Iteration 3214, loss = 0.80171787
Iteration 3215, loss = 0.83202939
Iteration 3216, loss = 0.80020381
Iteration 3217, loss = 0.83984401
Iteration 3218, loss = 0.80633869
Iteration 3219, loss = 0.84343907
Iteration 3220, loss = 0.80929712
Iteration 3221, loss = 0.83481056
Iteration 3222, loss = 0.80529946
Iteration 3223, loss = 0.82367464
Iteration 3224, loss = 0.80667472
Iteration 3225, loss = 0.82028427
Iteration 3226, loss = 0.81331611
Iteration 3227, loss = 0.81955958
Iteration 3228, loss = 0.81731128
Iteration 3229, loss = 0.81541947
Iteration 3230, loss = 0.81572002
Iteration 3231, loss = 0.80477696
Iteration 3232, loss = 0.81005375
Iteration 3233, loss = 0.81545031
Iteration 3234, loss = 0.81719552
Iteration 3235, loss = 0.83500272
Iteration 3236, loss = 0.83734768
Iteration 3237, loss = 0.81882953
Iteration 3238, loss = 0.81817183
Iteration 3239, loss = 0.81536311
Iteration 3240, loss = 0.81520804
Iteration 3241, loss = 0.81900507
Iteration 3242, loss = 0.81099330
Iteration 3243, loss = 0.81491837
Iteration 3244, loss = 0.80518143
Iteration 3245, loss = 0.81202206
Iteration 3246, loss = 0.80278710
Iteration 3247, loss = 0.80825370
Iteration 3248, loss = 0.79917879
Iteration 3249, loss = 0.80446574
Iteration 3250, loss = 0.79834758
Iteration 3251, loss = 0.80176762
Iteration 3252, loss = 0.79613478
Iteration 3253, loss = 0.79691854
Iteration 3254, loss = 0.79314946
Iteration 3255, loss = 0.79331322
Iteration 3256, loss = 0.79162618
Iteration 3257, loss = 0.79073444
Iteration 3258, loss = 0.78935936
Iteration 3259, loss = 0.78703156
Iteration 3260, loss = 0.78620333
Iteration 3261, loss = 0.78387322
Iteration 3262, loss = 0.78378161
Iteration 3263, loss = 0.78138954
Iteration 3264, loss = 0.78123889
Iteration 3265, loss = 0.77875103
Iteration 3266, loss = 0.77843090
Iteration 3267, loss = 0.77609236
Iteration 3268, loss = 0.77565847
Iteration 3269, loss = 0.77363387
Iteration 3270, loss = 0.77305650
Iteration 3271, loss = 0.77128116
Iteration 3272, loss = 0.77047972
Iteration 3273, loss = 0.76892115
Iteration 3274, loss = 0.76798407
Iteration 3275, loss = 0.76666564
Iteration 3276, loss = 0.76561171
Iteration 3277, loss = 0.76440803
Iteration 3278, loss = 0.76323315
Iteration 3279, loss = 0.76215654
Iteration 3280, loss = 0.76100045
Iteration 3281, loss = 0.76005639
Iteration 3282, loss = 0.75889654
Iteration 3283, loss = 0.75797027
Iteration 3284, loss = 0.75679742
Iteration 3285, loss = 0.75590238
Iteration 3286, loss = 0.75478542
Iteration 3287, loss = 0.75392871
Iteration 3288, loss = 0.75286299
Iteration 3289, loss = 0.75201481
Iteration 3290, loss = 0.75099629
Iteration 3291, loss = 0.75015596
Iteration 3292, loss = 0.74918743
Iteration 3293, loss = 0.74835311
Iteration 3294, loss = 0.74743261
Iteration 3295, loss = 0.74661122
Iteration 3296, loss = 0.74574156
Iteration 3297, loss = 0.74493619
Iteration 3298, loss = 0.74410615
Iteration 3299, loss = 0.74331062
Iteration 3300, loss = 0.74251308
Iteration 3301, loss = 0.74173623
Iteration 3302, loss = 0.74097699
Iteration 3303, loss = 0.74022494
Iteration 3304, loss = 0.73949521
Iteration 3305, loss = 0.73876065
Iteration 3306, loss = 0.73805372
Iteration 3307, loss = 0.73734140
Iteration 3308, loss = 0.73666138
Iteration 3309, loss = 0.73597475
Iteration 3310, loss = 0.73531791
Iteration 3311, loss = 0.73465324
Iteration 3312, loss = 0.73401601
Iteration 3313, loss = 0.73337342
Iteration 3314, loss = 0.73275650
Iteration 3315, loss = 0.73213687
Iteration 3316, loss = 0.73153968
Iteration 3317, loss = 0.73094165
Iteration 3318, loss = 0.73036275
Iteration 3319, loss = 0.72978521
Iteration 3320, loss = 0.72922420
Iteration 3321, loss = 0.72866658
Iteration 3322, loss = 0.72812306
Iteration 3323, loss = 0.72758444
Iteration 3324, loss = 0.72705798
Iteration 3325, loss = 0.72653772
Iteration 3326, loss = 0.72602797
Iteration 3327, loss = 0.72552512
Iteration 3328, loss = 0.72503137
Iteration 3329, loss = 0.72454512
Iteration 3330, loss = 0.72406718
Iteration 3331, loss = 0.72359711
Iteration 3332, loss = 0.72313449
Iteration 3333, loss = 0.72267969
Iteration 3334, loss = 0.72223176
Iteration 3335, loss = 0.72179176
Iteration 3336, loss = 0.72135836
Iteration 3337, loss = 0.72093274
Iteration 3338, loss = 0.72051329
Iteration 3339, loss = 0.72010126
Iteration 3340, loss = 0.71969516
Iteration 3341, loss = 0.71929632
Iteration 3342, loss = 0.71890334
Iteration 3343, loss = 0.71851735
Iteration 3344, loss = 0.71813703
Iteration 3345, loss = 0.71776334
Iteration 3346, loss = 0.71739514
Iteration 3347, loss = 0.71703330
Iteration 3348, loss = 0.71667685
Iteration 3349, loss = 0.71632651
Iteration 3350, loss = 0.71598146
Iteration 3351, loss = 0.71564223
Iteration 3352, loss = 0.71530815
Iteration 3353, loss = 0.71497964
Iteration 3354, loss = 0.71465614
Iteration 3355, loss = 0.71433798
Iteration 3356, loss = 0.71402472
Iteration 3357, loss = 0.71371658
Iteration 3358, loss = 0.71341321
Iteration 3359, loss = 0.71311476
Iteration 3360, loss = 0.71282094
Iteration 3361, loss = 0.71253183
Iteration 3362, loss = 0.71224722
Iteration 3363, loss = 0.71196717
Iteration 3364, loss = 0.71169148
Iteration 3365, loss = 0.71142017
Iteration 3366, loss = 0.71115310
Iteration 3367, loss = 0.71089024
Iteration 3368, loss = 0.71063148
Iteration 3369, loss = 0.71037679
Iteration 3370, loss = 0.71012607
Iteration 3371, loss = 0.70987928
Iteration 3372, loss = 0.70963633
Iteration 3373, loss = 0.70939718
Iteration 3374, loss = 0.70916175
Iteration 3375, loss = 0.70892997
Iteration 3376, loss = 0.70870180
Iteration 3377, loss = 0.70847716
Iteration 3378, loss = 0.70825601
Iteration 3379, loss = 0.70803828
Iteration 3380, loss = 0.70782391
Iteration 3381, loss = 0.70761285
Iteration 3382, loss = 0.70740505
Iteration 3383, loss = 0.70720044
Iteration 3384, loss = 0.70699898
Iteration 3385, loss = 0.70680061
Iteration 3386, loss = 0.70660529
Iteration 3387, loss = 0.70641296
Iteration 3388, loss = 0.70622358
Iteration 3389, loss = 0.70603708
Iteration 3390, loss = 0.70585344
Iteration 3391, loss = 0.70567259
Iteration 3392, loss = 0.70549449
Iteration 3393, loss = 0.70531911
Iteration 3394, loss = 0.70514638
Iteration 3395, loss = 0.70497628
Iteration 3396, loss = 0.70480876
Iteration 3397, loss = 0.70464376
Iteration 3398, loss = 0.70448126
Iteration 3399, loss = 0.70432122
Iteration 3400, loss = 0.70416358
Iteration 3401, loss = 0.70400832
Iteration 3402, loss = 0.70385539
Iteration 3403, loss = 0.70370475
Iteration 3404, loss = 0.70355638
Iteration 3405, loss = 0.70341023
Iteration 3406, loss = 0.70326626
Iteration 3407, loss = 0.70312444
Iteration 3408, loss = 0.70298474
Iteration 3409, loss = 0.70284712
Iteration 3410, loss = 0.70271154
Iteration 3411, loss = 0.70257798
Iteration 3412, loss = 0.70244640
Iteration 3413, loss = 0.70231677
Iteration 3414, loss = 0.70218906
Iteration 3415, loss = 0.70206324
Iteration 3416, loss = 0.70193927
Iteration 3417, loss = 0.70181713
Iteration 3418, loss = 0.70169679
Iteration 3419, loss = 0.70157821
Iteration 3420, loss = 0.70146138
Iteration 3421, loss = 0.70134626
Iteration 3422, loss = 0.70123282
Iteration 3423, loss = 0.70112104
Iteration 3424, loss = 0.70101089
Iteration 3425, loss = 0.70090235
Iteration 3426, loss = 0.70079539
Iteration 3427, loss = 0.70068998
Iteration 3428, loss = 0.70058610
Iteration 3429, loss = 0.70048373
Iteration 3430, loss = 0.70038284
Iteration 3431, loss = 0.70028341
Iteration 3432, loss = 0.70018541
Iteration 3433, loss = 0.70008882
Iteration 3434, loss = 0.69999362
Iteration 3435, loss = 0.69989979
Iteration 3436, loss = 0.69980730
Iteration 3437, loss = 0.69971614
Iteration 3438, loss = 0.69962628
Iteration 3439, loss = 0.69953770
Iteration 3440, loss = 0.69945038
Iteration 3441, loss = 0.69936430
Iteration 3442, loss = 0.69927944
Iteration 3443, loss = 0.69919578
Iteration 3444, loss = 0.69911330
Iteration 3445, loss = 0.69903199
Iteration 3446, loss = 0.69895181
Iteration 3447, loss = 0.69887276
Iteration 3448, loss = 0.69879482
Iteration 3449, loss = 0.69871796
Iteration 3450, loss = 0.69864216
Iteration 3451, loss = 0.69856741
Iteration 3452, loss = 0.69849369
Iteration 3453, loss = 0.69842097
Iteration 3454, loss = 0.69834924
Iteration 3455, loss = 0.69827848
Iteration 3456, loss = 0.69820866
Iteration 3457, loss = 0.69813975
Iteration 3458, loss = 0.69807173
Iteration 3459, loss = 0.69800457
Iteration 3460, loss = 0.69793822
Iteration 3461, loss = 0.69787264
Iteration 3462, loss = 0.69780777
Iteration 3463, loss = 0.69774350
Iteration 3464, loss = 0.69767973
Iteration 3465, loss = 0.69761626
Iteration 3466, loss = 0.69755281
Iteration 3467, loss = 0.69748897
Iteration 3468, loss = 0.69742412
Iteration 3469, loss = 0.69735761
Iteration 3470, loss = 0.69728927
Iteration 3471, loss = 0.69722088
Iteration 3472, loss = 0.69715684
Iteration 3473, loss = 0.69710014
Iteration 3474, loss = 0.69704757
Iteration 3475, loss = 0.69699379
Iteration 3476, loss = 0.69693758
Iteration 3477, loss = 0.69688146
Iteration 3478, loss = 0.69682790
Iteration 3479, loss = 0.69677722
Iteration 3480, loss = 0.69672800
Iteration 3481, loss = 0.69667833
Iteration 3482, loss = 0.69662713
Iteration 3483, loss = 0.69657492
Iteration 3484, loss = 0.69652334
Iteration 3485, loss = 0.69647359
Iteration 3486, loss = 0.69642550
Iteration 3487, loss = 0.69637827
Iteration 3488, loss = 0.69633162
Iteration 3489, loss = 0.69628598
Iteration 3490, loss = 0.69624161
Iteration 3491, loss = 0.69619815
Iteration 3492, loss = 0.69615502
Iteration 3493, loss = 0.69611201
Iteration 3494, loss = 0.69606928
Iteration 3495, loss = 0.69602711
Iteration 3496, loss = 0.69598570
Iteration 3497, loss = 0.69594510
Iteration 3498, loss = 0.69590513
Iteration 3499, loss = 0.69586561
Iteration 3500, loss = 0.69582664
Iteration 3501, loss = 0.69578852
Iteration 3502, loss = 0.69575135
Iteration 3503, loss = 0.69571488
Iteration 3504, loss = 0.69567879
Iteration 3505, loss = 0.69564290
Iteration 3506, loss = 0.69560726
Iteration 3507, loss = 0.69557058
Iteration 3508, loss = 0.69555905
Iteration 3509, loss = 0.69637429
Iteration 3510, loss = 0.69595502
Iteration 3511, loss = 0.69573247
Iteration 3512, loss = 0.69600458
Iteration 3513, loss = 0.69584263
Iteration 3514, loss = 0.69581200
Iteration 3515, loss = 0.69582680
Iteration 3516, loss = 0.69574791
Iteration 3517, loss = 0.69578452
Iteration 3518, loss = 0.69569801
Iteration 3519, loss = 0.69563554
Iteration 3520, loss = 0.69563356
Iteration 3521, loss = 0.69555858
Iteration 3522, loss = 0.69549094
Iteration 3523, loss = 0.69542238
Iteration 3524, loss = 0.69539930
Iteration 3525, loss = 0.69530287
Iteration 3526, loss = 0.69523622
Iteration 3527, loss = 0.69521213
Iteration 3528, loss = 0.69512220
Iteration 3529, loss = 0.69507512
Iteration 3530, loss = 0.69504017
Iteration 3531, loss = 0.69496937
Iteration 3532, loss = 0.69494021
Iteration 3533, loss = 0.69489983
Iteration 3534, loss = 0.69485618
Iteration 3535, loss = 0.69482477
Iteration 3536, loss = 0.69480073
Iteration 3537, loss = 0.69476149
Iteration 3538, loss = 0.69474443
Iteration 3539, loss = 0.69472967
Iteration 3540, loss = 0.69485830
Iteration 3541, loss = 0.69489343
Iteration 3542, loss = 0.69470286
Iteration 3543, loss = 0.69475158
Iteration 3544, loss = 0.69476519
Iteration 3545, loss = 0.69467914
Iteration 3546, loss = 0.69467566
Iteration 3547, loss = 0.69464825
Iteration 3548, loss = 0.69463100
Iteration 3549, loss = 0.69459855
Iteration 3550, loss = 0.69457189
Iteration 3551, loss = 0.69454455
Iteration 3552, loss = 0.69453400
Iteration 3553, loss = 0.69448894
Iteration 3554, loss = 0.69447255
Iteration 3555, loss = 0.69444915
Iteration 3556, loss = 0.69441984
Iteration 3557, loss = 0.69439838
Iteration 3558, loss = 0.69437031
Iteration 3559, loss = 0.69435155
Iteration 3560, loss = 0.69432859
Iteration 3561, loss = 0.69430050
Iteration 3562, loss = 0.69428511
Iteration 3563, loss = 0.69426367
Iteration 3564, loss = 0.69423623
Iteration 3565, loss = 0.69422011
Iteration 3566, loss = 0.69419191
Iteration 3567, loss = 0.69414418
Iteration 3568, loss = 0.69394518
Iteration 3569, loss = 0.69378612
Iteration 3570, loss = 0.69389310
Iteration 3571, loss = 0.69372192
Iteration 3572, loss = 0.69299391
Iteration 3573, loss = 0.69316634
Iteration 3574, loss = 0.69617575
Iteration 3575, loss = 0.69642133
Iteration 3576, loss = 0.69341841
Iteration 3577, loss = 0.68948358
Iteration 3578, loss = 0.68594571
Iteration 3579, loss = 0.74228038
Iteration 3580, loss = 0.72494629
Iteration 3581, loss = 0.69876304
Iteration 3582, loss = 0.75525706
Iteration 3583, loss = 1.14283011
Iteration 3584, loss = 0.72807382
Iteration 3585, loss = 1.12422803
Iteration 3586, loss = 0.71082257
Iteration 3587, loss = 1.07452067
Iteration 3588, loss = 0.71115857
Iteration 3589, loss = 1.03983917
Iteration 3590, loss = 0.72037433
Iteration 3591, loss = 1.00473125
Iteration 3592, loss = 0.72011097
Iteration 3593, loss = 0.96923882
Iteration 3594, loss = 0.72123263
Iteration 3595, loss = 0.94668636
Iteration 3596, loss = 0.72812119
Iteration 3597, loss = 0.92258592
Iteration 3598, loss = 0.73065054
Iteration 3599, loss = 0.89841323
Iteration 3600, loss = 0.73494884
Iteration 3601, loss = 0.87754277
Iteration 3602, loss = 0.74142354
Iteration 3603, loss = 0.85693913
Iteration 3604, loss = 0.74455942
Iteration 3605, loss = 0.83401188
Iteration 3606, loss = 0.74593851
Iteration 3607, loss = 0.81304571
Iteration 3608, loss = 0.74703633
Iteration 3609, loss = 0.79449790
Iteration 3610, loss = 0.76549237
Iteration 3611, loss = 0.82143126
Iteration 3612, loss = 0.80642349
Iteration 3613, loss = 0.85755892
Iteration 3614, loss = 0.82269979
Iteration 3615, loss = 0.82023330
Iteration 3616, loss = 0.79155052
Iteration 3617, loss = 0.78780883
Iteration 3618, loss = 0.78658901
Iteration 3619, loss = 0.78661237
Iteration 3620, loss = 0.79672648
Iteration 3621, loss = 0.78960887
Iteration 3622, loss = 0.79938370
Iteration 3623, loss = 0.78603492
Iteration 3624, loss = 0.79699948
Iteration 3625, loss = 0.78384821
Iteration 3626, loss = 0.79725629
Iteration 3627, loss = 0.78468081
Iteration 3628, loss = 0.79686781
Iteration 3629, loss = 0.78354530
Iteration 3630, loss = 0.79423379
Iteration 3631, loss = 0.78263900
Iteration 3632, loss = 0.79360405
Iteration 3633, loss = 0.78441956
Iteration 3634, loss = 0.79432872
Iteration 3635, loss = 0.78571964
Iteration 3636, loss = 0.79322995
Iteration 3637, loss = 0.78490796
Iteration 3638, loss = 0.79081637
Iteration 3639, loss = 0.78383252
Iteration 3640, loss = 0.78918011
Iteration 3641, loss = 0.78372702
Iteration 3642, loss = 0.78833309
Iteration 3643, loss = 0.78369007
Iteration 3644, loss = 0.78721455
Iteration 3645, loss = 0.78312607
Iteration 3646, loss = 0.78582827
Iteration 3647, loss = 0.78233429
Iteration 3648, loss = 0.78434488
Iteration 3649, loss = 0.78127239
Iteration 3650, loss = 0.78271984
Iteration 3651, loss = 0.78017811
Iteration 3652, loss = 0.78140753
Iteration 3653, loss = 0.77941938
Iteration 3654, loss = 0.78035494
Iteration 3655, loss = 0.77854948
Iteration 3656, loss = 0.77901337
Iteration 3657, loss = 0.77730636
Iteration 3658, loss = 0.77752147
Iteration 3659, loss = 0.77609144
Iteration 3660, loss = 0.77623864
Iteration 3661, loss = 0.77504658
Iteration 3662, loss = 0.77506878
Iteration 3663, loss = 0.77397846
Iteration 3664, loss = 0.77384265
Iteration 3665, loss = 0.77282137
Iteration 3666, loss = 0.77258106
Iteration 3667, loss = 0.77165121
Iteration 3668, loss = 0.77136034
Iteration 3669, loss = 0.77052108
Iteration 3670, loss = 0.77018954
Iteration 3671, loss = 0.76941071
Iteration 3672, loss = 0.76903470
Iteration 3673, loss = 0.76829953
Iteration 3674, loss = 0.76789073
Iteration 3675, loss = 0.76719457
Iteration 3676, loss = 0.76676125
Iteration 3677, loss = 0.76609656
Iteration 3678, loss = 0.76564667
Iteration 3679, loss = 0.76501418
Iteration 3680, loss = 0.76455882
Iteration 3681, loss = 0.76395597
Iteration 3682, loss = 0.76349457
Iteration 3683, loss = 0.76291092
Iteration 3684, loss = 0.76244130
Iteration 3685, loss = 0.76187339
Iteration 3686, loss = 0.76140073
Iteration 3687, loss = 0.76085048
Iteration 3688, loss = 0.76038007
Iteration 3689, loss = 0.75984753
Iteration 3690, loss = 0.75938057
Iteration 3691, loss = 0.75886222
Iteration 3692, loss = 0.75839685
Iteration 3693, loss = 0.75788919
Iteration 3694, loss = 0.75742584
Iteration 3695, loss = 0.75692934
Iteration 3696, loss = 0.75647082
Iteration 3697, loss = 0.75598608
Iteration 3698, loss = 0.75553294
Iteration 3699, loss = 0.75505848
Iteration 3700, loss = 0.75461038
Iteration 3701, loss = 0.75414538
Iteration 3702, loss = 0.75370269
Iteration 3703, loss = 0.75324662
Iteration 3704, loss = 0.75280928
Iteration 3705, loss = 0.75236146
Iteration 3706, loss = 0.75192970
Iteration 3707, loss = 0.75149017
Iteration 3708, loss = 0.75106454
Iteration 3709, loss = 0.75063316
Iteration 3710, loss = 0.75021358
Iteration 3711, loss = 0.74978976
Iteration 3712, loss = 0.74937603
Iteration 3713, loss = 0.74895941
Iteration 3714, loss = 0.74855155
Iteration 3715, loss = 0.74814192
Iteration 3716, loss = 0.74773991
Iteration 3717, loss = 0.74733709
Iteration 3718, loss = 0.74694102
Iteration 3719, loss = 0.74654494
Iteration 3720, loss = 0.74615483
Iteration 3721, loss = 0.74576525
Iteration 3722, loss = 0.74538092
Iteration 3723, loss = 0.74499754
Iteration 3724, loss = 0.74461886
Iteration 3725, loss = 0.74424155
Iteration 3726, loss = 0.74386851
Iteration 3727, loss = 0.74349718
Iteration 3728, loss = 0.74312975
Iteration 3729, loss = 0.74276426
Iteration 3730, loss = 0.74240237
Iteration 3731, loss = 0.74204261
Iteration 3732, loss = 0.74168616
Iteration 3733, loss = 0.74133193
Iteration 3734, loss = 0.74098077
Iteration 3735, loss = 0.74063194
Iteration 3736, loss = 0.74028604
Iteration 3737, loss = 0.73994256
Iteration 3738, loss = 0.73960187
Iteration 3739, loss = 0.73926362
Iteration 3740, loss = 0.73892803
Iteration 3741, loss = 0.73859489
Iteration 3742, loss = 0.73826430
Iteration 3743, loss = 0.73793616
Iteration 3744, loss = 0.73761050
Iteration 3745, loss = 0.73728728
Iteration 3746, loss = 0.73696646
Iteration 3747, loss = 0.73664806
Iteration 3748, loss = 0.73633200
Iteration 3749, loss = 0.73601835
Iteration 3750, loss = 0.73570698
Iteration 3751, loss = 0.73539797
Iteration 3752, loss = 0.73509121
Iteration 3753, loss = 0.73478676
Iteration 3754, loss = 0.73448452
Iteration 3755, loss = 0.73418456
Iteration 3756, loss = 0.73388677
Iteration 3757, loss = 0.73359121
Iteration 3758, loss = 0.73329779
Iteration 3759, loss = 0.73300657
Iteration 3760, loss = 0.73271745
Iteration 3761, loss = 0.73243049
Iteration 3762, loss = 0.73214559
Iteration 3763, loss = 0.73186281
Iteration 3764, loss = 0.73158207
Iteration 3765, loss = 0.73130340
Iteration 3766, loss = 0.73102675
Iteration 3767, loss = 0.73075213
Iteration 3768, loss = 0.73047949
Iteration 3769, loss = 0.73020885
Iteration 3770, loss = 0.72994016
Iteration 3771, loss = 0.72967343
Iteration 3772, loss = 0.72940863
Iteration 3773, loss = 0.72914575
Iteration 3774, loss = 0.72888477
Iteration 3775, loss = 0.72862568
Iteration 3776, loss = 0.72836846
Iteration 3777, loss = 0.72811310
Iteration 3778, loss = 0.72785957
Iteration 3779, loss = 0.72760788
Iteration 3780, loss = 0.72735799
Iteration 3781, loss = 0.72710990
Iteration 3782, loss = 0.72686360
Iteration 3783, loss = 0.72661906
Iteration 3784, loss = 0.72637628
Iteration 3785, loss = 0.72613524
Iteration 3786, loss = 0.72589592
Iteration 3787, loss = 0.72565832
Iteration 3788, loss = 0.72542242
Iteration 3789, loss = 0.72518820
Iteration 3790, loss = 0.72495566
Iteration 3791, loss = 0.72472478
Iteration 3792, loss = 0.72449555
Iteration 3793, loss = 0.72426795
Iteration 3794, loss = 0.72404197
Iteration 3795, loss = 0.72381760
Iteration 3796, loss = 0.72359483
Iteration 3797, loss = 0.72337364
Iteration 3798, loss = 0.72315403
Iteration 3799, loss = 0.72293597
Iteration 3800, loss = 0.72271947
Iteration 3801, loss = 0.72250450
Iteration 3802, loss = 0.72229106
Iteration 3803, loss = 0.72207913
Iteration 3804, loss = 0.72186870
Iteration 3805, loss = 0.72165976
Iteration 3806, loss = 0.72145230
Iteration 3807, loss = 0.72124631
Iteration 3808, loss = 0.72104178
Iteration 3809, loss = 0.72083870
Iteration 3810, loss = 0.72063705
Iteration 3811, loss = 0.72043682
Iteration 3812, loss = 0.72023801
Iteration 3813, loss = 0.72004061
Iteration 3814, loss = 0.71984459
Iteration 3815, loss = 0.71964996
Iteration 3816, loss = 0.71945671
Iteration 3817, loss = 0.71926481
Iteration 3818, loss = 0.71907427
Iteration 3819, loss = 0.71888507
Iteration 3820, loss = 0.71869721
Iteration 3821, loss = 0.71851066
Iteration 3822, loss = 0.71832544
Iteration 3823, loss = 0.71814151
Iteration 3824, loss = 0.71795888
Iteration 3825, loss = 0.71777754
Iteration 3826, loss = 0.71759747
Iteration 3827, loss = 0.71741867
Iteration 3828, loss = 0.71724112
Iteration 3829, loss = 0.71706482
Iteration 3830, loss = 0.71688977
Iteration 3831, loss = 0.71671594
Iteration 3832, loss = 0.71654334
Iteration 3833, loss = 0.71637194
Iteration 3834, loss = 0.71620176
Iteration 3835, loss = 0.71603276
Iteration 3836, loss = 0.71586496
Iteration 3837, loss = 0.71569833
Iteration 3838, loss = 0.71553288
Iteration 3839, loss = 0.71536858
Iteration 3840, loss = 0.71520544
Iteration 3841, loss = 0.71504344
Iteration 3842, loss = 0.71488259
Iteration 3843, loss = 0.71472286
Iteration 3844, loss = 0.71456425
Iteration 3845, loss = 0.71440675
Iteration 3846, loss = 0.71425036
Iteration 3847, loss = 0.71409507
Iteration 3848, loss = 0.71394087
Iteration 3849, loss = 0.71378775
Iteration 3850, loss = 0.71363571
Iteration 3851, loss = 0.71348473
Iteration 3852, loss = 0.71333481
Iteration 3853, loss = 0.71318595
Iteration 3854, loss = 0.71303813
Iteration 3855, loss = 0.71289135
Iteration 3856, loss = 0.71274559
Iteration 3857, loss = 0.71260086
Iteration 3858, loss = 0.71245715
Iteration 3859, loss = 0.71231445
Iteration 3860, loss = 0.71217275
Iteration 3861, loss = 0.71203204
Iteration 3862, loss = 0.71189232
Iteration 3863, loss = 0.71175358
Iteration 3864, loss = 0.71161582
Iteration 3865, loss = 0.71147903
Iteration 3866, loss = 0.71134319
Iteration 3867, loss = 0.71120831
Iteration 3868, loss = 0.71107438
Iteration 3869, loss = 0.71094139
Iteration 3870, loss = 0.71080934
Iteration 3871, loss = 0.71067821
Iteration 3872, loss = 0.71054801
Iteration 3873, loss = 0.71041872
Iteration 3874, loss = 0.71029034
Iteration 3875, loss = 0.71016286
Iteration 3876, loss = 0.71003628
Iteration 3877, loss = 0.70991059
Iteration 3878, loss = 0.70978579
Iteration 3879, loss = 0.70966186
Iteration 3880, loss = 0.70953881
Iteration 3881, loss = 0.70941662
Iteration 3882, loss = 0.70929530
Iteration 3883, loss = 0.70917483
Iteration 3884, loss = 0.70905521
Iteration 3885, loss = 0.70893643
Iteration 3886, loss = 0.70881849
Iteration 3887, loss = 0.70870138
Iteration 3888, loss = 0.70858509
Iteration 3889, loss = 0.70846963
Iteration 3890, loss = 0.70835498
Iteration 3891, loss = 0.70824115
Iteration 3892, loss = 0.70812811
Iteration 3893, loss = 0.70801587
Iteration 3894, loss = 0.70790443
Iteration 3895, loss = 0.70779377
Iteration 3896, loss = 0.70768390
Iteration 3897, loss = 0.70757480
Iteration 3898, loss = 0.70746648
Iteration 3899, loss = 0.70735892
Iteration 3900, loss = 0.70725212
Iteration 3901, loss = 0.70714608
Iteration 3902, loss = 0.70704078
Iteration 3903, loss = 0.70693624
Iteration 3904, loss = 0.70683243
Iteration 3905, loss = 0.70672936
Iteration 3906, loss = 0.70662702
Iteration 3907, loss = 0.70652541
Iteration 3908, loss = 0.70642452
Iteration 3909, loss = 0.70632434
Iteration 3910, loss = 0.70622488
Iteration 3911, loss = 0.70612612
Iteration 3912, loss = 0.70602806
Iteration 3913, loss = 0.70593070
Iteration 3914, loss = 0.70583403
Iteration 3915, loss = 0.70573805
Iteration 3916, loss = 0.70564275
Iteration 3917, loss = 0.70554812
Iteration 3918, loss = 0.70545418
Iteration 3919, loss = 0.70536090
Iteration 3920, loss = 0.70526828
Iteration 3921, loss = 0.70517633
Iteration 3922, loss = 0.70508503
Iteration 3923, loss = 0.70499438
Iteration 3924, loss = 0.70490438
Iteration 3925, loss = 0.70481502
Iteration 3926, loss = 0.70472630
Iteration 3927, loss = 0.70463821
Iteration 3928, loss = 0.70455075
Iteration 3929, loss = 0.70446391
Iteration 3930, loss = 0.70437770
Iteration 3931, loss = 0.70429210
Iteration 3932, loss = 0.70420712
Iteration 3933, loss = 0.70412274
Iteration 3934, loss = 0.70403897
Iteration 3935, loss = 0.70395580
Iteration 3936, loss = 0.70387322
Iteration 3937, loss = 0.70379123
Iteration 3938, loss = 0.70370984
Iteration 3939, loss = 0.70362903
Iteration 3940, loss = 0.70354879
Iteration 3941, loss = 0.70346914
Iteration 3942, loss = 0.70339005
Iteration 3943, loss = 0.70331154
Iteration 3944, loss = 0.70323358
Iteration 3945, loss = 0.70315619
Iteration 3946, loss = 0.70307936
Iteration 3947, loss = 0.70300308
Iteration 3948, loss = 0.70292735
Iteration 3949, loss = 0.70285216
Iteration 3950, loss = 0.70277751
Iteration 3951, loss = 0.70270341
Iteration 3952, loss = 0.70262984
Iteration 3953, loss = 0.70255679
Iteration 3954, loss = 0.70248428
Iteration 3955, loss = 0.70241229
Iteration 3956, loss = 0.70234082
Iteration 3957, loss = 0.70226987
Iteration 3958, loss = 0.70219943
Iteration 3959, loss = 0.70212949
Iteration 3960, loss = 0.70206007
Iteration 3961, loss = 0.70199115
Iteration 3962, loss = 0.70192272
Iteration 3963, loss = 0.70185479
Iteration 3964, loss = 0.70178735
Iteration 3965, loss = 0.70172040
Iteration 3966, loss = 0.70165393
Iteration 3967, loss = 0.70158794
Iteration 3968, loss = 0.70152241
Iteration 3969, loss = 0.70145734
Iteration 3970, loss = 0.70139268
Iteration 3971, loss = 0.70132829
Iteration 3972, loss = 0.70126346
Iteration 3973, loss = 0.70118746
Iteration 3974, loss = 0.70085251
Iteration 3975, loss = 0.70215687
Iteration 3976, loss = 0.70234918
Iteration 3977, loss = 0.70158658
Iteration 3978, loss = 0.70119316
Iteration 3979, loss = 0.70179580
Iteration 3980, loss = 0.70208648
Iteration 3981, loss = 0.70123312
Iteration 3982, loss = 0.70141213
Iteration 3983, loss = 0.70093537
Iteration 3984, loss = 0.70092539
Iteration 3985, loss = 0.70087984
Iteration 3986, loss = 0.70073517
Iteration 3987, loss = 0.70061673
Iteration 3988, loss = 0.70047705
Iteration 3989, loss = 0.70049839
Iteration 3990, loss = 0.70044998
Iteration 3991, loss = 0.70030750
Iteration 3992, loss = 0.70022666
Iteration 3993, loss = 0.70024034
Iteration 3994, loss = 0.70010572
Iteration 3995, loss = 0.70008717
Iteration 3996, loss = 0.70004987
Iteration 3997, loss = 0.69993362
Iteration 3998, loss = 0.69986694
Iteration 3999, loss = 0.69985753
Iteration 4000, loss = 0.69977841
Iteration 4001, loss = 0.69968751
Iteration 4002, loss = 0.69965392
Iteration 4003, loss = 0.69961994
Iteration 4004, loss = 0.69954477
Iteration 4005, loss = 0.69947302
Iteration 4006, loss = 0.69944222
Iteration 4007, loss = 0.69939063
Iteration 4008, loss = 0.69932296
Iteration 4009, loss = 0.69927711
Iteration 4010, loss = 0.69922917
Iteration 4011, loss = 0.69917615
Iteration 4012, loss = 0.69912304
Iteration 4013, loss = 0.69907605
Iteration 4014, loss = 0.69902714
Iteration 4015, loss = 0.69897591
Iteration 4016, loss = 0.69892878
Iteration 4017, loss = 0.69888195
Iteration 4018, loss = 0.69883310
Iteration 4019, loss = 0.69878588
Iteration 4020, loss = 0.69874106
Iteration 4021, loss = 0.69869383
Iteration 4022, loss = 0.69864769
Iteration 4023, loss = 0.69860320
Iteration 4024, loss = 0.69855880
Iteration 4025, loss = 0.69851336
Iteration 4026, loss = 0.69846923
Iteration 4027, loss = 0.69842670
Iteration 4028, loss = 0.69838250
Iteration 4029, loss = 0.69833956
Iteration 4030, loss = 0.69829751
Iteration 4031, loss = 0.69825507
Iteration 4032, loss = 0.69821304
Iteration 4033, loss = 0.69817177
Iteration 4034, loss = 0.69813084
Iteration 4035, loss = 0.69808973
Iteration 4036, loss = 0.69804921
Iteration 4037, loss = 0.69800934
Iteration 4038, loss = 0.69796966
Iteration 4039, loss = 0.69792990
Iteration 4040, loss = 0.69789077
Iteration 4041, loss = 0.69785212
Iteration 4042, loss = 0.69781358
Iteration 4043, loss = 0.69777538
Iteration 4044, loss = 0.69773739
Iteration 4045, loss = 0.69769982
Iteration 4046, loss = 0.69766262
Iteration 4047, loss = 0.69762564
Iteration 4048, loss = 0.69758883
Iteration 4049, loss = 0.69755237
Iteration 4050, loss = 0.69751638
Iteration 4051, loss = 0.69748053
Iteration 4052, loss = 0.69744487
Iteration 4053, loss = 0.69740955
Iteration 4054, loss = 0.69737460
Iteration 4055, loss = 0.69733985
Iteration 4056, loss = 0.69730529
Iteration 4057, loss = 0.69727105
Iteration 4058, loss = 0.69723708
Iteration 4059, loss = 0.69720334
Iteration 4060, loss = 0.69716983
Iteration 4061, loss = 0.69713657
Iteration 4062, loss = 0.69710352
Iteration 4063, loss = 0.69707071
Iteration 4064, loss = 0.69703812
Iteration 4065, loss = 0.69700571
Iteration 4066, loss = 0.69697348
Iteration 4067, loss = 0.69694144
Iteration 4068, loss = 0.69690954
Iteration 4069, loss = 0.69687776
Iteration 4070, loss = 0.69684603
Iteration 4071, loss = 0.69681433
Iteration 4072, loss = 0.69678256
Iteration 4073, loss = 0.69675059
Iteration 4074, loss = 0.69671818
Iteration 4075, loss = 0.69668493
Iteration 4076, loss = 0.69665004
Iteration 4077, loss = 0.69661161
Iteration 4078, loss = 0.69656391
Iteration 4079, loss = 0.69648137
Iteration 4080, loss = 0.69605008
Iteration 4081, loss = 0.69471752
Iteration 4082, loss = 0.70348848
Iteration 4083, loss = 0.71950500
Iteration 4084, loss = 0.70611729
Iteration 4085, loss = 0.70113128
Iteration 4086, loss = 0.71266328
Iteration 4087, loss = 0.70453337
Iteration 4088, loss = 0.69998275
Iteration 4089, loss = 0.70765076
Iteration 4090, loss = 0.70171896
Iteration 4091, loss = 0.69798334
Iteration 4092, loss = 0.70417007
Iteration 4093, loss = 0.70306893
Iteration 4094, loss = 0.69968941
Iteration 4095, loss = 0.70208344
Iteration 4096, loss = 0.70031826
Iteration 4097, loss = 0.69730396
Iteration 4098, loss = 0.70049652
Iteration 4099, loss = 0.70139303
Iteration 4100, loss = 0.69806856
Iteration 4101, loss = 0.69866620
Iteration 4102, loss = 0.69934769
Iteration 4103, loss = 0.69675160
Iteration 4104, loss = 0.69809277
Iteration 4105, loss = 0.69902255
Iteration 4106, loss = 0.69630862
Iteration 4107, loss = 0.69656331
Iteration 4108, loss = 0.69802193
Iteration 4109, loss = 0.69664918
Iteration 4110, loss = 0.69683419
Iteration 4111, loss = 0.69547955
Iteration 4112, loss = 0.69387095
Iteration 4113, loss = 0.69057580
Iteration 4114, loss = 0.59749237
Iteration 4115, loss = 0.81060321
Iteration 4116, loss = 0.99951803
Iteration 4117, loss = 0.78201792
Iteration 4118, loss = 0.99972245
Iteration 4119, loss = 0.77911926
Iteration 4120, loss = 0.97483236
Iteration 4121, loss = 0.80849769
Iteration 4122, loss = 0.90612877
Iteration 4123, loss = 0.85206232
Iteration 4124, loss = 0.83930570
Iteration 4125, loss = 0.86658456
Iteration 4126, loss = 0.78567802
Iteration 4127, loss = 0.83389406
Iteration 4128, loss = 0.74525636
Iteration 4129, loss = 0.82823877
Iteration 4130, loss = 0.75502500
Iteration 4131, loss = 0.80420079
Iteration 4132, loss = 0.77673126
Iteration 4133, loss = 0.77490726
Iteration 4134, loss = 0.79197343
Iteration 4135, loss = 0.75514170
Iteration 4136, loss = 0.78726931
Iteration 4137, loss = 0.76140490
Iteration 4138, loss = 0.76779912
Iteration 4139, loss = 0.77650165
Iteration 4140, loss = 0.75528836
Iteration 4141, loss = 0.77336376
Iteration 4142, loss = 0.76062454
Iteration 4143, loss = 0.75895910
Iteration 4144, loss = 0.76651292
Iteration 4145, loss = 0.75297896
Iteration 4146, loss = 0.76289994
Iteration 4147, loss = 0.75712765
Iteration 4148, loss = 0.75344568
Iteration 4149, loss = 0.75877447
Iteration 4150, loss = 0.74972502
Iteration 4151, loss = 0.75382463
Iteration 4152, loss = 0.75153172
Iteration 4153, loss = 0.74823535
Iteration 4154, loss = 0.75220377
Iteration 4155, loss = 0.74654967
Iteration 4156, loss = 0.74803584
Iteration 4157, loss = 0.74711871
Iteration 4158, loss = 0.74417559
Iteration 4159, loss = 0.74611350
Iteration 4160, loss = 0.74291485
Iteration 4161, loss = 0.74273214
Iteration 4162, loss = 0.74233254
Iteration 4163, loss = 0.73999720
Iteration 4164, loss = 0.74089513
Iteration 4165, loss = 0.73887401
Iteration 4166, loss = 0.73839213
Iteration 4167, loss = 0.73807166
Iteration 4168, loss = 0.73624794
Iteration 4169, loss = 0.73659241
Iteration 4170, loss = 0.73509195
Iteration 4171, loss = 0.73441723
Iteration 4172, loss = 0.73400964
Iteration 4173, loss = 0.73260503
Iteration 4174, loss = 0.73248142
Iteration 4175, loss = 0.73139905
Iteration 4176, loss = 0.73066119
Iteration 4177, loss = 0.73025278
Iteration 4178, loss = 0.72915167
Iteration 4179, loss = 0.72886551
Iteration 4180, loss = 0.72800654
Iteration 4181, loss = 0.72732435
Iteration 4182, loss = 0.72685780
Iteration 4183, loss = 0.72597764
Iteration 4184, loss = 0.72555023
Iteration 4185, loss = 0.72484727
Iteration 4186, loss = 0.72419734
Iteration 4187, loss = 0.72372703
Iteration 4188, loss = 0.72298959
Iteration 4189, loss = 0.72251979
Iteration 4190, loss = 0.72191500
Iteration 4191, loss = 0.72133229
Iteration 4192, loss = 0.72087163
Iteration 4193, loss = 0.72023736
Iteration 4194, loss = 0.71976841
Iteration 4195, loss = 0.71921581
Iteration 4196, loss = 0.71867969
Iteration 4197, loss = 0.71821767
Iteration 4198, loss = 0.71766908
Iteration 4199, loss = 0.71721197
Iteration 4200, loss = 0.71671594
Iteration 4201, loss = 0.71621909
Iteration 4202, loss = 0.71577017
Iteration 4203, loss = 0.71526128
Iteration 4204, loss = 0.71478974
Iteration 4205, loss = 0.71423919
Iteration 4206, loss = 0.71345954
Iteration 4207, loss = 0.71241778
Iteration 4208, loss = 0.71169189
Iteration 4209, loss = 0.70992459
Iteration 4210, loss = 0.70774032
Iteration 4211, loss = 0.70527667
Iteration 4212, loss = 0.70136880
Iteration 4213, loss = 0.63966869
Iteration 4214, loss = 0.88865533
Iteration 4215, loss = 0.84802377
Iteration 4216, loss = 0.96695742
Iteration 4217, loss = 0.76015150
Iteration 4218, loss = 0.90361526
Iteration 4219, loss = 0.78966561
Iteration 4220, loss = 0.81156768
Iteration 4221, loss = 0.85275849
Iteration 4222, loss = 0.76248197
Iteration 4223, loss = 0.86301861
Iteration 4224, loss = 0.77524812
Iteration 4225, loss = 0.82558804
Iteration 4226, loss = 0.81153701
Iteration 4227, loss = 0.78136633
Iteration 4228, loss = 0.82519917
Iteration 4229, loss = 0.76691908
Iteration 4230, loss = 0.81283593
Iteration 4231, loss = 0.78251922
Iteration 4232, loss = 0.79009851
Iteration 4233, loss = 0.80033047
Iteration 4234, loss = 0.77507636
Iteration 4235, loss = 0.80283161
Iteration 4236, loss = 0.77484045
Iteration 4237, loss = 0.79079116
Iteration 4238, loss = 0.78177509
Iteration 4239, loss = 0.77691679
Iteration 4240, loss = 0.78664989
Iteration 4241, loss = 0.77058308
Iteration 4242, loss = 0.78407003
Iteration 4243, loss = 0.77225604
Iteration 4244, loss = 0.77701252
Iteration 4245, loss = 0.77568889
Iteration 4246, loss = 0.76995748
Iteration 4247, loss = 0.77553816
Iteration 4248, loss = 0.76639519
Iteration 4249, loss = 0.77161165
Iteration 4250, loss = 0.76617345
Iteration 4251, loss = 0.76640515
Iteration 4252, loss = 0.76663101
Iteration 4253, loss = 0.76267304
Iteration 4254, loss = 0.76549397
Iteration 4255, loss = 0.76063859
Iteration 4256, loss = 0.76225072
Iteration 4257, loss = 0.75963294
Iteration 4258, loss = 0.75857171
Iteration 4259, loss = 0.75856141
Iteration 4260, loss = 0.75577312
Iteration 4261, loss = 0.75674321
Iteration 4262, loss = 0.75403154
Iteration 4263, loss = 0.75418805
Iteration 4264, loss = 0.75270918
Iteration 4265, loss = 0.75152407
Iteration 4266, loss = 0.75121170
Iteration 4267, loss = 0.74930839
Iteration 4268, loss = 0.74933737
Iteration 4269, loss = 0.74765549
Iteration 4270, loss = 0.74722954
Iteration 4271, loss = 0.74618881
Iteration 4272, loss = 0.74512752
Iteration 4273, loss = 0.74463017
Iteration 4274, loss = 0.74329790
Iteration 4275, loss = 0.74291497
Iteration 4276, loss = 0.74173571
Iteration 4277, loss = 0.74111634
Iteration 4278, loss = 0.74026959
Iteration 4279, loss = 0.73933216
Iteration 4280, loss = 0.73859036
Iteration 4281, loss = 0.73752280
Iteration 4282, loss = 0.73663133
Iteration 4283, loss = 0.73590054
Iteration 4284, loss = 0.73547246
Iteration 4285, loss = 0.73414056
Iteration 4286, loss = 0.73352703
Iteration 4287, loss = 0.73307433
Iteration 4288, loss = 0.73180464
Iteration 4289, loss = 0.73120093
Iteration 4290, loss = 0.73000326
Iteration 4291, loss = 0.72822332
Iteration 4292, loss = 0.71978645
Iteration 4293, loss = 0.80886349
Iteration 4294, loss = 0.77599167
Iteration 4295, loss = 0.82274734
Iteration 4296, loss = 0.73438735
Iteration 4297, loss = 0.95028712
Iteration 4298, loss = 0.77123611
Iteration 4299, loss = 0.90972524
Iteration 4300, loss = 0.74521677
Iteration 4301, loss = 0.87127837
Iteration 4302, loss = 0.73399623
Iteration 4303, loss = 0.84309109
Iteration 4304, loss = 0.72941809
Iteration 4305, loss = 0.82086456
Iteration 4306, loss = 0.72866374
Iteration 4307, loss = 0.80128964
Iteration 4308, loss = 0.72802399
Iteration 4309, loss = 0.78438565
Iteration 4310, loss = 0.72730876
Iteration 4311, loss = 0.76984653
Iteration 4312, loss = 0.72752062
Iteration 4313, loss = 0.75950379
Iteration 4314, loss = 0.72738416
Iteration 4315, loss = 0.74859628
Iteration 4316, loss = 0.72532277
Iteration 4317, loss = 0.73838766
Iteration 4318, loss = 0.72229100
Iteration 4319, loss = 0.73078815
Iteration 4320, loss = 0.72080536
Iteration 4321, loss = 0.72293664
Iteration 4322, loss = 0.71649147
Iteration 4323, loss = 0.71722956
Iteration 4324, loss = 0.71515621
Iteration 4325, loss = 0.71365174
Iteration 4326, loss = 0.71026164
Iteration 4327, loss = 0.90480415
Iteration 4328, loss = 0.84885663
Iteration 4329, loss = 0.77921138
Iteration 4330, loss = 0.79726700
Iteration 4331, loss = 0.77991563
Iteration 4332, loss = 0.75995055
Iteration 4333, loss = 0.73385719
Iteration 4334, loss = 0.72845501
Iteration 4335, loss = 0.73103636
Iteration 4336, loss = 0.74533138
Iteration 4337, loss = 0.75554395
Iteration 4338, loss = 0.75906388
Iteration 4339, loss = 0.75638619
Iteration 4340, loss = 0.74804177
Iteration 4341, loss = 0.74343462
Iteration 4342, loss = 0.73904828
Iteration 4343, loss = 0.74127609
Iteration 4344, loss = 0.74275169
Iteration 4345, loss = 0.74639334
Iteration 4346, loss = 0.74728642
Iteration 4347, loss = 0.74735631
Iteration 4348, loss = 0.74614569
Iteration 4349, loss = 0.74418334
Iteration 4350, loss = 0.74325865
Iteration 4351, loss = 0.74188733
Iteration 4352, loss = 0.74216535
Iteration 4353, loss = 0.74168094
Iteration 4354, loss = 0.74221014
Iteration 4355, loss = 0.74181603
Iteration 4356, loss = 0.74170887
Iteration 4357, loss = 0.74102408
Iteration 4358, loss = 0.74023206
Iteration 4359, loss = 0.73944405
Iteration 4360, loss = 0.73847463
Iteration 4361, loss = 0.73798764
Iteration 4362, loss = 0.73732546
Iteration 4363, loss = 0.73717014
Iteration 4364, loss = 0.73667507
Iteration 4365, loss = 0.73633975
Iteration 4366, loss = 0.73560350
Iteration 4367, loss = 0.73487507
Iteration 4368, loss = 0.73406481
Iteration 4369, loss = 0.73335599
Iteration 4370, loss = 0.73283950
Iteration 4371, loss = 0.73233046
Iteration 4372, loss = 0.73194041
Iteration 4373, loss = 0.73135708
Iteration 4374, loss = 0.73080283
Iteration 4375, loss = 0.73008791
Iteration 4376, loss = 0.72946861
Iteration 4377, loss = 0.72883706
Iteration 4378, loss = 0.72830927
Iteration 4379, loss = 0.72780214
Iteration 4380, loss = 0.72729830
Iteration 4381, loss = 0.72679112
Iteration 4382, loss = 0.72623037
Iteration 4383, loss = 0.72569325
Iteration 4384, loss = 0.72512285
Iteration 4385, loss = 0.72460714
Iteration 4386, loss = 0.72407803
Iteration 4387, loss = 0.72359568
Iteration 4388, loss = 0.72310487
Iteration 4389, loss = 0.72263456
Iteration 4390, loss = 0.72215710
Iteration 4391, loss = 0.72167872
Iteration 4392, loss = 0.72120417
Iteration 4393, loss = 0.72072669
Iteration 4394, loss = 0.72026914
Iteration 4395, loss = 0.71981285
Iteration 4396, loss = 0.71938072
Iteration 4397, loss = 0.71894728
Iteration 4398, loss = 0.71852863
Iteration 4399, loss = 0.71810505
Iteration 4400, loss = 0.71768966
Iteration 4401, loss = 0.71727548
Iteration 4402, loss = 0.71686969
Iteration 4403, loss = 0.71647198
Iteration 4404, loss = 0.71608082
Iteration 4405, loss = 0.71569936
Iteration 4406, loss = 0.71532121
Iteration 4407, loss = 0.71495200
Iteration 4408, loss = 0.71458475
Iteration 4409, loss = 0.71422584
Iteration 4410, loss = 0.71386961
Iteration 4411, loss = 0.71352097
Iteration 4412, loss = 0.71317629
Iteration 4413, loss = 0.71283844
Iteration 4414, loss = 0.71250601
Iteration 4415, loss = 0.71217946
Iteration 4416, loss = 0.71185875
Iteration 4417, loss = 0.71154256
Iteration 4418, loss = 0.71123201
Iteration 4419, loss = 0.71092526
Iteration 4420, loss = 0.71062413
Iteration 4421, loss = 0.71032696
Iteration 4422, loss = 0.71003556
Iteration 4423, loss = 0.70974858
Iteration 4424, loss = 0.70946709
Iteration 4425, loss = 0.70918996
Iteration 4426, loss = 0.70891752
Iteration 4427, loss = 0.70864923
Iteration 4428, loss = 0.70838510
Iteration 4429, loss = 0.70812530
Iteration 4430, loss = 0.70786966
Iteration 4431, loss = 0.70761860
Iteration 4432, loss = 0.70737163
Iteration 4433, loss = 0.70712902
Iteration 4434, loss = 0.70689012
Iteration 4435, loss = 0.70665524
Iteration 4436, loss = 0.70642396
Iteration 4437, loss = 0.70619662
Iteration 4438, loss = 0.70597298
Iteration 4439, loss = 0.70575319
Iteration 4440, loss = 0.70553704
Iteration 4441, loss = 0.70532447
Iteration 4442, loss = 0.70511539
Iteration 4443, loss = 0.70490969
Iteration 4444, loss = 0.70470742
Iteration 4445, loss = 0.70450846
Iteration 4446, loss = 0.70431288
Iteration 4447, loss = 0.70412050
Iteration 4448, loss = 0.70393136
Iteration 4449, loss = 0.70374530
Iteration 4450, loss = 0.70356236
Iteration 4451, loss = 0.70338240
Iteration 4452, loss = 0.70320545
Iteration 4453, loss = 0.70303141
Iteration 4454, loss = 0.70286027
Iteration 4455, loss = 0.70269196
Iteration 4456, loss = 0.70252644
Iteration 4457, loss = 0.70236367
Iteration 4458, loss = 0.70220357
Iteration 4459, loss = 0.70204613
Iteration 4460, loss = 0.70189126
Iteration 4461, loss = 0.70173896
Iteration 4462, loss = 0.70158915
Iteration 4463, loss = 0.70144180
Iteration 4464, loss = 0.70129684
Iteration 4465, loss = 0.70115425
Iteration 4466, loss = 0.70101396
Iteration 4467, loss = 0.70087592
Iteration 4468, loss = 0.70074005
Iteration 4469, loss = 0.70060630
Iteration 4470, loss = 0.70047458
Iteration 4471, loss = 0.70034480
Iteration 4472, loss = 0.70021681
Iteration 4473, loss = 0.70009040
Iteration 4474, loss = 0.69996518
Iteration 4475, loss = 0.69984031
Iteration 4476, loss = 0.69971416
Iteration 4477, loss = 0.69958438
Iteration 4478, loss = 0.69945061
Iteration 4479, loss = 0.69932080
Iteration 4480, loss = 0.69920598
Iteration 4481, loss = 0.69909805
Iteration 4482, loss = 0.69898313
Iteration 4483, loss = 0.69886548
Iteration 4484, loss = 0.69875583
Iteration 4485, loss = 0.69865570
Iteration 4486, loss = 0.69855946
Iteration 4487, loss = 0.69846171
Iteration 4488, loss = 0.69836218
Iteration 4489, loss = 0.69826533
Iteration 4490, loss = 0.69817372
Iteration 4491, loss = 0.69808404
Iteration 4492, loss = 0.69799173
Iteration 4493, loss = 0.69789758
Iteration 4494, loss = 0.69780644
Iteration 4495, loss = 0.69771991
Iteration 4496, loss = 0.69763421
Iteration 4497, loss = 0.69754641
Iteration 4498, loss = 0.69745838
Iteration 4499, loss = 0.69737309
Iteration 4500, loss = 0.69729043
Iteration 4501, loss = 0.69720855
Iteration 4502, loss = 0.69712664
Iteration 4503, loss = 0.69704443
Iteration 4504, loss = 0.69696054
Iteration 4505, loss = 0.69687276
Iteration 4506, loss = 0.69677790
Iteration 4507, loss = 0.69666883
Iteration 4508, loss = 0.69652932
Iteration 4509, loss = 0.69632252
Iteration 4510, loss = 0.69594536
Iteration 4511, loss = 0.69495587
Iteration 4512, loss = 0.68783819
Iteration 4513, loss = 0.70543008
Iteration 4514, loss = 0.70422777
Iteration 4515, loss = 0.70833566
Iteration 4516, loss = 0.69986932
Iteration 4517, loss = 0.70372383
Iteration 4518, loss = 0.70026770
Iteration 4519, loss = 0.70331704
Iteration 4520, loss = 0.70366162
Iteration 4521, loss = 0.70230927
Iteration 4522, loss = 0.70441587
Iteration 4523, loss = 0.70133337
Iteration 4524, loss = 0.70383692
Iteration 4525, loss = 0.70189416
Iteration 4526, loss = 0.70328478
Iteration 4527, loss = 0.70301460
Iteration 4528, loss = 0.70259412
Iteration 4529, loss = 0.70358126
Iteration 4530, loss = 0.70228301
Iteration 4531, loss = 0.70341273
Iteration 4532, loss = 0.70219660
Iteration 4533, loss = 0.70285780
Iteration 4534, loss = 0.70256344
Iteration 4535, loss = 0.70247354
Iteration 4536, loss = 0.70269785
Iteration 4537, loss = 0.70198941
Iteration 4538, loss = 0.70244768
Iteration 4539, loss = 0.70181268
Iteration 4540, loss = 0.70211725
Iteration 4541, loss = 0.70174166
Iteration 4542, loss = 0.70163973
Iteration 4543, loss = 0.70159065
Iteration 4544, loss = 0.70125790
Iteration 4545, loss = 0.70138871
Iteration 4546, loss = 0.70097060
Iteration 4547, loss = 0.70102216
Iteration 4548, loss = 0.70070938
Iteration 4549, loss = 0.70064808
Iteration 4550, loss = 0.70051464
Iteration 4551, loss = 0.70029749
Iteration 4552, loss = 0.70023728
Iteration 4553, loss = 0.69996589
Iteration 4554, loss = 0.69994162
Iteration 4555, loss = 0.69971168
Iteration 4556, loss = 0.69962235
Iteration 4557, loss = 0.69944599
Iteration 4558, loss = 0.69929168
Iteration 4559, loss = 0.69918667
Iteration 4560, loss = 0.69900547
Iteration 4561, loss = 0.69892625
Iteration 4562, loss = 0.69874442
Iteration 4563, loss = 0.69864779
Iteration 4564, loss = 0.69849028
Iteration 4565, loss = 0.69837081
Iteration 4566, loss = 0.69825502
Iteration 4567, loss = 0.69812193
Iteration 4568, loss = 0.69802334
Iteration 4569, loss = 0.69787957
Iteration 4570, loss = 0.69778383
Iteration 4571, loss = 0.69765635
Iteration 4572, loss = 0.69755777
Iteration 4573, loss = 0.69744534
Iteration 4574, loss = 0.69733632
Iteration 4575, loss = 0.69723962
Iteration 4576, loss = 0.69713041
Iteration 4577, loss = 0.69704137
Iteration 4578, loss = 0.69693473
Iteration 4579, loss = 0.69684682
Iteration 4580, loss = 0.69674948
Iteration 4581, loss = 0.69666109
Iteration 4582, loss = 0.69657384
Iteration 4583, loss = 0.69648571
Iteration 4584, loss = 0.69640384
Iteration 4585, loss = 0.69631232
Iteration 4586, loss = 0.69622629
Iteration 4587, loss = 0.69612074
Iteration 4588, loss = 0.69590106
Iteration 4589, loss = 0.69575780
Iteration 4590, loss = 0.69579814
Iteration 4591, loss = 0.69549125
Iteration 4592, loss = 0.69544586
Iteration 4593, loss = 0.69527406
Iteration 4594, loss = 0.69517101
Iteration 4595, loss = 0.69483147
Iteration 4596, loss = 0.69505002
Iteration 4597, loss = 0.69607563
Iteration 4598, loss = 0.69551080
Iteration 4599, loss = 0.69416185
Iteration 4600, loss = 0.69468347
Iteration 4601, loss = 0.69343763
Iteration 4602, loss = 0.69236409
Iteration 4603, loss = 0.69051108
Iteration 4604, loss = 0.67026465
Iteration 4605, loss = 0.77304287
Iteration 4606, loss = 0.71264568
Iteration 4607, loss = 0.78717944
Iteration 4608, loss = 0.71518900
Iteration 4609, loss = 0.73604594
Iteration 4610, loss = 0.74993264
Iteration 4611, loss = 0.70237192
Iteration 4612, loss = 0.74862096
Iteration 4613, loss = 0.71174879
Iteration 4614, loss = 0.71529482
Iteration 4615, loss = 0.73242133
Iteration 4616, loss = 0.70153459
Iteration 4617, loss = 0.72811038
Iteration 4618, loss = 0.71040596
Iteration 4619, loss = 0.70674619
Iteration 4620, loss = 0.71943573
Iteration 4621, loss = 0.70003215
Iteration 4622, loss = 0.71512432
Iteration 4623, loss = 0.70737427
Iteration 4624, loss = 0.70305522
Iteration 4625, loss = 0.71197739
Iteration 4626, loss = 0.69998321
Iteration 4627, loss = 0.70792414
Iteration 4628, loss = 0.70474200
Iteration 4629, loss = 0.70102430
Iteration 4630, loss = 0.70680141
Iteration 4631, loss = 0.69953671
Iteration 4632, loss = 0.70362768
Iteration 4633, loss = 0.70248919
Iteration 4634, loss = 0.69985885
Iteration 4635, loss = 0.70355350
Iteration 4636, loss = 0.69922389
Iteration 4637, loss = 0.70122084
Iteration 4638, loss = 0.70078270
Iteration 4639, loss = 0.69892519
Iteration 4640, loss = 0.70123227
Iteration 4641, loss = 0.69874077
Iteration 4642, loss = 0.69974253
Iteration 4643, loss = 0.69959587
Iteration 4644, loss = 0.69832598
Iteration 4645, loss = 0.69968200
Iteration 4646, loss = 0.69820596
Iteration 4647, loss = 0.69868979
Iteration 4648, loss = 0.69864258
Iteration 4649, loss = 0.69780497
Iteration 4650, loss = 0.69858908
Iteration 4651, loss = 0.69771099
Iteration 4652, loss = 0.69794355
Iteration 4653, loss = 0.69792061
Iteration 4654, loss = 0.69736803
Iteration 4655, loss = 0.69779434
Iteration 4656, loss = 0.69724571
Iteration 4657, loss = 0.69734335
Iteration 4658, loss = 0.69732097
Iteration 4659, loss = 0.69696756
Iteration 4660, loss = 0.69719665
Iteration 4661, loss = 0.69684527
Iteration 4662, loss = 0.69686917
Iteration 4663, loss = 0.69682993
Iteration 4664, loss = 0.69659531
Iteration 4665, loss = 0.69670940
Iteration 4666, loss = 0.69647978
Iteration 4667, loss = 0.69647131
Iteration 4668, loss = 0.69642256
Iteration 4669, loss = 0.69626125
Iteration 4670, loss = 0.69630717
Iteration 4671, loss = 0.69615023
Iteration 4672, loss = 0.69612675
Iteration 4673, loss = 0.69607441
Iteration 4674, loss = 0.69595917
Iteration 4675, loss = 0.69596567
Iteration 4676, loss = 0.69585283
Iteration 4677, loss = 0.69582288
Iteration 4678, loss = 0.69577172
Iteration 4679, loss = 0.69568684
Iteration 4680, loss = 0.69567186
Iteration 4681, loss = 0.69558617
Iteration 4682, loss = 0.69555278
Iteration 4683, loss = 0.69550413
Iteration 4684, loss = 0.69543925
Iteration 4685, loss = 0.69541407
Iteration 4686, loss = 0.69534695
Iteration 4687, loss = 0.69531275
Iteration 4688, loss = 0.69526725
Iteration 4689, loss = 0.69521506
Iteration 4690, loss = 0.69518519
Iteration 4691, loss = 0.69513091
Iteration 4692, loss = 0.69509761
Iteration 4693, loss = 0.69505606
Iteration 4694, loss = 0.69501267
Iteration 4695, loss = 0.69498147
Iteration 4696, loss = 0.69493627
Iteration 4697, loss = 0.69490441
Iteration 4698, loss = 0.69486672
Iteration 4699, loss = 0.69482957
Iteration 4700, loss = 0.69479897
Iteration 4701, loss = 0.69476066
Iteration 4702, loss = 0.69473079
Iteration 4703, loss = 0.69469685
Iteration 4704, loss = 0.69466433
Iteration 4705, loss = 0.69463521
Iteration 4706, loss = 0.69460209
Iteration 4707, loss = 0.69457433
Iteration 4708, loss = 0.69454391
Iteration 4709, loss = 0.69451513
Iteration 4710, loss = 0.69448804
Iteration 4711, loss = 0.69445905
Iteration 4712, loss = 0.69443344
Iteration 4713, loss = 0.69440617
Iteration 4714, loss = 0.69438045
Iteration 4715, loss = 0.69435556
Iteration 4716, loss = 0.69432999
Iteration 4717, loss = 0.69430657
Iteration 4718, loss = 0.69428230
Iteration 4719, loss = 0.69425945
Iteration 4720, loss = 0.69423721
Iteration 4721, loss = 0.69421519
Iteration 4722, loss = 0.69419479
Iteration 4723, loss = 0.69417389
Iteration 4724, loss = 0.69415310
Iteration 4725, loss = 0.69413107
Iteration 4726, loss = 0.69410882
Iteration 4727, loss = 0.69408879
Iteration 4728, loss = 0.69407020
Iteration 4729, loss = 0.69405247
Iteration 4730, loss = 0.69403374
Iteration 4731, loss = 0.69401490
Iteration 4732, loss = 0.69399788
Iteration 4733, loss = 0.69398235
Iteration 4734, loss = 0.69396696
Iteration 4735, loss = 0.69394926
Iteration 4736, loss = 0.69392993
Iteration 4737, loss = 0.69391201
Iteration 4738, loss = 0.69389689
Iteration 4739, loss = 0.69388302
Iteration 4740, loss = 0.69386769
Iteration 4741, loss = 0.69385136
Iteration 4742, loss = 0.69383625
Iteration 4743, loss = 0.69382283
Iteration 4744, loss = 0.69380942
Iteration 4745, loss = 0.69379494
Iteration 4746, loss = 0.69378092
Iteration 4747, loss = 0.69376827
Iteration 4748, loss = 0.69375588
Iteration 4749, loss = 0.69374287
Iteration 4750, loss = 0.69373003
Iteration 4751, loss = 0.69371828
Iteration 4752, loss = 0.69370683
Iteration 4753, loss = 0.69369495
Iteration 4754, loss = 0.69368331
Iteration 4755, loss = 0.69367250
Iteration 4756, loss = 0.69366205
Iteration 4757, loss = 0.69365146
Iteration 4758, loss = 0.69364135
Iteration 4759, loss = 0.69363223
Iteration 4760, loss = 0.69362364
Iteration 4761, loss = 0.69361469
Iteration 4762, loss = 0.69360462
Iteration 4763, loss = 0.69359339
Iteration 4764, loss = 0.69358238
Iteration 4765, loss = 0.69357325
Iteration 4766, loss = 0.69356567
Iteration 4767, loss = 0.69355766
Iteration 4768, loss = 0.69354820
Iteration 4769, loss = 0.69353872
Iteration 4770, loss = 0.69353086
Iteration 4771, loss = 0.69352381
Iteration 4772, loss = 0.69351590
Iteration 4773, loss = 0.69350739
Iteration 4774, loss = 0.69349979
Iteration 4775, loss = 0.69349318
Iteration 4776, loss = 0.69348635
Iteration 4777, loss = 0.69347913
Iteration 4778, loss = 0.69347260
Iteration 4779, loss = 0.69346712
Iteration 4780, loss = 0.69346173
Iteration 4781, loss = 0.69345558
Iteration 4782, loss = 0.69344864
Iteration 4783, loss = 0.69344154
Iteration 4784, loss = 0.69343530
Iteration 4785, loss = 0.69343061
Iteration 4786, loss = 0.69342667
Iteration 4787, loss = 0.69342121
Iteration 4788, loss = 0.69341305
Iteration 4789, loss = 0.69340470
Iteration 4790, loss = 0.69339934
Iteration 4791, loss = 0.69339626
Iteration 4792, loss = 0.69339213
Iteration 4793, loss = 0.69338575
Iteration 4794, loss = 0.69337974
Iteration 4795, loss = 0.69337622
Iteration 4796, loss = 0.69337356
Iteration 4797, loss = 0.69336906
Iteration 4798, loss = 0.69336273
Iteration 4799, loss = 0.69335671
Iteration 4800, loss = 0.69335203
Iteration 4801, loss = 0.69334791
Iteration 4802, loss = 0.69334376
Iteration 4803, loss = 0.69333985
Iteration 4804, loss = 0.69333596
Iteration 4805, loss = 0.69333152
Iteration 4806, loss = 0.69332695
Iteration 4807, loss = 0.69332324
Iteration 4808, loss = 0.69332019
Iteration 4809, loss = 0.69331666
Iteration 4810, loss = 0.69331245
Iteration 4811, loss = 0.69330858
Iteration 4812, loss = 0.69330555
Iteration 4813, loss = 0.69330262
Iteration 4814, loss = 0.69329912
Iteration 4815, loss = 0.69329550
Iteration 4816, loss = 0.69329240
Iteration 4817, loss = 0.69328966
Iteration 4818, loss = 0.69328674
Iteration 4819, loss = 0.69328362
Iteration 4820, loss = 0.69328072
Iteration 4821, loss = 0.69327819
Iteration 4822, loss = 0.69327585
Iteration 4823, loss = 0.69327359
Iteration 4824, loss = 0.69327157
Iteration 4825, loss = 0.69326984
Iteration 4826, loss = 0.69326796
Iteration 4827, loss = 0.69326520
Iteration 4828, loss = 0.69326144
Iteration 4829, loss = 0.69325776
Iteration 4830, loss = 0.69325538
Iteration 4831, loss = 0.69325425
Iteration 4832, loss = 0.69325333
Iteration 4833, loss = 0.69325178
Iteration 4834, loss = 0.69324993
Iteration 4835, loss = 0.69324836
Iteration 4836, loss = 0.69324656
Iteration 4837, loss = 0.69324369
Iteration 4838, loss = 0.69324066
Iteration 4839, loss = 0.69323922
Iteration 4840, loss = 0.69323924
Iteration 4841, loss = 0.69323830
Iteration 4842, loss = 0.69323457
Iteration 4843, loss = 0.69322981
Iteration 4844, loss = 0.69322729
Iteration 4845, loss = 0.69322719
Iteration 4846, loss = 0.69322676
Iteration 4847, loss = 0.69322426
Iteration 4848, loss = 0.69322107
Iteration 4849, loss = 0.69321929
Iteration 4850, loss = 0.69321871
Iteration 4851, loss = 0.69321755
Iteration 4852, loss = 0.69321535
Iteration 4853, loss = 0.69321328
Iteration 4854, loss = 0.69321210
Iteration 4855, loss = 0.69321116
Iteration 4856, loss = 0.69320968
Iteration 4857, loss = 0.69320791
Iteration 4858, loss = 0.69320652
Iteration 4859, loss = 0.69320549
Iteration 4860, loss = 0.69320433
Iteration 4861, loss = 0.69320292
Iteration 4862, loss = 0.69320157
Iteration 4863, loss = 0.69320047
Iteration 4864, loss = 0.69319943
Iteration 4865, loss = 0.69319827
Iteration 4866, loss = 0.69319706
Iteration 4867, loss = 0.69319597
Iteration 4868, loss = 0.69319499
Iteration 4869, loss = 0.69319398
Iteration 4870, loss = 0.69319294
Iteration 4871, loss = 0.69319193
Iteration 4872, loss = 0.69319102
Iteration 4873, loss = 0.69319016
Iteration 4874, loss = 0.69318934
Iteration 4875, loss = 0.69318862
Iteration 4876, loss = 0.69318809
Iteration 4877, loss = 0.69318784
Iteration 4878, loss = 0.69318788
Iteration 4879, loss = 0.69318808
Iteration 4880, loss = 0.69318795
Iteration 4881, loss = 0.69318684
Iteration 4882, loss = 0.69318493
Iteration 4883, loss = 0.69318362
Iteration 4884, loss = 0.69318404
Iteration 4885, loss = 0.69318557
Iteration 4886, loss = 0.69318635
Iteration 4887, loss = 0.69318501
Iteration 4888, loss = 0.69318207
Iteration 4889, loss = 0.69317934
Iteration 4890, loss = 0.69317800
Iteration 4891, loss = 0.69317775
Iteration 4892, loss = 0.69317763
Iteration 4893, loss = 0.69317707
Iteration 4894, loss = 0.69317610
Iteration 4895, loss = 0.69317492
Iteration 4896, loss = 0.69317389
Iteration 4897, loss = 0.69317333
Iteration 4898, loss = 0.69317311
Iteration 4899, loss = 0.69317268
Iteration 4900, loss = 0.69317176
Iteration 4901, loss = 0.69317077
Iteration 4902, loss = 0.69317025
Iteration 4903, loss = 0.69317009
Iteration 4904, loss = 0.69316973
Iteration 4905, loss = 0.69316895
Iteration 4906, loss = 0.69316821
Iteration 4907, loss = 0.69316792
Iteration 4908, loss = 0.69316791
Iteration 4909, loss = 0.69316780
Iteration 4910, loss = 0.69316768
Iteration 4911, loss = 0.69316797
Iteration 4912, loss = 0.69316874
Iteration 4913, loss = 0.69316921
Iteration 4914, loss = 0.69316830
Iteration 4915, loss = 0.69316602
Iteration 4916, loss = 0.69316405
Iteration 4917, loss = 0.69316380
Iteration 4918, loss = 0.69316462
Iteration 4919, loss = 0.69316477
Iteration 4920, loss = 0.69316359
Iteration 4921, loss = 0.69316225
Iteration 4922, loss = 0.69316204
Iteration 4923, loss = 0.69316250
Iteration 4924, loss = 0.69316239
Iteration 4925, loss = 0.69316154
Iteration 4926, loss = 0.69316106
Iteration 4927, loss = 0.69316147
Iteration 4928, loss = 0.69316209
Iteration 4929, loss = 0.69316221
Iteration 4930, loss = 0.69316204
Iteration 4931, loss = 0.69316179
Iteration 4932, loss = 0.69316104
Iteration 4933, loss = 0.69315961
Iteration 4934, loss = 0.69315839
Iteration 4935, loss = 0.69315827
Iteration 4936, loss = 0.69315886
Iteration 4937, loss = 0.69315904
Iteration 4938, loss = 0.69315828
Iteration 4939, loss = 0.69315730
Iteration 4940, loss = 0.69315692
Iteration 4941, loss = 0.69315709
Iteration 4942, loss = 0.69315715
Iteration 4943, loss = 0.69315678
Iteration 4944, loss = 0.69315622
Iteration 4945, loss = 0.69315588
Iteration 4946, loss = 0.69315580
Iteration 4947, loss = 0.69315575
Iteration 4948, loss = 0.69315555
Iteration 4949, loss = 0.69315520
Iteration 4950, loss = 0.69315489
Iteration 4951, loss = 0.69315474
Iteration 4952, loss = 0.69315468
Iteration 4953, loss = 0.69315453
Iteration 4954, loss = 0.69315426
Iteration 4955, loss = 0.69315399
Iteration 4956, loss = 0.69315385
Iteration 4957, loss = 0.69315379
Iteration 4958, loss = 0.69315365
Iteration 4959, loss = 0.69315342
Iteration 4960, loss = 0.69315321
Iteration 4961, loss = 0.69315309
Iteration 4962, loss = 0.69315301
Iteration 4963, loss = 0.69315287
Iteration 4964, loss = 0.69315268
Iteration 4965, loss = 0.69315251
Iteration 4966, loss = 0.69315241
Iteration 4967, loss = 0.69315231
Iteration 4968, loss = 0.69315219
Iteration 4969, loss = 0.69315203
Iteration 4970, loss = 0.69315190
Iteration 4971, loss = 0.69315180
Iteration 4972, loss = 0.69315171
Iteration 4973, loss = 0.69315161
Iteration 4974, loss = 0.69315150
Iteration 4975, loss = 0.69315143
Iteration 4976, loss = 0.69315142
Iteration 4977, loss = 0.69315148
Iteration 4978, loss = 0.69315167
Iteration 4979, loss = 0.69315210
Iteration 4980, loss = 0.69315295
Iteration 4981, loss = 0.69315443
Iteration 4982, loss = 0.69315650
Iteration 4983, loss = 0.69315843
Iteration 4984, loss = 0.69315852
Iteration 4985, loss = 0.69315571
Iteration 4986, loss = 0.69315216
Iteration 4987, loss = 0.69315154
Iteration 4988, loss = 0.69315442
Iteration 4989, loss = 0.69315790
Iteration 4990, loss = 0.69315943
Iteration 4991, loss = 0.69315962
Iteration 4992, loss = 0.69316010
Iteration 4993, loss = 0.69315992
Iteration 4994, loss = 0.69315760
Iteration 4995, loss = 0.69315444
Iteration 4996, loss = 0.69315304
Iteration 4997, loss = 0.69315383
Iteration 4998, loss = 0.69315430
Iteration 4999, loss = 0.69315293
Iteration 5000, loss = 0.69315155
