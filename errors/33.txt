Iteration 1, loss = 0.73028819
Iteration 2, loss = 2.87393978
Iteration 3, loss = 1.67532068
Iteration 4, loss = 1.34531004
Iteration 5, loss = 1.16591534
Iteration 6, loss = 2.01385891
Iteration 7, loss = 2.14432291
Iteration 8, loss = 0.89008443
Iteration 9, loss = 0.72508857
Iteration 10, loss = 0.64006261
Iteration 11, loss = 0.74294996
Iteration 12, loss = 0.73726779
Iteration 13, loss = 0.72398317
Iteration 14, loss = 0.64360997
Iteration 15, loss = 0.77467416
Iteration 16, loss = 0.83402788
Iteration 17, loss = 0.76953138
Iteration 18, loss = 0.71574834
Iteration 19, loss = 0.64847377
Iteration 20, loss = 0.76476353
Iteration 21, loss = 0.70363271
Iteration 22, loss = 0.84238053
Iteration 23, loss = 0.76775398
Iteration 24, loss = 0.64245167
Iteration 25, loss = 0.80323051
Iteration 26, loss = 0.90748865
Iteration 27, loss = 0.74739477
Iteration 28, loss = 0.74986642
Iteration 29, loss = 0.79453333
Iteration 30, loss = 0.81933194
Iteration 31, loss = 0.77913790
Iteration 32, loss = 0.80953794
Iteration 33, loss = 0.81749973
Iteration 34, loss = 0.75425740
Iteration 35, loss = 0.78137235
Iteration 36, loss = 0.70930568
Iteration 37, loss = 0.67555217
Iteration 38, loss = 0.68556460
Iteration 39, loss = 0.48960645
Iteration 40, loss = 0.64483376
Iteration 41, loss = 0.73149764
Iteration 42, loss = 0.76804649
Iteration 43, loss = 0.74975263
Iteration 44, loss = 0.77403688
Iteration 45, loss = 0.75776031
Iteration 46, loss = 0.73941524
Iteration 47, loss = 0.85971246
Iteration 48, loss = 0.78332514
Iteration 49, loss = 0.73072315
Iteration 50, loss = 0.75644938
Iteration 51, loss = 0.98191075
Iteration 52, loss = 1.68717645
Iteration 53, loss = 0.92326020
Iteration 54, loss = 0.79789077
Iteration 55, loss = 0.80438455
Iteration 56, loss = 0.84957977
Iteration 57, loss = 1.56744476
Iteration 58, loss = 0.86733009
Iteration 59, loss = 1.16634163
Iteration 60, loss = 0.99631928
Iteration 61, loss = 1.00029174
Iteration 62, loss = 0.94827809
Iteration 63, loss = 0.85751792
Iteration 64, loss = 0.94381117
Iteration 65, loss = 0.82188961
Iteration 66, loss = 0.84846452
Iteration 67, loss = 0.83607612
Iteration 68, loss = 0.91280800
Iteration 69, loss = 0.78466515
Iteration 70, loss = 0.88985530
Iteration 71, loss = 0.75865566
Iteration 72, loss = 0.71686306
Iteration 73, loss = 0.79637922
Iteration 74, loss = 0.76123607
Iteration 75, loss = 0.89315957
Iteration 76, loss = 0.78849473
Iteration 77, loss = 0.89000014
Iteration 78, loss = 0.77910091
Iteration 79, loss = 0.85853238
Iteration 80, loss = 0.77654257
Iteration 81, loss = 0.78563538
Iteration 82, loss = 0.77036195
Iteration 83, loss = 0.77917985
Iteration 84, loss = 0.76423491
Iteration 85, loss = 0.77209169
Iteration 86, loss = 0.75857950
Iteration 87, loss = 0.76389939
Iteration 88, loss = 0.75169468
Iteration 89, loss = 0.75497115
Iteration 90, loss = 0.74174103
Iteration 91, loss = 0.60979746
Iteration 92, loss = 0.93552819
Iteration 93, loss = 0.84228635
Iteration 94, loss = 0.95278193
Iteration 95, loss = 0.79306069
Iteration 96, loss = 0.93679913
Iteration 97, loss = 0.75423597
Iteration 98, loss = 0.85232638
Iteration 99, loss = 0.77114747
Iteration 100, loss = 0.95563062
Iteration 101, loss = 0.94557336
Iteration 102, loss = 0.76208101
Iteration 103, loss = 0.75850066
Iteration 104, loss = 0.75911833
Iteration 105, loss = 0.76729103
Iteration 106, loss = 0.77304968
Iteration 107, loss = 0.89971886
Iteration 108, loss = 0.82006510
Iteration 109, loss = 0.81423916
Iteration 110, loss = 0.80693105
Iteration 111, loss = 0.78593550
Iteration 112, loss = 0.80853504
Iteration 113, loss = 0.75771292
Iteration 114, loss = 0.85043017
Iteration 115, loss = 0.71755188
Iteration 116, loss = 0.77071059
Iteration 117, loss = 0.75560733
Iteration 118, loss = 0.77553773
Iteration 119, loss = 0.76254735
Iteration 120, loss = 0.77297119
Iteration 121, loss = 0.76483744
Iteration 122, loss = 0.76670260
Iteration 123, loss = 0.76275246
Iteration 124, loss = 0.92199903
Iteration 125, loss = 1.25420457
Iteration 126, loss = 0.80446928
Iteration 127, loss = 0.78022861
Iteration 128, loss = 0.86757763
Iteration 129, loss = 0.77799408
Iteration 130, loss = 0.86399440
Iteration 131, loss = 0.78556376
Iteration 132, loss = 0.82684689
Iteration 133, loss = 0.91577562
Iteration 134, loss = 0.83858271
Iteration 135, loss = 0.85441803
Iteration 136, loss = 0.84043831
Iteration 137, loss = 0.82279660
Iteration 138, loss = 0.83512260
Iteration 139, loss = 0.79798502
Iteration 140, loss = 0.81940641
Iteration 141, loss = 0.78219016
Iteration 142, loss = 0.80629759
Iteration 143, loss = 0.76722663
Iteration 144, loss = 0.79231489
Iteration 145, loss = 0.75414444
Iteration 146, loss = 0.78004773
Iteration 147, loss = 0.74480758
Iteration 148, loss = 0.76954196
Iteration 149, loss = 0.73633212
Iteration 150, loss = 0.75961646
Iteration 151, loss = 0.73134539
Iteration 152, loss = 0.83955682
Iteration 153, loss = 0.81639244
Iteration 154, loss = 0.75098247
Iteration 155, loss = 0.80037651
Iteration 156, loss = 0.74553883
Iteration 157, loss = 0.78147223
Iteration 158, loss = 0.73014368
Iteration 159, loss = 0.84333481
Iteration 160, loss = 0.76617499
Iteration 161, loss = 0.73223246
Iteration 162, loss = 0.77868789
Iteration 163, loss = 0.73995186
Iteration 164, loss = 0.76570938
Iteration 165, loss = 0.74000390
Iteration 166, loss = 0.75153370
Iteration 167, loss = 0.71914836
Iteration 168, loss = 0.68782165
Iteration 169, loss = 0.89868176
Iteration 170, loss = 1.30283236
Iteration 171, loss = 0.96111505
Iteration 172, loss = 1.12607766
Iteration 173, loss = 1.16609208
Iteration 174, loss = 0.84995318
Iteration 175, loss = 1.14462558
Iteration 176, loss = 0.78412025
Iteration 177, loss = 1.08071323
Iteration 178, loss = 0.78256142
Iteration 179, loss = 0.71740348
Iteration 180, loss = 0.99028259
Iteration 181, loss = 0.79998489
Iteration 182, loss = 0.97322594
Iteration 183, loss = 0.81582193
Iteration 184, loss = 0.92820111
Iteration 185, loss = 0.83614695
Iteration 186, loss = 0.91386550
Iteration 187, loss = 0.83223442
Iteration 188, loss = 0.84642926
Iteration 189, loss = 0.84851770
Iteration 190, loss = 0.79145270
Iteration 191, loss = 0.84517150
Iteration 192, loss = 0.76361067
Iteration 193, loss = 0.82989091
Iteration 194, loss = 0.75205995
Iteration 195, loss = 0.83716983
Iteration 196, loss = 0.75670809
Iteration 197, loss = 0.80841286
Iteration 198, loss = 0.76432800
Iteration 199, loss = 0.77367488
Iteration 200, loss = 0.76023907
Iteration 201, loss = 0.75912903
Iteration 202, loss = 0.75839577
Iteration 203, loss = 0.71738128
Iteration 204, loss = 0.76444498
Iteration 205, loss = 0.77773006
Iteration 206, loss = 0.77273528
Iteration 207, loss = 0.76859370
Iteration 208, loss = 0.77259844
Iteration 209, loss = 0.75760806
Iteration 210, loss = 0.76478021
Iteration 211, loss = 0.73806370
Iteration 212, loss = 0.76197409
Iteration 213, loss = 0.78078406
Iteration 214, loss = 0.77155033
Iteration 215, loss = 0.77212848
Iteration 216, loss = 0.77505074
Iteration 217, loss = 0.76365868
Iteration 218, loss = 0.77345320
Iteration 219, loss = 0.75622593
Iteration 220, loss = 0.76689943
Iteration 221, loss = 0.74907885
Iteration 222, loss = 0.75464166
Iteration 223, loss = 0.75800579
Iteration 224, loss = 0.74751371
Iteration 225, loss = 0.76972746
Iteration 226, loss = 0.76381103
Iteration 227, loss = 0.77481328
Iteration 228, loss = 0.76770637
Iteration 229, loss = 0.77304085
Iteration 230, loss = 0.76623676
Iteration 231, loss = 0.76543292
Iteration 232, loss = 0.79027981
Iteration 233, loss = 0.81630675
Iteration 234, loss = 0.83348999
Iteration 235, loss = 0.86094592
Iteration 236, loss = 0.86281709
Iteration 237, loss = 0.81788144
Iteration 238, loss = 0.86222162
Iteration 239, loss = 0.78067302
Iteration 240, loss = 0.84403424
Iteration 241, loss = 0.75931481
Iteration 242, loss = 0.82290316
Iteration 243, loss = 0.75289578
Iteration 244, loss = 0.80559193
Iteration 245, loss = 0.74591162
Iteration 246, loss = 0.77006286
Iteration 247, loss = 0.76094636
Iteration 248, loss = 0.76471069
Iteration 249, loss = 0.76324526
Iteration 250, loss = 0.76265463
Iteration 251, loss = 0.75787917
Iteration 252, loss = 0.75094454
Iteration 253, loss = 0.76494969
Iteration 254, loss = 0.77109415
Iteration 255, loss = 0.76634584
Iteration 256, loss = 0.76739317
Iteration 257, loss = 0.76323527
Iteration 258, loss = 0.76240909
Iteration 259, loss = 0.72628619
Iteration 260, loss = 0.75770162
Iteration 261, loss = 0.79605244
Iteration 262, loss = 0.75185711
Iteration 263, loss = 0.79253905
Iteration 264, loss = 0.88365926
Iteration 265, loss = 0.81355628
Iteration 266, loss = 0.70625200
Iteration 267, loss = 1.26244653
Iteration 268, loss = 0.82528622
Iteration 269, loss = 1.16671520
Iteration 270, loss = 1.03980123
Iteration 271, loss = 0.90299945
Iteration 272, loss = 1.07880018
Iteration 273, loss = 0.72330653
Iteration 274, loss = 1.17301044
Iteration 275, loss = 0.78465946
Iteration 276, loss = 1.04448921
Iteration 277, loss = 0.87532431
Iteration 278, loss = 0.92595933
Iteration 279, loss = 0.94219346
Iteration 280, loss = 0.81013059
Iteration 281, loss = 0.94110159
Iteration 282, loss = 0.76708895
Iteration 283, loss = 0.90655399
Iteration 284, loss = 0.77250097
Iteration 285, loss = 0.94919691
Iteration 286, loss = 0.78685189
Iteration 287, loss = 0.90317814
Iteration 288, loss = 0.81747281
Iteration 289, loss = 0.85127300
Iteration 290, loss = 0.78841268
Iteration 291, loss = 0.76757016
Iteration 292, loss = 0.82098813
Iteration 293, loss = 0.78577531
Iteration 294, loss = 0.76535662
Iteration 295, loss = 0.77015029
Iteration 296, loss = 0.77772698
Iteration 297, loss = 0.77501213
Iteration 298, loss = 0.77526140
Iteration 299, loss = 0.77016481
Iteration 300, loss = 0.76753760
Iteration 301, loss = 0.76286791
Iteration 302, loss = 0.75923999
Iteration 303, loss = 0.75278364
Iteration 304, loss = 0.83616122
Iteration 305, loss = 0.90161506
Iteration 306, loss = 0.75453723
Iteration 307, loss = 0.76473781
Iteration 308, loss = 0.75225355
Iteration 309, loss = 0.84783547
Iteration 310, loss = 0.79272926
Iteration 311, loss = 0.85619808
Iteration 312, loss = 0.79586541
Iteration 313, loss = 0.84207058
Iteration 314, loss = 0.78891693
Iteration 315, loss = 0.81958379
Iteration 316, loss = 0.77842820
Iteration 317, loss = 0.79780990
Iteration 318, loss = 0.77219436
Iteration 319, loss = 0.78409619
Iteration 320, loss = 0.77102337
Iteration 321, loss = 0.77628945
Iteration 322, loss = 0.77014170
Iteration 323, loss = 0.71013741
Iteration 324, loss = 0.82424346
Iteration 325, loss = 0.79148841
Iteration 326, loss = 0.83482145
Iteration 327, loss = 0.78850027
Iteration 328, loss = 0.92972385
Iteration 329, loss = 0.80524455
Iteration 330, loss = 0.90447828
Iteration 331, loss = 0.78316623
Iteration 332, loss = 0.86938986
Iteration 333, loss = 0.76394147
Iteration 334, loss = 0.86163545
Iteration 335, loss = 0.78895333
Iteration 336, loss = 0.71187761
Iteration 337, loss = 0.78083667
Iteration 338, loss = 0.78645315
Iteration 339, loss = 0.79097048
Iteration 340, loss = 0.78692779
Iteration 341, loss = 0.78690517
Iteration 342, loss = 0.78129224
Iteration 343, loss = 0.78086502
Iteration 344, loss = 0.77645658
Iteration 345, loss = 0.77606771
Iteration 346, loss = 0.75865122
Iteration 347, loss = 0.78903596
Iteration 348, loss = 0.79987106
Iteration 349, loss = 0.78837935
Iteration 350, loss = 0.77594580
Iteration 351, loss = 0.81702488
Iteration 352, loss = 0.78849703
Iteration 353, loss = 0.81202666
Iteration 354, loss = 0.78296575
Iteration 355, loss = 0.80388553
Iteration 356, loss = 0.77785375
Iteration 357, loss = 0.79726010
Iteration 358, loss = 0.77435570
Iteration 359, loss = 0.78722257
Iteration 360, loss = 0.79597883
Iteration 361, loss = 0.81059927
Iteration 362, loss = 0.78318769
Iteration 363, loss = 0.81582795
Iteration 364, loss = 0.78945897
Iteration 365, loss = 0.81100061
Iteration 366, loss = 0.78704070
Iteration 367, loss = 0.79981465
Iteration 368, loss = 0.77885139
Iteration 369, loss = 0.78658722
Iteration 370, loss = 0.79211194
Iteration 371, loss = 0.79511083
Iteration 372, loss = 0.77681542
Iteration 373, loss = 0.78593454
Iteration 374, loss = 0.78576956
Iteration 375, loss = 0.78855204
Iteration 376, loss = 0.78316169
Iteration 377, loss = 0.78281553
Iteration 378, loss = 0.77641392
Iteration 379, loss = 0.77700648
Iteration 380, loss = 0.77278985
Iteration 381, loss = 0.77439543
Iteration 382, loss = 0.77166431
Iteration 383, loss = 0.77336836
Iteration 384, loss = 0.77070220
Iteration 385, loss = 0.77062407
Iteration 386, loss = 0.76754953
Iteration 387, loss = 0.76597817
Iteration 388, loss = 0.76045229
Iteration 389, loss = 0.75984918
Iteration 390, loss = 0.82693144
Iteration 391, loss = 0.79600732
Iteration 392, loss = 0.79028544
Iteration 393, loss = 0.82331541
Iteration 394, loss = 0.79354269
Iteration 395, loss = 0.80313339
Iteration 396, loss = 0.80063729
Iteration 397, loss = 0.77962665
Iteration 398, loss = 0.79417895
Iteration 399, loss = 0.77381722
Iteration 400, loss = 0.78043882
Iteration 401, loss = 0.77820139
Iteration 402, loss = 0.77075663
Iteration 403, loss = 0.78059084
Iteration 404, loss = 0.76969598
Iteration 405, loss = 0.77686868
Iteration 406, loss = 0.77290070
Iteration 407, loss = 0.77080972
Iteration 408, loss = 0.77443430
Iteration 409, loss = 0.76747133
Iteration 410, loss = 0.77155035
Iteration 411, loss = 0.76650902
Iteration 412, loss = 0.76622662
Iteration 413, loss = 0.76587717
Iteration 414, loss = 0.76208932
Iteration 415, loss = 0.75823314
Iteration 416, loss = 0.72379228
Iteration 417, loss = 0.82580033
Iteration 418, loss = 0.89442042
Iteration 419, loss = 0.78118228
Iteration 420, loss = 0.88915500
Iteration 421, loss = 0.71429855
Iteration 422, loss = 0.83827495
Iteration 423, loss = 0.77267762
Iteration 424, loss = 0.81273666
Iteration 425, loss = 0.78274482
Iteration 426, loss = 0.78789664
Iteration 427, loss = 0.79592384
Iteration 428, loss = 0.77280153
Iteration 429, loss = 0.79886320
Iteration 430, loss = 0.76772920
Iteration 431, loss = 0.78953993
Iteration 432, loss = 0.76994970
Iteration 433, loss = 0.77569150
Iteration 434, loss = 0.77399535
Iteration 435, loss = 0.76508544
Iteration 436, loss = 0.77418656
Iteration 437, loss = 0.75436887
Iteration 438, loss = 0.71305466
Iteration 439, loss = 0.77147758
Iteration 440, loss = 0.71857217
Iteration 441, loss = 0.87703458
Iteration 442, loss = 0.81069221
Iteration 443, loss = 0.86719857
Iteration 444, loss = 0.82362877
Iteration 445, loss = 0.82116827
Iteration 446, loss = 0.82428791
Iteration 447, loss = 0.78618428
Iteration 448, loss = 0.79221458
Iteration 449, loss = 0.78825723
Iteration 450, loss = 0.82814388
Iteration 451, loss = 0.76405885
Iteration 452, loss = 0.78986759
Iteration 453, loss = 0.79898106
Iteration 454, loss = 0.80586658
Iteration 455, loss = 0.79063269
Iteration 456, loss = 0.79779925
Iteration 457, loss = 0.78559935
Iteration 458, loss = 0.78132596
Iteration 459, loss = 0.78458160
Iteration 460, loss = 0.77557645
Iteration 461, loss = 0.78065759
Iteration 462, loss = 0.77605203
Iteration 463, loss = 0.79989330
Iteration 464, loss = 0.78189257
Iteration 465, loss = 0.78943550
Iteration 466, loss = 0.78971890
Iteration 467, loss = 0.77379127
Iteration 468, loss = 0.78082526
Iteration 469, loss = 0.77770599
Iteration 470, loss = 0.78036206
Iteration 471, loss = 0.77447659
Iteration 472, loss = 0.77664714
Iteration 473, loss = 0.77513488
Iteration 474, loss = 0.77286268
Iteration 475, loss = 0.77448143
Iteration 476, loss = 0.77116431
Iteration 477, loss = 0.77182110
Iteration 478, loss = 0.76950105
Iteration 479, loss = 0.76410749
Iteration 480, loss = 0.75867440
Iteration 481, loss = 0.84495797
Iteration 482, loss = 0.93647350
Iteration 483, loss = 0.79842806
Iteration 484, loss = 0.84080159
Iteration 485, loss = 0.83962060
Iteration 486, loss = 0.78739529
Iteration 487, loss = 0.79619660
Iteration 488, loss = 0.81882763
Iteration 489, loss = 0.89003770
Iteration 490, loss = 0.77264641
Iteration 491, loss = 0.88085836
Iteration 492, loss = 0.77122332
Iteration 493, loss = 0.78188141
Iteration 494, loss = 1.03217490
Iteration 495, loss = 0.82153155
Iteration 496, loss = 1.24099432
Iteration 497, loss = 0.84277640
Iteration 498, loss = 1.26320565
Iteration 499, loss = 0.87420572
Iteration 500, loss = 1.56089039
Iteration 501, loss = 0.99737499
Iteration 502, loss = 1.48647026
Iteration 503, loss = 1.30662874
Iteration 504, loss = 1.12564265
Iteration 505, loss = 1.40374297
Iteration 506, loss = 0.85994013
Iteration 507, loss = 1.28282545
Iteration 508, loss = 0.81828003
Iteration 509, loss = 1.19720088
Iteration 510, loss = 0.90147354
Iteration 511, loss = 1.09927251
Iteration 512, loss = 0.98284112
Iteration 513, loss = 0.96281653
Iteration 514, loss = 0.91628414
Iteration 515, loss = 0.85156424
Iteration 516, loss = 0.89098666
Iteration 517, loss = 0.82767380
Iteration 518, loss = 0.86602691
Iteration 519, loss = 0.81105889
Iteration 520, loss = 0.84486110
Iteration 521, loss = 0.80004759
Iteration 522, loss = 0.80252398
Iteration 523, loss = 0.99480688
Iteration 524, loss = 0.82278341
Iteration 525, loss = 0.87289302
Iteration 526, loss = 0.88144304
Iteration 527, loss = 0.82310601
Iteration 528, loss = 1.37176625
Iteration 529, loss = 0.88307580
Iteration 530, loss = 1.37805286
Iteration 531, loss = 1.03000268
Iteration 532, loss = 1.28355936
Iteration 533, loss = 1.16594476
Iteration 534, loss = 1.22504691
Iteration 535, loss = 0.98839706
Iteration 536, loss = 0.99424786
Iteration 537, loss = 0.85140546
Iteration 538, loss = 0.88478212
Iteration 539, loss = 0.82433580
Iteration 540, loss = 0.88155879
Iteration 541, loss = 0.80285885
Iteration 542, loss = 0.86474417
Iteration 543, loss = 0.79353430
Iteration 544, loss = 0.81949409
Iteration 545, loss = 0.83503673
Iteration 546, loss = 0.83029733
Iteration 547, loss = 0.85728721
Iteration 548, loss = 0.82161764
Iteration 549, loss = 0.85852514
Iteration 550, loss = 0.81040444
Iteration 551, loss = 0.84411187
Iteration 552, loss = 0.80262363
Iteration 553, loss = 0.82558652
Iteration 554, loss = 0.80278173
Iteration 555, loss = 0.81008000
Iteration 556, loss = 0.80371991
Iteration 557, loss = 0.80289799
Iteration 558, loss = 0.81538018
Iteration 559, loss = 0.79930608
Iteration 560, loss = 0.81361182
Iteration 561, loss = 0.79544920
Iteration 562, loss = 0.80777583
Iteration 563, loss = 0.79398798
Iteration 564, loss = 0.80151446
Iteration 565, loss = 0.79484021
Iteration 566, loss = 0.79613561
Iteration 567, loss = 0.79549101
Iteration 568, loss = 0.79169079
Iteration 569, loss = 0.79515355
Iteration 570, loss = 0.78909666
Iteration 571, loss = 0.79380362
Iteration 572, loss = 0.78776648
Iteration 573, loss = 0.79106979
Iteration 574, loss = 0.78669642
Iteration 575, loss = 0.78799355
Iteration 576, loss = 0.78626405
Iteration 577, loss = 0.78500670
Iteration 578, loss = 0.78499130
Iteration 579, loss = 0.78234589
Iteration 580, loss = 0.78317011
Iteration 581, loss = 0.77999129
Iteration 582, loss = 0.78019375
Iteration 583, loss = 0.77569894
Iteration 584, loss = 0.77047760
Iteration 585, loss = 0.68953626
Iteration 586, loss = 0.73486478
Iteration 587, loss = 0.78681584
Iteration 588, loss = 0.78814119
Iteration 589, loss = 0.78676079
Iteration 590, loss = 0.78470074
Iteration 591, loss = 0.77848277
Iteration 592, loss = 0.76510102
Iteration 593, loss = 0.77173959
Iteration 594, loss = 0.90484439
Iteration 595, loss = 0.90900577
Iteration 596, loss = 0.83779002
Iteration 597, loss = 0.91922195
Iteration 598, loss = 0.83766438
Iteration 599, loss = 0.90696398
Iteration 600, loss = 0.82033399
Iteration 601, loss = 0.87714241
Iteration 602, loss = 0.80785729
Iteration 603, loss = 0.85102628
Iteration 604, loss = 0.80740080
Iteration 605, loss = 0.83185142
Iteration 606, loss = 0.81229019
Iteration 607, loss = 0.81567081
Iteration 608, loss = 0.85316763
Iteration 609, loss = 0.80251771
Iteration 610, loss = 0.84822125
Iteration 611, loss = 0.80496833
Iteration 612, loss = 0.83321858
Iteration 613, loss = 0.80336925
Iteration 614, loss = 0.81894311
Iteration 615, loss = 0.80304819
Iteration 616, loss = 0.79973515
Iteration 617, loss = 0.80716926
Iteration 618, loss = 0.88747747
Iteration 619, loss = 0.80531143
Iteration 620, loss = 0.87491287
Iteration 621, loss = 0.79918014
Iteration 622, loss = 0.85809379
Iteration 623, loss = 0.78049674
Iteration 624, loss = 0.81748790
Iteration 625, loss = 0.81320056
Iteration 626, loss = 0.81679349
Iteration 627, loss = 0.80644353
Iteration 628, loss = 0.81290185
Iteration 629, loss = 0.80058936
Iteration 630, loss = 0.81014084
Iteration 631, loss = 0.79707754
Iteration 632, loss = 0.80765204
Iteration 633, loss = 0.79459564
Iteration 634, loss = 0.80442144
Iteration 635, loss = 0.79137421
Iteration 636, loss = 0.79671546
Iteration 637, loss = 0.79184404
Iteration 638, loss = 0.89002343
Iteration 639, loss = 0.80954616
Iteration 640, loss = 0.88872533
Iteration 641, loss = 0.81315896
Iteration 642, loss = 0.86991852
Iteration 643, loss = 0.80297062
Iteration 644, loss = 0.84690704
Iteration 645, loss = 0.79523749
Iteration 646, loss = 0.83241434
Iteration 647, loss = 0.79423179
Iteration 648, loss = 0.82461239
Iteration 649, loss = 0.79611147
Iteration 650, loss = 0.81826328
Iteration 651, loss = 0.79644210
Iteration 652, loss = 0.81076554
Iteration 653, loss = 0.79489936
Iteration 654, loss = 0.80364098
Iteration 655, loss = 0.79364125
Iteration 656, loss = 0.79837940
Iteration 657, loss = 0.79302785
Iteration 658, loss = 0.79440836
Iteration 659, loss = 0.79241021
Iteration 660, loss = 0.79110109
Iteration 661, loss = 0.79122646
Iteration 662, loss = 0.78803958
Iteration 663, loss = 0.78967442
Iteration 664, loss = 0.78560459
Iteration 665, loss = 0.78816410
Iteration 666, loss = 0.78381246
Iteration 667, loss = 0.78666241
Iteration 668, loss = 0.78239682
Iteration 669, loss = 0.78495794
Iteration 670, loss = 0.78112523
Iteration 671, loss = 0.78318405
Iteration 672, loss = 0.77955106
Iteration 673, loss = 0.78110198
Iteration 674, loss = 0.77763090
Iteration 675, loss = 0.77831791
Iteration 676, loss = 0.77609075
Iteration 677, loss = 0.77589044
Iteration 678, loss = 0.77405949
Iteration 679, loss = 0.77282987
Iteration 680, loss = 0.76869914
Iteration 681, loss = 0.75467197
Iteration 682, loss = 0.88876137
Iteration 683, loss = 0.85636509
Iteration 684, loss = 0.79378075
Iteration 685, loss = 0.83403391
Iteration 686, loss = 0.80841361
Iteration 687, loss = 1.02328555
Iteration 688, loss = 1.06931278
Iteration 689, loss = 0.88571178
Iteration 690, loss = 1.11311417
Iteration 691, loss = 0.89292698
Iteration 692, loss = 1.09112384
Iteration 693, loss = 0.88735552
Iteration 694, loss = 0.92428804
Iteration 695, loss = 0.94014963
Iteration 696, loss = 0.92246847
Iteration 697, loss = 0.88673966
Iteration 698, loss = 0.92387573
Iteration 699, loss = 0.84889889
Iteration 700, loss = 0.92490599
Iteration 701, loss = 0.82620699
Iteration 702, loss = 0.92302431
Iteration 703, loss = 0.81089670
Iteration 704, loss = 0.91710873
Iteration 705, loss = 0.80185501
Iteration 706, loss = 0.90725516
Iteration 707, loss = 0.79270166
Iteration 708, loss = 0.88621098
Iteration 709, loss = 0.79003527
Iteration 710, loss = 0.83047962
Iteration 711, loss = 0.79284062
Iteration 712, loss = 0.81178167
Iteration 713, loss = 0.79487082
Iteration 714, loss = 0.79245333
Iteration 715, loss = 0.71969117
Iteration 716, loss = 0.82758333
Iteration 717, loss = 0.80234747
Iteration 718, loss = 0.84618152
Iteration 719, loss = 0.81521885
Iteration 720, loss = 0.85315394
Iteration 721, loss = 0.82197597
Iteration 722, loss = 0.84523509
Iteration 723, loss = 0.82050406
Iteration 724, loss = 0.82871662
Iteration 725, loss = 0.81523452
Iteration 726, loss = 0.81071542
Iteration 727, loss = 0.80872761
Iteration 728, loss = 0.79693971
Iteration 729, loss = 0.80244536
Iteration 730, loss = 0.78832023
Iteration 731, loss = 0.79685228
Iteration 732, loss = 0.78142434
Iteration 733, loss = 0.75406882
Iteration 734, loss = 0.79414713
Iteration 735, loss = 0.82565495
Iteration 736, loss = 0.79292677
Iteration 737, loss = 0.81531673
Iteration 738, loss = 0.79337558
Iteration 739, loss = 0.80623332
Iteration 740, loss = 0.79583945
Iteration 741, loss = 0.79876839
Iteration 742, loss = 0.79752249
Iteration 743, loss = 0.79246435
Iteration 744, loss = 0.79724056
Iteration 745, loss = 0.78679698
Iteration 746, loss = 0.79305363
Iteration 747, loss = 0.74804322
Iteration 748, loss = 0.93497283
Iteration 749, loss = 0.88725922
Iteration 750, loss = 0.91923909
Iteration 751, loss = 0.88209859
Iteration 752, loss = 0.89692564
Iteration 753, loss = 0.86884238
Iteration 754, loss = 0.86823675
Iteration 755, loss = 0.85559213
Iteration 756, loss = 0.84369587
Iteration 757, loss = 0.84311508
Iteration 758, loss = 0.82379737
Iteration 759, loss = 0.83550695
Iteration 760, loss = 0.81139961
Iteration 761, loss = 0.83022761
Iteration 762, loss = 0.80185639
Iteration 763, loss = 0.81482129
Iteration 764, loss = 0.85578521
Iteration 765, loss = 0.81744741
Iteration 766, loss = 0.85114602
Iteration 767, loss = 0.80542065
Iteration 768, loss = 0.80821059
Iteration 769, loss = 0.80247166
Iteration 770, loss = 0.80626646
Iteration 771, loss = 0.79611738
Iteration 772, loss = 0.79773212
Iteration 773, loss = 0.79142919
Iteration 774, loss = 0.79505305
Iteration 775, loss = 0.79215265
Iteration 776, loss = 0.79260327
Iteration 777, loss = 0.89889992
Iteration 778, loss = 1.11516518
Iteration 779, loss = 0.83981606
Iteration 780, loss = 1.47366875
Iteration 781, loss = 1.05425511
Iteration 782, loss = 1.39652194
Iteration 783, loss = 1.29330033
Iteration 784, loss = 1.06657912
Iteration 785, loss = 1.23979696
Iteration 786, loss = 0.86813755
Iteration 787, loss = 1.12826874
Iteration 788, loss = 0.80170415
Iteration 789, loss = 1.05728588
Iteration 790, loss = 0.79545552
Iteration 791, loss = 1.01324401
Iteration 792, loss = 0.80975524
Iteration 793, loss = 0.98342058
Iteration 794, loss = 0.81351549
Iteration 795, loss = 1.04943251
Iteration 796, loss = 0.79356844
Iteration 797, loss = 0.90084788
Iteration 798, loss = 0.85313419
Iteration 799, loss = 0.87734425
Iteration 800, loss = 0.79678922
Iteration 801, loss = 0.87393387
Iteration 802, loss = 1.39249304
Iteration 803, loss = 0.91079207
Iteration 804, loss = 1.37368091
Iteration 805, loss = 1.07152984
Iteration 806, loss = 1.23266210
Iteration 807, loss = 1.16239014
Iteration 808, loss = 1.00893896
Iteration 809, loss = 0.71128949
Iteration 810, loss = 0.92964793
Iteration 811, loss = 0.84988922
Iteration 812, loss = 0.92357479
Iteration 813, loss = 0.85424253
Iteration 814, loss = 0.90701932
Iteration 815, loss = 0.84710686
Iteration 816, loss = 0.88580902
Iteration 817, loss = 0.83597605
Iteration 818, loss = 0.86624944
Iteration 819, loss = 0.82747424
Iteration 820, loss = 0.85448838
Iteration 821, loss = 0.82424394
Iteration 822, loss = 0.84675339
Iteration 823, loss = 0.82229973
Iteration 824, loss = 0.84076453
Iteration 825, loss = 0.81945331
Iteration 826, loss = 0.83381727
Iteration 827, loss = 0.81550540
Iteration 828, loss = 0.82221776
Iteration 829, loss = 0.80492944
Iteration 830, loss = 0.78861938
Iteration 831, loss = 0.80768033
Iteration 832, loss = 0.80938149
Iteration 833, loss = 0.80999717
Iteration 834, loss = 0.80820595
Iteration 835, loss = 0.80602118
Iteration 836, loss = 0.80406093
Iteration 837, loss = 0.80404535
Iteration 838, loss = 0.80163294
Iteration 839, loss = 0.79690303
Iteration 840, loss = 0.77947304
Iteration 841, loss = 0.67434300
Iteration 842, loss = 1.67264593
Iteration 843, loss = 1.10808919
Iteration 844, loss = 1.51971648
Iteration 845, loss = 0.84892075
Iteration 846, loss = 1.38011794
Iteration 847, loss = 0.89909881
Iteration 848, loss = 1.30786392
Iteration 849, loss = 1.04405775
Iteration 850, loss = 1.14066837
Iteration 851, loss = 1.13654001
Iteration 852, loss = 0.93451408
Iteration 853, loss = 1.09981669
Iteration 854, loss = 0.83908792
Iteration 855, loss = 1.04332674
Iteration 856, loss = 0.82032831
Iteration 857, loss = 0.95856012
Iteration 858, loss = 0.82391825
Iteration 859, loss = 0.92166256
Iteration 860, loss = 0.82197607
Iteration 861, loss = 0.88470259
Iteration 862, loss = 0.82134332
Iteration 863, loss = 0.85700500
Iteration 864, loss = 0.82112498
Iteration 865, loss = 0.83539447
Iteration 866, loss = 0.82208353
Iteration 867, loss = 0.81851883
Iteration 868, loss = 0.81193190
Iteration 869, loss = 0.65102488
Iteration 870, loss = 0.87958163
Iteration 871, loss = 0.89244145
Iteration 872, loss = 0.85149443
Iteration 873, loss = 0.90500726
Iteration 874, loss = 0.83448710
Iteration 875, loss = 0.90387754
Iteration 876, loss = 0.81907398
Iteration 877, loss = 0.89072909
Iteration 878, loss = 0.81094031
Iteration 879, loss = 0.87464865
Iteration 880, loss = 0.80852249
Iteration 881, loss = 0.85503127
Iteration 882, loss = 0.80992911
Iteration 883, loss = 0.83728001
Iteration 884, loss = 0.81387833
Iteration 885, loss = 0.82224323
Iteration 886, loss = 0.81817375
Iteration 887, loss = 0.81177620
Iteration 888, loss = 0.82079404
Iteration 889, loss = 0.80566554
Iteration 890, loss = 0.82092158
Iteration 891, loss = 0.80230097
Iteration 892, loss = 0.81744188
Iteration 893, loss = 0.80067638
Iteration 894, loss = 0.81164323
Iteration 895, loss = 0.79971625
Iteration 896, loss = 0.80511213
Iteration 897, loss = 0.79883532
Iteration 898, loss = 0.79878323
Iteration 899, loss = 0.79765953
Iteration 900, loss = 0.79361671
Iteration 901, loss = 0.79381642
Iteration 902, loss = 0.77279566
Iteration 903, loss = 0.87091878
Iteration 904, loss = 0.88999717
Iteration 905, loss = 0.81130437
Iteration 906, loss = 0.89699564
Iteration 907, loss = 0.79788894
Iteration 908, loss = 0.88447312
Iteration 909, loss = 0.79183404
Iteration 910, loss = 0.85369596
Iteration 911, loss = 0.79285661
Iteration 912, loss = 0.82034899
Iteration 913, loss = 0.78335136
Iteration 914, loss = 0.83986605
Iteration 915, loss = 0.76141792
Iteration 916, loss = 0.83608986
Iteration 917, loss = 0.85292164
Iteration 918, loss = 0.82995150
Iteration 919, loss = 0.85237824
Iteration 920, loss = 0.81561702
Iteration 921, loss = 0.83558220
Iteration 922, loss = 0.77857140
Iteration 923, loss = 0.96362714
Iteration 924, loss = 0.81936367
Iteration 925, loss = 0.90969057
Iteration 926, loss = 0.81714311
Iteration 927, loss = 0.84804529
Iteration 928, loss = 0.77069666
Iteration 929, loss = 1.12803360
Iteration 930, loss = 1.66608772
Iteration 931, loss = 1.31644137
Iteration 932, loss = 1.32830535
Iteration 933, loss = 1.51091309
Iteration 934, loss = 0.95422204
Iteration 935, loss = 1.39453004
Iteration 936, loss = 0.90968416
Iteration 937, loss = 1.33558384
Iteration 938, loss = 0.98199275
Iteration 939, loss = 1.26842896
Iteration 940, loss = 1.07555102
Iteration 941, loss = 1.15208482
Iteration 942, loss = 1.10893985
Iteration 943, loss = 1.02720601
Iteration 944, loss = 1.08159161
Iteration 945, loss = 0.93705088
Iteration 946, loss = 1.03096517
Iteration 947, loss = 0.88517305
Iteration 948, loss = 0.98270802
Iteration 949, loss = 0.85562807
Iteration 950, loss = 0.94384881
Iteration 951, loss = 0.83892344
Iteration 952, loss = 0.91247464
Iteration 953, loss = 0.82824475
Iteration 954, loss = 0.88806217
Iteration 955, loss = 0.82130108
Iteration 956, loss = 0.86903838
Iteration 957, loss = 0.81651441
Iteration 958, loss = 0.85397278
Iteration 959, loss = 0.81247273
Iteration 960, loss = 0.83657899
Iteration 961, loss = 0.83063838
Iteration 962, loss = 0.81505140
Iteration 963, loss = 0.83304628
Iteration 964, loss = 0.81399172
Iteration 965, loss = 0.82908536
Iteration 966, loss = 0.80917212
Iteration 967, loss = 0.82219264
Iteration 968, loss = 0.80543626
Iteration 969, loss = 0.81661057
Iteration 970, loss = 0.80439853
Iteration 971, loss = 0.81281356
Iteration 972, loss = 0.80453937
Iteration 973, loss = 0.80872825
Iteration 974, loss = 0.79195049
Iteration 975, loss = 0.81174049
Iteration 976, loss = 0.80500146
Iteration 977, loss = 0.81142883
Iteration 978, loss = 0.80345732
Iteration 979, loss = 0.82131532
Iteration 980, loss = 0.82837533
Iteration 981, loss = 0.79567252
Iteration 982, loss = 0.83483146
Iteration 983, loss = 0.81790971
Iteration 984, loss = 0.82584136
Iteration 985, loss = 0.87269923
Iteration 986, loss = 0.83330760
Iteration 987, loss = 0.84787556
Iteration 988, loss = 0.84192944
Iteration 989, loss = 0.82667582
Iteration 990, loss = 0.84407121
Iteration 991, loss = 0.81232006
Iteration 992, loss = 0.83908428
Iteration 993, loss = 0.80597456
Iteration 994, loss = 0.82910219
Iteration 995, loss = 0.81880389
Iteration 996, loss = 0.80916658
Iteration 997, loss = 0.80151101
Iteration 998, loss = 0.77798542
Iteration 999, loss = 1.12437470
Iteration 1000, loss = 0.84534912
Iteration 1001, loss = 0.94513039
Iteration 1002, loss = 1.52917249
Iteration 1003, loss = 1.14991203
Iteration 1004, loss = 0.92637827
Iteration 1005, loss = 1.26127644
Iteration 1006, loss = 0.96336658
Iteration 1007, loss = 1.31040403
Iteration 1008, loss = 0.98105704
Iteration 1009, loss = 1.32356835
Iteration 1010, loss = 0.99816616
Iteration 1011, loss = 1.31077681
Iteration 1012, loss = 1.01949226
Iteration 1013, loss = 1.27305297
Iteration 1014, loss = 1.05313488
Iteration 1015, loss = 1.20487482
Iteration 1016, loss = 1.07019405
Iteration 1017, loss = 1.12326686
Iteration 1018, loss = 1.06294617
Iteration 1019, loss = 1.04774305
Iteration 1020, loss = 1.02885282
Iteration 1021, loss = 0.99924269
Iteration 1022, loss = 0.99035933
Iteration 1023, loss = 0.96571598
Iteration 1024, loss = 0.94927634
Iteration 1025, loss = 0.92927772
Iteration 1026, loss = 0.94168070
Iteration 1027, loss = 0.90924681
Iteration 1028, loss = 0.91148806
Iteration 1029, loss = 0.89469347
Iteration 1030, loss = 0.88602708
Iteration 1031, loss = 0.88299803
Iteration 1032, loss = 0.86427146
Iteration 1033, loss = 0.87312761
Iteration 1034, loss = 0.84819814
Iteration 1035, loss = 0.86412933
Iteration 1036, loss = 0.83297533
Iteration 1037, loss = 0.85070299
Iteration 1038, loss = 0.89922196
Iteration 1039, loss = 0.92258014
Iteration 1040, loss = 0.83540427
Iteration 1041, loss = 0.92822215
Iteration 1042, loss = 0.83751261
Iteration 1043, loss = 1.06636377
Iteration 1044, loss = 0.80657381
Iteration 1045, loss = 0.79416393
Iteration 1046, loss = 1.12542592
Iteration 1047, loss = 0.89927975
Iteration 1048, loss = 1.09127058
Iteration 1049, loss = 0.82927611
Iteration 1050, loss = 0.97549728
Iteration 1051, loss = 0.73759625
Iteration 1052, loss = 0.84638312
Iteration 1053, loss = 0.81614016
Iteration 1054, loss = 0.82396197
Iteration 1055, loss = 0.85291585
Iteration 1056, loss = 0.82849418
Iteration 1057, loss = 0.84521459
Iteration 1058, loss = 0.82734649
Iteration 1059, loss = 0.83517083
Iteration 1060, loss = 0.82154962
Iteration 1061, loss = 0.82063394
Iteration 1062, loss = 0.81732798
Iteration 1063, loss = 0.82205727
Iteration 1064, loss = 0.81935607
Iteration 1065, loss = 0.81892489
Iteration 1066, loss = 0.81750164
Iteration 1067, loss = 0.81450607
Iteration 1068, loss = 0.81359185
Iteration 1069, loss = 0.81415212
Iteration 1070, loss = 0.80769695
Iteration 1071, loss = 0.80471157
Iteration 1072, loss = 0.80169669
Iteration 1073, loss = 0.79707366
Iteration 1074, loss = 0.74896678
Iteration 1075, loss = 1.04454629
Iteration 1076, loss = 1.06153135
Iteration 1077, loss = 1.09648736
Iteration 1078, loss = 0.95756268
Iteration 1079, loss = 1.07371701
Iteration 1080, loss = 0.89115129
Iteration 1081, loss = 1.02620742
Iteration 1082, loss = 0.85380748
Iteration 1083, loss = 0.97512606
Iteration 1084, loss = 0.74889035
Iteration 1085, loss = 1.01544861
Iteration 1086, loss = 0.85582391
Iteration 1087, loss = 0.98677047
Iteration 1088, loss = 0.83515934
Iteration 1089, loss = 0.95720735
Iteration 1090, loss = 0.82979437
Iteration 1091, loss = 0.93175782
Iteration 1092, loss = 0.83214740
Iteration 1093, loss = 0.91142312
Iteration 1094, loss = 0.83616168
Iteration 1095, loss = 0.89363098
Iteration 1096, loss = 0.83857454
Iteration 1097, loss = 0.87729582
Iteration 1098, loss = 0.83757889
Iteration 1099, loss = 0.86037952
Iteration 1100, loss = 0.82229680
Iteration 1101, loss = 0.83226005
Iteration 1102, loss = 0.86777442
Iteration 1103, loss = 0.82302831
Iteration 1104, loss = 0.85307910
Iteration 1105, loss = 0.80776067
Iteration 1106, loss = 0.74656972
Iteration 1107, loss = 1.12629329
Iteration 1108, loss = 1.09478567
Iteration 1109, loss = 1.04390186
Iteration 1110, loss = 1.05949908
Iteration 1111, loss = 1.01403778
Iteration 1112, loss = 1.01506605
Iteration 1113, loss = 0.98721616
Iteration 1114, loss = 0.97343792
Iteration 1115, loss = 0.95630974
Iteration 1116, loss = 0.93888393
Iteration 1117, loss = 0.92967489
Iteration 1118, loss = 0.91432499
Iteration 1119, loss = 0.90855469
Iteration 1120, loss = 0.89801402
Iteration 1121, loss = 0.89189863
Iteration 1122, loss = 0.88602889
Iteration 1123, loss = 0.87723276
Iteration 1124, loss = 0.87606423
Iteration 1125, loss = 0.86435411
Iteration 1126, loss = 0.86699107
Iteration 1127, loss = 0.85271329
Iteration 1128, loss = 0.85791459
Iteration 1129, loss = 0.84144343
Iteration 1130, loss = 0.90959522
Iteration 1131, loss = 0.85495300
Iteration 1132, loss = 1.02529352
Iteration 1133, loss = 0.88231994
Iteration 1134, loss = 0.99209766
Iteration 1135, loss = 0.88709169
Iteration 1136, loss = 1.06026557
Iteration 1137, loss = 0.83913930
Iteration 1138, loss = 1.00001600
Iteration 1139, loss = 0.84796024
Iteration 1140, loss = 0.92113980
Iteration 1141, loss = 0.84616441
Iteration 1142, loss = 0.90363400
Iteration 1143, loss = 0.83920718
Iteration 1144, loss = 0.88569906
Iteration 1145, loss = 0.83412036
Iteration 1146, loss = 0.87396041
Iteration 1147, loss = 0.83337252
Iteration 1148, loss = 0.86649567
Iteration 1149, loss = 0.83361224
Iteration 1150, loss = 0.85990589
Iteration 1151, loss = 0.83255717
Iteration 1152, loss = 0.85372460
Iteration 1153, loss = 0.85325047
Iteration 1154, loss = 0.85294679
Iteration 1155, loss = 0.87651433
Iteration 1156, loss = 0.87745562
Iteration 1157, loss = 0.89035857
Iteration 1158, loss = 0.88354466
Iteration 1159, loss = 0.88564040
Iteration 1160, loss = 0.87507197
Iteration 1161, loss = 0.87282982
Iteration 1162, loss = 0.86266496
Iteration 1163, loss = 0.85856864
Iteration 1164, loss = 0.81333326
Iteration 1165, loss = 0.85784911
Iteration 1166, loss = 0.85655007
Iteration 1167, loss = 0.85910387
Iteration 1168, loss = 0.85751518
Iteration 1169, loss = 0.85821793
Iteration 1170, loss = 0.85598585
Iteration 1171, loss = 0.85636656
Iteration 1172, loss = 0.85457387
Iteration 1173, loss = 0.85533498
Iteration 1174, loss = 0.85458005
Iteration 1175, loss = 0.85563711
Iteration 1176, loss = 0.85529031
Iteration 1177, loss = 0.85604531
Iteration 1178, loss = 0.85584796
Iteration 1179, loss = 0.85490218
Iteration 1180, loss = 0.85503160
Iteration 1181, loss = 0.85322909
Iteration 1182, loss = 0.85349410
Iteration 1183, loss = 0.85181267
Iteration 1184, loss = 0.85228427
Iteration 1185, loss = 0.85109566
Iteration 1186, loss = 0.85133483
Iteration 1187, loss = 0.85046649
Iteration 1188, loss = 0.85016987
Iteration 1189, loss = 0.85242886
Iteration 1190, loss = 0.85299068
Iteration 1191, loss = 0.85443759
Iteration 1192, loss = 0.85396385
Iteration 1193, loss = 0.84900576
Iteration 1194, loss = 0.84799559
Iteration 1195, loss = 0.84440664
Iteration 1196, loss = 0.84302000
Iteration 1197, loss = 0.83894385
Iteration 1198, loss = 0.98714435
Iteration 1199, loss = 0.87484087
Iteration 1200, loss = 0.95967948
Iteration 1201, loss = 0.90611978
Iteration 1202, loss = 0.91855951
Iteration 1203, loss = 0.92080635
Iteration 1204, loss = 0.88012446
Iteration 1205, loss = 0.91989314
Iteration 1206, loss = 0.85820433
Iteration 1207, loss = 0.90797204
Iteration 1208, loss = 0.85488495
Iteration 1209, loss = 0.89122229
Iteration 1210, loss = 0.86293300
Iteration 1211, loss = 0.87408948
Iteration 1212, loss = 0.87262732
Iteration 1213, loss = 0.86103379
Iteration 1214, loss = 0.87680768
Iteration 1215, loss = 0.85404167
Iteration 1216, loss = 0.87342829
Iteration 1217, loss = 0.85284913
Iteration 1218, loss = 0.86534581
Iteration 1219, loss = 0.85512653
Iteration 1220, loss = 0.85648522
Iteration 1221, loss = 0.85711866
Iteration 1222, loss = 0.84962233
Iteration 1223, loss = 0.85646729
Iteration 1224, loss = 0.84623848
Iteration 1225, loss = 0.85337626
Iteration 1226, loss = 0.84594447
Iteration 1227, loss = 0.84919056
Iteration 1228, loss = 0.84683483
Iteration 1229, loss = 0.84526093
Iteration 1230, loss = 0.84689668
Iteration 1231, loss = 0.84242248
Iteration 1232, loss = 0.84536000
Iteration 1233, loss = 0.84087254
Iteration 1234, loss = 0.84266268
Iteration 1235, loss = 0.84012829
Iteration 1236, loss = 0.83975443
Iteration 1237, loss = 0.83952778
Iteration 1238, loss = 0.83749485
Iteration 1239, loss = 0.83843959
Iteration 1240, loss = 0.83603259
Iteration 1241, loss = 0.83683505
Iteration 1242, loss = 0.83509840
Iteration 1243, loss = 0.83491920
Iteration 1244, loss = 0.83428047
Iteration 1245, loss = 0.83322376
Iteration 1246, loss = 0.83329108
Iteration 1247, loss = 0.83184772
Iteration 1248, loss = 0.83194912
Iteration 1249, loss = 0.83076028
Iteration 1250, loss = 0.83046062
Iteration 1251, loss = 0.82975465
Iteration 1252, loss = 0.82895444
Iteration 1253, loss = 0.82860668
Iteration 1254, loss = 0.82759542
Iteration 1255, loss = 0.82731938
Iteration 1256, loss = 0.82640463
Iteration 1257, loss = 0.82596227
Iteration 1258, loss = 0.82532340
Iteration 1259, loss = 0.82468076
Iteration 1260, loss = 0.82422458
Iteration 1261, loss = 0.82337350
Iteration 1262, loss = 0.82268349
Iteration 1263, loss = 0.82196296
Iteration 1264, loss = 0.82123095
Iteration 1265, loss = 0.82085091
Iteration 1266, loss = 0.82028147
Iteration 1267, loss = 0.81910677
Iteration 1268, loss = 0.82018469
Iteration 1269, loss = 0.82361980
Iteration 1270, loss = 0.82157622
Iteration 1271, loss = 0.82267346
Iteration 1272, loss = 0.81939294
Iteration 1273, loss = 0.81856185
Iteration 1274, loss = 0.81838927
Iteration 1275, loss = 0.81639216
Iteration 1276, loss = 0.81652601
Iteration 1277, loss = 0.81366100
Iteration 1278, loss = 0.80827009
Iteration 1279, loss = 0.82851363
Iteration 1280, loss = 1.09711518
Iteration 1281, loss = 0.85393270
Iteration 1282, loss = 1.01186776
Iteration 1283, loss = 0.90612800
Iteration 1284, loss = 0.91464775
Iteration 1285, loss = 0.94839961
Iteration 1286, loss = 0.84654666
Iteration 1287, loss = 0.95188805
Iteration 1288, loss = 0.82154292
Iteration 1289, loss = 0.91753448
Iteration 1290, loss = 0.83269251
Iteration 1291, loss = 0.86846246
Iteration 1292, loss = 0.86149382
Iteration 1293, loss = 0.83218240
Iteration 1294, loss = 0.87712591
Iteration 1295, loss = 0.81946483
Iteration 1296, loss = 0.86686784
Iteration 1297, loss = 0.82487806
Iteration 1298, loss = 0.83937161
Iteration 1299, loss = 0.83472132
Iteration 1300, loss = 0.81398227
Iteration 1301, loss = 0.81851826
Iteration 1302, loss = 0.84987222
Iteration 1303, loss = 0.83000150
Iteration 1304, loss = 0.83781564
Iteration 1305, loss = 0.84073773
Iteration 1306, loss = 0.82286418
Iteration 1307, loss = 0.83842660
Iteration 1308, loss = 0.81381478
Iteration 1309, loss = 0.82737124
Iteration 1310, loss = 0.81338059
Iteration 1311, loss = 0.81640525
Iteration 1312, loss = 0.81542450
Iteration 1313, loss = 0.80750491
Iteration 1314, loss = 0.81420489
Iteration 1315, loss = 0.80116081
Iteration 1316, loss = 0.79901945
Iteration 1317, loss = 1.03621043
Iteration 1318, loss = 0.94046410
Iteration 1319, loss = 0.93199693
Iteration 1320, loss = 1.03670117
Iteration 1321, loss = 0.94261874
Iteration 1322, loss = 1.03079736
Iteration 1323, loss = 0.91218367
Iteration 1324, loss = 1.02075362
Iteration 1325, loss = 0.89124716
Iteration 1326, loss = 1.01374614
Iteration 1327, loss = 0.88102674
Iteration 1328, loss = 1.00922683
Iteration 1329, loss = 0.87238336
Iteration 1330, loss = 0.99910938
Iteration 1331, loss = 0.86213465
Iteration 1332, loss = 0.98693019
Iteration 1333, loss = 0.85352805
Iteration 1334, loss = 0.97511126
Iteration 1335, loss = 0.85675410
Iteration 1336, loss = 1.07340530
Iteration 1337, loss = 0.88125935
Iteration 1338, loss = 1.06315938
Iteration 1339, loss = 0.89971724
Iteration 1340, loss = 1.03492823
Iteration 1341, loss = 0.89781097
Iteration 1342, loss = 1.00025455
Iteration 1343, loss = 0.89202961
Iteration 1344, loss = 0.97416177
Iteration 1345, loss = 0.88904657
Iteration 1346, loss = 0.95603763
Iteration 1347, loss = 0.88510518
Iteration 1348, loss = 0.93981583
Iteration 1349, loss = 0.87643570
Iteration 1350, loss = 0.92354515
Iteration 1351, loss = 0.86530215
Iteration 1352, loss = 0.90908565
Iteration 1353, loss = 0.85542858
Iteration 1354, loss = 0.89809233
Iteration 1355, loss = 0.84697511
Iteration 1356, loss = 0.88858692
Iteration 1357, loss = 0.83893579
Iteration 1358, loss = 0.87942622
Iteration 1359, loss = 0.83147424
Iteration 1360, loss = 0.87064213
Iteration 1361, loss = 0.82211727
Iteration 1362, loss = 0.87756570
Iteration 1363, loss = 0.81967577
Iteration 1364, loss = 0.86741831
Iteration 1365, loss = 0.81889709
Iteration 1366, loss = 0.85690103
Iteration 1367, loss = 0.81629343
Iteration 1368, loss = 0.84765609
Iteration 1369, loss = 0.81374645
Iteration 1370, loss = 0.83973865
Iteration 1371, loss = 0.81184150
Iteration 1372, loss = 0.83418265
Iteration 1373, loss = 0.81014593
Iteration 1374, loss = 0.82816363
Iteration 1375, loss = 0.80720924
Iteration 1376, loss = 0.82159872
Iteration 1377, loss = 0.80445977
Iteration 1378, loss = 0.81688230
Iteration 1379, loss = 0.80151484
Iteration 1380, loss = 0.81184350
Iteration 1381, loss = 0.79828949
Iteration 1382, loss = 0.80585926
Iteration 1383, loss = 0.79367576
Iteration 1384, loss = 0.79925402
Iteration 1385, loss = 0.79306966
Iteration 1386, loss = 0.79543544
Iteration 1387, loss = 0.78779538
Iteration 1388, loss = 0.82381962
Iteration 1389, loss = 0.97059848
Iteration 1390, loss = 0.82384013
Iteration 1391, loss = 0.95905264
Iteration 1392, loss = 0.82779541
Iteration 1393, loss = 0.86352632
Iteration 1394, loss = 0.95430535
Iteration 1395, loss = 1.11626206
Iteration 1396, loss = 0.95758649
Iteration 1397, loss = 0.90832949
Iteration 1398, loss = 0.94641160
Iteration 1399, loss = 0.82589375
Iteration 1400, loss = 1.00697577
Iteration 1401, loss = 0.82273829
Iteration 1402, loss = 0.96905769
Iteration 1403, loss = 0.83257399
Iteration 1404, loss = 0.93384725
Iteration 1405, loss = 0.84671857
Iteration 1406, loss = 0.90495656
Iteration 1407, loss = 0.85688147
Iteration 1408, loss = 0.88080651
Iteration 1409, loss = 0.86016766
Iteration 1410, loss = 0.85891544
Iteration 1411, loss = 0.85752777
Iteration 1412, loss = 0.84157507
Iteration 1413, loss = 0.85221773
Iteration 1414, loss = 0.82928996
Iteration 1415, loss = 0.84676571
Iteration 1416, loss = 0.82161478
Iteration 1417, loss = 0.84142423
Iteration 1418, loss = 0.81632950
Iteration 1419, loss = 0.83592610
Iteration 1420, loss = 0.81263878
Iteration 1421, loss = 0.83069463
Iteration 1422, loss = 0.80938755
Iteration 1423, loss = 0.82501015
Iteration 1424, loss = 0.80650648
Iteration 1425, loss = 0.81973725
Iteration 1426, loss = 0.80337014
Iteration 1427, loss = 0.81348367
Iteration 1428, loss = 0.79894485
Iteration 1429, loss = 0.80613076
Iteration 1430, loss = 0.79047720
Iteration 1431, loss = 0.78147253
Iteration 1432, loss = 0.88321229
Iteration 1433, loss = 0.85347237
Iteration 1434, loss = 0.86135246
Iteration 1435, loss = 0.86499933
Iteration 1436, loss = 0.83832792
Iteration 1437, loss = 0.86640321
Iteration 1438, loss = 0.81822122
Iteration 1439, loss = 0.86083969
Iteration 1440, loss = 0.80589777
Iteration 1441, loss = 0.85207573
Iteration 1442, loss = 0.80160229
Iteration 1443, loss = 0.84337763
Iteration 1444, loss = 0.80216735
Iteration 1445, loss = 0.83385547
Iteration 1446, loss = 0.80421676
Iteration 1447, loss = 0.82330911
Iteration 1448, loss = 0.80573340
Iteration 1449, loss = 0.81321771
Iteration 1450, loss = 0.80104398
Iteration 1451, loss = 0.79919016
Iteration 1452, loss = 0.80712266
Iteration 1453, loss = 0.81406149
Iteration 1454, loss = 0.81721535
Iteration 1455, loss = 0.82194875
Iteration 1456, loss = 0.82036959
Iteration 1457, loss = 0.81677201
Iteration 1458, loss = 0.81127586
Iteration 1459, loss = 0.80679532
Iteration 1460, loss = 0.80313149
Iteration 1461, loss = 0.80125133
Iteration 1462, loss = 0.80087615
Iteration 1463, loss = 0.80139261
Iteration 1464, loss = 0.80208560
Iteration 1465, loss = 0.80308100
Iteration 1466, loss = 0.80372018
Iteration 1467, loss = 0.80351666
Iteration 1468, loss = 0.80305806
Iteration 1469, loss = 0.80209197
Iteration 1470, loss = 0.80096005
Iteration 1471, loss = 0.79990828
Iteration 1472, loss = 0.79897814
Iteration 1473, loss = 0.79805853
Iteration 1474, loss = 0.79750186
Iteration 1475, loss = 0.79711222
Iteration 1476, loss = 0.79680364
Iteration 1477, loss = 0.79642563
Iteration 1478, loss = 0.79610408
Iteration 1479, loss = 0.79570368
Iteration 1480, loss = 0.79514156
Iteration 1481, loss = 0.79419819
Iteration 1482, loss = 0.79156312
Iteration 1483, loss = 0.79049617
Iteration 1484, loss = 0.76515240
Iteration 1485, loss = 0.80105721
Iteration 1486, loss = 0.81148121
Iteration 1487, loss = 0.79857515
Iteration 1488, loss = 0.80873000
Iteration 1489, loss = 0.79462223
Iteration 1490, loss = 0.80495974
Iteration 1491, loss = 0.79297079
Iteration 1492, loss = 0.80162237
Iteration 1493, loss = 0.79283352
Iteration 1494, loss = 0.79861981
Iteration 1495, loss = 0.79263860
Iteration 1496, loss = 0.79539815
Iteration 1497, loss = 0.79233761
Iteration 1498, loss = 0.79166472
Iteration 1499, loss = 0.78883271
Iteration 1500, loss = 0.78738857
Iteration 1501, loss = 0.78390777
Iteration 1502, loss = 0.77909147
Iteration 1503, loss = 0.77293214
Iteration 1504, loss = 0.76338957
Iteration 1505, loss = 0.70590973
Iteration 1506, loss = 1.35764293
Iteration 1507, loss = 1.45345091
Iteration 1508, loss = 1.39785454
Iteration 1509, loss = 1.00410680
Iteration 1510, loss = 1.19355729
Iteration 1511, loss = 0.94094280
Iteration 1512, loss = 1.13691494
Iteration 1513, loss = 0.89536836
Iteration 1514, loss = 1.06504788
Iteration 1515, loss = 0.86020187
Iteration 1516, loss = 1.00295349
Iteration 1517, loss = 0.84152533
Iteration 1518, loss = 0.95998042
Iteration 1519, loss = 0.83752039
Iteration 1520, loss = 0.93281587
Iteration 1521, loss = 0.84166544
Iteration 1522, loss = 0.91682127
Iteration 1523, loss = 0.84858628
Iteration 1524, loss = 0.90257033
Iteration 1525, loss = 0.84880844
Iteration 1526, loss = 0.88807721
Iteration 1527, loss = 0.84681697
Iteration 1528, loss = 0.87470376
Iteration 1529, loss = 0.84212295
Iteration 1530, loss = 0.86223279
Iteration 1531, loss = 0.83682177
Iteration 1532, loss = 0.85225986
Iteration 1533, loss = 0.83255567
Iteration 1534, loss = 0.84469549
Iteration 1535, loss = 0.82927297
Iteration 1536, loss = 0.83881276
Iteration 1537, loss = 0.82596795
Iteration 1538, loss = 0.83327480
Iteration 1539, loss = 0.82227343
Iteration 1540, loss = 0.82816422
Iteration 1541, loss = 0.81892546
Iteration 1542, loss = 0.82421453
Iteration 1543, loss = 0.81665710
Iteration 1544, loss = 0.82145275
Iteration 1545, loss = 0.81487922
Iteration 1546, loss = 0.81896289
Iteration 1547, loss = 0.81300687
Iteration 1548, loss = 0.81635368
Iteration 1549, loss = 0.81085465
Iteration 1550, loss = 0.81355799
Iteration 1551, loss = 0.80850621
Iteration 1552, loss = 0.81080507
Iteration 1553, loss = 0.80625351
Iteration 1554, loss = 0.80850942
Iteration 1555, loss = 0.80338299
Iteration 1556, loss = 0.80559779
Iteration 1557, loss = 0.79782169
Iteration 1558, loss = 0.81523893
Iteration 1559, loss = 0.86622017
Iteration 1560, loss = 0.82095809
Iteration 1561, loss = 0.86720980
Iteration 1562, loss = 0.82104953
Iteration 1563, loss = 0.85256531
Iteration 1564, loss = 0.81249802
Iteration 1565, loss = 0.83873055
Iteration 1566, loss = 0.80725371
Iteration 1567, loss = 0.83055833
Iteration 1568, loss = 0.80585259
Iteration 1569, loss = 0.82591953
Iteration 1570, loss = 0.80600142
Iteration 1571, loss = 0.82254575
Iteration 1572, loss = 0.80532324
Iteration 1573, loss = 0.81821414
Iteration 1574, loss = 0.80313813
Iteration 1575, loss = 0.81317596
Iteration 1576, loss = 0.80033562
Iteration 1577, loss = 0.80874208
Iteration 1578, loss = 0.79755093
Iteration 1579, loss = 0.80021413
Iteration 1580, loss = 0.78573879
Iteration 1581, loss = 0.89029012
Iteration 1582, loss = 0.83222279
Iteration 1583, loss = 0.88997714
Iteration 1584, loss = 0.84442363
Iteration 1585, loss = 0.87334662
Iteration 1586, loss = 0.84039514
Iteration 1587, loss = 0.85062051
Iteration 1588, loss = 0.83330693
Iteration 1589, loss = 0.83399555
Iteration 1590, loss = 0.83111019
Iteration 1591, loss = 0.82562732
Iteration 1592, loss = 0.83200163
Iteration 1593, loss = 0.82144401
Iteration 1594, loss = 0.83237687
Iteration 1595, loss = 0.81874678
Iteration 1596, loss = 0.83119160
Iteration 1597, loss = 0.81659732
Iteration 1598, loss = 0.82876120
Iteration 1599, loss = 0.81527179
Iteration 1600, loss = 0.82597345
Iteration 1601, loss = 0.81466823
Iteration 1602, loss = 0.82304939
Iteration 1603, loss = 0.81438971
Iteration 1604, loss = 0.82008575
Iteration 1605, loss = 0.81412192
Iteration 1606, loss = 0.81727104
Iteration 1607, loss = 0.81384279
Iteration 1608, loss = 0.81485593
Iteration 1609, loss = 0.81345503
Iteration 1610, loss = 0.81272928
Iteration 1611, loss = 0.81266205
Iteration 1612, loss = 0.81069949
Iteration 1613, loss = 0.81142356
Iteration 1614, loss = 0.80886352
Iteration 1615, loss = 0.81000330
Iteration 1616, loss = 0.80736994
Iteration 1617, loss = 0.80851872
Iteration 1618, loss = 0.80600984
Iteration 1619, loss = 0.80668318
Iteration 1620, loss = 0.80414998
Iteration 1621, loss = 0.80363141
Iteration 1622, loss = 0.80048516
Iteration 1623, loss = 0.79768905
Iteration 1624, loss = 0.79002531
Iteration 1625, loss = 0.75527974
Iteration 1626, loss = 0.87594958
Iteration 1627, loss = 0.92804819
Iteration 1628, loss = 0.82978845
Iteration 1629, loss = 0.94786908
Iteration 1630, loss = 0.82051746
Iteration 1631, loss = 0.89756125
Iteration 1632, loss = 0.83366974
Iteration 1633, loss = 0.83948959
Iteration 1634, loss = 0.85618467
Iteration 1635, loss = 0.80632069
Iteration 1636, loss = 0.86123105
Iteration 1637, loss = 0.80258751
Iteration 1638, loss = 0.84349888
Iteration 1639, loss = 0.81389990
Iteration 1640, loss = 0.81778097
Iteration 1641, loss = 0.82472068
Iteration 1642, loss = 0.80038740
Iteration 1643, loss = 0.82522235
Iteration 1644, loss = 0.79650603
Iteration 1645, loss = 0.81481119
Iteration 1646, loss = 0.80044208
Iteration 1647, loss = 0.80088221
Iteration 1648, loss = 0.80372582
Iteration 1649, loss = 0.79032790
Iteration 1650, loss = 0.80116195
Iteration 1651, loss = 0.78531976
Iteration 1652, loss = 0.79265523
Iteration 1653, loss = 0.78500409
Iteration 1654, loss = 0.78431436
Iteration 1655, loss = 0.78374558
Iteration 1656, loss = 0.77417752
Iteration 1657, loss = 0.77154938
Iteration 1658, loss = 0.70129774
Iteration 1659, loss = 0.78154392
Iteration 1660, loss = 0.79800868
Iteration 1661, loss = 0.77137341
Iteration 1662, loss = 0.78534510
Iteration 1663, loss = 0.72025594
Iteration 1664, loss = 1.33767000
Iteration 1665, loss = 1.36534946
Iteration 1666, loss = 1.26656214
Iteration 1667, loss = 1.25271923
Iteration 1668, loss = 1.20755652
Iteration 1669, loss = 1.14513487
Iteration 1670, loss = 1.12280502
Iteration 1671, loss = 1.07785385
Iteration 1672, loss = 1.04106418
Iteration 1673, loss = 1.03692103
Iteration 1674, loss = 0.97500326
Iteration 1675, loss = 1.01798812
Iteration 1676, loss = 0.92704207
Iteration 1677, loss = 1.00776611
Iteration 1678, loss = 0.89570209
Iteration 1679, loss = 0.98428142
Iteration 1680, loss = 0.80016765
Iteration 1681, loss = 0.87487788
Iteration 1682, loss = 0.81556545
Iteration 1683, loss = 0.89959807
Iteration 1684, loss = 0.84760200
Iteration 1685, loss = 0.87160299
Iteration 1686, loss = 0.87106507
Iteration 1687, loss = 0.83903595
Iteration 1688, loss = 0.86620266
Iteration 1689, loss = 0.81892393
Iteration 1690, loss = 0.84189488
Iteration 1691, loss = 0.81725230
Iteration 1692, loss = 0.81392300
Iteration 1693, loss = 0.81835963
Iteration 1694, loss = 0.79596401
Iteration 1695, loss = 0.79845359
Iteration 1696, loss = 0.82087799
Iteration 1697, loss = 0.80925427
Iteration 1698, loss = 0.81992182
Iteration 1699, loss = 0.81151592
Iteration 1700, loss = 0.80976589
Iteration 1701, loss = 0.81039786
Iteration 1702, loss = 0.80346193
Iteration 1703, loss = 0.81083266
Iteration 1704, loss = 0.80408249
Iteration 1705, loss = 0.80998804
Iteration 1706, loss = 0.80596126
Iteration 1707, loss = 0.80625118
Iteration 1708, loss = 0.80596126
Iteration 1709, loss = 0.80212279
Iteration 1710, loss = 0.80435628
Iteration 1711, loss = 0.80001026
Iteration 1712, loss = 0.80208100
Iteration 1713, loss = 0.79630702
Iteration 1714, loss = 0.79154771
Iteration 1715, loss = 0.80313279
Iteration 1716, loss = 0.80893552
Iteration 1717, loss = 0.80208685
Iteration 1718, loss = 0.81962869
Iteration 1719, loss = 0.84317197
Iteration 1720, loss = 0.80110072
Iteration 1721, loss = 0.86112460
Iteration 1722, loss = 0.86331459
Iteration 1723, loss = 0.83071120
Iteration 1724, loss = 0.88154505
Iteration 1725, loss = 0.81610509
Iteration 1726, loss = 0.86509541
Iteration 1727, loss = 0.81387115
Iteration 1728, loss = 0.83701351
Iteration 1729, loss = 0.82426769
Iteration 1730, loss = 0.81610555
Iteration 1731, loss = 0.92329487
Iteration 1732, loss = 0.88471117
Iteration 1733, loss = 0.82375621
Iteration 1734, loss = 0.90489127
Iteration 1735, loss = 0.84387491
Iteration 1736, loss = 0.90481542
Iteration 1737, loss = 0.86931023
Iteration 1738, loss = 0.88542768
Iteration 1739, loss = 0.88477930
Iteration 1740, loss = 0.86374619
Iteration 1741, loss = 0.88340495
Iteration 1742, loss = 0.84679135
Iteration 1743, loss = 0.86755822
Iteration 1744, loss = 0.83891377
Iteration 1745, loss = 0.89602932
Iteration 1746, loss = 0.95800605
Iteration 1747, loss = 0.83712203
Iteration 1748, loss = 0.95287585
Iteration 1749, loss = 0.85000157
Iteration 1750, loss = 0.92582606
Iteration 1751, loss = 0.86265688
Iteration 1752, loss = 0.88248991
Iteration 1753, loss = 0.86242272
Iteration 1754, loss = 0.85829178
Iteration 1755, loss = 0.84797259
Iteration 1756, loss = 0.84524720
Iteration 1757, loss = 0.85184348
Iteration 1758, loss = 0.83622872
Iteration 1759, loss = 0.85125793
Iteration 1760, loss = 0.83145436
Iteration 1761, loss = 0.84931830
Iteration 1762, loss = 0.83189342
Iteration 1763, loss = 0.84400854
Iteration 1764, loss = 0.83035824
Iteration 1765, loss = 0.83446600
Iteration 1766, loss = 0.82821161
Iteration 1767, loss = 0.82636481
Iteration 1768, loss = 0.82297039
Iteration 1769, loss = 0.82041728
Iteration 1770, loss = 0.82628252
Iteration 1771, loss = 0.82503412
Iteration 1772, loss = 0.82439833
Iteration 1773, loss = 0.82108951
Iteration 1774, loss = 0.80964234
Iteration 1775, loss = 0.80413302
Iteration 1776, loss = 1.01019080
Iteration 1777, loss = 0.89011417
Iteration 1778, loss = 0.93086655
Iteration 1779, loss = 0.96323835
Iteration 1780, loss = 0.87218192
Iteration 1781, loss = 0.97371784
Iteration 1782, loss = 0.84929572
Iteration 1783, loss = 0.92460160
Iteration 1784, loss = 0.85808464
Iteration 1785, loss = 0.86258661
Iteration 1786, loss = 0.87755820
Iteration 1787, loss = 0.82786640
Iteration 1788, loss = 0.88061069
Iteration 1789, loss = 0.82644504
Iteration 1790, loss = 0.86160509
Iteration 1791, loss = 0.84203753
Iteration 1792, loss = 0.83674443
Iteration 1793, loss = 0.85326503
Iteration 1794, loss = 0.82333366
Iteration 1795, loss = 0.84845893
Iteration 1796, loss = 0.82400736
Iteration 1797, loss = 0.83284104
Iteration 1798, loss = 0.83017871
Iteration 1799, loss = 0.81955055
Iteration 1800, loss = 0.83197019
Iteration 1801, loss = 0.81570123
Iteration 1802, loss = 0.82613990
Iteration 1803, loss = 0.81847723
Iteration 1804, loss = 0.81751902
Iteration 1805, loss = 0.82103705
Iteration 1806, loss = 0.81233343
Iteration 1807, loss = 0.81891297
Iteration 1808, loss = 0.81149979
Iteration 1809, loss = 0.80961093
Iteration 1810, loss = 0.83668585
Iteration 1811, loss = 0.83547142
Iteration 1812, loss = 0.83457576
Iteration 1813, loss = 0.85420509
Iteration 1814, loss = 0.82975799
Iteration 1815, loss = 0.84706438
Iteration 1816, loss = 0.82321462
Iteration 1817, loss = 0.82905256
Iteration 1818, loss = 0.82155678
Iteration 1819, loss = 0.81517482
Iteration 1820, loss = 0.82261298
Iteration 1821, loss = 0.81080093
Iteration 1822, loss = 0.82121150
Iteration 1823, loss = 0.81252887
Iteration 1824, loss = 0.81632894
Iteration 1825, loss = 0.81447388
Iteration 1826, loss = 0.81039324
Iteration 1827, loss = 0.81409310
Iteration 1828, loss = 0.80726976
Iteration 1829, loss = 0.81131658
Iteration 1830, loss = 0.80669995
Iteration 1831, loss = 0.80672973
Iteration 1832, loss = 0.80615822
Iteration 1833, loss = 0.80319942
Iteration 1834, loss = 0.80458821
Iteration 1835, loss = 0.80048716
Iteration 1836, loss = 0.80086593
Iteration 1837, loss = 0.79568015
Iteration 1838, loss = 0.77794231
Iteration 1839, loss = 0.83234044
Iteration 1840, loss = 0.83910471
Iteration 1841, loss = 0.81858061
Iteration 1842, loss = 0.84298041
Iteration 1843, loss = 0.80489875
Iteration 1844, loss = 0.83041760
Iteration 1845, loss = 0.80113715
Iteration 1846, loss = 0.81480685
Iteration 1847, loss = 0.80571812
Iteration 1848, loss = 0.80368079
Iteration 1849, loss = 0.81034708
Iteration 1850, loss = 0.79571780
Iteration 1851, loss = 0.80774179
Iteration 1852, loss = 0.79222128
Iteration 1853, loss = 0.78439088
Iteration 1854, loss = 0.69606700
Iteration 1855, loss = 0.83276206
Iteration 1856, loss = 0.89489790
Iteration 1857, loss = 0.81191959
Iteration 1858, loss = 0.88445167
Iteration 1859, loss = 0.81283786
Iteration 1860, loss = 0.84539627
Iteration 1861, loss = 0.82839204
Iteration 1862, loss = 0.81183504
Iteration 1863, loss = 0.83997789
Iteration 1864, loss = 0.79896238
Iteration 1865, loss = 0.83328950
Iteration 1866, loss = 0.80125392
Iteration 1867, loss = 0.81353641
Iteration 1868, loss = 0.79526042
Iteration 1869, loss = 0.80642854
Iteration 1870, loss = 0.80692298
Iteration 1871, loss = 0.80656748
Iteration 1872, loss = 0.80674714
Iteration 1873, loss = 0.80203539
Iteration 1874, loss = 0.80173480
Iteration 1875, loss = 0.79714448
Iteration 1876, loss = 0.79848680
Iteration 1877, loss = 0.79615646
Iteration 1878, loss = 0.79739892
Iteration 1879, loss = 0.79518472
Iteration 1880, loss = 0.79470075
Iteration 1881, loss = 0.79324841
Iteration 1882, loss = 0.78803509
Iteration 1883, loss = 0.77798246
Iteration 1884, loss = 0.93937533
Iteration 1885, loss = 1.46209499
Iteration 1886, loss = 0.96919874
Iteration 1887, loss = 1.44060102
Iteration 1888, loss = 1.25191805
Iteration 1889, loss = 1.19715217
Iteration 1890, loss = 1.30453083
Iteration 1891, loss = 0.94590686
Iteration 1892, loss = 0.99014634
Iteration 1893, loss = 0.87695966
Iteration 1894, loss = 0.93199646
Iteration 1895, loss = 0.86789738
Iteration 1896, loss = 0.87257833
Iteration 1897, loss = 0.85792148
Iteration 1898, loss = 0.85530077
Iteration 1899, loss = 0.89835814
Iteration 1900, loss = 0.83608025
Iteration 1901, loss = 0.90136914
Iteration 1902, loss = 0.82576167
Iteration 1903, loss = 0.89271198
Iteration 1904, loss = 0.81954999
Iteration 1905, loss = 0.87723463
Iteration 1906, loss = 0.82010173
Iteration 1907, loss = 0.86117126
Iteration 1908, loss = 0.82421589
Iteration 1909, loss = 0.84356172
Iteration 1910, loss = 0.82666495
Iteration 1911, loss = 0.82745192
Iteration 1912, loss = 0.82819650
Iteration 1913, loss = 0.81628678
Iteration 1914, loss = 0.82790717
Iteration 1915, loss = 0.80900992
Iteration 1916, loss = 0.82403462
Iteration 1917, loss = 0.80485719
Iteration 1918, loss = 0.81809168
Iteration 1919, loss = 0.80299917
Iteration 1920, loss = 0.81134504
Iteration 1921, loss = 0.80257204
Iteration 1922, loss = 0.80533002
Iteration 1923, loss = 0.80256531
Iteration 1924, loss = 0.80023267
Iteration 1925, loss = 0.80139903
Iteration 1926, loss = 0.79550100
Iteration 1927, loss = 0.79895783
Iteration 1928, loss = 0.79225568
Iteration 1929, loss = 0.79541180
Iteration 1930, loss = 0.78930409
Iteration 1931, loss = 0.79149911
Iteration 1932, loss = 0.78575613
Iteration 1933, loss = 0.78327731
Iteration 1934, loss = 0.76115691
Iteration 1935, loss = 0.84302807
Iteration 1936, loss = 0.88251866
Iteration 1937, loss = 0.83396761
Iteration 1938, loss = 0.88368556
Iteration 1939, loss = 0.81634647
Iteration 1940, loss = 0.86486935
Iteration 1941, loss = 0.78935988
Iteration 1942, loss = 0.78297101
Iteration 1943, loss = 0.91155465
Iteration 1944, loss = 0.96369467
Iteration 1945, loss = 0.85060906
Iteration 1946, loss = 0.97956023
Iteration 1947, loss = 0.84640961
Iteration 1948, loss = 0.96932968
Iteration 1949, loss = 0.82957752
Iteration 1950, loss = 0.94755913
Iteration 1951, loss = 0.81347314
Iteration 1952, loss = 0.92519267
Iteration 1953, loss = 0.80497079
Iteration 1954, loss = 0.90653307
Iteration 1955, loss = 0.80261086
Iteration 1956, loss = 0.88885480
Iteration 1957, loss = 0.80352904
Iteration 1958, loss = 0.87074808
Iteration 1959, loss = 0.80517931
Iteration 1960, loss = 0.85215833
Iteration 1961, loss = 0.80708052
Iteration 1962, loss = 0.83469393
Iteration 1963, loss = 0.80875867
Iteration 1964, loss = 0.81908915
Iteration 1965, loss = 0.80929742
Iteration 1966, loss = 0.80605364
Iteration 1967, loss = 0.80728481
Iteration 1968, loss = 0.79485229
Iteration 1969, loss = 0.79642978
Iteration 1970, loss = 0.85591296
Iteration 1971, loss = 0.93162137
Iteration 1972, loss = 0.83802952
Iteration 1973, loss = 0.93509067
Iteration 1974, loss = 0.81965144
Iteration 1975, loss = 0.92493936
Iteration 1976, loss = 0.80336834
Iteration 1977, loss = 0.91004304
Iteration 1978, loss = 0.79705240
Iteration 1979, loss = 0.89519287
Iteration 1980, loss = 0.79661551
Iteration 1981, loss = 0.87686495
Iteration 1982, loss = 0.79711413
Iteration 1983, loss = 0.85491296
Iteration 1984, loss = 0.79835958
Iteration 1985, loss = 0.83337911
Iteration 1986, loss = 0.80143724
Iteration 1987, loss = 0.81567931
Iteration 1988, loss = 0.80554447
Iteration 1989, loss = 0.80278594
Iteration 1990, loss = 0.80832744
Iteration 1991, loss = 0.79376822
Iteration 1992, loss = 0.80805062
Iteration 1993, loss = 0.78778693
Iteration 1994, loss = 0.80458731
Iteration 1995, loss = 0.78415486
Iteration 1996, loss = 0.79892999
Iteration 1997, loss = 0.78201295
Iteration 1998, loss = 0.78995406
Iteration 1999, loss = 0.78611518
Iteration 2000, loss = 0.77969930
Iteration 2001, loss = 0.77440658
Iteration 2002, loss = 0.78701376
Iteration 2003, loss = 0.80449149
Iteration 2004, loss = 0.78361436
Iteration 2005, loss = 0.79850200
Iteration 2006, loss = 0.77758674
Iteration 2007, loss = 0.79116814
Iteration 2008, loss = 0.76610752
Iteration 2009, loss = 0.79453265
Iteration 2010, loss = 0.83421120
Iteration 2011, loss = 0.79399378
Iteration 2012, loss = 0.83153342
Iteration 2013, loss = 0.78953992
Iteration 2014, loss = 0.81552813
Iteration 2015, loss = 0.78699952
Iteration 2016, loss = 0.79962611
Iteration 2017, loss = 0.79119020
Iteration 2018, loss = 0.79089363
Iteration 2019, loss = 0.79677727
Iteration 2020, loss = 0.78546411
Iteration 2021, loss = 0.79691181
Iteration 2022, loss = 0.78125869
Iteration 2023, loss = 0.79222879
Iteration 2024, loss = 0.77956413
Iteration 2025, loss = 0.78649852
Iteration 2026, loss = 0.78057049
Iteration 2027, loss = 0.78197083
Iteration 2028, loss = 0.78213180
Iteration 2029, loss = 0.77856588
Iteration 2030, loss = 0.78207369
Iteration 2031, loss = 0.77614395
Iteration 2032, loss = 0.78065403
Iteration 2033, loss = 0.77597774
Iteration 2034, loss = 0.77772433
Iteration 2035, loss = 0.77597420
Iteration 2036, loss = 0.77494111
Iteration 2037, loss = 0.77573654
Iteration 2038, loss = 0.77320085
Iteration 2039, loss = 0.77475343
Iteration 2040, loss = 0.77199485
Iteration 2041, loss = 0.77334416
Iteration 2042, loss = 0.77144782
Iteration 2043, loss = 0.77180107
Iteration 2044, loss = 0.77101846
Iteration 2045, loss = 0.77027958
Iteration 2046, loss = 0.77031485
Iteration 2047, loss = 0.76895061
Iteration 2048, loss = 0.76931692
Iteration 2049, loss = 0.76796640
Iteration 2050, loss = 0.76816546
Iteration 2051, loss = 0.76720490
Iteration 2052, loss = 0.76702543
Iteration 2053, loss = 0.76659418
Iteration 2054, loss = 0.76598929
Iteration 2055, loss = 0.76583147
Iteration 2056, loss = 0.76502599
Iteration 2057, loss = 0.76493545
Iteration 2058, loss = 0.76416464
Iteration 2059, loss = 0.76398072
Iteration 2060, loss = 0.76344463
Iteration 2061, loss = 0.76308043
Iteration 2062, loss = 0.76274238
Iteration 2063, loss = 0.76226562
Iteration 2064, loss = 0.76206873
Iteration 2065, loss = 0.76156796
Iteration 2066, loss = 0.76135020
Iteration 2067, loss = 0.76088427
Iteration 2068, loss = 0.76059780
Iteration 2069, loss = 0.76023398
Iteration 2070, loss = 0.75986580
Iteration 2071, loss = 0.75956317
Iteration 2072, loss = 0.75914301
Iteration 2073, loss = 0.75883740
Iteration 2074, loss = 0.75838241
Iteration 2075, loss = 0.75802678
Iteration 2076, loss = 0.75762439
Iteration 2077, loss = 0.75727929
Iteration 2078, loss = 0.75694247
Iteration 2079, loss = 0.75656287
Iteration 2080, loss = 0.75623724
Iteration 2081, loss = 0.75587399
Iteration 2082, loss = 0.75557874
Iteration 2083, loss = 0.75523450
Iteration 2084, loss = 0.75492146
Iteration 2085, loss = 0.75461669
Iteration 2086, loss = 0.75430759
Iteration 2087, loss = 0.75399986
Iteration 2088, loss = 0.75359516
Iteration 2089, loss = 0.75313943
Iteration 2090, loss = 0.75291354
Iteration 2091, loss = 0.75270796
Iteration 2092, loss = 0.75238079
Iteration 2093, loss = 0.75197582
Iteration 2094, loss = 0.75154036
Iteration 2095, loss = 0.75130247
Iteration 2096, loss = 0.75112703
Iteration 2097, loss = 0.75173105
Iteration 2098, loss = 0.75189046
Iteration 2099, loss = 0.75123878
Iteration 2100, loss = 0.75017287
Iteration 2101, loss = 0.74965956
Iteration 2102, loss = 0.74927420
Iteration 2103, loss = 0.74882024
Iteration 2104, loss = 0.74869928
Iteration 2105, loss = 0.74831813
Iteration 2106, loss = 0.74823177
Iteration 2107, loss = 0.74778004
Iteration 2108, loss = 0.74707843
Iteration 2109, loss = 0.74641517
Iteration 2110, loss = 0.74627059
Iteration 2111, loss = 0.74629025
Iteration 2112, loss = 0.74526003
Iteration 2113, loss = 0.74458568
Iteration 2114, loss = 0.74409999
Iteration 2115, loss = 0.74318750
Iteration 2116, loss = 0.74211005
Iteration 2117, loss = 0.73610041
Iteration 2118, loss = 0.69358806
Iteration 2119, loss = 0.77795613
Iteration 2120, loss = 0.83410483
Iteration 2121, loss = 0.76311730
Iteration 2122, loss = 0.82176638
Iteration 2123, loss = 0.76854299
Iteration 2124, loss = 0.77918307
Iteration 2125, loss = 0.78244988
Iteration 2126, loss = 0.75034748
Iteration 2127, loss = 0.78585824
Iteration 2128, loss = 0.75154996
Iteration 2129, loss = 0.77291586
Iteration 2130, loss = 0.76627985
Iteration 2131, loss = 0.75565100
Iteration 2132, loss = 0.77125632
Iteration 2133, loss = 0.74839231
Iteration 2134, loss = 0.76194758
Iteration 2135, loss = 0.75165858
Iteration 2136, loss = 0.74943678
Iteration 2137, loss = 0.75656513
Iteration 2138, loss = 0.74470247
Iteration 2139, loss = 0.75609460
Iteration 2140, loss = 0.74968874
Iteration 2141, loss = 0.75000192
Iteration 2142, loss = 0.74951119
Iteration 2143, loss = 0.73600124
Iteration 2144, loss = 0.62531151
Iteration 2145, loss = 0.84730905
Iteration 2146, loss = 0.97182379
Iteration 2147, loss = 0.80014398
Iteration 2148, loss = 0.99154965
Iteration 2149, loss = 0.76794236
Iteration 2150, loss = 0.90212332
Iteration 2151, loss = 0.76301446
Iteration 2152, loss = 0.87681745
Iteration 2153, loss = 0.75750099
Iteration 2154, loss = 0.85353804
Iteration 2155, loss = 0.75802595
Iteration 2156, loss = 0.83100952
Iteration 2157, loss = 0.76051440
Iteration 2158, loss = 0.81030498
Iteration 2159, loss = 0.76539032
Iteration 2160, loss = 0.79213142
Iteration 2161, loss = 0.76950622
Iteration 2162, loss = 0.77730051
Iteration 2163, loss = 0.77305850
Iteration 2164, loss = 0.76684616
Iteration 2165, loss = 0.77406120
Iteration 2166, loss = 0.75794357
Iteration 2167, loss = 0.77099232
Iteration 2168, loss = 0.75181234
Iteration 2169, loss = 0.76607597
Iteration 2170, loss = 0.74446709
Iteration 2171, loss = 0.75565429
Iteration 2172, loss = 0.73178525
Iteration 2173, loss = 0.96208027
Iteration 2174, loss = 1.23255153
Iteration 2175, loss = 0.89368255
Iteration 2176, loss = 1.22823430
Iteration 2177, loss = 1.04934860
Iteration 2178, loss = 1.11360683
Iteration 2179, loss = 1.09788717
Iteration 2180, loss = 0.96316569
Iteration 2181, loss = 1.04466463
Iteration 2182, loss = 0.86366665
Iteration 2183, loss = 0.97305327
Iteration 2184, loss = 0.81012405
Iteration 2185, loss = 0.91559934
Iteration 2186, loss = 0.78682912
Iteration 2187, loss = 0.87623681
Iteration 2188, loss = 0.78056196
Iteration 2189, loss = 0.85013996
Iteration 2190, loss = 0.77916183
Iteration 2191, loss = 0.82830158
Iteration 2192, loss = 0.75999388
Iteration 2193, loss = 0.84140131
Iteration 2194, loss = 0.80296954
Iteration 2195, loss = 0.82549290
Iteration 2196, loss = 0.78861893
Iteration 2197, loss = 0.80600074
Iteration 2198, loss = 0.77957592
Iteration 2199, loss = 0.79326347
Iteration 2200, loss = 0.75330119
Iteration 2201, loss = 0.85046300
Iteration 2202, loss = 0.76077082
Iteration 2203, loss = 0.97899361
Iteration 2204, loss = 0.89399265
Iteration 2205, loss = 0.86680462
Iteration 2206, loss = 0.87006881
Iteration 2207, loss = 0.84850809
Iteration 2208, loss = 0.73957280
Iteration 2209, loss = 1.06977958
Iteration 2210, loss = 0.78623563
Iteration 2211, loss = 1.04430549
Iteration 2212, loss = 0.79508393
Iteration 2213, loss = 0.98850975
Iteration 2214, loss = 0.82092267
Iteration 2215, loss = 0.93351545
Iteration 2216, loss = 0.84512479
Iteration 2217, loss = 0.88252798
Iteration 2218, loss = 0.85920443
Iteration 2219, loss = 0.84240542
Iteration 2220, loss = 0.85787886
Iteration 2221, loss = 0.80985109
Iteration 2222, loss = 0.84600682
Iteration 2223, loss = 0.78724131
Iteration 2224, loss = 0.83248961
Iteration 2225, loss = 0.77435382
Iteration 2226, loss = 0.82066423
Iteration 2227, loss = 0.76720057
Iteration 2228, loss = 0.80933826
Iteration 2229, loss = 0.76236021
Iteration 2230, loss = 0.79957973
Iteration 2231, loss = 0.75944152
Iteration 2232, loss = 0.79090718
Iteration 2233, loss = 0.75773493
Iteration 2234, loss = 0.78431239
Iteration 2235, loss = 0.75705720
Iteration 2236, loss = 0.77847504
Iteration 2237, loss = 0.75612029
Iteration 2238, loss = 0.77325721
Iteration 2239, loss = 0.75511300
Iteration 2240, loss = 0.76886786
Iteration 2241, loss = 0.75435972
Iteration 2242, loss = 0.76522203
Iteration 2243, loss = 0.75362899
Iteration 2244, loss = 0.76229489
Iteration 2245, loss = 0.75300520
Iteration 2246, loss = 0.75982014
Iteration 2247, loss = 0.75225084
Iteration 2248, loss = 0.75744087
Iteration 2249, loss = 0.75147056
Iteration 2250, loss = 0.75560611
Iteration 2251, loss = 0.75059953
Iteration 2252, loss = 0.75362364
Iteration 2253, loss = 0.74977605
Iteration 2254, loss = 0.75209941
Iteration 2255, loss = 0.74791801
Iteration 2256, loss = 0.73771777
Iteration 2257, loss = 0.76230351
Iteration 2258, loss = 0.77347354
Iteration 2259, loss = 0.76415784
Iteration 2260, loss = 0.77029189
Iteration 2261, loss = 0.75781473
Iteration 2262, loss = 0.76357365
Iteration 2263, loss = 0.75325348
Iteration 2264, loss = 0.76116502
Iteration 2265, loss = 0.75342023
Iteration 2266, loss = 0.76145403
Iteration 2267, loss = 0.75366041
Iteration 2268, loss = 0.75992400
Iteration 2269, loss = 0.75227242
Iteration 2270, loss = 0.75760757
Iteration 2271, loss = 0.75108553
Iteration 2272, loss = 0.75608536
Iteration 2273, loss = 0.75056901
Iteration 2274, loss = 0.75474528
Iteration 2275, loss = 0.75015093
Iteration 2276, loss = 0.75354380
Iteration 2277, loss = 0.74962164
Iteration 2278, loss = 0.75208154
Iteration 2279, loss = 0.74903259
Iteration 2280, loss = 0.75116529
Iteration 2281, loss = 0.74853279
Iteration 2282, loss = 0.74994034
Iteration 2283, loss = 0.74801584
Iteration 2284, loss = 0.74914344
Iteration 2285, loss = 0.74770246
Iteration 2286, loss = 0.74801483
Iteration 2287, loss = 0.74683414
Iteration 2288, loss = 0.74703348
Iteration 2289, loss = 0.74620709
Iteration 2290, loss = 0.74591014
Iteration 2291, loss = 0.74510973
Iteration 2292, loss = 0.74464305
Iteration 2293, loss = 0.74362984
Iteration 2294, loss = 0.74297294
Iteration 2295, loss = 0.74210924
Iteration 2296, loss = 0.73768454
Iteration 2297, loss = 0.68790677
Iteration 2298, loss = 0.76374878
Iteration 2299, loss = 0.77997679
Iteration 2300, loss = 0.76666470
Iteration 2301, loss = 0.77626220
Iteration 2302, loss = 0.76185805
Iteration 2303, loss = 0.76808538
Iteration 2304, loss = 0.75585270
Iteration 2305, loss = 0.76260782
Iteration 2306, loss = 0.75413172
Iteration 2307, loss = 0.76094694
Iteration 2308, loss = 0.75388880
Iteration 2309, loss = 0.75981797
Iteration 2310, loss = 0.75297155
Iteration 2311, loss = 0.75462190
Iteration 2312, loss = 0.65541735
Iteration 2313, loss = 0.76814633
Iteration 2314, loss = 0.76760231
Iteration 2315, loss = 0.77984938
Iteration 2316, loss = 0.77435172
Iteration 2317, loss = 0.77791603
Iteration 2318, loss = 0.76936965
Iteration 2319, loss = 0.76918390
Iteration 2320, loss = 0.76317477
Iteration 2321, loss = 0.76397664
Iteration 2322, loss = 0.76001924
Iteration 2323, loss = 0.76119070
Iteration 2324, loss = 0.75960517
Iteration 2325, loss = 0.76078962
Iteration 2326, loss = 0.75940675
Iteration 2327, loss = 0.75960329
Iteration 2328, loss = 0.75841012
Iteration 2329, loss = 0.75818699
Iteration 2330, loss = 0.75739556
Iteration 2331, loss = 0.75709696
Iteration 2332, loss = 0.75743588
Iteration 2333, loss = 0.75666675
Iteration 2334, loss = 0.75832421
Iteration 2335, loss = 0.75806666
Iteration 2336, loss = 0.75830962
Iteration 2337, loss = 0.75648308
Iteration 2338, loss = 0.75533539
Iteration 2339, loss = 0.75353684
Iteration 2340, loss = 0.75309057
Iteration 2341, loss = 0.75245129
Iteration 2342, loss = 0.75273184
Iteration 2343, loss = 0.75238985
Iteration 2344, loss = 0.75229489
Iteration 2345, loss = 0.75161729
Iteration 2346, loss = 0.75112478
Iteration 2347, loss = 0.75008533
Iteration 2348, loss = 0.74954112
Iteration 2349, loss = 0.74904449
Iteration 2350, loss = 0.74872419
Iteration 2351, loss = 0.74793467
Iteration 2352, loss = 0.74753017
Iteration 2353, loss = 0.74680598
Iteration 2354, loss = 0.74651981
Iteration 2355, loss = 0.74596404
Iteration 2356, loss = 0.74526977
Iteration 2357, loss = 0.74457438
Iteration 2358, loss = 0.74394931
Iteration 2359, loss = 0.74289621
Iteration 2360, loss = 0.74133656
Iteration 2361, loss = 0.74021292
Iteration 2362, loss = 0.73896395
Iteration 2363, loss = 0.73786361
Iteration 2364, loss = 0.73593314
Iteration 2365, loss = 0.72770462
Iteration 2366, loss = 0.63972137
Iteration 2367, loss = 0.73680192
Iteration 2368, loss = 0.75109690
Iteration 2369, loss = 0.78636237
Iteration 2370, loss = 0.84218451
Iteration 2371, loss = 0.79616838
Iteration 2372, loss = 0.81393542
Iteration 2373, loss = 0.77945806
Iteration 2374, loss = 0.72578845
Iteration 2375, loss = 0.77374209
Iteration 2376, loss = 1.20963260
Iteration 2377, loss = 0.77881778
Iteration 2378, loss = 1.15266301
Iteration 2379, loss = 0.83636813
Iteration 2380, loss = 1.07305803
Iteration 2381, loss = 0.91053491
Iteration 2382, loss = 0.95562509
Iteration 2383, loss = 0.93145733
Iteration 2384, loss = 0.85089294
Iteration 2385, loss = 0.90807037
Iteration 2386, loss = 0.88899561
Iteration 2387, loss = 0.77470131
Iteration 2388, loss = 0.80000368
Iteration 2389, loss = 0.79171342
Iteration 2390, loss = 0.80843835
Iteration 2391, loss = 0.79976278
Iteration 2392, loss = 0.80797525
Iteration 2393, loss = 0.79791918
Iteration 2394, loss = 0.80070448
Iteration 2395, loss = 0.79066197
Iteration 2396, loss = 0.79049396
Iteration 2397, loss = 0.78251350
Iteration 2398, loss = 0.78230167
Iteration 2399, loss = 0.77781616
Iteration 2400, loss = 0.77759571
Iteration 2401, loss = 0.77518622
Iteration 2402, loss = 0.77488586
Iteration 2403, loss = 0.77390815
Iteration 2404, loss = 0.77320860
Iteration 2405, loss = 0.77362258
Iteration 2406, loss = 0.77313258
Iteration 2407, loss = 0.77323111
Iteration 2408, loss = 0.77245426
Iteration 2409, loss = 0.77333431
Iteration 2410, loss = 0.77171758
Iteration 2411, loss = 0.77204509
Iteration 2412, loss = 0.77005395
Iteration 2413, loss = 0.76957942
Iteration 2414, loss = 0.76605360
Iteration 2415, loss = 0.76251844
Iteration 2416, loss = 0.75397946
Iteration 2417, loss = 0.74097021
Iteration 2418, loss = 0.66087356
Iteration 2419, loss = 1.31931906
Iteration 2420, loss = 1.32838499
Iteration 2421, loss = 1.36519900
Iteration 2422, loss = 0.86994356
Iteration 2423, loss = 0.82269679
Iteration 2424, loss = 1.28628514
Iteration 2425, loss = 0.82070171
Iteration 2426, loss = 1.17238615
Iteration 2427, loss = 0.88641139
Iteration 2428, loss = 0.91404323
Iteration 2429, loss = 1.04340284
Iteration 2430, loss = 0.82910983
Iteration 2431, loss = 1.02723244
Iteration 2432, loss = 0.81895176
Iteration 2433, loss = 0.95789084
Iteration 2434, loss = 0.82897746
Iteration 2435, loss = 0.87977980
Iteration 2436, loss = 0.85744788
Iteration 2437, loss = 0.82519091
Iteration 2438, loss = 0.87739303
Iteration 2439, loss = 0.79845935
Iteration 2440, loss = 0.87192852
Iteration 2441, loss = 0.79627138
Iteration 2442, loss = 0.84370981
Iteration 2443, loss = 0.80482807
Iteration 2444, loss = 0.81545189
Iteration 2445, loss = 0.81930321
Iteration 2446, loss = 0.79648023
Iteration 2447, loss = 0.82380000
Iteration 2448, loss = 0.78871128
Iteration 2449, loss = 0.81563452
Iteration 2450, loss = 0.79030492
Iteration 2451, loss = 0.80148243
Iteration 2452, loss = 0.79551365
Iteration 2453, loss = 0.78843675
Iteration 2454, loss = 0.79731891
Iteration 2455, loss = 0.78165554
Iteration 2456, loss = 0.79457412
Iteration 2457, loss = 0.78110952
Iteration 2458, loss = 0.78779830
Iteration 2459, loss = 0.78247496
Iteration 2460, loss = 0.78015020
Iteration 2461, loss = 0.78250558
Iteration 2462, loss = 0.77390009
Iteration 2463, loss = 0.77841504
Iteration 2464, loss = 0.72446091
Iteration 2465, loss = 0.79708498
Iteration 2466, loss = 0.79728125
Iteration 2467, loss = 0.80856335
Iteration 2468, loss = 0.79545032
Iteration 2469, loss = 0.80145805
Iteration 2470, loss = 0.78954122
Iteration 2471, loss = 0.78765019
Iteration 2472, loss = 0.78728723
Iteration 2473, loss = 0.78212877
Iteration 2474, loss = 0.78876216
Iteration 2475, loss = 0.78419511
Iteration 2476, loss = 0.78826772
Iteration 2477, loss = 0.78682672
Iteration 2478, loss = 0.78518547
Iteration 2479, loss = 0.78689124
Iteration 2480, loss = 0.78286847
Iteration 2481, loss = 0.78501505
Iteration 2482, loss = 0.78251338
Iteration 2483, loss = 0.78247323
Iteration 2484, loss = 0.78252472
Iteration 2485, loss = 0.78048587
Iteration 2486, loss = 0.78168616
Iteration 2487, loss = 0.77975787
Iteration 2488, loss = 0.78030587
Iteration 2489, loss = 0.77984300
Iteration 2490, loss = 0.77907146
Iteration 2491, loss = 0.77955207
Iteration 2492, loss = 0.77814447
Iteration 2493, loss = 0.77833677
Iteration 2494, loss = 0.77733966
Iteration 2495, loss = 0.77805729
Iteration 2496, loss = 0.78561036
Iteration 2497, loss = 0.78130755
Iteration 2498, loss = 0.78591060
Iteration 2499, loss = 0.78526304
Iteration 2500, loss = 0.78012223
Iteration 2501, loss = 0.78159501
Iteration 2502, loss = 0.77513790
Iteration 2503, loss = 0.77714996
Iteration 2504, loss = 0.77574644
Iteration 2505, loss = 0.77525764
Iteration 2506, loss = 0.77700594
Iteration 2507, loss = 0.77387495
Iteration 2508, loss = 0.77501230
Iteration 2509, loss = 0.77259466
Iteration 2510, loss = 0.77193761
Iteration 2511, loss = 0.77199511
Iteration 2512, loss = 0.77025553
Iteration 2513, loss = 0.77115575
Iteration 2514, loss = 0.76961429
Iteration 2515, loss = 0.76947185
Iteration 2516, loss = 0.76901369
Iteration 2517, loss = 0.76786278
Iteration 2518, loss = 0.76813886
Iteration 2519, loss = 0.76699308
Iteration 2520, loss = 0.76692513
Iteration 2521, loss = 0.76635064
Iteration 2522, loss = 0.76554362
Iteration 2523, loss = 0.76539436
Iteration 2524, loss = 0.76443824
Iteration 2525, loss = 0.76425731
Iteration 2526, loss = 0.76371720
Iteration 2527, loss = 0.76322388
Iteration 2528, loss = 0.76304363
Iteration 2529, loss = 0.76239323
Iteration 2530, loss = 0.76217959
Iteration 2531, loss = 0.76165492
Iteration 2532, loss = 0.76119992
Iteration 2533, loss = 0.76088102
Iteration 2534, loss = 0.76032492
Iteration 2535, loss = 0.76005161
Iteration 2536, loss = 0.75958683
Iteration 2537, loss = 0.75921334
Iteration 2538, loss = 0.75891224
Iteration 2539, loss = 0.75846174
Iteration 2540, loss = 0.75807251
Iteration 2541, loss = 0.77812733
Iteration 2542, loss = 0.85935262
Iteration 2543, loss = 0.78257014
Iteration 2544, loss = 0.82304291
Iteration 2545, loss = 0.82475506
Iteration 2546, loss = 0.78802231
Iteration 2547, loss = 0.83408468
Iteration 2548, loss = 0.76865107
Iteration 2549, loss = 0.80640829
Iteration 2550, loss = 0.77232170
Iteration 2551, loss = 0.77411245
Iteration 2552, loss = 0.78633614
Iteration 2553, loss = 0.75954087
Iteration 2554, loss = 0.78872905
Iteration 2555, loss = 0.76217158
Iteration 2556, loss = 0.77489939
Iteration 2557, loss = 0.76985050
Iteration 2558, loss = 0.75951304
Iteration 2559, loss = 0.77183817
Iteration 2560, loss = 0.75434636
Iteration 2561, loss = 0.76593011
Iteration 2562, loss = 0.75795219
Iteration 2563, loss = 0.75714132
Iteration 2564, loss = 0.76143113
Iteration 2565, loss = 0.75201592
Iteration 2566, loss = 0.75942482
Iteration 2567, loss = 0.75226005
Iteration 2568, loss = 0.75408095
Iteration 2569, loss = 0.75442328
Iteration 2570, loss = 0.75012975
Iteration 2571, loss = 0.75439539
Iteration 2572, loss = 0.74949346
Iteration 2573, loss = 0.75161745
Iteration 2574, loss = 0.75045894
Iteration 2575, loss = 0.74855314
Iteration 2576, loss = 0.75045245
Iteration 2577, loss = 0.74724180
Iteration 2578, loss = 0.74879785
Iteration 2579, loss = 0.74743158
Iteration 2580, loss = 0.74676214
Iteration 2581, loss = 0.74753666
Iteration 2582, loss = 0.74564575
Iteration 2583, loss = 0.74663847
Iteration 2584, loss = 0.74545130
Iteration 2585, loss = 0.74517367
Iteration 2586, loss = 0.74524832
Iteration 2587, loss = 0.74400733
Iteration 2588, loss = 0.74447967
Iteration 2589, loss = 0.74357466
Iteration 2590, loss = 0.74347093
Iteration 2591, loss = 0.74331788
Iteration 2592, loss = 0.74255401
Iteration 2593, loss = 0.74273848
Iteration 2594, loss = 0.74205030
Iteration 2595, loss = 0.74191385
Iteration 2596, loss = 0.74155928
Iteration 2597, loss = 0.74053287
Iteration 2598, loss = 0.74028537
Iteration 2599, loss = 0.73951457
Iteration 2600, loss = 0.73072187
Iteration 2601, loss = 0.75053004
Iteration 2602, loss = 0.76248013
Iteration 2603, loss = 0.75747065
Iteration 2604, loss = 0.76059791
Iteration 2605, loss = 0.76039684
Iteration 2606, loss = 0.74922497
Iteration 2607, loss = 0.74814173
Iteration 2608, loss = 0.75011537
Iteration 2609, loss = 0.74486307
Iteration 2610, loss = 0.74616132
Iteration 2611, loss = 0.74867290
Iteration 2612, loss = 0.74534093
Iteration 2613, loss = 0.74548665
Iteration 2614, loss = 0.74587896
Iteration 2615, loss = 0.73958642
Iteration 2616, loss = 0.71905731
Iteration 2617, loss = 0.89911487
Iteration 2618, loss = 1.05112046
Iteration 2619, loss = 0.78888343
Iteration 2620, loss = 1.11140569
Iteration 2621, loss = 0.77564665
Iteration 2622, loss = 1.05265033
Iteration 2623, loss = 0.79944588
Iteration 2624, loss = 0.90976966
Iteration 2625, loss = 0.86098972
Iteration 2626, loss = 0.79063894
Iteration 2627, loss = 0.90526402
Iteration 2628, loss = 0.75120846
Iteration 2629, loss = 0.87864339
Iteration 2630, loss = 0.77377893
Iteration 2631, loss = 0.80901458
Iteration 2632, loss = 0.81926036
Iteration 2633, loss = 0.75966789
Iteration 2634, loss = 0.83092974
Iteration 2635, loss = 0.75459490
Iteration 2636, loss = 0.79838545
Iteration 2637, loss = 0.77753455
Iteration 2638, loss = 0.76057334
Iteration 2639, loss = 0.79307389
Iteration 2640, loss = 0.74818259
Iteration 2641, loss = 0.78040230
Iteration 2642, loss = 0.75902693
Iteration 2643, loss = 0.75700900
Iteration 2644, loss = 0.76940106
Iteration 2645, loss = 0.74797209
Iteration 2646, loss = 0.75759604
Iteration 2647, loss = 0.76699377
Iteration 2648, loss = 0.75854936
Iteration 2649, loss = 0.75676789
Iteration 2650, loss = 0.77155057
Iteration 2651, loss = 0.77219124
Iteration 2652, loss = 0.76422798
Iteration 2653, loss = 0.76768379
Iteration 2654, loss = 0.76630809
Iteration 2655, loss = 0.75744186
Iteration 2656, loss = 0.75833736
Iteration 2657, loss = 0.76092938
Iteration 2658, loss = 0.75700817
Iteration 2659, loss = 0.75793494
Iteration 2660, loss = 0.75932678
Iteration 2661, loss = 0.75896410
Iteration 2662, loss = 0.76003855
Iteration 2663, loss = 0.76206355
Iteration 2664, loss = 0.76302504
Iteration 2665, loss = 0.76101485
Iteration 2666, loss = 0.75897548
Iteration 2667, loss = 0.75840607
Iteration 2668, loss = 0.75765142
Iteration 2669, loss = 0.75693051
Iteration 2670, loss = 0.75694320
Iteration 2671, loss = 0.75676736
Iteration 2672, loss = 0.75537352
Iteration 2673, loss = 0.75323255
Iteration 2674, loss = 0.75157756
Iteration 2675, loss = 0.77587879
Iteration 2676, loss = 0.82779097
Iteration 2677, loss = 0.75694013
Iteration 2678, loss = 0.74913615
Iteration 2679, loss = 0.76567613
Iteration 2680, loss = 0.80963432
Iteration 2681, loss = 0.83859824
Iteration 2682, loss = 0.77394524
Iteration 2683, loss = 0.80879695
Iteration 2684, loss = 0.81066974
Iteration 2685, loss = 0.75958252
Iteration 2686, loss = 0.78932549
Iteration 2687, loss = 0.78519785
Iteration 2688, loss = 0.74394188
Iteration 2689, loss = 0.83646182
Iteration 2690, loss = 0.92452428
Iteration 2691, loss = 0.77582738
Iteration 2692, loss = 0.86665606
Iteration 2693, loss = 0.84790716
Iteration 2694, loss = 0.76702202
Iteration 2695, loss = 0.85707039
Iteration 2696, loss = 0.79639775
Iteration 2697, loss = 0.77888463
Iteration 2698, loss = 0.83712539
Iteration 2699, loss = 0.77255667
Iteration 2700, loss = 0.78880316
Iteration 2701, loss = 0.80992395
Iteration 2702, loss = 0.76165910
Iteration 2703, loss = 0.78996420
Iteration 2704, loss = 0.78347381
Iteration 2705, loss = 0.76122352
Iteration 2706, loss = 0.80678213
Iteration 2707, loss = 0.77788456
Iteration 2708, loss = 0.76133872
Iteration 2709, loss = 0.79131822
Iteration 2710, loss = 0.76074125
Iteration 2711, loss = 0.75047313
Iteration 2712, loss = 0.66361588
Iteration 2713, loss = 0.86922956
Iteration 2714, loss = 1.07342743
Iteration 2715, loss = 0.80374125
Iteration 2716, loss = 1.03496945
Iteration 2717, loss = 0.85879018
Iteration 2718, loss = 0.87425889
Iteration 2719, loss = 0.95498057
Iteration 2720, loss = 0.79765990
Iteration 2721, loss = 0.92868052
Iteration 2722, loss = 0.83477670
Iteration 2723, loss = 0.82181195
Iteration 2724, loss = 0.89130983
Iteration 2725, loss = 0.79017435
Iteration 2726, loss = 0.85240141
Iteration 2727, loss = 0.82842717
Iteration 2728, loss = 0.78738702
Iteration 2729, loss = 0.84210237
Iteration 2730, loss = 0.78579338
Iteration 2731, loss = 0.79877609
Iteration 2732, loss = 0.81516833
Iteration 2733, loss = 0.77455884
Iteration 2734, loss = 0.80656143
Iteration 2735, loss = 0.79237260
Iteration 2736, loss = 0.77846353
Iteration 2737, loss = 0.80174876
Iteration 2738, loss = 0.77711008
Iteration 2739, loss = 0.78190509
Iteration 2740, loss = 0.78821298
Iteration 2741, loss = 0.76875698
Iteration 2742, loss = 0.78048855
Iteration 2743, loss = 0.77490900
Iteration 2744, loss = 0.76647763
Iteration 2745, loss = 0.77677674
Iteration 2746, loss = 0.76722730
Iteration 2747, loss = 0.76744843
Iteration 2748, loss = 0.77221921
Iteration 2749, loss = 0.76367310
Iteration 2750, loss = 0.76762443
Iteration 2751, loss = 0.76708950
Iteration 2752, loss = 0.76180042
Iteration 2753, loss = 0.76587998
Iteration 2754, loss = 0.76250165
Iteration 2755, loss = 0.76027150
Iteration 2756, loss = 0.76357302
Iteration 2757, loss = 0.76037049
Iteration 2758, loss = 0.75872268
Iteration 2759, loss = 0.76063523
Iteration 2760, loss = 0.75701383
Iteration 2761, loss = 0.75484678
Iteration 2762, loss = 0.72956258
Iteration 2763, loss = 0.76556002
Iteration 2764, loss = 0.77541720
Iteration 2765, loss = 0.75940041
Iteration 2766, loss = 0.76521216
Iteration 2767, loss = 0.76736166
Iteration 2768, loss = 0.75367177
Iteration 2769, loss = 0.75860473
Iteration 2770, loss = 0.75705800
Iteration 2771, loss = 0.73925359
Iteration 2772, loss = 0.76248761
Iteration 2773, loss = 0.79362384
Iteration 2774, loss = 0.77019643
Iteration 2775, loss = 0.77254402
Iteration 2776, loss = 0.77863497
Iteration 2777, loss = 0.75600165
Iteration 2778, loss = 0.76636981
Iteration 2779, loss = 0.76119822
Iteration 2780, loss = 0.75033412
Iteration 2781, loss = 0.75960180
Iteration 2782, loss = 0.74497894
Iteration 2783, loss = 0.71157252
Iteration 2784, loss = 0.96837135
Iteration 2785, loss = 1.09185252
Iteration 2786, loss = 0.82812361
Iteration 2787, loss = 1.18904776
Iteration 2788, loss = 0.78565458
Iteration 2789, loss = 1.15757831
Iteration 2790, loss = 0.78574394
Iteration 2791, loss = 1.01929598
Iteration 2792, loss = 0.84328229
Iteration 2793, loss = 0.85020515
Iteration 2794, loss = 0.93487398
Iteration 2795, loss = 0.76927415
Iteration 2796, loss = 0.93933071
Iteration 2797, loss = 0.78222274
Iteration 2798, loss = 0.85245939
Iteration 2799, loss = 0.84661158
Iteration 2800, loss = 0.77302242
Iteration 2801, loss = 0.90599297
Iteration 2802, loss = 0.84845041
Iteration 2803, loss = 0.79905696
Iteration 2804, loss = 0.88422014
Iteration 2805, loss = 0.77806483
Iteration 2806, loss = 0.82981922
Iteration 2807, loss = 0.80366373
Iteration 2808, loss = 0.77410221
Iteration 2809, loss = 0.82689692
Iteration 2810, loss = 0.77145629
Iteration 2811, loss = 0.80501244
Iteration 2812, loss = 0.79534337
Iteration 2813, loss = 0.77130781
Iteration 2814, loss = 0.80051850
Iteration 2815, loss = 0.76556051
Iteration 2816, loss = 0.77835480
Iteration 2817, loss = 0.77714743
Iteration 2818, loss = 0.75413745
Iteration 2819, loss = 0.73492824
Iteration 2820, loss = 1.17442190
Iteration 2821, loss = 1.32889643
Iteration 2822, loss = 0.91337370
Iteration 2823, loss = 1.58983715
Iteration 2824, loss = 0.99682968
Iteration 2825, loss = 1.74700923
Iteration 2826, loss = 1.33286311
Iteration 2827, loss = 1.55432242
Iteration 2828, loss = 1.51490216
Iteration 2829, loss = 1.11270166
Iteration 2830, loss = 1.16352033
Iteration 2831, loss = 0.90073402
Iteration 2832, loss = 0.91221281
Iteration 2833, loss = 0.92888994
Iteration 2834, loss = 0.84084576
Iteration 2835, loss = 0.97386869
Iteration 2836, loss = 0.80396064
Iteration 2837, loss = 0.97181940
Iteration 2838, loss = 0.78584567
Iteration 2839, loss = 0.93742926
Iteration 2840, loss = 0.79006208
Iteration 2841, loss = 0.88623403
Iteration 2842, loss = 0.81313767
Iteration 2843, loss = 0.83508992
Iteration 2844, loss = 0.84066653
Iteration 2845, loss = 0.80064116
Iteration 2846, loss = 0.85382831
Iteration 2847, loss = 0.78716173
Iteration 2848, loss = 0.84425894
Iteration 2849, loss = 0.79040642
Iteration 2850, loss = 0.82071528
Iteration 2851, loss = 0.80274640
Iteration 2852, loss = 0.79844202
Iteration 2853, loss = 0.81310049
Iteration 2854, loss = 0.78654140
Iteration 2855, loss = 0.81290750
Iteration 2856, loss = 0.78557013
Iteration 2857, loss = 0.80329790
Iteration 2858, loss = 0.79079072
Iteration 2859, loss = 0.79137672
Iteration 2860, loss = 0.79568444
Iteration 2861, loss = 0.78386247
Iteration 2862, loss = 0.79588161
Iteration 2863, loss = 0.78256833
Iteration 2864, loss = 0.79129262
Iteration 2865, loss = 0.78486982
Iteration 2866, loss = 0.78509466
Iteration 2867, loss = 0.78686847
Iteration 2868, loss = 0.78079711
Iteration 2869, loss = 0.78630386
Iteration 2870, loss = 0.77965409
Iteration 2871, loss = 0.78338722
Iteration 2872, loss = 0.78037434
Iteration 2873, loss = 0.77989217
Iteration 2874, loss = 0.78091605
Iteration 2875, loss = 0.77755383
Iteration 2876, loss = 0.78009674
Iteration 2877, loss = 0.77676938
Iteration 2878, loss = 0.77808713
Iteration 2879, loss = 0.77672134
Iteration 2880, loss = 0.77586529
Iteration 2881, loss = 0.77636474
Iteration 2882, loss = 0.77428743
Iteration 2883, loss = 0.77524518
Iteration 2884, loss = 0.77345786
Iteration 2885, loss = 0.77356647
Iteration 2886, loss = 0.77276695
Iteration 2887, loss = 0.77156606
Iteration 2888, loss = 0.77102675
Iteration 2889, loss = 0.76810842
Iteration 2890, loss = 0.76428411
Iteration 2891, loss = 0.72165325
Iteration 2892, loss = 0.80104125
Iteration 2893, loss = 0.85722525
Iteration 2894, loss = 0.79314652
Iteration 2895, loss = 0.82504497
Iteration 2896, loss = 0.82086810
Iteration 2897, loss = 0.78103578
Iteration 2898, loss = 0.81739015
Iteration 2899, loss = 0.79010222
Iteration 2900, loss = 0.78483656
Iteration 2901, loss = 0.80754690
Iteration 2902, loss = 0.77927114
Iteration 2903, loss = 0.79144221
Iteration 2904, loss = 0.78585664
Iteration 2905, loss = 0.77782695
Iteration 2906, loss = 0.79294611
Iteration 2907, loss = 0.79084761
Iteration 2908, loss = 0.78372518
Iteration 2909, loss = 0.78689489
Iteration 2910, loss = 0.77918569
Iteration 2911, loss = 0.77655985
Iteration 2912, loss = 0.78148178
Iteration 2913, loss = 0.77631942
Iteration 2914, loss = 0.77541192
Iteration 2915, loss = 0.77615316
Iteration 2916, loss = 0.77033501
Iteration 2917, loss = 0.76808949
Iteration 2918, loss = 0.74747015
Iteration 2919, loss = 0.80548349
Iteration 2920, loss = 0.83853086
Iteration 2921, loss = 0.78983674
Iteration 2922, loss = 0.81725653
Iteration 2923, loss = 0.80341777
Iteration 2924, loss = 0.77902102
Iteration 2925, loss = 0.80544601
Iteration 2926, loss = 0.78128215
Iteration 2927, loss = 0.78547666
Iteration 2928, loss = 0.79810068
Iteration 2929, loss = 0.77751379
Iteration 2930, loss = 0.79026369
Iteration 2931, loss = 0.78561514
Iteration 2932, loss = 0.77459411
Iteration 2933, loss = 0.78553049
Iteration 2934, loss = 0.77458173
Iteration 2935, loss = 0.77440875
Iteration 2936, loss = 0.77919207
Iteration 2937, loss = 0.76903028
Iteration 2938, loss = 0.77316831
Iteration 2939, loss = 0.77125054
Iteration 2940, loss = 0.76587725
Iteration 2941, loss = 0.76870091
Iteration 2942, loss = 0.76043878
Iteration 2943, loss = 0.75638135
Iteration 2944, loss = 0.75055183
Iteration 2945, loss = 0.70205073
Iteration 2946, loss = 0.87949516
Iteration 2947, loss = 1.13528371
Iteration 2948, loss = 0.83551132
Iteration 2949, loss = 1.17837286
Iteration 2950, loss = 0.82772350
Iteration 2951, loss = 1.13536869
Iteration 2952, loss = 0.81936176
Iteration 2953, loss = 1.03133667
Iteration 2954, loss = 0.83345034
Iteration 2955, loss = 0.90652035
Iteration 2956, loss = 0.88155331
Iteration 2957, loss = 0.82111144
Iteration 2958, loss = 0.92037991
Iteration 2959, loss = 0.79397095
Iteration 2960, loss = 0.90886258
Iteration 2961, loss = 0.80781536
Iteration 2962, loss = 0.85794476
Iteration 2963, loss = 0.83839646
Iteration 2964, loss = 0.80957623
Iteration 2965, loss = 0.85607231
Iteration 2966, loss = 0.79186996
Iteration 2967, loss = 0.84340550
Iteration 2968, loss = 0.80137555
Iteration 2969, loss = 0.81348412
Iteration 2970, loss = 0.81773092
Iteration 2971, loss = 0.79140125
Iteration 2972, loss = 0.82000016
Iteration 2973, loss = 0.78853417
Iteration 2974, loss = 0.80609867
Iteration 2975, loss = 0.79577221
Iteration 2976, loss = 0.78952670
Iteration 2977, loss = 0.80014963
Iteration 2978, loss = 0.78148008
Iteration 2979, loss = 0.79462457
Iteration 2980, loss = 0.78239185
Iteration 2981, loss = 0.78335834
Iteration 2982, loss = 0.78081790
Iteration 2983, loss = 0.76464849
Iteration 2984, loss = 0.88042717
Iteration 2985, loss = 0.86950005
Iteration 2986, loss = 0.83448396
Iteration 2987, loss = 0.89338477
Iteration 2988, loss = 0.79394321
Iteration 2989, loss = 0.85596856
Iteration 2990, loss = 0.85847181
Iteration 2991, loss = 1.19920849
Iteration 2992, loss = 0.86943416
Iteration 2993, loss = 1.23441533
Iteration 2994, loss = 0.89916843
Iteration 2995, loss = 1.26108223
Iteration 2996, loss = 0.95645610
Iteration 2997, loss = 1.22715823
Iteration 2998, loss = 1.28111564
Iteration 2999, loss = 1.50145929
Iteration 3000, loss = 1.44491145
Iteration 3001, loss = 1.04523651
Iteration 3002, loss = 1.35947949
Iteration 3003, loss = 0.85598501
Iteration 3004, loss = 1.22417852
Iteration 3005, loss = 0.81345066
Iteration 3006, loss = 1.13783699
Iteration 3007, loss = 0.80812543
Iteration 3008, loss = 1.09001311
Iteration 3009, loss = 0.81804284
Iteration 3010, loss = 1.06356766
Iteration 3011, loss = 0.83509527
Iteration 3012, loss = 1.04540166
Iteration 3013, loss = 0.84672834
Iteration 3014, loss = 1.00263676
Iteration 3015, loss = 0.80261255
Iteration 3016, loss = 0.81643428
Iteration 3017, loss = 0.81883243
Iteration 3018, loss = 0.82028083
Iteration 3019, loss = 0.82030624
Iteration 3020, loss = 0.81119680
Iteration 3021, loss = 0.80983613
Iteration 3022, loss = 0.79951289
Iteration 3023, loss = 0.80185783
Iteration 3024, loss = 0.79270347
Iteration 3025, loss = 0.79822042
Iteration 3026, loss = 0.79175684
Iteration 3027, loss = 0.79776665
Iteration 3028, loss = 0.79211172
Iteration 3029, loss = 0.79651224
Iteration 3030, loss = 0.78982656
Iteration 3031, loss = 0.80596137
Iteration 3032, loss = 0.79603060
Iteration 3033, loss = 0.80139513
Iteration 3034, loss = 0.79525724
Iteration 3035, loss = 0.79215787
Iteration 3036, loss = 0.78985234
Iteration 3037, loss = 0.77475258
Iteration 3038, loss = 0.79619646
Iteration 3039, loss = 0.79217372
Iteration 3040, loss = 0.78361137
Iteration 3041, loss = 0.82934341
Iteration 3042, loss = 0.80115303
Iteration 3043, loss = 0.82358215
Iteration 3044, loss = 0.80018874
Iteration 3045, loss = 0.81251439
Iteration 3046, loss = 0.79190798
Iteration 3047, loss = 0.86830021
Iteration 3048, loss = 0.85452362
Iteration 3049, loss = 0.85198718
Iteration 3050, loss = 0.84852976
Iteration 3051, loss = 0.82821219
Iteration 3052, loss = 0.84235809
Iteration 3053, loss = 0.81624159
Iteration 3054, loss = 0.84152755
Iteration 3055, loss = 0.80915196
Iteration 3056, loss = 0.83780456
Iteration 3057, loss = 0.80055701
Iteration 3058, loss = 0.83050159
Iteration 3059, loss = 0.79432481
Iteration 3060, loss = 0.82474543
Iteration 3061, loss = 0.79210271
Iteration 3062, loss = 0.81980534
Iteration 3063, loss = 0.79069093
Iteration 3064, loss = 0.81329021
Iteration 3065, loss = 0.78872434
Iteration 3066, loss = 0.80639983
Iteration 3067, loss = 0.78786880
Iteration 3068, loss = 0.80109760
Iteration 3069, loss = 0.78826483
Iteration 3070, loss = 0.79653577
Iteration 3071, loss = 0.78810035
Iteration 3072, loss = 0.79186669
Iteration 3073, loss = 0.78741759
Iteration 3074, loss = 0.78807688
Iteration 3075, loss = 0.78695127
Iteration 3076, loss = 0.78534556
Iteration 3077, loss = 0.78629213
Iteration 3078, loss = 0.78308056
Iteration 3079, loss = 0.78516121
Iteration 3080, loss = 0.78123226
Iteration 3081, loss = 0.78383501
Iteration 3082, loss = 0.77987006
Iteration 3083, loss = 0.78240987
Iteration 3084, loss = 0.77879986
Iteration 3085, loss = 0.78087649
Iteration 3086, loss = 0.77788843
Iteration 3087, loss = 0.77932528
Iteration 3088, loss = 0.77708760
Iteration 3089, loss = 0.77785295
Iteration 3090, loss = 0.77635424
Iteration 3091, loss = 0.77649217
Iteration 3092, loss = 0.77560055
Iteration 3093, loss = 0.77521289
Iteration 3094, loss = 0.77477909
Iteration 3095, loss = 0.77404365
Iteration 3096, loss = 0.77392825
Iteration 3097, loss = 0.77300842
Iteration 3098, loss = 0.77304997
Iteration 3099, loss = 0.77206527
Iteration 3100, loss = 0.77213008
Iteration 3101, loss = 0.77118164
Iteration 3102, loss = 0.77118929
Iteration 3103, loss = 0.77034980
Iteration 3104, loss = 0.77025582
Iteration 3105, loss = 0.76955350
Iteration 3106, loss = 0.76933733
Iteration 3107, loss = 0.76876853
Iteration 3108, loss = 0.76843888
Iteration 3109, loss = 0.76798671
Iteration 3110, loss = 0.76757149
Iteration 3111, loss = 0.76720412
Iteration 3112, loss = 0.76671145
Iteration 3113, loss = 0.76624770
Iteration 3114, loss = 0.76465546
Iteration 3115, loss = 0.76636282
Iteration 3116, loss = 0.76832990
Iteration 3117, loss = 0.76520749
Iteration 3118, loss = 0.76824515
Iteration 3119, loss = 0.76343664
Iteration 3120, loss = 0.76549437
Iteration 3121, loss = 0.76196868
Iteration 3122, loss = 0.76324013
Iteration 3123, loss = 0.76150008
Iteration 3124, loss = 0.76055428
Iteration 3125, loss = 0.76010910
Iteration 3126, loss = 0.75798301
Iteration 3127, loss = 0.75798748
Iteration 3128, loss = 0.75493302
Iteration 3129, loss = 0.75484507
Iteration 3130, loss = 0.75151287
Iteration 3131, loss = 0.74946235
Iteration 3132, loss = 0.71949124
Iteration 3133, loss = 0.78434120
Iteration 3134, loss = 0.81467788
Iteration 3135, loss = 0.78458235
Iteration 3136, loss = 0.81235756
Iteration 3137, loss = 0.77237302
Iteration 3138, loss = 0.79886753
Iteration 3139, loss = 0.76323319
Iteration 3140, loss = 0.78980939
Iteration 3141, loss = 0.76437952
Iteration 3142, loss = 0.78546209
Iteration 3143, loss = 0.76910445
Iteration 3144, loss = 0.77996217
Iteration 3145, loss = 0.77061908
Iteration 3146, loss = 0.77269867
Iteration 3147, loss = 0.77052426
Iteration 3148, loss = 0.76666506
Iteration 3149, loss = 0.74944234
Iteration 3150, loss = 0.75829132
Iteration 3151, loss = 0.75830990
Iteration 3152, loss = 0.74560257
Iteration 3153, loss = 0.83343037
Iteration 3154, loss = 0.79576918
Iteration 3155, loss = 0.82743913
Iteration 3156, loss = 0.79638239
Iteration 3157, loss = 0.79023259
Iteration 3158, loss = 0.78837104
Iteration 3159, loss = 0.76877403
Iteration 3160, loss = 0.79050312
Iteration 3161, loss = 0.76819913
Iteration 3162, loss = 0.79004292
Iteration 3163, loss = 0.76984877
Iteration 3164, loss = 0.77796096
Iteration 3165, loss = 0.77002911
Iteration 3166, loss = 0.76702439
Iteration 3167, loss = 0.77201786
Iteration 3168, loss = 0.76179931
Iteration 3169, loss = 0.77795768
Iteration 3170, loss = 0.76627031
Iteration 3171, loss = 0.77488745
Iteration 3172, loss = 0.76613408
Iteration 3173, loss = 0.76552361
Iteration 3174, loss = 0.76403612
Iteration 3175, loss = 0.75871365
Iteration 3176, loss = 0.76392828
Iteration 3177, loss = 0.75724666
Iteration 3178, loss = 0.76243704
Iteration 3179, loss = 0.75792145
Iteration 3180, loss = 0.75911211
Iteration 3181, loss = 0.75697454
Iteration 3182, loss = 0.75436963
Iteration 3183, loss = 0.75467837
Iteration 3184, loss = 0.75104081
Iteration 3185, loss = 0.75279130
Iteration 3186, loss = 0.74942331
Iteration 3187, loss = 0.74954426
Iteration 3188, loss = 0.74671199
Iteration 3189, loss = 0.74337402
Iteration 3190, loss = 0.73250410
Iteration 3191, loss = 0.79624411
Iteration 3192, loss = 0.82289986
Iteration 3193, loss = 0.77599748
Iteration 3194, loss = 0.83186875
Iteration 3195, loss = 0.76605718
Iteration 3196, loss = 0.82658544
Iteration 3197, loss = 0.76199698
Iteration 3198, loss = 0.80741852
Iteration 3199, loss = 0.76410469
Iteration 3200, loss = 0.78688719
Iteration 3201, loss = 0.76745162
Iteration 3202, loss = 0.76668788
Iteration 3203, loss = 0.77120655
Iteration 3204, loss = 0.75436060
Iteration 3205, loss = 0.77088655
Iteration 3206, loss = 0.74739649
Iteration 3207, loss = 0.76559791
Iteration 3208, loss = 0.74566277
Iteration 3209, loss = 0.75801597
Iteration 3210, loss = 0.74518546
Iteration 3211, loss = 0.74640199
Iteration 3212, loss = 0.74209911
Iteration 3213, loss = 0.73402589
Iteration 3214, loss = 0.72974488
Iteration 3215, loss = 0.66093945
Iteration 3216, loss = 1.04875619
Iteration 3217, loss = 1.32685021
Iteration 3218, loss = 0.97296983
Iteration 3219, loss = 1.41689809
Iteration 3220, loss = 1.05039552
Iteration 3221, loss = 1.38645120
Iteration 3222, loss = 1.18706141
Iteration 3223, loss = 1.19252988
Iteration 3224, loss = 1.18474052
Iteration 3225, loss = 1.01799969
Iteration 3226, loss = 1.09004006
Iteration 3227, loss = 0.93773493
Iteration 3228, loss = 0.99029081
Iteration 3229, loss = 0.91957341
Iteration 3230, loss = 0.91352519
Iteration 3231, loss = 0.92039688
Iteration 3232, loss = 0.85577619
Iteration 3233, loss = 0.92649908
Iteration 3234, loss = 0.81799315
Iteration 3235, loss = 0.93123186
Iteration 3236, loss = 0.79294073
Iteration 3237, loss = 0.93246642
Iteration 3238, loss = 0.77928661
Iteration 3239, loss = 0.93032124
Iteration 3240, loss = 0.76911013
Iteration 3241, loss = 0.92167726
Iteration 3242, loss = 0.76138736
Iteration 3243, loss = 0.90908162
Iteration 3244, loss = 0.75473087
Iteration 3245, loss = 0.89207452
Iteration 3246, loss = 0.74995008
Iteration 3247, loss = 0.87330929
Iteration 3248, loss = 0.74657589
Iteration 3249, loss = 0.85158816
Iteration 3250, loss = 0.74559598
Iteration 3251, loss = 0.83002867
Iteration 3252, loss = 0.74746902
Iteration 3253, loss = 0.80818271
Iteration 3254, loss = 0.75116291
Iteration 3255, loss = 0.78805104
Iteration 3256, loss = 0.75591775
Iteration 3257, loss = 0.77076692
Iteration 3258, loss = 0.76007226
Iteration 3259, loss = 0.75742573
Iteration 3260, loss = 0.76281163
Iteration 3261, loss = 0.74835545
Iteration 3262, loss = 0.76316345
Iteration 3263, loss = 0.74299473
Iteration 3264, loss = 0.76114331
Iteration 3265, loss = 0.74074400
Iteration 3266, loss = 0.75725681
Iteration 3267, loss = 0.74036623
Iteration 3268, loss = 0.75221054
Iteration 3269, loss = 0.74104313
Iteration 3270, loss = 0.74693379
Iteration 3271, loss = 0.74182062
Iteration 3272, loss = 0.74229330
Iteration 3273, loss = 0.74188063
Iteration 3274, loss = 0.73753417
Iteration 3275, loss = 0.73140949
Iteration 3276, loss = 0.75455327
Iteration 3277, loss = 0.78008134
Iteration 3278, loss = 0.74746877
Iteration 3279, loss = 0.77628968
Iteration 3280, loss = 0.74024064
Iteration 3281, loss = 0.76501761
Iteration 3282, loss = 0.74121283
Iteration 3283, loss = 0.75546683
Iteration 3284, loss = 0.74754673
Iteration 3285, loss = 0.74775841
Iteration 3286, loss = 0.75130600
Iteration 3287, loss = 0.74101119
Iteration 3288, loss = 0.75075430
Iteration 3289, loss = 0.73775081
Iteration 3290, loss = 0.74809701
Iteration 3291, loss = 0.73838575
Iteration 3292, loss = 0.74439694
Iteration 3293, loss = 0.74002225
Iteration 3294, loss = 0.74026195
Iteration 3295, loss = 0.74104408
Iteration 3296, loss = 0.73724945
Iteration 3297, loss = 0.74097217
Iteration 3298, loss = 0.73591400
Iteration 3299, loss = 0.73976222
Iteration 3300, loss = 0.73579329
Iteration 3301, loss = 0.73777816
Iteration 3302, loss = 0.73601840
Iteration 3303, loss = 0.73570901
Iteration 3304, loss = 0.73607439
Iteration 3305, loss = 0.73428925
Iteration 3306, loss = 0.73575158
Iteration 3307, loss = 0.73343702
Iteration 3308, loss = 0.73384685
Iteration 3309, loss = 0.73548061
Iteration 3310, loss = 0.73303273
Iteration 3311, loss = 0.73556365
Iteration 3312, loss = 0.73343913
Iteration 3313, loss = 0.73406734
Iteration 3314, loss = 0.73194368
Iteration 3315, loss = 0.73145922
Iteration 3316, loss = 0.73089999
Iteration 3317, loss = 0.72926070
Iteration 3318, loss = 0.72865450
Iteration 3319, loss = 0.72593738
Iteration 3320, loss = 0.72630714
Iteration 3321, loss = 0.72413965
Iteration 3322, loss = 0.72341511
Iteration 3323, loss = 0.72053853
Iteration 3324, loss = 0.71928885
Iteration 3325, loss = 0.71365368
Iteration 3326, loss = 0.69909342
Iteration 3327, loss = 0.96451043
Iteration 3328, loss = 1.62149626
Iteration 3329, loss = 1.09782076
Iteration 3330, loss = 1.42887087
Iteration 3331, loss = 1.49180072
Iteration 3332, loss = 0.92429599
Iteration 3333, loss = 1.34439468
Iteration 3334, loss = 0.78716535
Iteration 3335, loss = 1.23236581
Iteration 3336, loss = 0.81207738
Iteration 3337, loss = 1.15938750
Iteration 3338, loss = 0.90268561
Iteration 3339, loss = 1.07358740
Iteration 3340, loss = 0.97596154
Iteration 3341, loss = 0.96849785
Iteration 3342, loss = 0.98234864
Iteration 3343, loss = 0.88310136
Iteration 3344, loss = 0.94514960
Iteration 3345, loss = 0.83010316
Iteration 3346, loss = 0.89728867
Iteration 3347, loss = 0.80229413
Iteration 3348, loss = 0.85647915
Iteration 3349, loss = 0.78747899
Iteration 3350, loss = 0.82331839
Iteration 3351, loss = 0.78019240
Iteration 3352, loss = 0.79829317
Iteration 3353, loss = 0.77393874
Iteration 3354, loss = 0.72966475
Iteration 3355, loss = 0.74116432
Iteration 3356, loss = 0.77426558
Iteration 3357, loss = 0.74369026
Iteration 3358, loss = 0.74928675
Iteration 3359, loss = 0.74283803
Iteration 3360, loss = 0.75128358
Iteration 3361, loss = 0.74932108
Iteration 3362, loss = 0.75022469
Iteration 3363, loss = 0.74659962
Iteration 3364, loss = 0.73726788
Iteration 3365, loss = 0.72165316
Iteration 3366, loss = 0.79132964
Iteration 3367, loss = 0.80964009
Iteration 3368, loss = 0.79980888
Iteration 3369, loss = 0.81012741
Iteration 3370, loss = 0.79384294
Iteration 3371, loss = 0.79860643
Iteration 3372, loss = 0.77798852
Iteration 3373, loss = 0.78487252
Iteration 3374, loss = 0.76428856
Iteration 3375, loss = 0.77509548
Iteration 3376, loss = 0.75523007
Iteration 3377, loss = 0.77014658
Iteration 3378, loss = 0.75174058
Iteration 3379, loss = 0.76862851
Iteration 3380, loss = 0.74942582
Iteration 3381, loss = 0.76437053
Iteration 3382, loss = 0.74290525
Iteration 3383, loss = 0.75805687
Iteration 3384, loss = 0.73950450
Iteration 3385, loss = 0.75455222
Iteration 3386, loss = 0.73815487
Iteration 3387, loss = 0.75174366
Iteration 3388, loss = 0.73699373
Iteration 3389, loss = 0.74859650
Iteration 3390, loss = 0.73422329
Iteration 3391, loss = 0.74331644
Iteration 3392, loss = 0.71815409
Iteration 3393, loss = 0.75017995
Iteration 3394, loss = 0.74528625
Iteration 3395, loss = 0.75555726
Iteration 3396, loss = 0.74517878
Iteration 3397, loss = 0.74744073
Iteration 3398, loss = 0.73794066
Iteration 3399, loss = 0.74042692
Iteration 3400, loss = 0.73639351
Iteration 3401, loss = 0.73996183
Iteration 3402, loss = 0.73786146
Iteration 3403, loss = 0.73966717
Iteration 3404, loss = 0.73797399
Iteration 3405, loss = 0.73819607
Iteration 3406, loss = 0.73711440
Iteration 3407, loss = 0.73617594
Iteration 3408, loss = 0.69668032
Iteration 3409, loss = 0.74087696
Iteration 3410, loss = 0.74725332
Iteration 3411, loss = 0.74529749
Iteration 3412, loss = 0.74872380
Iteration 3413, loss = 0.74429487
Iteration 3414, loss = 0.74494606
Iteration 3415, loss = 0.74122597
Iteration 3416, loss = 0.73965869
Iteration 3417, loss = 0.74652032
Iteration 3418, loss = 0.74471370
Iteration 3419, loss = 0.74935679
Iteration 3420, loss = 0.74747094
Iteration 3421, loss = 0.74960863
Iteration 3422, loss = 0.74695183
Iteration 3423, loss = 0.74724478
Iteration 3424, loss = 0.74539165
Iteration 3425, loss = 0.74589593
Iteration 3426, loss = 0.74538121
Iteration 3427, loss = 0.74545817
Iteration 3428, loss = 0.74468928
Iteration 3429, loss = 0.74083193
Iteration 3430, loss = 0.74984365
Iteration 3431, loss = 0.80794167
Iteration 3432, loss = 0.76472708
Iteration 3433, loss = 0.81031250
Iteration 3434, loss = 0.76553302
Iteration 3435, loss = 0.79088751
Iteration 3436, loss = 0.75347775
Iteration 3437, loss = 0.77143553
Iteration 3438, loss = 0.74944696
Iteration 3439, loss = 0.76198044
Iteration 3440, loss = 0.74284701
Iteration 3441, loss = 0.70015943
Iteration 3442, loss = 0.80031029
Iteration 3443, loss = 0.91095610
Iteration 3444, loss = 0.81303405
Iteration 3445, loss = 0.87609991
Iteration 3446, loss = 0.80707587
Iteration 3447, loss = 0.84297558
Iteration 3448, loss = 0.80162954
Iteration 3449, loss = 0.82376974
Iteration 3450, loss = 0.80019374
Iteration 3451, loss = 0.80968717
Iteration 3452, loss = 0.79445220
Iteration 3453, loss = 0.79646775
Iteration 3454, loss = 0.78757895
Iteration 3455, loss = 0.78631759
Iteration 3456, loss = 0.78139557
Iteration 3457, loss = 0.77946123
Iteration 3458, loss = 0.77613534
Iteration 3459, loss = 0.77295325
Iteration 3460, loss = 0.77041764
Iteration 3461, loss = 0.76766476
Iteration 3462, loss = 0.76476423
Iteration 3463, loss = 0.76692134
Iteration 3464, loss = 0.75456317
Iteration 3465, loss = 0.76441154
Iteration 3466, loss = 0.74751181
Iteration 3467, loss = 0.75870428
Iteration 3468, loss = 0.74002002
Iteration 3469, loss = 0.74903604
Iteration 3470, loss = 0.72689295
Iteration 3471, loss = 0.70410155
Iteration 3472, loss = 0.81630085
Iteration 3473, loss = 0.94561844
Iteration 3474, loss = 0.81743066
Iteration 3475, loss = 0.93036145
Iteration 3476, loss = 0.77015738
Iteration 3477, loss = 1.06323463
Iteration 3478, loss = 0.79023066
Iteration 3479, loss = 1.03054457
Iteration 3480, loss = 0.81037472
Iteration 3481, loss = 0.98671106
Iteration 3482, loss = 0.82547176
Iteration 3483, loss = 0.94699528
Iteration 3484, loss = 0.83671807
Iteration 3485, loss = 0.91534227
Iteration 3486, loss = 0.84330228
Iteration 3487, loss = 0.88525208
Iteration 3488, loss = 0.83618577
Iteration 3489, loss = 0.85866318
Iteration 3490, loss = 0.82474737
Iteration 3491, loss = 0.83672848
Iteration 3492, loss = 0.81116795
Iteration 3493, loss = 0.82122792
Iteration 3494, loss = 0.79906267
Iteration 3495, loss = 0.80882555
Iteration 3496, loss = 0.78733449
Iteration 3497, loss = 0.79972890
Iteration 3498, loss = 0.77806787
Iteration 3499, loss = 0.79229597
Iteration 3500, loss = 0.76975743
Iteration 3501, loss = 0.78603874
Iteration 3502, loss = 0.76297948
Iteration 3503, loss = 0.78034101
Iteration 3504, loss = 0.75704533
Iteration 3505, loss = 0.77527206
Iteration 3506, loss = 0.75248452
Iteration 3507, loss = 0.77065199
Iteration 3508, loss = 0.74863531
Iteration 3509, loss = 0.76632805
Iteration 3510, loss = 0.74572152
Iteration 3511, loss = 0.76239001
Iteration 3512, loss = 0.74337977
Iteration 3513, loss = 0.75870484
Iteration 3514, loss = 0.74166449
Iteration 3515, loss = 0.75534681
Iteration 3516, loss = 0.74027186
Iteration 3517, loss = 0.75212956
Iteration 3518, loss = 0.73913732
Iteration 3519, loss = 0.74916968
Iteration 3520, loss = 0.73819981
Iteration 3521, loss = 0.74645775
Iteration 3522, loss = 0.73748644
Iteration 3523, loss = 0.74409368
Iteration 3524, loss = 0.73689958
Iteration 3525, loss = 0.74192372
Iteration 3526, loss = 0.73621297
Iteration 3527, loss = 0.73954549
Iteration 3528, loss = 0.73539375
Iteration 3529, loss = 0.73582760
Iteration 3530, loss = 0.73594287
Iteration 3531, loss = 0.73912969
Iteration 3532, loss = 0.73643331
Iteration 3533, loss = 0.73761915
Iteration 3534, loss = 0.73325525
Iteration 3535, loss = 0.73456705
Iteration 3536, loss = 0.73242422
Iteration 3537, loss = 0.73064148
Iteration 3538, loss = 0.73119716
Iteration 3539, loss = 0.65728776
Iteration 3540, loss = 0.75719401
Iteration 3541, loss = 0.85813958
Iteration 3542, loss = 0.76367426
Iteration 3543, loss = 0.78455630
Iteration 3544, loss = 0.81344527
Iteration 3545, loss = 0.74393388
Iteration 3546, loss = 0.80072766
Iteration 3547, loss = 0.76417246
Iteration 3548, loss = 0.75604414
Iteration 3549, loss = 0.78766827
Iteration 3550, loss = 0.74463692
Iteration 3551, loss = 0.77474713
Iteration 3552, loss = 0.76311993
Iteration 3553, loss = 0.75100080
Iteration 3554, loss = 0.77372605
Iteration 3555, loss = 0.74768479
Iteration 3556, loss = 0.76120665
Iteration 3557, loss = 0.75855853
Iteration 3558, loss = 0.74643560
Iteration 3559, loss = 0.76123396
Iteration 3560, loss = 0.75029369
Iteration 3561, loss = 0.75172158
Iteration 3562, loss = 0.75689792
Iteration 3563, loss = 0.74526070
Iteration 3564, loss = 0.75307630
Iteration 3565, loss = 0.74723655
Iteration 3566, loss = 0.74534984
Iteration 3567, loss = 0.74878945
Iteration 3568, loss = 0.74154976
Iteration 3569, loss = 0.74492601
Iteration 3570, loss = 0.74185563
Iteration 3571, loss = 0.73859636
Iteration 3572, loss = 0.73875407
Iteration 3573, loss = 0.73204122
Iteration 3574, loss = 0.73502366
Iteration 3575, loss = 0.73147819
Iteration 3576, loss = 0.72054579
Iteration 3577, loss = 0.85477574
Iteration 3578, loss = 1.50827932
Iteration 3579, loss = 0.86406934
Iteration 3580, loss = 1.57647957
Iteration 3581, loss = 1.17408867
Iteration 3582, loss = 1.43611372
Iteration 3583, loss = 1.39885411
Iteration 3584, loss = 1.06053737
Iteration 3585, loss = 1.26684851
Iteration 3586, loss = 0.86441601
Iteration 3587, loss = 0.95101640
Iteration 3588, loss = 0.81535871
Iteration 3589, loss = 0.89957182
Iteration 3590, loss = 0.80080364
Iteration 3591, loss = 0.84925749
Iteration 3592, loss = 0.79150173
Iteration 3593, loss = 0.81339860
Iteration 3594, loss = 0.79313583
Iteration 3595, loss = 0.79448200
Iteration 3596, loss = 0.80049987
Iteration 3597, loss = 0.78477542
Iteration 3598, loss = 0.80523428
Iteration 3599, loss = 0.77772222
Iteration 3600, loss = 0.80379985
Iteration 3601, loss = 0.77251592
Iteration 3602, loss = 0.79881719
Iteration 3603, loss = 0.77045131
Iteration 3604, loss = 0.79242630
Iteration 3605, loss = 0.77045269
Iteration 3606, loss = 0.78517989
Iteration 3607, loss = 0.77108734
Iteration 3608, loss = 0.77810342
Iteration 3609, loss = 0.77188092
Iteration 3610, loss = 0.77231070
Iteration 3611, loss = 0.77196463
Iteration 3612, loss = 0.76479859
Iteration 3613, loss = 0.76671237
Iteration 3614, loss = 0.76513484
Iteration 3615, loss = 0.76069786
Iteration 3616, loss = 0.73372189
Iteration 3617, loss = 1.01751916
Iteration 3618, loss = 0.78918055
Iteration 3619, loss = 1.00459960
Iteration 3620, loss = 0.81022955
Iteration 3621, loss = 0.98279555
Iteration 3622, loss = 0.81225966
Iteration 3623, loss = 0.95222271
Iteration 3624, loss = 0.80413646
Iteration 3625, loss = 0.92360898
Iteration 3626, loss = 0.79737472
Iteration 3627, loss = 0.90295085
Iteration 3628, loss = 0.79427780
Iteration 3629, loss = 0.88826974
Iteration 3630, loss = 0.79296125
Iteration 3631, loss = 0.87668792
Iteration 3632, loss = 0.79115197
Iteration 3633, loss = 0.86553329
Iteration 3634, loss = 0.78805893
Iteration 3635, loss = 0.85437546
Iteration 3636, loss = 0.78406163
Iteration 3637, loss = 0.84328835
Iteration 3638, loss = 0.78022838
Iteration 3639, loss = 0.83306292
Iteration 3640, loss = 0.77706174
Iteration 3641, loss = 0.82364990
Iteration 3642, loss = 0.77458358
Iteration 3643, loss = 0.81501094
Iteration 3644, loss = 0.77263423
Iteration 3645, loss = 0.80687187
Iteration 3646, loss = 0.77111415
Iteration 3647, loss = 0.79944356
Iteration 3648, loss = 0.77009562
Iteration 3649, loss = 0.79273507
Iteration 3650, loss = 0.76942658
Iteration 3651, loss = 0.78675839
Iteration 3652, loss = 0.76880988
Iteration 3653, loss = 0.78339877
Iteration 3654, loss = 0.76917588
Iteration 3655, loss = 0.77247295
Iteration 3656, loss = 0.76786212
Iteration 3657, loss = 0.77095166
Iteration 3658, loss = 0.76622019
Iteration 3659, loss = 0.76572771
Iteration 3660, loss = 0.75318741
Iteration 3661, loss = 0.76669750
Iteration 3662, loss = 0.76925136
Iteration 3663, loss = 0.76919659
Iteration 3664, loss = 0.76897899
Iteration 3665, loss = 0.76665298
Iteration 3666, loss = 0.76557343
Iteration 3667, loss = 0.76423436
Iteration 3668, loss = 0.76398460
Iteration 3669, loss = 0.76298526
Iteration 3670, loss = 0.76277337
Iteration 3671, loss = 0.76193131
Iteration 3672, loss = 0.76177551
Iteration 3673, loss = 0.76110941
Iteration 3674, loss = 0.76097662
Iteration 3675, loss = 0.76031281
Iteration 3676, loss = 0.75999558
Iteration 3677, loss = 0.75919712
Iteration 3678, loss = 0.75870579
Iteration 3679, loss = 0.75789191
Iteration 3680, loss = 0.75746651
Iteration 3681, loss = 0.75686395
Iteration 3682, loss = 0.75657320
Iteration 3683, loss = 0.75618279
Iteration 3684, loss = 0.75583169
Iteration 3685, loss = 0.75539527
Iteration 3686, loss = 0.75496118
Iteration 3687, loss = 0.75429549
Iteration 3688, loss = 0.75383911
Iteration 3689, loss = 0.75334849
Iteration 3690, loss = 0.75258873
Iteration 3691, loss = 0.75252064
Iteration 3692, loss = 0.75203941
Iteration 3693, loss = 0.75026683
Iteration 3694, loss = 0.74149616
Iteration 3695, loss = 0.76996616
Iteration 3696, loss = 0.77420059
Iteration 3697, loss = 0.76623346
Iteration 3698, loss = 0.77067236
Iteration 3699, loss = 0.75731325
Iteration 3700, loss = 0.76443181
Iteration 3701, loss = 0.75037776
Iteration 3702, loss = 0.75900781
Iteration 3703, loss = 0.74207441
Iteration 3704, loss = 0.83732325
Iteration 3705, loss = 0.77398716
Iteration 3706, loss = 0.80915180
Iteration 3707, loss = 0.74698078
Iteration 3708, loss = 0.89341488
Iteration 3709, loss = 0.76658452
Iteration 3710, loss = 0.86991601
Iteration 3711, loss = 0.76066658
Iteration 3712, loss = 0.84416086
Iteration 3713, loss = 0.75130755
Iteration 3714, loss = 0.82512400
Iteration 3715, loss = 0.75033910
Iteration 3716, loss = 0.81405734
Iteration 3717, loss = 0.74989976
Iteration 3718, loss = 0.80224278
Iteration 3719, loss = 0.74689667
Iteration 3720, loss = 0.79063675
Iteration 3721, loss = 0.74305852
Iteration 3722, loss = 0.77936872
Iteration 3723, loss = 0.73876548
Iteration 3724, loss = 0.76834527
Iteration 3725, loss = 0.73511451
Iteration 3726, loss = 0.75664246
Iteration 3727, loss = 0.72736985
Iteration 3728, loss = 0.72997003
Iteration 3729, loss = 0.88094500
Iteration 3730, loss = 0.95222767
Iteration 3731, loss = 1.25261965
Iteration 3732, loss = 0.95832171
Iteration 3733, loss = 1.26099019
Iteration 3734, loss = 0.78276730
Iteration 3735, loss = 1.17108350
Iteration 3736, loss = 0.81748302
Iteration 3737, loss = 1.07887362
Iteration 3738, loss = 0.90440528
Iteration 3739, loss = 0.95532672
Iteration 3740, loss = 0.95253764
Iteration 3741, loss = 0.84983003
Iteration 3742, loss = 0.94755541
Iteration 3743, loss = 0.78961248
Iteration 3744, loss = 0.91916429
Iteration 3745, loss = 0.76102737
Iteration 3746, loss = 0.88465735
Iteration 3747, loss = 0.74997077
Iteration 3748, loss = 0.85745618
Iteration 3749, loss = 0.74842421
Iteration 3750, loss = 0.83420750
Iteration 3751, loss = 0.75101884
Iteration 3752, loss = 0.81575690
Iteration 3753, loss = 0.75275750
Iteration 3754, loss = 0.79940691
Iteration 3755, loss = 0.75245454
Iteration 3756, loss = 0.78368996
Iteration 3757, loss = 0.75156314
Iteration 3758, loss = 0.77064084
Iteration 3759, loss = 0.75050909
Iteration 3760, loss = 0.76062697
Iteration 3761, loss = 0.74415507
Iteration 3762, loss = 0.74885845
Iteration 3763, loss = 0.74036565
Iteration 3764, loss = 0.74095866
Iteration 3765, loss = 0.73002981
Iteration 3766, loss = 0.86242113
Iteration 3767, loss = 0.76001639
Iteration 3768, loss = 0.84048869
Iteration 3769, loss = 0.74313048
Iteration 3770, loss = 0.80165033
Iteration 3771, loss = 0.70757096
Iteration 3772, loss = 1.51067831
Iteration 3773, loss = 1.29109349
Iteration 3774, loss = 1.16193793
Iteration 3775, loss = 1.08218426
Iteration 3776, loss = 1.29250020
Iteration 3777, loss = 0.92817364
Iteration 3778, loss = 1.25430302
Iteration 3779, loss = 0.92101853
Iteration 3780, loss = 1.18268224
Iteration 3781, loss = 0.95627771
Iteration 3782, loss = 1.07902251
Iteration 3783, loss = 0.97435416
Iteration 3784, loss = 0.96231753
Iteration 3785, loss = 0.95891289
Iteration 3786, loss = 0.86474275
Iteration 3787, loss = 0.92286598
Iteration 3788, loss = 0.80256020
Iteration 3789, loss = 0.88748943
Iteration 3790, loss = 0.77620884
Iteration 3791, loss = 0.86382632
Iteration 3792, loss = 0.76815558
Iteration 3793, loss = 0.84434152
Iteration 3794, loss = 0.76635479
Iteration 3795, loss = 0.83117112
Iteration 3796, loss = 0.76932231
Iteration 3797, loss = 0.81910071
Iteration 3798, loss = 0.77095536
Iteration 3799, loss = 0.80762584
Iteration 3800, loss = 0.77121035
Iteration 3801, loss = 0.79755205
Iteration 3802, loss = 0.77079575
Iteration 3803, loss = 0.78877711
Iteration 3804, loss = 0.76901334
Iteration 3805, loss = 0.78034436
Iteration 3806, loss = 0.76593422
Iteration 3807, loss = 0.77270036
Iteration 3808, loss = 0.76263163
Iteration 3809, loss = 0.76669643
Iteration 3810, loss = 0.76026251
Iteration 3811, loss = 0.76252596
Iteration 3812, loss = 0.75827919
Iteration 3813, loss = 0.75913495
Iteration 3814, loss = 0.75655400
Iteration 3815, loss = 0.75664656
Iteration 3816, loss = 0.75535540
Iteration 3817, loss = 0.75508883
Iteration 3818, loss = 0.75431314
Iteration 3819, loss = 0.75306376
Iteration 3820, loss = 0.75233917
Iteration 3821, loss = 0.75107442
Iteration 3822, loss = 0.75096589
Iteration 3823, loss = 0.74988363
Iteration 3824, loss = 0.75003051
Iteration 3825, loss = 0.74900215
Iteration 3826, loss = 0.74921145
Iteration 3827, loss = 0.74820193
Iteration 3828, loss = 0.74838259
Iteration 3829, loss = 0.74739903
Iteration 3830, loss = 0.74752229
Iteration 3831, loss = 0.74658789
Iteration 3832, loss = 0.74665953
Iteration 3833, loss = 0.74580679
Iteration 3834, loss = 0.74585329
Iteration 3835, loss = 0.74511275
Iteration 3836, loss = 0.74516129
Iteration 3837, loss = 0.74454681
Iteration 3838, loss = 0.74459974
Iteration 3839, loss = 0.74406794
Iteration 3840, loss = 0.74405183
Iteration 3841, loss = 0.74352639
Iteration 3842, loss = 0.74343975
Iteration 3843, loss = 0.74296665
Iteration 3844, loss = 0.74287571
Iteration 3845, loss = 0.74247609
Iteration 3846, loss = 0.74238251
Iteration 3847, loss = 0.74203521
Iteration 3848, loss = 0.74192765
Iteration 3849, loss = 0.74161297
Iteration 3850, loss = 0.74148391
Iteration 3851, loss = 0.74119008
Iteration 3852, loss = 0.74104159
Iteration 3853, loss = 0.74076607
Iteration 3854, loss = 0.74060400
Iteration 3855, loss = 0.74034674
Iteration 3856, loss = 0.74017827
Iteration 3857, loss = 0.73994053
Iteration 3858, loss = 0.73977048
Iteration 3859, loss = 0.73955026
Iteration 3860, loss = 0.73937948
Iteration 3861, loss = 0.73917264
Iteration 3862, loss = 0.73900005
Iteration 3863, loss = 0.73880205
Iteration 3864, loss = 0.73862682
Iteration 3865, loss = 0.73843564
Iteration 3866, loss = 0.73825970
Iteration 3867, loss = 0.73807570
Iteration 3868, loss = 0.73790107
Iteration 3869, loss = 0.73772386
Iteration 3870, loss = 0.73755131
Iteration 3871, loss = 0.73737985
Iteration 3872, loss = 0.73720915
Iteration 3873, loss = 0.73704180
Iteration 3874, loss = 0.73687248
Iteration 3875, loss = 0.73670827
Iteration 3876, loss = 0.73654039
Iteration 3877, loss = 0.73637872
Iteration 3878, loss = 0.73621160
Iteration 3879, loss = 0.73602767
Iteration 3880, loss = 0.73542047
Iteration 3881, loss = 0.73463170
Iteration 3882, loss = 0.73196427
Iteration 3883, loss = 0.75493282
Iteration 3884, loss = 0.75226199
Iteration 3885, loss = 0.76534681
Iteration 3886, loss = 0.75871412
Iteration 3887, loss = 0.75659007
Iteration 3888, loss = 0.75357422
Iteration 3889, loss = 0.74777136
Iteration 3890, loss = 0.75137396
Iteration 3891, loss = 0.74587499
Iteration 3892, loss = 0.75210782
Iteration 3893, loss = 0.74752418
Iteration 3894, loss = 0.75266197
Iteration 3895, loss = 0.74575551
Iteration 3896, loss = 0.75743760
Iteration 3897, loss = 0.75503727
Iteration 3898, loss = 0.75364791
Iteration 3899, loss = 0.76813170
Iteration 3900, loss = 0.79463226
Iteration 3901, loss = 0.77658502
Iteration 3902, loss = 0.78501845
Iteration 3903, loss = 0.77133233
Iteration 3904, loss = 0.76500806
Iteration 3905, loss = 0.76503630
Iteration 3906, loss = 0.75389990
Iteration 3907, loss = 0.76188628
Iteration 3908, loss = 0.75290239
Iteration 3909, loss = 0.76018965
Iteration 3910, loss = 0.75540171
Iteration 3911, loss = 0.75691582
Iteration 3912, loss = 0.75677838
Iteration 3913, loss = 0.75220900
Iteration 3914, loss = 0.75544152
Iteration 3915, loss = 0.75008147
Iteration 3916, loss = 0.75274026
Iteration 3917, loss = 0.74958676
Iteration 3918, loss = 0.75004102
Iteration 3919, loss = 0.74732903
Iteration 3920, loss = 0.74889617
Iteration 3921, loss = 0.75041907
Iteration 3922, loss = 0.75061201
Iteration 3923, loss = 0.74772214
Iteration 3924, loss = 0.73712010
Iteration 3925, loss = 0.81874818
Iteration 3926, loss = 1.00290602
Iteration 3927, loss = 0.75031428
Iteration 3928, loss = 0.89054161
Iteration 3929, loss = 1.04816084
Iteration 3930, loss = 0.78853254
Iteration 3931, loss = 0.97844657
Iteration 3932, loss = 0.83107419
Iteration 3933, loss = 0.84000715
Iteration 3934, loss = 0.88073233
Iteration 3935, loss = 0.76224536
Iteration 3936, loss = 0.92282142
Iteration 3937, loss = 0.79047447
Iteration 3938, loss = 0.82223474
Iteration 3939, loss = 0.85338925
Iteration 3940, loss = 0.78357614
Iteration 3941, loss = 0.86036746
Iteration 3942, loss = 0.77336772
Iteration 3943, loss = 0.81615787
Iteration 3944, loss = 0.79064569
Iteration 3945, loss = 0.77425730
Iteration 3946, loss = 0.80904594
Iteration 3947, loss = 0.76272049
Iteration 3948, loss = 0.80040048
Iteration 3949, loss = 0.77293887
Iteration 3950, loss = 0.77625159
Iteration 3951, loss = 0.78529551
Iteration 3952, loss = 0.76113707
Iteration 3953, loss = 0.78445047
Iteration 3954, loss = 0.76310922
Iteration 3955, loss = 0.77071382
Iteration 3956, loss = 0.77038250
Iteration 3957, loss = 0.75931060
Iteration 3958, loss = 0.77219203
Iteration 3959, loss = 0.75810618
Iteration 3960, loss = 0.76475982
Iteration 3961, loss = 0.76185109
Iteration 3962, loss = 0.75692557
Iteration 3963, loss = 0.76247182
Iteration 3964, loss = 0.75253147
Iteration 3965, loss = 0.75515602
Iteration 3966, loss = 0.72848655
Iteration 3967, loss = 0.77776768
Iteration 3968, loss = 0.81273546
Iteration 3969, loss = 0.76644248
Iteration 3970, loss = 0.80542236
Iteration 3971, loss = 0.78060046
Iteration 3972, loss = 0.77289758
Iteration 3973, loss = 0.79018718
Iteration 3974, loss = 0.75745846
Iteration 3975, loss = 0.77629135
Iteration 3976, loss = 0.76548345
Iteration 3977, loss = 0.75747032
Iteration 3978, loss = 0.77255848
Iteration 3979, loss = 0.75515030
Iteration 3980, loss = 0.76528482
Iteration 3981, loss = 0.76338338
Iteration 3982, loss = 0.75498336
Iteration 3983, loss = 0.76444373
Iteration 3984, loss = 0.75381977
Iteration 3985, loss = 0.75597903
Iteration 3986, loss = 0.75711700
Iteration 3987, loss = 0.75017266
Iteration 3988, loss = 0.75597442
Iteration 3989, loss = 0.75135229
Iteration 3990, loss = 0.75088007
Iteration 3991, loss = 0.75321827
Iteration 3992, loss = 0.74817620
Iteration 3993, loss = 0.75076229
Iteration 3994, loss = 0.74905105
Iteration 3995, loss = 0.74724870
Iteration 3996, loss = 0.74924759
Iteration 3997, loss = 0.74621564
Iteration 3998, loss = 0.74697013
Iteration 3999, loss = 0.74678550
Iteration 4000, loss = 0.74365531
Iteration 4001, loss = 0.74925844
Iteration 4002, loss = 0.75939666
Iteration 4003, loss = 0.75183087
Iteration 4004, loss = 0.75747843
Iteration 4005, loss = 0.75792127
Iteration 4006, loss = 0.74731872
Iteration 4007, loss = 0.75079691
Iteration 4008, loss = 0.74942065
Iteration 4009, loss = 0.74394959
Iteration 4010, loss = 0.74817403
Iteration 4011, loss = 0.74647454
Iteration 4012, loss = 0.74291568
Iteration 4013, loss = 0.74546447
Iteration 4014, loss = 0.74184635
Iteration 4015, loss = 0.73868098
Iteration 4016, loss = 0.73561021
Iteration 4017, loss = 0.72866167
Iteration 4018, loss = 0.87234981
Iteration 4019, loss = 1.00651391
Iteration 4020, loss = 0.77130961
Iteration 4021, loss = 1.03902341
Iteration 4022, loss = 0.76044533
Iteration 4023, loss = 0.95076182
Iteration 4024, loss = 0.81313862
Iteration 4025, loss = 0.82206116
Iteration 4026, loss = 0.88612650
Iteration 4027, loss = 0.75669931
Iteration 4028, loss = 0.88458776
Iteration 4029, loss = 0.76584112
Iteration 4030, loss = 0.81274357
Iteration 4031, loss = 0.81282325
Iteration 4032, loss = 0.75552175
Iteration 4033, loss = 0.82756335
Iteration 4034, loss = 0.75409950
Iteration 4035, loss = 0.79083342
Iteration 4036, loss = 0.78410957
Iteration 4037, loss = 0.75332732
Iteration 4038, loss = 0.79462164
Iteration 4039, loss = 0.75059330
Iteration 4040, loss = 0.77099991
Iteration 4041, loss = 0.76809978
Iteration 4042, loss = 0.74643233
Iteration 4043, loss = 0.75890934
Iteration 4044, loss = 0.74588551
Iteration 4045, loss = 0.75428622
Iteration 4046, loss = 0.75370641
Iteration 4047, loss = 0.74368754
Iteration 4048, loss = 0.74990453
Iteration 4049, loss = 0.74741886
Iteration 4050, loss = 0.74184743
Iteration 4051, loss = 0.74739291
Iteration 4052, loss = 0.74391147
Iteration 4053, loss = 0.73992415
Iteration 4054, loss = 0.74277282
Iteration 4055, loss = 0.73912936
Iteration 4056, loss = 0.73666364
Iteration 4057, loss = 0.73827065
Iteration 4058, loss = 0.73284763
Iteration 4059, loss = 0.71225053
Iteration 4060, loss = 0.83411094
Iteration 4061, loss = 1.05913957
Iteration 4062, loss = 0.75498975
Iteration 4063, loss = 1.08227040
Iteration 4064, loss = 0.75375707
Iteration 4065, loss = 0.98603465
Iteration 4066, loss = 0.80661604
Iteration 4067, loss = 0.83387189
Iteration 4068, loss = 0.88875552
Iteration 4069, loss = 0.74707944
Iteration 4070, loss = 0.89643133
Iteration 4071, loss = 0.74880100
Iteration 4072, loss = 0.82136822
Iteration 4073, loss = 0.80266609
Iteration 4074, loss = 0.69617067
Iteration 4075, loss = 0.84535756
Iteration 4076, loss = 0.78190843
Iteration 4077, loss = 0.81169539
Iteration 4078, loss = 0.83839585
Iteration 4079, loss = 0.78310132
Iteration 4080, loss = 0.83872559
Iteration 4081, loss = 0.77518964
Iteration 4082, loss = 0.79332666
Iteration 4083, loss = 0.78286345
Iteration 4084, loss = 0.75460283
Iteration 4085, loss = 0.78418112
Iteration 4086, loss = 0.74806041
Iteration 4087, loss = 0.76836962
Iteration 4088, loss = 0.76064295
Iteration 4089, loss = 0.75046107
Iteration 4090, loss = 0.76578007
Iteration 4091, loss = 0.74416973
Iteration 4092, loss = 0.75576218
Iteration 4093, loss = 0.74029505
Iteration 4094, loss = 0.73763066
Iteration 4095, loss = 0.84457450
Iteration 4096, loss = 0.88360577
Iteration 4097, loss = 0.81200775
Iteration 4098, loss = 0.89823740
Iteration 4099, loss = 0.77530957
Iteration 4100, loss = 0.87911450
Iteration 4101, loss = 0.76043483
Iteration 4102, loss = 0.85489311
Iteration 4103, loss = 0.77064271
Iteration 4104, loss = 0.82800553
Iteration 4105, loss = 0.78825599
Iteration 4106, loss = 0.79800548
Iteration 4107, loss = 0.80046024
Iteration 4108, loss = 0.77407749
Iteration 4109, loss = 0.80387438
Iteration 4110, loss = 0.76336704
Iteration 4111, loss = 0.79929930
Iteration 4112, loss = 0.76459320
Iteration 4113, loss = 0.78849051
Iteration 4114, loss = 0.77086304
Iteration 4115, loss = 0.77502639
Iteration 4116, loss = 0.77583446
Iteration 4117, loss = 0.76227112
Iteration 4118, loss = 0.77216640
Iteration 4119, loss = 0.75946375
Iteration 4120, loss = 0.76738826
Iteration 4121, loss = 0.76238457
Iteration 4122, loss = 0.76570010
Iteration 4123, loss = 0.76179322
Iteration 4124, loss = 0.75888038
Iteration 4125, loss = 0.75635643
Iteration 4126, loss = 0.74474811
Iteration 4127, loss = 0.56074283
Iteration 4128, loss = 0.77435739
Iteration 4129, loss = 0.88011670
Iteration 4130, loss = 0.77390599
Iteration 4131, loss = 0.86891023
Iteration 4132, loss = 0.77248881
Iteration 4133, loss = 0.85119391
Iteration 4134, loss = 0.76916651
Iteration 4135, loss = 0.82985084
Iteration 4136, loss = 0.76750508
Iteration 4137, loss = 0.81181402
Iteration 4138, loss = 0.77081926
Iteration 4139, loss = 0.79782868
Iteration 4140, loss = 0.77577991
Iteration 4141, loss = 0.81323806
Iteration 4142, loss = 0.87456564
Iteration 4143, loss = 0.79071598
Iteration 4144, loss = 0.87512344
Iteration 4145, loss = 0.78602510
Iteration 4146, loss = 0.86001273
Iteration 4147, loss = 0.77790622
Iteration 4148, loss = 0.84369187
Iteration 4149, loss = 0.77553462
Iteration 4150, loss = 0.83098798
Iteration 4151, loss = 0.77780863
Iteration 4152, loss = 0.81940487
Iteration 4153, loss = 0.78010043
Iteration 4154, loss = 0.80713211
Iteration 4155, loss = 0.78156744
Iteration 4156, loss = 0.79465746
Iteration 4157, loss = 0.78050815
Iteration 4158, loss = 0.78234573
Iteration 4159, loss = 0.77591367
Iteration 4160, loss = 0.76915251
Iteration 4161, loss = 0.76282618
Iteration 4162, loss = 0.92022381
Iteration 4163, loss = 0.90089972
Iteration 4164, loss = 0.88951384
Iteration 4165, loss = 0.90995158
Iteration 4166, loss = 0.85927967
Iteration 4167, loss = 0.91033535
Iteration 4168, loss = 0.83199486
Iteration 4169, loss = 0.90549970
Iteration 4170, loss = 0.81094065
Iteration 4171, loss = 0.89744276
Iteration 4172, loss = 0.79629843
Iteration 4173, loss = 0.88880317
Iteration 4174, loss = 0.78726859
Iteration 4175, loss = 0.87588781
Iteration 4176, loss = 0.78116424
Iteration 4177, loss = 0.86085457
Iteration 4178, loss = 0.77910092
Iteration 4179, loss = 0.84542189
Iteration 4180, loss = 0.77998800
Iteration 4181, loss = 0.82918586
Iteration 4182, loss = 0.78180742
Iteration 4183, loss = 0.81326938
Iteration 4184, loss = 0.78442906
Iteration 4185, loss = 0.79935223
Iteration 4186, loss = 0.78685953
Iteration 4187, loss = 0.78800241
Iteration 4188, loss = 0.78737086
Iteration 4189, loss = 0.77931312
Iteration 4190, loss = 0.78751123
Iteration 4191, loss = 0.77079943
Iteration 4192, loss = 0.77638795
Iteration 4193, loss = 0.78774738
Iteration 4194, loss = 0.79653238
Iteration 4195, loss = 0.80675700
Iteration 4196, loss = 0.80741666
Iteration 4197, loss = 0.80872689
Iteration 4198, loss = 0.80191618
Iteration 4199, loss = 0.79727778
Iteration 4200, loss = 0.78703744
Iteration 4201, loss = 0.78780788
Iteration 4202, loss = 0.78457822
Iteration 4203, loss = 0.78143587
Iteration 4204, loss = 0.78038527
Iteration 4205, loss = 0.77837775
Iteration 4206, loss = 0.77948809
Iteration 4207, loss = 0.77735691
Iteration 4208, loss = 0.77100682
Iteration 4209, loss = 0.97849322
Iteration 4210, loss = 1.32979727
Iteration 4211, loss = 0.89136374
Iteration 4212, loss = 1.26147592
Iteration 4213, loss = 1.08379300
Iteration 4214, loss = 1.03187074
Iteration 4215, loss = 0.84399067
Iteration 4216, loss = 0.82522061
Iteration 4217, loss = 0.85018674
Iteration 4218, loss = 0.82320856
Iteration 4219, loss = 0.83318993
Iteration 4220, loss = 0.80792167
Iteration 4221, loss = 0.81184901
Iteration 4222, loss = 0.79494783
Iteration 4223, loss = 0.79593112
Iteration 4224, loss = 0.78835696
Iteration 4225, loss = 0.78887737
Iteration 4226, loss = 0.78635045
Iteration 4227, loss = 0.78007267
Iteration 4228, loss = 0.77914864
Iteration 4229, loss = 0.73211892
Iteration 4230, loss = 0.84530493
Iteration 4231, loss = 0.81253621
Iteration 4232, loss = 0.84365405
Iteration 4233, loss = 0.80462329
Iteration 4234, loss = 0.82803390
Iteration 4235, loss = 0.79039361
Iteration 4236, loss = 0.81164659
Iteration 4237, loss = 0.78166688
Iteration 4238, loss = 0.80312788
Iteration 4239, loss = 0.78002996
Iteration 4240, loss = 0.79960694
Iteration 4241, loss = 0.78009146
Iteration 4242, loss = 0.79609465
Iteration 4243, loss = 0.77903093
Iteration 4244, loss = 0.79187202
Iteration 4245, loss = 0.77706946
Iteration 4246, loss = 0.78710952
Iteration 4247, loss = 0.77301793
Iteration 4248, loss = 0.77566373
Iteration 4249, loss = 0.77372461
Iteration 4250, loss = 0.77621608
Iteration 4251, loss = 0.77394061
Iteration 4252, loss = 0.77461973
Iteration 4253, loss = 0.77145539
Iteration 4254, loss = 0.76950421
Iteration 4255, loss = 0.76565963
Iteration 4256, loss = 0.76168393
Iteration 4257, loss = 0.75818621
Iteration 4258, loss = 0.73837607
Iteration 4259, loss = 0.93168403
Iteration 4260, loss = 0.96142236
Iteration 4261, loss = 0.89929027
Iteration 4262, loss = 0.95970425
Iteration 4263, loss = 0.86878424
Iteration 4264, loss = 0.95179706
Iteration 4265, loss = 0.75636369
Iteration 4266, loss = 0.86851961
Iteration 4267, loss = 0.99516935
Iteration 4268, loss = 0.82419602
Iteration 4269, loss = 0.94489282
Iteration 4270, loss = 0.80317637
Iteration 4271, loss = 0.90622863
Iteration 4272, loss = 0.79401881
Iteration 4273, loss = 0.87813575
Iteration 4274, loss = 0.79187412
Iteration 4275, loss = 0.85777538
Iteration 4276, loss = 0.79147776
Iteration 4277, loss = 0.84166055
Iteration 4278, loss = 0.79182293
Iteration 4279, loss = 0.82867603
Iteration 4280, loss = 0.79142212
Iteration 4281, loss = 0.81726844
Iteration 4282, loss = 0.79031699
Iteration 4283, loss = 0.80764952
Iteration 4284, loss = 0.78943449
Iteration 4285, loss = 0.80040927
Iteration 4286, loss = 0.78913936
Iteration 4287, loss = 0.79503863
Iteration 4288, loss = 0.78894648
Iteration 4289, loss = 0.79101942
Iteration 4290, loss = 0.78863252
Iteration 4291, loss = 0.78764713
Iteration 4292, loss = 0.78765306
Iteration 4293, loss = 0.78457984
Iteration 4294, loss = 0.78631485
Iteration 4295, loss = 0.78210940
Iteration 4296, loss = 0.78495018
Iteration 4297, loss = 0.78022243
Iteration 4298, loss = 0.78359261
Iteration 4299, loss = 0.77875329
Iteration 4300, loss = 0.78219636
Iteration 4301, loss = 0.77753667
Iteration 4302, loss = 0.78073114
Iteration 4303, loss = 0.77643820
Iteration 4304, loss = 0.77918831
Iteration 4305, loss = 0.77542979
Iteration 4306, loss = 0.77769610
Iteration 4307, loss = 0.77455786
Iteration 4308, loss = 0.77628297
Iteration 4309, loss = 0.77373117
Iteration 4310, loss = 0.77491645
Iteration 4311, loss = 0.77292177
Iteration 4312, loss = 0.77362668
Iteration 4313, loss = 0.77213042
Iteration 4314, loss = 0.77242195
Iteration 4315, loss = 0.77133790
Iteration 4316, loss = 0.77128285
Iteration 4317, loss = 0.77051975
Iteration 4318, loss = 0.77019892
Iteration 4319, loss = 0.76967787
Iteration 4320, loss = 0.76916950
Iteration 4321, loss = 0.76881989
Iteration 4322, loss = 0.76819820
Iteration 4323, loss = 0.76796094
Iteration 4324, loss = 0.76727981
Iteration 4325, loss = 0.76709445
Iteration 4326, loss = 0.76638889
Iteration 4327, loss = 0.76620920
Iteration 4328, loss = 0.76550781
Iteration 4329, loss = 0.76530516
Iteration 4330, loss = 0.76463161
Iteration 4331, loss = 0.76439415
Iteration 4332, loss = 0.76376562
Iteration 4333, loss = 0.76348619
Iteration 4334, loss = 0.76290426
Iteration 4335, loss = 0.76257933
Iteration 4336, loss = 0.76204242
Iteration 4337, loss = 0.76166780
Iteration 4338, loss = 0.76114878
Iteration 4339, loss = 0.76071833
Iteration 4340, loss = 0.76024744
Iteration 4341, loss = 0.75982741
Iteration 4342, loss = 0.75939979
Iteration 4343, loss = 0.75895716
Iteration 4344, loss = 0.75853896
Iteration 4345, loss = 0.75808349
Iteration 4346, loss = 0.75767405
Iteration 4347, loss = 0.75721070
Iteration 4348, loss = 0.75682508
Iteration 4349, loss = 0.75643222
Iteration 4350, loss = 0.75612217
Iteration 4351, loss = 0.75574800
Iteration 4352, loss = 0.75539930
Iteration 4353, loss = 0.75500540
Iteration 4354, loss = 0.75466404
Iteration 4355, loss = 0.75429866
Iteration 4356, loss = 0.75394778
Iteration 4357, loss = 0.75355630
Iteration 4358, loss = 0.75316971
Iteration 4359, loss = 0.75278213
Iteration 4360, loss = 0.75242067
Iteration 4361, loss = 0.75205695
Iteration 4362, loss = 0.75102603
Iteration 4363, loss = 0.74713279
Iteration 4364, loss = 0.74320819
Iteration 4365, loss = 0.75995654
Iteration 4366, loss = 0.76896415
Iteration 4367, loss = 0.76301499
Iteration 4368, loss = 0.76432456
Iteration 4369, loss = 0.75510897
Iteration 4370, loss = 0.75613264
Iteration 4371, loss = 0.75076918
Iteration 4372, loss = 0.75368975
Iteration 4373, loss = 0.75166719
Iteration 4374, loss = 0.75380790
Iteration 4375, loss = 0.75231454
Iteration 4376, loss = 0.75239581
Iteration 4377, loss = 0.75076633
Iteration 4378, loss = 0.74963442
Iteration 4379, loss = 0.74945734
Iteration 4380, loss = 0.74854460
Iteration 4381, loss = 0.74850363
Iteration 4382, loss = 0.74857038
Iteration 4383, loss = 0.74924039
Iteration 4384, loss = 0.74647486
Iteration 4385, loss = 0.73624252
Iteration 4386, loss = 0.74816550
Iteration 4387, loss = 0.73415177
Iteration 4388, loss = 0.79171512
Iteration 4389, loss = 0.80596889
Iteration 4390, loss = 0.78214180
Iteration 4391, loss = 0.81091179
Iteration 4392, loss = 0.76397110
Iteration 4393, loss = 0.80226476
Iteration 4394, loss = 0.75237871
Iteration 4395, loss = 0.79483399
Iteration 4396, loss = 0.75217852
Iteration 4397, loss = 0.78838188
Iteration 4398, loss = 0.75430648
Iteration 4399, loss = 0.77755208
Iteration 4400, loss = 0.75715806
Iteration 4401, loss = 0.76695424
Iteration 4402, loss = 0.75767141
Iteration 4403, loss = 0.75736915
Iteration 4404, loss = 0.76016780
Iteration 4405, loss = 0.75267649
Iteration 4406, loss = 0.76030102
Iteration 4407, loss = 0.74887729
Iteration 4408, loss = 0.75836231
Iteration 4409, loss = 0.74700429
Iteration 4410, loss = 0.75511738
Iteration 4411, loss = 0.74647343
Iteration 4412, loss = 0.75197164
Iteration 4413, loss = 0.74597410
Iteration 4414, loss = 0.74770882
Iteration 4415, loss = 0.74578488
Iteration 4416, loss = 0.74443836
Iteration 4417, loss = 0.74406204
Iteration 4418, loss = 0.74004194
Iteration 4419, loss = 0.74125318
Iteration 4420, loss = 0.73695909
Iteration 4421, loss = 0.73632444
Iteration 4422, loss = 0.73256922
Iteration 4423, loss = 0.73137665
Iteration 4424, loss = 0.72304238
Iteration 4425, loss = 0.66651486
Iteration 4426, loss = 0.76069502
Iteration 4427, loss = 0.77888074
Iteration 4428, loss = 0.78906748
Iteration 4429, loss = 0.78892637
Iteration 4430, loss = 0.78787638
Iteration 4431, loss = 0.77457806
Iteration 4432, loss = 0.76830486
Iteration 4433, loss = 0.75870254
Iteration 4434, loss = 0.75611500
Iteration 4435, loss = 0.75657450
Iteration 4436, loss = 0.75581024
Iteration 4437, loss = 0.75890578
Iteration 4438, loss = 0.75302962
Iteration 4439, loss = 0.79989169
Iteration 4440, loss = 1.17811026
Iteration 4441, loss = 0.80884486
Iteration 4442, loss = 1.18298459
Iteration 4443, loss = 0.84346025
Iteration 4444, loss = 1.15595673
Iteration 4445, loss = 0.84631812
Iteration 4446, loss = 1.11818013
Iteration 4447, loss = 0.82962878
Iteration 4448, loss = 1.07635869
Iteration 4449, loss = 0.80793377
Iteration 4450, loss = 1.03965239
Iteration 4451, loss = 0.79313780
Iteration 4452, loss = 1.01177042
Iteration 4453, loss = 0.78496242
Iteration 4454, loss = 0.98909624
Iteration 4455, loss = 0.78072740
Iteration 4456, loss = 0.96917890
Iteration 4457, loss = 0.77578484
Iteration 4458, loss = 0.93422915
Iteration 4459, loss = 0.80030634
Iteration 4460, loss = 0.84254673
Iteration 4461, loss = 0.81796853
Iteration 4462, loss = 0.81059109
Iteration 4463, loss = 0.81844350
Iteration 4464, loss = 0.78724884
Iteration 4465, loss = 0.81972048
Iteration 4466, loss = 0.78364257
Iteration 4467, loss = 0.81799618
Iteration 4468, loss = 0.78531292
Iteration 4469, loss = 0.80595672
Iteration 4470, loss = 0.78715757
Iteration 4471, loss = 0.79292496
Iteration 4472, loss = 0.79169679
Iteration 4473, loss = 0.78521944
Iteration 4474, loss = 0.79460752
Iteration 4475, loss = 0.78067680
Iteration 4476, loss = 0.79234053
Iteration 4477, loss = 0.77882217
Iteration 4478, loss = 0.78747847
Iteration 4479, loss = 0.77974853
Iteration 4480, loss = 0.78244366
Iteration 4481, loss = 0.78115481
Iteration 4482, loss = 0.77821132
Iteration 4483, loss = 0.78140773
Iteration 4484, loss = 0.77581012
Iteration 4485, loss = 0.78039304
Iteration 4486, loss = 0.77517825
Iteration 4487, loss = 0.77826059
Iteration 4488, loss = 0.77374346
Iteration 4489, loss = 0.77387358
Iteration 4490, loss = 0.77700051
Iteration 4491, loss = 0.77851889
Iteration 4492, loss = 0.77781026
Iteration 4493, loss = 0.77608687
Iteration 4494, loss = 0.77415058
Iteration 4495, loss = 0.77341326
Iteration 4496, loss = 0.77318804
Iteration 4497, loss = 0.77348040
Iteration 4498, loss = 0.77361546
Iteration 4499, loss = 0.77349844
Iteration 4500, loss = 0.77308804
Iteration 4501, loss = 0.77253984
Iteration 4502, loss = 0.77208498
Iteration 4503, loss = 0.77165836
Iteration 4504, loss = 0.77135737
Iteration 4505, loss = 0.77099842
Iteration 4506, loss = 0.77056317
Iteration 4507, loss = 0.76949974
Iteration 4508, loss = 0.77039021
Iteration 4509, loss = 0.77322678
Iteration 4510, loss = 0.74590012
Iteration 4511, loss = 0.77596473
Iteration 4512, loss = 0.81216461
Iteration 4513, loss = 0.79863590
Iteration 4514, loss = 0.82224112
Iteration 4515, loss = 0.81436637
Iteration 4516, loss = 0.81591288
Iteration 4517, loss = 0.81502589
Iteration 4518, loss = 0.80155301
Iteration 4519, loss = 0.80584624
Iteration 4520, loss = 0.78887503
Iteration 4521, loss = 0.79450773
Iteration 4522, loss = 0.78311341
Iteration 4523, loss = 0.78675184
Iteration 4524, loss = 0.78366748
Iteration 4525, loss = 0.78340856
Iteration 4526, loss = 0.78617132
Iteration 4527, loss = 0.78200559
Iteration 4528, loss = 0.78660811
Iteration 4529, loss = 0.78177095
Iteration 4530, loss = 0.78492268
Iteration 4531, loss = 0.78184830
Iteration 4532, loss = 0.78216895
Iteration 4533, loss = 0.78162742
Iteration 4534, loss = 0.77964227
Iteration 4535, loss = 0.78078037
Iteration 4536, loss = 0.77806799
Iteration 4537, loss = 0.77946823
Iteration 4538, loss = 0.77747495
Iteration 4539, loss = 0.77797268
Iteration 4540, loss = 0.77716828
Iteration 4541, loss = 0.77641410
Iteration 4542, loss = 0.77647494
Iteration 4543, loss = 0.77497362
Iteration 4544, loss = 0.77525620
Iteration 4545, loss = 0.77381657
Iteration 4546, loss = 0.77382985
Iteration 4547, loss = 0.77299342
Iteration 4548, loss = 0.77255899
Iteration 4549, loss = 0.77233938
Iteration 4550, loss = 0.77161253
Iteration 4551, loss = 0.77168244
Iteration 4552, loss = 0.77094267
Iteration 4553, loss = 0.77092873
Iteration 4554, loss = 0.77037190
Iteration 4555, loss = 0.77005697
Iteration 4556, loss = 0.76974754
Iteration 4557, loss = 0.76924341
Iteration 4558, loss = 0.76902213
Iteration 4559, loss = 0.76840981
Iteration 4560, loss = 0.76820193
Iteration 4561, loss = 0.76774797
Iteration 4562, loss = 0.76744161
Iteration 4563, loss = 0.76708656
Iteration 4564, loss = 0.76668278
Iteration 4565, loss = 0.76644185
Iteration 4566, loss = 0.76601070
Iteration 4567, loss = 0.76573385
Iteration 4568, loss = 0.76531712
Iteration 4569, loss = 0.76499061
Iteration 4570, loss = 0.76463533
Iteration 4571, loss = 0.76424395
Iteration 4572, loss = 0.76392616
Iteration 4573, loss = 0.76353818
Iteration 4574, loss = 0.76324047
Iteration 4575, loss = 0.76288044
Iteration 4576, loss = 0.76256866
Iteration 4577, loss = 0.76225823
Iteration 4578, loss = 0.76194090
Iteration 4579, loss = 0.76165686
Iteration 4580, loss = 0.76133195
Iteration 4581, loss = 0.76104997
Iteration 4582, loss = 0.76073956
Iteration 4583, loss = 0.76044669
Iteration 4584, loss = 0.76015041
Iteration 4585, loss = 0.75984721
Iteration 4586, loss = 0.75956451
Iteration 4587, loss = 0.75926333
Iteration 4588, loss = 0.75898115
Iteration 4589, loss = 0.75868630
Iteration 4590, loss = 0.75840064
Iteration 4591, loss = 0.75811715
Iteration 4592, loss = 0.75782920
Iteration 4593, loss = 0.75755239
Iteration 4594, loss = 0.75726830
Iteration 4595, loss = 0.75699498
Iteration 4596, loss = 0.75671672
Iteration 4597, loss = 0.75644128
Iteration 4598, loss = 0.75616919
Iteration 4599, loss = 0.75589575
Iteration 4600, loss = 0.75562893
Iteration 4601, loss = 0.75535853
Iteration 4602, loss = 0.75509360
Iteration 4603, loss = 0.75482859
Iteration 4604, loss = 0.75456534
Iteration 4605, loss = 0.75430506
Iteration 4606, loss = 0.75404483
Iteration 4607, loss = 0.75378988
Iteration 4608, loss = 0.75353491
Iteration 4609, loss = 0.75328287
Iteration 4610, loss = 0.75303161
Iteration 4611, loss = 0.75278113
Iteration 4612, loss = 0.75253268
Iteration 4613, loss = 0.75228393
Iteration 4614, loss = 0.75203779
Iteration 4615, loss = 0.75179249
Iteration 4616, loss = 0.75154937
Iteration 4617, loss = 0.75130800
Iteration 4618, loss = 0.75106782
Iteration 4619, loss = 0.75082988
Iteration 4620, loss = 0.75059263
Iteration 4621, loss = 0.75035702
Iteration 4622, loss = 0.75012221
Iteration 4623, loss = 0.74988849
Iteration 4624, loss = 0.74965605
Iteration 4625, loss = 0.74942438
Iteration 4626, loss = 0.74919422
Iteration 4627, loss = 0.74896497
Iteration 4628, loss = 0.74873699
Iteration 4629, loss = 0.74850997
Iteration 4630, loss = 0.74828371
Iteration 4631, loss = 0.74805833
Iteration 4632, loss = 0.74783329
Iteration 4633, loss = 0.74760869
Iteration 4634, loss = 0.74738405
Iteration 4635, loss = 0.74715908
Iteration 4636, loss = 0.74693317
Iteration 4637, loss = 0.74670509
Iteration 4638, loss = 0.74647305
Iteration 4639, loss = 0.74623253
Iteration 4640, loss = 0.74595844
Iteration 4641, loss = 0.74472168
Iteration 4642, loss = 0.74635027
Iteration 4643, loss = 0.75040011
Iteration 4644, loss = 0.74841569
Iteration 4645, loss = 0.74679213
Iteration 4646, loss = 0.74638334
Iteration 4647, loss = 0.74420779
Iteration 4648, loss = 0.74532101
Iteration 4649, loss = 0.74495174
Iteration 4650, loss = 0.74243878
Iteration 4651, loss = 0.74199792
Iteration 4652, loss = 0.74086248
Iteration 4653, loss = 0.73866516
Iteration 4654, loss = 0.73781811
Iteration 4655, loss = 0.73374098
Iteration 4656, loss = 0.72307620
Iteration 4657, loss = 0.82184441
Iteration 4658, loss = 0.95596474
Iteration 4659, loss = 0.71986751
Iteration 4660, loss = 1.10072445
Iteration 4661, loss = 0.87593752
Iteration 4662, loss = 0.93910403
Iteration 4663, loss = 0.92624914
Iteration 4664, loss = 0.82223621
Iteration 4665, loss = 0.96914835
Iteration 4666, loss = 0.77117751
Iteration 4667, loss = 0.98710454
Iteration 4668, loss = 0.75950179
Iteration 4669, loss = 0.96410618
Iteration 4670, loss = 0.76262412
Iteration 4671, loss = 0.90396775
Iteration 4672, loss = 0.78043737
Iteration 4673, loss = 0.83026677
Iteration 4674, loss = 0.81218401
Iteration 4675, loss = 0.77103278
Iteration 4676, loss = 0.83253189
Iteration 4677, loss = 0.72742944
Iteration 4678, loss = 0.94279581
Iteration 4679, loss = 0.85553272
Iteration 4680, loss = 0.85003681
Iteration 4681, loss = 0.90444149
Iteration 4682, loss = 0.78809189
Iteration 4683, loss = 0.91234584
Iteration 4684, loss = 0.76661584
Iteration 4685, loss = 0.88157677
Iteration 4686, loss = 0.78143825
Iteration 4687, loss = 0.83155664
Iteration 4688, loss = 0.81368916
Iteration 4689, loss = 0.78909106
Iteration 4690, loss = 0.83397967
Iteration 4691, loss = 0.77067321
Iteration 4692, loss = 0.82597449
Iteration 4693, loss = 0.77549908
Iteration 4694, loss = 0.79954353
Iteration 4695, loss = 0.79093253
Iteration 4696, loss = 0.77586965
Iteration 4697, loss = 0.79944803
Iteration 4698, loss = 0.76739647
Iteration 4699, loss = 0.79302987
Iteration 4700, loss = 0.77239340
Iteration 4701, loss = 0.77863137
Iteration 4702, loss = 0.78054812
Iteration 4703, loss = 0.76791115
Iteration 4704, loss = 0.78201593
Iteration 4705, loss = 0.76587176
Iteration 4706, loss = 0.77550256
Iteration 4707, loss = 0.76938270
Iteration 4708, loss = 0.76724073
Iteration 4709, loss = 0.77204739
Iteration 4710, loss = 0.76307802
Iteration 4711, loss = 0.77015563
Iteration 4712, loss = 0.76356257
Iteration 4713, loss = 0.76531218
Iteration 4714, loss = 0.76535606
Iteration 4715, loss = 0.76142038
Iteration 4716, loss = 0.76515956
Iteration 4717, loss = 0.76026825
Iteration 4718, loss = 0.76059055
Iteration 4719, loss = 0.74225567
Iteration 4720, loss = 0.78379519
Iteration 4721, loss = 0.79029128
Iteration 4722, loss = 0.79400550
Iteration 4723, loss = 0.80064200
Iteration 4724, loss = 0.78484340
Iteration 4725, loss = 0.78786301
Iteration 4726, loss = 0.77567773
Iteration 4727, loss = 0.77518123
Iteration 4728, loss = 0.77204954
Iteration 4729, loss = 0.76610454
Iteration 4730, loss = 0.76857913
Iteration 4731, loss = 0.76248807
Iteration 4732, loss = 0.76606049
Iteration 4733, loss = 0.76281510
Iteration 4734, loss = 0.76258058
Iteration 4735, loss = 0.76187535
Iteration 4736, loss = 0.75801717
Iteration 4737, loss = 0.75737799
Iteration 4738, loss = 0.75978456
Iteration 4739, loss = 0.72551793
Iteration 4740, loss = 0.76420397
Iteration 4741, loss = 0.76451372
Iteration 4742, loss = 0.76701246
Iteration 4743, loss = 0.76308990
Iteration 4744, loss = 0.75971263
Iteration 4745, loss = 0.75735909
Iteration 4746, loss = 0.75477838
Iteration 4747, loss = 0.75564579
Iteration 4748, loss = 0.75529662
Iteration 4749, loss = 0.75608452
Iteration 4750, loss = 0.75585878
Iteration 4751, loss = 0.75455359
Iteration 4752, loss = 0.75429371
Iteration 4753, loss = 0.75304429
Iteration 4754, loss = 0.75281251
Iteration 4755, loss = 0.75227742
Iteration 4756, loss = 0.75160068
Iteration 4757, loss = 0.75140268
Iteration 4758, loss = 0.75044223
Iteration 4759, loss = 0.74930255
Iteration 4760, loss = 0.74856559
Iteration 4761, loss = 0.75757578
Iteration 4762, loss = 0.76025610
Iteration 4763, loss = 0.75748111
Iteration 4764, loss = 0.75700389
Iteration 4765, loss = 0.75177447
Iteration 4766, loss = 0.74965118
Iteration 4767, loss = 0.75216128
Iteration 4768, loss = 0.75114031
Iteration 4769, loss = 0.75091312
Iteration 4770, loss = 0.75124986
Iteration 4771, loss = 0.74894717
Iteration 4772, loss = 0.74866981
Iteration 4773, loss = 0.74880559
Iteration 4774, loss = 0.74742020
Iteration 4775, loss = 0.74775738
Iteration 4776, loss = 0.74740277
Iteration 4777, loss = 0.74597345
Iteration 4778, loss = 0.74595053
Iteration 4779, loss = 0.74557292
Iteration 4780, loss = 0.74501750
Iteration 4781, loss = 0.74537262
Iteration 4782, loss = 0.74486181
Iteration 4783, loss = 0.74403744
Iteration 4784, loss = 0.74377923
Iteration 4785, loss = 0.74315296
Iteration 4786, loss = 0.74281082
Iteration 4787, loss = 0.74285511
Iteration 4788, loss = 0.74237909
Iteration 4789, loss = 0.74197669
Iteration 4790, loss = 0.74170642
Iteration 4791, loss = 0.74110426
Iteration 4792, loss = 0.74065964
Iteration 4793, loss = 0.74028183
Iteration 4794, loss = 0.73974422
Iteration 4795, loss = 0.73853923
Iteration 4796, loss = 0.73950198
Iteration 4797, loss = 0.74149982
Iteration 4798, loss = 0.74129282
Iteration 4799, loss = 0.73981999
Iteration 4800, loss = 0.73953007
Iteration 4801, loss = 0.73889974
Iteration 4802, loss = 0.73785193
Iteration 4803, loss = 0.73806111
Iteration 4804, loss = 0.73818208
Iteration 4805, loss = 0.73746961
Iteration 4806, loss = 0.73726782
Iteration 4807, loss = 0.73722418
Iteration 4808, loss = 0.73661340
Iteration 4809, loss = 0.73630648
Iteration 4810, loss = 0.73635516
Iteration 4811, loss = 0.73595276
Iteration 4812, loss = 0.73552120
Iteration 4813, loss = 0.73546160
Iteration 4814, loss = 0.73518717
Iteration 4815, loss = 0.73475877
Iteration 4816, loss = 0.73461585
Iteration 4817, loss = 0.73442036
Iteration 4818, loss = 0.73400529
Iteration 4819, loss = 0.73374047
Iteration 4820, loss = 0.73355165
Iteration 4821, loss = 0.73322431
Iteration 4822, loss = 0.73296927
Iteration 4823, loss = 0.73281970
Iteration 4824, loss = 0.73255282
Iteration 4825, loss = 0.73225029
Iteration 4826, loss = 0.73204452
Iteration 4827, loss = 0.73180292
Iteration 4828, loss = 0.73150474
Iteration 4829, loss = 0.73127227
Iteration 4830, loss = 0.73105700
Iteration 4831, loss = 0.73078910
Iteration 4832, loss = 0.73053729
Iteration 4833, loss = 0.73030725
Iteration 4834, loss = 0.73003289
Iteration 4835, loss = 0.72973384
Iteration 4836, loss = 0.72939547
Iteration 4837, loss = 0.72885842
Iteration 4838, loss = 0.72836482
Iteration 4839, loss = 0.72803793
Iteration 4840, loss = 0.72725606
Iteration 4841, loss = 0.72579604
Iteration 4842, loss = 0.72498762
Iteration 4843, loss = 0.72389392
Iteration 4844, loss = 0.72225075
Iteration 4845, loss = 0.71697217
Iteration 4846, loss = 0.65092321
Iteration 4847, loss = 1.02854561
Iteration 4848, loss = 0.86135339
Iteration 4849, loss = 0.79783252
Iteration 4850, loss = 1.00460129
Iteration 4851, loss = 0.76598726
Iteration 4852, loss = 0.86772173
Iteration 4853, loss = 0.88736706
Iteration 4854, loss = 0.74167580
Iteration 4855, loss = 0.87480091
Iteration 4856, loss = 0.80241768
Iteration 4857, loss = 0.75421108
Iteration 4858, loss = 0.85442099
Iteration 4859, loss = 0.76611558
Iteration 4860, loss = 0.77107057
Iteration 4861, loss = 0.82625314
Iteration 4862, loss = 0.75200708
Iteration 4863, loss = 0.77814022
Iteration 4864, loss = 0.80071278
Iteration 4865, loss = 0.74653792
Iteration 4866, loss = 0.77654168
Iteration 4867, loss = 0.78054496
Iteration 4868, loss = 0.74399045
Iteration 4869, loss = 0.77105574
Iteration 4870, loss = 0.76672736
Iteration 4871, loss = 0.74341057
Iteration 4872, loss = 0.76554654
Iteration 4873, loss = 0.75836424
Iteration 4874, loss = 0.74399734
Iteration 4875, loss = 0.76091275
Iteration 4876, loss = 0.75324327
Iteration 4877, loss = 0.74428111
Iteration 4878, loss = 0.75652593
Iteration 4879, loss = 0.74933273
Iteration 4880, loss = 0.74364227
Iteration 4881, loss = 0.75216502
Iteration 4882, loss = 0.74632023
Iteration 4883, loss = 0.74272760
Iteration 4884, loss = 0.74896612
Iteration 4885, loss = 0.74424643
Iteration 4886, loss = 0.74176290
Iteration 4887, loss = 0.74627200
Iteration 4888, loss = 0.74256917
Iteration 4889, loss = 0.74098222
Iteration 4890, loss = 0.74418556
Iteration 4891, loss = 0.74129368
Iteration 4892, loss = 0.74015197
Iteration 4893, loss = 0.74244601
Iteration 4894, loss = 0.73973717
Iteration 4895, loss = 0.73892992
Iteration 4896, loss = 0.74039312
Iteration 4897, loss = 0.73848808
Iteration 4898, loss = 0.73772722
Iteration 4899, loss = 0.73875002
Iteration 4900, loss = 0.73280593
Iteration 4901, loss = 0.75088958
Iteration 4902, loss = 0.75777411
Iteration 4903, loss = 0.74374939
Iteration 4904, loss = 0.74653046
Iteration 4905, loss = 0.74399379
Iteration 4906, loss = 0.72359138
Iteration 4907, loss = 0.80769775
Iteration 4908, loss = 1.03239363
Iteration 4909, loss = 0.75660907
Iteration 4910, loss = 0.94554995
Iteration 4911, loss = 0.84384946
Iteration 4912, loss = 0.81481342
Iteration 4913, loss = 1.68624904
Iteration 4914, loss = 0.89809443
Iteration 4915, loss = 1.89138285
Iteration 4916, loss = 1.33028311
Iteration 4917, loss = 1.77303130
Iteration 4918, loss = 1.76091929
Iteration 4919, loss = 1.07291375
Iteration 4920, loss = 1.37804583
Iteration 4921, loss = 0.94761679
Iteration 4922, loss = 1.06421566
Iteration 4923, loss = 1.03949225
Iteration 4924, loss = 0.88468473
Iteration 4925, loss = 1.16704406
Iteration 4926, loss = 0.82126720
Iteration 4927, loss = 1.25541080
Iteration 4928, loss = 0.81076025
Iteration 4929, loss = 1.32190536
Iteration 4930, loss = 0.84146142
Iteration 4931, loss = 1.39887823
Iteration 4932, loss = 0.93720320
Iteration 4933, loss = 1.45941772
Iteration 4934, loss = 1.13389398
Iteration 4935, loss = 1.37357609
Iteration 4936, loss = 1.26692778
Iteration 4937, loss = 1.12267861
Iteration 4938, loss = 1.19903181
Iteration 4939, loss = 0.96901631
Iteration 4940, loss = 1.05604368
Iteration 4941, loss = 0.93343774
Iteration 4942, loss = 0.94037760
Iteration 4943, loss = 0.94383569
Iteration 4944, loss = 0.86090125
Iteration 4945, loss = 0.96864208
Iteration 4946, loss = 0.75612641
Iteration 4947, loss = 0.85620194
Iteration 4948, loss = 0.74771149
Iteration 4949, loss = 0.83145792
Iteration 4950, loss = 0.75843800
Iteration 4951, loss = 0.79361091
Iteration 4952, loss = 0.77833974
Iteration 4953, loss = 0.76105608
Iteration 4954, loss = 0.79163238
Iteration 4955, loss = 0.74664071
Iteration 4956, loss = 0.78805001
Iteration 4957, loss = 0.74779693
Iteration 4958, loss = 0.77089403
Iteration 4959, loss = 0.75715867
Iteration 4960, loss = 0.75351851
Iteration 4961, loss = 0.76516201
Iteration 4962, loss = 0.74449852
Iteration 4963, loss = 0.76375809
Iteration 4964, loss = 0.74413782
Iteration 4965, loss = 0.75521646
Iteration 4966, loss = 0.74904862
Iteration 4967, loss = 0.74652892
Iteration 4968, loss = 0.75262993
Iteration 4969, loss = 0.74193672
Iteration 4970, loss = 0.75110982
Iteration 4971, loss = 0.74203988
Iteration 4972, loss = 0.74633572
Iteration 4973, loss = 0.74444835
Iteration 4974, loss = 0.74189112
Iteration 4975, loss = 0.74555218
Iteration 4976, loss = 0.73982128
Iteration 4977, loss = 0.74402517
Iteration 4978, loss = 0.74013946
Iteration 4979, loss = 0.74122263
Iteration 4980, loss = 0.74113068
Iteration 4981, loss = 0.73896771
Iteration 4982, loss = 0.74109734
Iteration 4983, loss = 0.73812649
Iteration 4984, loss = 0.73978597
Iteration 4985, loss = 0.73831823
Iteration 4986, loss = 0.73810704
Iteration 4987, loss = 0.73851746
Iteration 4988, loss = 0.73697903
Iteration 4989, loss = 0.73804516
Iteration 4990, loss = 0.73660431
Iteration 4991, loss = 0.73701943
Iteration 4992, loss = 0.73657894
Iteration 4993, loss = 0.73491055
Iteration 4994, loss = 0.73355251
Iteration 4995, loss = 0.73302029
Iteration 4996, loss = 0.73649841
Iteration 4997, loss = 0.75076392
Iteration 4998, loss = 0.77254893
Iteration 4999, loss = 0.74688015
Iteration 5000, loss = 0.76844613
