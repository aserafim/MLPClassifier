Iteration 1, loss = 0.73102514
Iteration 2, loss = 6.32187863
Iteration 3, loss = 2.63999536
Iteration 4, loss = 0.90029953
Iteration 5, loss = 2.03905442
Iteration 6, loss = 2.13154042
Iteration 7, loss = 1.46070409
Iteration 8, loss = 0.79484926
Iteration 9, loss = 1.49561580
Iteration 10, loss = 1.43079953
Iteration 11, loss = 1.14991850
Iteration 12, loss = 0.91008581
Iteration 13, loss = 0.89244631
Iteration 14, loss = 0.75073556
Iteration 15, loss = 0.77619088
Iteration 16, loss = 0.73306730
Iteration 17, loss = 0.79185866
Iteration 18, loss = 1.04241490
Iteration 19, loss = 0.78459729
Iteration 20, loss = 0.79842512
Iteration 21, loss = 0.77404854
Iteration 22, loss = 0.81690518
Iteration 23, loss = 0.77042849
Iteration 24, loss = 0.85207254
Iteration 25, loss = 0.80666378
Iteration 26, loss = 0.76328194
Iteration 27, loss = 0.79444031
Iteration 28, loss = 0.98145505
Iteration 29, loss = 0.78877676
Iteration 30, loss = 0.89558724
Iteration 31, loss = 0.79433748
Iteration 32, loss = 0.75916001
Iteration 33, loss = 0.75499719
Iteration 34, loss = 0.72018037
Iteration 35, loss = 0.79954395
Iteration 36, loss = 0.83291175
Iteration 37, loss = 0.79348798
Iteration 38, loss = 0.81930414
Iteration 39, loss = 1.28981029
Iteration 40, loss = 1.80348935
Iteration 41, loss = 1.27102695
Iteration 42, loss = 0.95955725
Iteration 43, loss = 1.14948419
Iteration 44, loss = 0.80552455
Iteration 45, loss = 1.25509426
Iteration 46, loss = 0.79033061
Iteration 47, loss = 0.83218222
Iteration 48, loss = 0.86455583
Iteration 49, loss = 2.00670071
Iteration 50, loss = 0.82020105
Iteration 51, loss = 0.80433922
Iteration 52, loss = 1.74778417
Iteration 53, loss = 0.99198452
Iteration 54, loss = 0.84640549
Iteration 55, loss = 1.33725711
Iteration 56, loss = 1.05552107
Iteration 57, loss = 0.83614664
Iteration 58, loss = 0.93857839
Iteration 59, loss = 0.93630927
Iteration 60, loss = 1.05148015
Iteration 61, loss = 1.09340093
Iteration 62, loss = 0.85842408
Iteration 63, loss = 0.95201857
Iteration 64, loss = 0.90824726
Iteration 65, loss = 0.89916831
Iteration 66, loss = 0.85672875
Iteration 67, loss = 0.89864022
Iteration 68, loss = 0.84810961
Iteration 69, loss = 0.85891502
Iteration 70, loss = 0.90425881
Iteration 71, loss = 0.96210428
Iteration 72, loss = 0.90271334
Iteration 73, loss = 0.84781858
Iteration 74, loss = 0.92358512
Iteration 75, loss = 0.78921039
Iteration 76, loss = 0.92130098
Iteration 77, loss = 0.80897515
Iteration 78, loss = 0.83372027
Iteration 79, loss = 0.81813335
Iteration 80, loss = 0.79486670
Iteration 81, loss = 0.81192074
Iteration 82, loss = 0.78250698
Iteration 83, loss = 0.85603412
Iteration 84, loss = 0.78238242
Iteration 85, loss = 0.83850864
Iteration 86, loss = 0.81868065
Iteration 87, loss = 0.78341863
Iteration 88, loss = 0.81462871
Iteration 89, loss = 0.76431503
Iteration 90, loss = 0.77150720
Iteration 91, loss = 0.77228819
Iteration 92, loss = 0.70903889
Iteration 93, loss = 0.78273374
Iteration 94, loss = 0.77294676
Iteration 95, loss = 0.80734170
Iteration 96, loss = 0.76022569
Iteration 97, loss = 0.84268250
Iteration 98, loss = 0.76853424
Iteration 99, loss = 0.76316061
Iteration 100, loss = 0.86849309
Iteration 101, loss = 0.77303211
Iteration 102, loss = 0.81485665
Iteration 103, loss = 0.83642607
Iteration 104, loss = 0.78200315
Iteration 105, loss = 0.83649397
Iteration 106, loss = 0.80849315
Iteration 107, loss = 0.81034680
Iteration 108, loss = 0.82671923
Iteration 109, loss = 0.78668419
Iteration 110, loss = 0.82318571
Iteration 111, loss = 0.81087232
Iteration 112, loss = 0.77556313
Iteration 113, loss = 0.78912840
Iteration 114, loss = 0.77252304
Iteration 115, loss = 0.76751371
Iteration 116, loss = 0.76965390
Iteration 117, loss = 0.76883401
Iteration 118, loss = 0.76225504
Iteration 119, loss = 0.76167700
Iteration 120, loss = 0.75979630
Iteration 121, loss = 0.76936697
Iteration 122, loss = 0.74875469
Iteration 123, loss = 1.70162470
Iteration 124, loss = 0.65947016
Iteration 125, loss = 1.45747896
Iteration 126, loss = 1.29258129
Iteration 127, loss = 0.85093271
Iteration 128, loss = 1.04147029
Iteration 129, loss = 0.86372154
Iteration 130, loss = 0.87269221
Iteration 131, loss = 0.98769123
Iteration 132, loss = 0.91406225
Iteration 133, loss = 0.86946293
Iteration 134, loss = 0.82394621
Iteration 135, loss = 0.88386202
Iteration 136, loss = 0.82870340
Iteration 137, loss = 0.66845116
Iteration 138, loss = 1.24255036
Iteration 139, loss = 0.80240333
Iteration 140, loss = 0.80902313
Iteration 141, loss = 1.06584582
Iteration 142, loss = 0.82635435
Iteration 143, loss = 1.04482601
Iteration 144, loss = 0.82057528
Iteration 145, loss = 0.93706295
Iteration 146, loss = 0.88544260
Iteration 147, loss = 0.83207970
Iteration 148, loss = 0.78819845
Iteration 149, loss = 1.07921975
Iteration 150, loss = 0.80295478
Iteration 151, loss = 0.96139389
Iteration 152, loss = 0.92659782
Iteration 153, loss = 0.81670998
Iteration 154, loss = 1.05225753
Iteration 155, loss = 1.10269682
Iteration 156, loss = 0.76443897
Iteration 157, loss = 1.01487397
Iteration 158, loss = 0.65837729
Iteration 159, loss = 0.88563141
Iteration 160, loss = 0.78378907
Iteration 161, loss = 0.94131328
Iteration 162, loss = 0.81787682
Iteration 163, loss = 0.83464777
Iteration 164, loss = 0.88956070
Iteration 165, loss = 0.77395978
Iteration 166, loss = 0.85860225
Iteration 167, loss = 0.81612090
Iteration 168, loss = 0.77862772
Iteration 169, loss = 0.81586874
Iteration 170, loss = 1.01815501
Iteration 171, loss = 0.83858209
Iteration 172, loss = 1.22615141
Iteration 173, loss = 0.82841113
Iteration 174, loss = 1.10893246
Iteration 175, loss = 1.00035451
Iteration 176, loss = 0.87533253
Iteration 177, loss = 0.98277524
Iteration 178, loss = 0.78083248
Iteration 179, loss = 0.93225899
Iteration 180, loss = 0.80258263
Iteration 181, loss = 0.87043871
Iteration 182, loss = 0.80388177
Iteration 183, loss = 0.83012277
Iteration 184, loss = 0.81186648
Iteration 185, loss = 0.88512006
Iteration 186, loss = 0.76926396
Iteration 187, loss = 0.86675019
Iteration 188, loss = 0.77603444
Iteration 189, loss = 0.92652034
Iteration 190, loss = 0.64797644
Iteration 191, loss = 0.93778428
Iteration 192, loss = 0.79541262
Iteration 193, loss = 0.91391472
Iteration 194, loss = 0.77991195
Iteration 195, loss = 0.88514774
Iteration 196, loss = 0.76903583
Iteration 197, loss = 1.01131068
Iteration 198, loss = 0.72562889
Iteration 199, loss = 1.05400470
Iteration 200, loss = 0.78133163
Iteration 201, loss = 1.01732473
Iteration 202, loss = 0.86113097
Iteration 203, loss = 0.90340514
Iteration 204, loss = 1.00721158
Iteration 205, loss = 0.84387326
Iteration 206, loss = 0.98234338
Iteration 207, loss = 0.72630750
Iteration 208, loss = 0.85047143
Iteration 209, loss = 0.82791206
Iteration 210, loss = 0.81554769
Iteration 211, loss = 0.84306741
Iteration 212, loss = 0.78612121
Iteration 213, loss = 0.86867217
Iteration 214, loss = 0.95992725
Iteration 215, loss = 0.79759800
Iteration 216, loss = 0.88292024
Iteration 217, loss = 0.80399763
Iteration 218, loss = 0.85961132
Iteration 219, loss = 0.79392634
Iteration 220, loss = 0.81632541
Iteration 221, loss = 0.78384090
Iteration 222, loss = 0.79213311
Iteration 223, loss = 0.80824631
Iteration 224, loss = 0.87230753
Iteration 225, loss = 0.81972859
Iteration 226, loss = 0.84094690
Iteration 227, loss = 0.82698648
Iteration 228, loss = 0.81329102
Iteration 229, loss = 0.82826626
Iteration 230, loss = 0.79342666
Iteration 231, loss = 0.82527693
Iteration 232, loss = 0.78254764
Iteration 233, loss = 0.81988552
Iteration 234, loss = 0.77858104
Iteration 235, loss = 0.81263959
Iteration 236, loss = 0.77783859
Iteration 237, loss = 0.80349191
Iteration 238, loss = 0.77735301
Iteration 239, loss = 0.79262652
Iteration 240, loss = 0.76490434
Iteration 241, loss = 0.77562510
Iteration 242, loss = 0.78539471
Iteration 243, loss = 0.80583504
Iteration 244, loss = 0.78397880
Iteration 245, loss = 0.80307900
Iteration 246, loss = 0.78469215
Iteration 247, loss = 0.79655517
Iteration 248, loss = 0.78277959
Iteration 249, loss = 0.78991424
Iteration 250, loss = 0.78106589
Iteration 251, loss = 0.78559023
Iteration 252, loss = 0.78036765
Iteration 253, loss = 0.78210497
Iteration 254, loss = 0.77918460
Iteration 255, loss = 0.77924966
Iteration 256, loss = 0.77803086
Iteration 257, loss = 0.77704444
Iteration 258, loss = 0.77685404
Iteration 259, loss = 0.77528047
Iteration 260, loss = 0.77549785
Iteration 261, loss = 0.77349244
Iteration 262, loss = 0.77373568
Iteration 263, loss = 0.76923606
Iteration 264, loss = 0.77116819
Iteration 265, loss = 0.77146917
Iteration 266, loss = 0.77102480
Iteration 267, loss = 0.77070006
Iteration 268, loss = 0.76980394
Iteration 269, loss = 0.76904177
Iteration 270, loss = 0.76800621
Iteration 271, loss = 0.76727125
Iteration 272, loss = 0.76654274
Iteration 273, loss = 0.76614480
Iteration 274, loss = 0.78089826
Iteration 275, loss = 0.82010838
Iteration 276, loss = 0.77078128
Iteration 277, loss = 0.81583363
Iteration 278, loss = 0.77963352
Iteration 279, loss = 0.81289787
Iteration 280, loss = 0.78595041
Iteration 281, loss = 0.80756046
Iteration 282, loss = 0.78739796
Iteration 283, loss = 0.79939920
Iteration 284, loss = 0.78453540
Iteration 285, loss = 0.78963659
Iteration 286, loss = 0.77927905
Iteration 287, loss = 0.78014543
Iteration 288, loss = 0.77367262
Iteration 289, loss = 0.77240313
Iteration 290, loss = 0.76924092
Iteration 291, loss = 0.76677171
Iteration 292, loss = 0.76544391
Iteration 293, loss = 0.76239582
Iteration 294, loss = 0.76168414
Iteration 295, loss = 0.75691322
Iteration 296, loss = 0.75638041
Iteration 297, loss = 0.74971330
Iteration 298, loss = 0.74502563
Iteration 299, loss = 0.72015718
Iteration 300, loss = 0.87265925
Iteration 301, loss = 0.88450946
Iteration 302, loss = 0.87317438
Iteration 303, loss = 0.85763326
Iteration 304, loss = 0.86067272
Iteration 305, loss = 0.83043560
Iteration 306, loss = 0.84371674
Iteration 307, loss = 0.80712553
Iteration 308, loss = 0.82655618
Iteration 309, loss = 0.78933028
Iteration 310, loss = 0.81145163
Iteration 311, loss = 0.77651805
Iteration 312, loss = 0.79869014
Iteration 313, loss = 0.76760633
Iteration 314, loss = 0.78926640
Iteration 315, loss = 0.75710885
Iteration 316, loss = 0.73536551
Iteration 317, loss = 1.07010225
Iteration 318, loss = 0.78347245
Iteration 319, loss = 1.04142843
Iteration 320, loss = 0.78333143
Iteration 321, loss = 0.98978197
Iteration 322, loss = 0.83493367
Iteration 323, loss = 0.91530679
Iteration 324, loss = 0.87526054
Iteration 325, loss = 0.83574994
Iteration 326, loss = 0.88297074
Iteration 327, loss = 0.77997798
Iteration 328, loss = 0.86946506
Iteration 329, loss = 0.75788338
Iteration 330, loss = 0.84764312
Iteration 331, loss = 0.75707450
Iteration 332, loss = 0.82007863
Iteration 333, loss = 0.75965125
Iteration 334, loss = 0.62008814
Iteration 335, loss = 0.96894762
Iteration 336, loss = 0.76093773
Iteration 337, loss = 0.94014144
Iteration 338, loss = 0.76126179
Iteration 339, loss = 0.78748133
Iteration 340, loss = 0.79792032
Iteration 341, loss = 0.76797785
Iteration 342, loss = 0.76313745
Iteration 343, loss = 0.77363015
Iteration 344, loss = 0.77198807
Iteration 345, loss = 0.82613400
Iteration 346, loss = 0.78240546
Iteration 347, loss = 0.97145300
Iteration 348, loss = 0.82355502
Iteration 349, loss = 0.99702174
Iteration 350, loss = 0.80522900
Iteration 351, loss = 0.94435341
Iteration 352, loss = 0.84718091
Iteration 353, loss = 0.85592377
Iteration 354, loss = 0.87603136
Iteration 355, loss = 0.78895214
Iteration 356, loss = 0.86838304
Iteration 357, loss = 0.71412768
Iteration 358, loss = 0.79219174
Iteration 359, loss = 1.03796726
Iteration 360, loss = 0.82630832
Iteration 361, loss = 0.99252071
Iteration 362, loss = 0.86540305
Iteration 363, loss = 0.92714749
Iteration 364, loss = 0.89929607
Iteration 365, loss = 0.84692047
Iteration 366, loss = 0.90355474
Iteration 367, loss = 0.79651643
Iteration 368, loss = 0.88865478
Iteration 369, loss = 0.77525033
Iteration 370, loss = 0.86503945
Iteration 371, loss = 0.77744921
Iteration 372, loss = 0.83884698
Iteration 373, loss = 0.78929587
Iteration 374, loss = 0.81382219
Iteration 375, loss = 0.79869079
Iteration 376, loss = 0.79177759
Iteration 377, loss = 0.80274496
Iteration 378, loss = 0.77564528
Iteration 379, loss = 0.79935667
Iteration 380, loss = 0.75027789
Iteration 381, loss = 0.89428720
Iteration 382, loss = 0.77955500
Iteration 383, loss = 0.88908127
Iteration 384, loss = 0.77665349
Iteration 385, loss = 0.86009586
Iteration 386, loss = 0.79560982
Iteration 387, loss = 0.84191524
Iteration 388, loss = 0.78976508
Iteration 389, loss = 0.79729836
Iteration 390, loss = 0.80061613
Iteration 391, loss = 0.78069621
Iteration 392, loss = 0.80338805
Iteration 393, loss = 0.77687039
Iteration 394, loss = 0.78514663
Iteration 395, loss = 0.77987275
Iteration 396, loss = 0.77931092
Iteration 397, loss = 0.78041944
Iteration 398, loss = 0.77457693
Iteration 399, loss = 0.77970767
Iteration 400, loss = 0.77188683
Iteration 401, loss = 0.77876734
Iteration 402, loss = 0.77094226
Iteration 403, loss = 0.77783074
Iteration 404, loss = 0.76793214
Iteration 405, loss = 0.81104695
Iteration 406, loss = 0.83032953
Iteration 407, loss = 0.73881416
Iteration 408, loss = 0.87104775
Iteration 409, loss = 0.79075719
Iteration 410, loss = 0.85981956
Iteration 411, loss = 0.78517753
Iteration 412, loss = 0.83820323
Iteration 413, loss = 0.77673235
Iteration 414, loss = 0.81969010
Iteration 415, loss = 0.77036265
Iteration 416, loss = 0.87829998
Iteration 417, loss = 0.80639226
Iteration 418, loss = 0.81735301
Iteration 419, loss = 0.80361271
Iteration 420, loss = 0.82131262
Iteration 421, loss = 0.79558114
Iteration 422, loss = 0.81631427
Iteration 423, loss = 0.78647637
Iteration 424, loss = 0.80653677
Iteration 425, loss = 0.77696393
Iteration 426, loss = 0.78257669
Iteration 427, loss = 0.77335495
Iteration 428, loss = 0.78232778
Iteration 429, loss = 0.77761241
Iteration 430, loss = 0.76549813
Iteration 431, loss = 0.90436428
Iteration 432, loss = 0.86375186
Iteration 433, loss = 0.87584651
Iteration 434, loss = 0.86075354
Iteration 435, loss = 0.84358124
Iteration 436, loss = 0.84018581
Iteration 437, loss = 0.80615969
Iteration 438, loss = 0.59221589
Iteration 439, loss = 0.79935441
Iteration 440, loss = 0.82347347
Iteration 441, loss = 0.81494522
Iteration 442, loss = 0.83163816
Iteration 443, loss = 0.82532091
Iteration 444, loss = 0.83218594
Iteration 445, loss = 0.80894971
Iteration 446, loss = 0.83792487
Iteration 447, loss = 0.84302096
Iteration 448, loss = 0.82833752
Iteration 449, loss = 0.83953963
Iteration 450, loss = 0.81670203
Iteration 451, loss = 0.82994868
Iteration 452, loss = 0.80431147
Iteration 453, loss = 0.81419001
Iteration 454, loss = 0.79377690
Iteration 455, loss = 0.80783774
Iteration 456, loss = 0.78821278
Iteration 457, loss = 0.78503163
Iteration 458, loss = 0.79565036
Iteration 459, loss = 0.79271885
Iteration 460, loss = 0.79705627
Iteration 461, loss = 0.79323233
Iteration 462, loss = 0.79654214
Iteration 463, loss = 0.79204814
Iteration 464, loss = 0.79386985
Iteration 465, loss = 0.78929720
Iteration 466, loss = 0.79026105
Iteration 467, loss = 0.78698606
Iteration 468, loss = 0.78761162
Iteration 469, loss = 0.78575642
Iteration 470, loss = 0.78605797
Iteration 471, loss = 0.78529898
Iteration 472, loss = 0.78508318
Iteration 473, loss = 0.78483238
Iteration 474, loss = 0.78302874
Iteration 475, loss = 0.80729140
Iteration 476, loss = 0.82167943
Iteration 477, loss = 0.83166800
Iteration 478, loss = 0.94968008
Iteration 479, loss = 0.83545901
Iteration 480, loss = 0.93377811
Iteration 481, loss = 0.82835904
Iteration 482, loss = 0.91345154
Iteration 483, loss = 0.82282372
Iteration 484, loss = 0.89357223
Iteration 485, loss = 0.81595797
Iteration 486, loss = 0.87671244
Iteration 487, loss = 0.81125341
Iteration 488, loss = 0.85581680
Iteration 489, loss = 0.91141113
Iteration 490, loss = 1.17315461
Iteration 491, loss = 0.90187841
Iteration 492, loss = 1.16347330
Iteration 493, loss = 0.93573763
Iteration 494, loss = 1.16266689
Iteration 495, loss = 0.87839870
Iteration 496, loss = 1.24643022
Iteration 497, loss = 0.92130799
Iteration 498, loss = 1.19040216
Iteration 499, loss = 1.02976493
Iteration 500, loss = 1.04996196
Iteration 501, loss = 1.05681127
Iteration 502, loss = 0.91875825
Iteration 503, loss = 1.03113817
Iteration 504, loss = 0.83814184
Iteration 505, loss = 0.99186683
Iteration 506, loss = 0.80945330
Iteration 507, loss = 0.95786124
Iteration 508, loss = 0.80293346
Iteration 509, loss = 0.93098891
Iteration 510, loss = 0.80424606
Iteration 511, loss = 0.90609774
Iteration 512, loss = 0.80799573
Iteration 513, loss = 0.88554648
Iteration 514, loss = 0.81089070
Iteration 515, loss = 0.86777202
Iteration 516, loss = 0.81393480
Iteration 517, loss = 0.87402467
Iteration 518, loss = 0.80305599
Iteration 519, loss = 0.84444313
Iteration 520, loss = 0.80594785
Iteration 521, loss = 0.83672509
Iteration 522, loss = 0.80531334
Iteration 523, loss = 0.82727057
Iteration 524, loss = 0.80262982
Iteration 525, loss = 0.81925187
Iteration 526, loss = 0.80067413
Iteration 527, loss = 0.81395294
Iteration 528, loss = 0.80038151
Iteration 529, loss = 0.81007495
Iteration 530, loss = 0.79913591
Iteration 531, loss = 0.80585236
Iteration 532, loss = 0.79721035
Iteration 533, loss = 0.80219031
Iteration 534, loss = 0.79545475
Iteration 535, loss = 0.79926831
Iteration 536, loss = 0.79389194
Iteration 537, loss = 0.79685185
Iteration 538, loss = 0.79243754
Iteration 539, loss = 0.79443038
Iteration 540, loss = 0.79039771
Iteration 541, loss = 0.79163208
Iteration 542, loss = 0.78840747
Iteration 543, loss = 0.78937744
Iteration 544, loss = 0.78573554
Iteration 545, loss = 0.78618319
Iteration 546, loss = 0.79895124
Iteration 547, loss = 0.78648721
Iteration 548, loss = 0.79665742
Iteration 549, loss = 0.78346296
Iteration 550, loss = 0.79077152
Iteration 551, loss = 0.77905837
Iteration 552, loss = 0.78429359
Iteration 553, loss = 0.77397215
Iteration 554, loss = 0.74854541
Iteration 555, loss = 0.63646185
Iteration 556, loss = 0.96415494
Iteration 557, loss = 0.99971462
Iteration 558, loss = 0.88166466
Iteration 559, loss = 1.01587581
Iteration 560, loss = 0.84671590
Iteration 561, loss = 0.99785940
Iteration 562, loss = 0.81449397
Iteration 563, loss = 0.92866348
Iteration 564, loss = 0.99643906
Iteration 565, loss = 0.87266734
Iteration 566, loss = 0.96793000
Iteration 567, loss = 0.87693799
Iteration 568, loss = 0.93297773
Iteration 569, loss = 0.87199845
Iteration 570, loss = 0.89350257
Iteration 571, loss = 0.85973118
Iteration 572, loss = 0.86180442
Iteration 573, loss = 0.85087422
Iteration 574, loss = 0.86321893
Iteration 575, loss = 0.93100481
Iteration 576, loss = 0.83635202
Iteration 577, loss = 0.92192328
Iteration 578, loss = 0.83151934
Iteration 579, loss = 0.89906122
Iteration 580, loss = 0.86600875
Iteration 581, loss = 1.06650553
Iteration 582, loss = 0.83105712
Iteration 583, loss = 0.95999755
Iteration 584, loss = 0.85201389
Iteration 585, loss = 0.94079815
Iteration 586, loss = 0.85122338
Iteration 587, loss = 0.90726138
Iteration 588, loss = 0.83447124
Iteration 589, loss = 0.81285832
Iteration 590, loss = 0.88387492
Iteration 591, loss = 0.79416524
Iteration 592, loss = 0.80689971
Iteration 593, loss = 0.82479723
Iteration 594, loss = 0.81258879
Iteration 595, loss = 0.81669471
Iteration 596, loss = 0.75185557
Iteration 597, loss = 0.83077597
Iteration 598, loss = 0.84557465
Iteration 599, loss = 0.83025615
Iteration 600, loss = 0.83750099
Iteration 601, loss = 0.82720846
Iteration 602, loss = 0.82502010
Iteration 603, loss = 0.87604625
Iteration 604, loss = 0.97836452
Iteration 605, loss = 0.85576048
Iteration 606, loss = 0.87211989
Iteration 607, loss = 0.80530121
Iteration 608, loss = 0.55216692
Iteration 609, loss = 0.90547955
Iteration 610, loss = 0.88924141
Iteration 611, loss = 1.15717596
Iteration 612, loss = 0.84877278
Iteration 613, loss = 1.47554734
Iteration 614, loss = 0.87587516
Iteration 615, loss = 1.41426695
Iteration 616, loss = 1.08299401
Iteration 617, loss = 1.15448265
Iteration 618, loss = 1.24213207
Iteration 619, loss = 0.88014933
Iteration 620, loss = 1.18923785
Iteration 621, loss = 0.87043642
Iteration 622, loss = 1.08751889
Iteration 623, loss = 0.94898337
Iteration 624, loss = 1.46016974
Iteration 625, loss = 0.91852015
Iteration 626, loss = 1.37238627
Iteration 627, loss = 1.15244292
Iteration 628, loss = 1.11055795
Iteration 629, loss = 1.24451465
Iteration 630, loss = 0.88656073
Iteration 631, loss = 1.18820587
Iteration 632, loss = 0.86103486
Iteration 633, loss = 1.10446227
Iteration 634, loss = 0.84969073
Iteration 635, loss = 0.90718432
Iteration 636, loss = 0.86097619
Iteration 637, loss = 0.83846718
Iteration 638, loss = 0.85063536
Iteration 639, loss = 0.84909614
Iteration 640, loss = 0.84983066
Iteration 641, loss = 0.84667062
Iteration 642, loss = 0.84627230
Iteration 643, loss = 0.84339166
Iteration 644, loss = 0.84275844
Iteration 645, loss = 0.84046422
Iteration 646, loss = 0.83895798
Iteration 647, loss = 0.83730939
Iteration 648, loss = 0.83574281
Iteration 649, loss = 0.83499016
Iteration 650, loss = 0.83368484
Iteration 651, loss = 0.83346975
Iteration 652, loss = 0.83222666
Iteration 653, loss = 0.83178374
Iteration 654, loss = 0.83027299
Iteration 655, loss = 0.82934666
Iteration 656, loss = 0.82777068
Iteration 657, loss = 0.82664130
Iteration 658, loss = 0.82532897
Iteration 659, loss = 0.82421408
Iteration 660, loss = 0.82311394
Iteration 661, loss = 0.82178722
Iteration 662, loss = 0.82051171
Iteration 663, loss = 0.81898269
Iteration 664, loss = 0.81746224
Iteration 665, loss = 0.81527485
Iteration 666, loss = 0.81261409
Iteration 667, loss = 0.80694630
Iteration 668, loss = 0.83046923
Iteration 669, loss = 0.82058434
Iteration 670, loss = 0.83365847
Iteration 671, loss = 0.81136026
Iteration 672, loss = 0.80595618
Iteration 673, loss = 0.82999799
Iteration 674, loss = 0.81909566
Iteration 675, loss = 0.82509391
Iteration 676, loss = 0.83314990
Iteration 677, loss = 0.84230480
Iteration 678, loss = 0.83623066
Iteration 679, loss = 0.82590750
Iteration 680, loss = 0.83515743
Iteration 681, loss = 0.81487033
Iteration 682, loss = 0.83107081
Iteration 683, loss = 0.81060194
Iteration 684, loss = 0.82669423
Iteration 685, loss = 0.81104466
Iteration 686, loss = 0.81990995
Iteration 687, loss = 0.81127215
Iteration 688, loss = 0.81394912
Iteration 689, loss = 0.81259996
Iteration 690, loss = 0.80940352
Iteration 691, loss = 0.81228593
Iteration 692, loss = 0.80600862
Iteration 693, loss = 0.81042429
Iteration 694, loss = 0.80367513
Iteration 695, loss = 0.82928453
Iteration 696, loss = 0.82248618
Iteration 697, loss = 0.81530662
Iteration 698, loss = 0.81569343
Iteration 699, loss = 0.81872887
Iteration 700, loss = 0.80649461
Iteration 701, loss = 0.81518263
Iteration 702, loss = 0.79951580
Iteration 703, loss = 0.81053668
Iteration 704, loss = 0.79718723
Iteration 705, loss = 0.80671073
Iteration 706, loss = 0.79688724
Iteration 707, loss = 0.80171032
Iteration 708, loss = 0.79660984
Iteration 709, loss = 0.79685243
Iteration 710, loss = 0.79493952
Iteration 711, loss = 0.79128083
Iteration 712, loss = 0.78946683
Iteration 713, loss = 0.64723811
Iteration 714, loss = 0.79876370
Iteration 715, loss = 0.86127879
Iteration 716, loss = 0.80391035
Iteration 717, loss = 0.82451145
Iteration 718, loss = 0.82545488
Iteration 719, loss = 0.81097863
Iteration 720, loss = 0.82249680
Iteration 721, loss = 0.80001570
Iteration 722, loss = 0.81614368
Iteration 723, loss = 0.79324557
Iteration 724, loss = 0.81108090
Iteration 725, loss = 0.79034030
Iteration 726, loss = 0.80560178
Iteration 727, loss = 0.78770110
Iteration 728, loss = 0.79845297
Iteration 729, loss = 0.78517241
Iteration 730, loss = 0.78607081
Iteration 731, loss = 0.75854503
Iteration 732, loss = 0.90556503
Iteration 733, loss = 0.98209231
Iteration 734, loss = 0.91670504
Iteration 735, loss = 0.95226715
Iteration 736, loss = 0.91244374
Iteration 737, loss = 0.90342269
Iteration 738, loss = 0.89243262
Iteration 739, loss = 0.86421728
Iteration 740, loss = 0.87554672
Iteration 741, loss = 0.83789723
Iteration 742, loss = 0.85611136
Iteration 743, loss = 0.87151131
Iteration 744, loss = 0.79158965
Iteration 745, loss = 0.86114028
Iteration 746, loss = 0.81307230
Iteration 747, loss = 0.82002038
Iteration 748, loss = 0.83035363
Iteration 749, loss = 0.79534799
Iteration 750, loss = 0.83024506
Iteration 751, loss = 0.78664228
Iteration 752, loss = 0.81600938
Iteration 753, loss = 0.78308566
Iteration 754, loss = 0.79392854
Iteration 755, loss = 0.78326331
Iteration 756, loss = 0.77593996
Iteration 757, loss = 0.76531196
Iteration 758, loss = 0.64851100
Iteration 759, loss = 0.91924117
Iteration 760, loss = 1.00323224
Iteration 761, loss = 0.91158135
Iteration 762, loss = 0.99538991
Iteration 763, loss = 0.89458489
Iteration 764, loss = 0.94707997
Iteration 765, loss = 0.82198583
Iteration 766, loss = 1.63381064
Iteration 767, loss = 0.92606770
Iteration 768, loss = 1.45592967
Iteration 769, loss = 1.44955751
Iteration 770, loss = 0.88862601
Iteration 771, loss = 1.38983000
Iteration 772, loss = 0.99219020
Iteration 773, loss = 1.13641932
Iteration 774, loss = 1.18837527
Iteration 775, loss = 0.92785003
Iteration 776, loss = 1.05923648
Iteration 777, loss = 0.81687008
Iteration 778, loss = 1.01427957
Iteration 779, loss = 0.82104912
Iteration 780, loss = 0.94811799
Iteration 781, loss = 0.86426585
Iteration 782, loss = 0.87458433
Iteration 783, loss = 0.89484423
Iteration 784, loss = 0.82045322
Iteration 785, loss = 0.89753793
Iteration 786, loss = 0.79692581
Iteration 787, loss = 0.87870103
Iteration 788, loss = 0.79256193
Iteration 789, loss = 0.89980054
Iteration 790, loss = 0.79641207
Iteration 791, loss = 0.84650124
Iteration 792, loss = 0.79974248
Iteration 793, loss = 0.83736984
Iteration 794, loss = 0.80495595
Iteration 795, loss = 0.82411330
Iteration 796, loss = 0.80907811
Iteration 797, loss = 0.81101580
Iteration 798, loss = 0.81084845
Iteration 799, loss = 0.80090149
Iteration 800, loss = 0.81009035
Iteration 801, loss = 0.79422533
Iteration 802, loss = 0.80662146
Iteration 803, loss = 0.78986190
Iteration 804, loss = 0.80099876
Iteration 805, loss = 0.78671814
Iteration 806, loss = 0.79400765
Iteration 807, loss = 0.78406967
Iteration 808, loss = 0.78624636
Iteration 809, loss = 0.77973731
Iteration 810, loss = 0.77575881
Iteration 811, loss = 0.75051526
Iteration 812, loss = 0.81324828
Iteration 813, loss = 0.85741306
Iteration 814, loss = 0.81923021
Iteration 815, loss = 0.84869441
Iteration 816, loss = 0.80403214
Iteration 817, loss = 0.82953914
Iteration 818, loss = 0.80421722
Iteration 819, loss = 0.81660410
Iteration 820, loss = 0.78053131
Iteration 821, loss = 0.79103859
Iteration 822, loss = 0.80315367
Iteration 823, loss = 0.79583570
Iteration 824, loss = 0.80376887
Iteration 825, loss = 0.79668070
Iteration 826, loss = 0.80107732
Iteration 827, loss = 0.79432585
Iteration 828, loss = 0.79673981
Iteration 829, loss = 0.79109731
Iteration 830, loss = 0.79278598
Iteration 831, loss = 0.78864894
Iteration 832, loss = 0.79167149
Iteration 833, loss = 0.78528564
Iteration 834, loss = 0.79606052
Iteration 835, loss = 0.78925637
Iteration 836, loss = 0.79485202
Iteration 837, loss = 0.78833868
Iteration 838, loss = 0.79296631
Iteration 839, loss = 0.78790364
Iteration 840, loss = 0.79144142
Iteration 841, loss = 0.78737810
Iteration 842, loss = 0.78995493
Iteration 843, loss = 0.78700863
Iteration 844, loss = 0.78873213
Iteration 845, loss = 0.78661115
Iteration 846, loss = 0.78753575
Iteration 847, loss = 0.78612133
Iteration 848, loss = 0.78639778
Iteration 849, loss = 0.78551002
Iteration 850, loss = 0.78530554
Iteration 851, loss = 0.78486608
Iteration 852, loss = 0.78433141
Iteration 853, loss = 0.78413822
Iteration 854, loss = 0.78331961
Iteration 855, loss = 0.78325316
Iteration 856, loss = 0.78229871
Iteration 857, loss = 0.78229192
Iteration 858, loss = 0.78127892
Iteration 859, loss = 0.78127556
Iteration 860, loss = 0.78031951
Iteration 861, loss = 0.78031759
Iteration 862, loss = 0.77945336
Iteration 863, loss = 0.77937673
Iteration 864, loss = 0.77859535
Iteration 865, loss = 0.77844089
Iteration 866, loss = 0.77777034
Iteration 867, loss = 0.77753222
Iteration 868, loss = 0.77694488
Iteration 869, loss = 0.77661673
Iteration 870, loss = 0.77610254
Iteration 871, loss = 0.77570511
Iteration 872, loss = 0.77525152
Iteration 873, loss = 0.77480707
Iteration 874, loss = 0.77439979
Iteration 875, loss = 0.77392037
Iteration 876, loss = 0.77353020
Iteration 877, loss = 0.77302709
Iteration 878, loss = 0.77264664
Iteration 879, loss = 0.77214373
Iteration 880, loss = 0.77176463
Iteration 881, loss = 0.77126651
Iteration 882, loss = 0.77087398
Iteration 883, loss = 0.77038118
Iteration 884, loss = 0.76996778
Iteration 885, loss = 0.76948085
Iteration 886, loss = 0.76904323
Iteration 887, loss = 0.76855723
Iteration 888, loss = 0.76808757
Iteration 889, loss = 0.76758352
Iteration 890, loss = 0.76705181
Iteration 891, loss = 0.76646281
Iteration 892, loss = 0.76576833
Iteration 893, loss = 0.76501576
Iteration 894, loss = 0.76430549
Iteration 895, loss = 0.76365182
Iteration 896, loss = 0.76279472
Iteration 897, loss = 0.76147744
Iteration 898, loss = 0.75913224
Iteration 899, loss = 0.75576814
Iteration 900, loss = 0.74899572
Iteration 901, loss = 0.72655403
Iteration 902, loss = 0.88449188
Iteration 903, loss = 1.02691349
Iteration 904, loss = 0.80948731
Iteration 905, loss = 1.06571720
Iteration 906, loss = 0.79219135
Iteration 907, loss = 1.05807306
Iteration 908, loss = 0.78497007
Iteration 909, loss = 1.02747967
Iteration 910, loss = 0.77222811
Iteration 911, loss = 0.98977364
Iteration 912, loss = 0.76001261
Iteration 913, loss = 0.94795457
Iteration 914, loss = 0.71641548
Iteration 915, loss = 1.55166039
Iteration 916, loss = 0.80495567
Iteration 917, loss = 1.46140648
Iteration 918, loss = 1.24958012
Iteration 919, loss = 0.98021276
Iteration 920, loss = 1.30041121
Iteration 921, loss = 0.76365277
Iteration 922, loss = 1.20669898
Iteration 923, loss = 0.86712065
Iteration 924, loss = 0.91442505
Iteration 925, loss = 0.84376625
Iteration 926, loss = 0.79398223
Iteration 927, loss = 0.82281343
Iteration 928, loss = 0.90072182
Iteration 929, loss = 0.80076515
Iteration 930, loss = 0.87848939
Iteration 931, loss = 0.80630882
Iteration 932, loss = 0.84413845
Iteration 933, loss = 0.80134520
Iteration 934, loss = 0.81175524
Iteration 935, loss = 0.79519603
Iteration 936, loss = 0.78856098
Iteration 937, loss = 0.79418105
Iteration 938, loss = 0.77828668
Iteration 939, loss = 0.79664154
Iteration 940, loss = 0.77567729
Iteration 941, loss = 0.79802395
Iteration 942, loss = 0.77457525
Iteration 943, loss = 0.79488790
Iteration 944, loss = 0.77212773
Iteration 945, loss = 0.78840322
Iteration 946, loss = 0.77458489
Iteration 947, loss = 0.77070733
Iteration 948, loss = 0.77690565
Iteration 949, loss = 0.76818962
Iteration 950, loss = 0.77277247
Iteration 951, loss = 0.76589260
Iteration 952, loss = 0.76820376
Iteration 953, loss = 0.76732692
Iteration 954, loss = 0.76464944
Iteration 955, loss = 0.76702522
Iteration 956, loss = 0.76218684
Iteration 957, loss = 0.76384614
Iteration 958, loss = 0.76038422
Iteration 959, loss = 0.75978724
Iteration 960, loss = 0.75590134
Iteration 961, loss = 0.74562300
Iteration 962, loss = 0.63324995
Iteration 963, loss = 0.93435034
Iteration 964, loss = 1.21037723
Iteration 965, loss = 0.90634554
Iteration 966, loss = 1.26118364
Iteration 967, loss = 0.95093235
Iteration 968, loss = 1.24601060
Iteration 969, loss = 1.00535734
Iteration 970, loss = 1.15754405
Iteration 971, loss = 1.05069911
Iteration 972, loss = 1.02895998
Iteration 973, loss = 1.04446142
Iteration 974, loss = 0.93282540
Iteration 975, loss = 1.00420872
Iteration 976, loss = 0.86627052
Iteration 977, loss = 0.95200761
Iteration 978, loss = 0.83146328
Iteration 979, loss = 0.90621270
Iteration 980, loss = 0.81077389
Iteration 981, loss = 0.87233646
Iteration 982, loss = 0.80193984
Iteration 983, loss = 0.84606496
Iteration 984, loss = 0.79612850
Iteration 985, loss = 0.82416208
Iteration 986, loss = 0.77075010
Iteration 987, loss = 0.88752720
Iteration 988, loss = 0.83205925
Iteration 989, loss = 0.90124477
Iteration 990, loss = 0.82595359
Iteration 991, loss = 0.85121820
Iteration 992, loss = 0.83385382
Iteration 993, loss = 0.84419784
Iteration 994, loss = 0.82385794
Iteration 995, loss = 0.81688979
Iteration 996, loss = 0.82912797
Iteration 997, loss = 0.76108621
Iteration 998, loss = 0.80268963
Iteration 999, loss = 0.82911149
Iteration 1000, loss = 0.80588624
