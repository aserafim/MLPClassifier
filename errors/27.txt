Iteration 1, loss = 0.71534405
Iteration 2, loss = 9.00639158
Iteration 3, loss = 3.27868608
Iteration 4, loss = 1.77768634
Iteration 5, loss = 1.89668681
Iteration 6, loss = 1.60950170
Iteration 7, loss = 1.00608809
Iteration 8, loss = 1.94921391
Iteration 9, loss = 1.96230041
Iteration 10, loss = 0.74449384
Iteration 11, loss = 1.57461531
Iteration 12, loss = 1.15703026
Iteration 13, loss = 1.26106075
Iteration 14, loss = 1.06783923
Iteration 15, loss = 0.91399079
Iteration 16, loss = 0.97954951
Iteration 17, loss = 1.01924413
Iteration 18, loss = 1.17520824
Iteration 19, loss = 1.49708605
Iteration 20, loss = 1.06382225
Iteration 21, loss = 1.05826367
Iteration 22, loss = 0.98917058
Iteration 23, loss = 1.03819125
Iteration 24, loss = 1.34024313
Iteration 25, loss = 0.91135837
Iteration 26, loss = 0.95697076
Iteration 27, loss = 1.11589630
Iteration 28, loss = 1.10395912
Iteration 29, loss = 1.10867776
Iteration 30, loss = 1.07836496
Iteration 31, loss = 0.95613993
Iteration 32, loss = 1.02181942
Iteration 33, loss = 1.68708369
Iteration 34, loss = 1.25956653
Iteration 35, loss = 0.94195023
Iteration 36, loss = 1.52803623
Iteration 37, loss = 1.19960396
Iteration 38, loss = 0.96196990
Iteration 39, loss = 1.06212792
Iteration 40, loss = 1.16566146
Iteration 41, loss = 1.00519593
Iteration 42, loss = 0.95059098
Iteration 43, loss = 0.91972004
Iteration 44, loss = 0.95120373
Iteration 45, loss = 1.05762677
Iteration 46, loss = 0.97209390
Iteration 47, loss = 1.12935879
Iteration 48, loss = 1.01439089
Iteration 49, loss = 1.05820741
Iteration 50, loss = 2.47315800
Iteration 51, loss = 1.25045631
Iteration 52, loss = 0.93978600
Iteration 53, loss = 1.13949948
Iteration 54, loss = 1.19888672
Iteration 55, loss = 1.19744553
Iteration 56, loss = 1.06419939
Iteration 57, loss = 1.03071633
Iteration 58, loss = 1.12430440
Iteration 59, loss = 0.89425966
Iteration 60, loss = 1.13886112
Iteration 61, loss = 1.25268692
Iteration 62, loss = 1.03692142
Iteration 63, loss = 1.09424931
Iteration 64, loss = 1.06838122
Iteration 65, loss = 0.99046756
Iteration 66, loss = 1.37295774
Iteration 67, loss = 1.02384787
Iteration 68, loss = 1.47223706
Iteration 69, loss = 1.26113305
Iteration 70, loss = 1.77806092
Iteration 71, loss = 0.97596371
Iteration 72, loss = 1.57379427
Iteration 73, loss = 1.32848079
Iteration 74, loss = 1.42416916
Iteration 75, loss = 1.47581881
Iteration 76, loss = 1.10955529
Iteration 77, loss = 1.19197010
Iteration 78, loss = 1.29397428
Iteration 79, loss = 0.94529288
Iteration 80, loss = 1.24388093
Iteration 81, loss = 1.05407910
Iteration 82, loss = 1.03435143
Iteration 83, loss = 1.13442312
Iteration 84, loss = 1.64829097
Iteration 85, loss = 0.94185854
Iteration 86, loss = 0.98410330
Iteration 87, loss = 0.95567955
Iteration 88, loss = 0.96112391
Iteration 89, loss = 0.94286268
Iteration 90, loss = 0.85264557
Iteration 91, loss = 0.99703040
Iteration 92, loss = 1.13845782
Iteration 93, loss = 1.48811793
Iteration 94, loss = 1.42781652
Iteration 95, loss = 0.97584724
Iteration 96, loss = 1.35397688
Iteration 97, loss = 1.30160348
Iteration 98, loss = 0.92134091
Iteration 99, loss = 1.60321455
Iteration 100, loss = 0.91647353
Iteration 101, loss = 1.24524893
Iteration 102, loss = 0.99435132
Iteration 103, loss = 1.24187491
Iteration 104, loss = 1.08463381
Iteration 105, loss = 0.98399019
Iteration 106, loss = 1.14313483
Iteration 107, loss = 0.93157027
Iteration 108, loss = 1.01246167
Iteration 109, loss = 1.53879644
Iteration 110, loss = 0.89340875
Iteration 111, loss = 1.35169219
Iteration 112, loss = 1.39872091
Iteration 113, loss = 0.86034744
Iteration 114, loss = 1.67479273
Iteration 115, loss = 1.39976355
Iteration 116, loss = 1.11166400
Iteration 117, loss = 1.30915601
Iteration 118, loss = 0.76317448
Iteration 119, loss = 1.50032944
Iteration 120, loss = 1.20990309
Iteration 121, loss = 0.97758815
Iteration 122, loss = 1.32955036
Iteration 123, loss = 1.24236463
Iteration 124, loss = 0.95440066
Iteration 125, loss = 1.17343498
Iteration 126, loss = 1.18325386
Iteration 127, loss = 0.95340311
Iteration 128, loss = 1.03507267
Iteration 129, loss = 1.11961346
Iteration 130, loss = 0.95210506
Iteration 131, loss = 0.95231147
Iteration 132, loss = 0.93849369
Iteration 133, loss = 0.92173763
Iteration 134, loss = 0.99729218
Iteration 135, loss = 0.89716444
Iteration 136, loss = 0.91874204
Iteration 137, loss = 1.05114141
Iteration 138, loss = 0.90086132
Iteration 139, loss = 1.00928145
Iteration 140, loss = 1.03722358
Iteration 141, loss = 0.88023981
Iteration 142, loss = 1.19034525
Iteration 143, loss = 0.94173196
Iteration 144, loss = 1.35525492
Iteration 145, loss = 1.19725168
Iteration 146, loss = 0.89586137
Iteration 147, loss = 1.18881443
Iteration 148, loss = 0.97585935
Iteration 149, loss = 0.88934507
Iteration 150, loss = 0.99654205
Iteration 151, loss = 0.92865468
Iteration 152, loss = 0.90037008
Iteration 153, loss = 0.89618739
Iteration 154, loss = 0.89418931
Iteration 155, loss = 0.88556876
Iteration 156, loss = 0.89161698
Iteration 157, loss = 0.87922772
Iteration 158, loss = 0.88264177
Iteration 159, loss = 0.87873101
Iteration 160, loss = 0.86561237
Iteration 161, loss = 0.83964518
Iteration 162, loss = 1.61643314
Iteration 163, loss = 1.02818211
Iteration 164, loss = 1.30057787
Iteration 165, loss = 1.01486254
Iteration 166, loss = 1.06278098
Iteration 167, loss = 1.20120826
Iteration 168, loss = 0.94059617
Iteration 169, loss = 1.03444351
Iteration 170, loss = 1.08052720
Iteration 171, loss = 0.88663384
Iteration 172, loss = 1.00629772
Iteration 173, loss = 0.99656666
Iteration 174, loss = 0.87777220
Iteration 175, loss = 0.98602550
Iteration 176, loss = 0.92876762
Iteration 177, loss = 0.79040712
Iteration 178, loss = 1.37547020
Iteration 179, loss = 0.93046289
Iteration 180, loss = 1.20337924
Iteration 181, loss = 1.25837530
Iteration 182, loss = 0.91368025
Iteration 183, loss = 1.15392987
Iteration 184, loss = 1.12899253
Iteration 185, loss = 0.88922401
Iteration 186, loss = 1.05032171
Iteration 187, loss = 0.93478490
Iteration 188, loss = 1.06809573
Iteration 189, loss = 1.05157062
Iteration 190, loss = 1.33549149
Iteration 191, loss = 1.02164163
Iteration 192, loss = 1.01492013
Iteration 193, loss = 1.21283468
Iteration 194, loss = 0.94405582
Iteration 195, loss = 1.03122204
Iteration 196, loss = 1.12456888
Iteration 197, loss = 0.92013523
Iteration 198, loss = 1.01229684
Iteration 199, loss = 1.06357241
Iteration 200, loss = 0.90635478
Iteration 201, loss = 0.98882791
Iteration 202, loss = 1.00808398
Iteration 203, loss = 0.88871551
Iteration 204, loss = 1.03010742
Iteration 205, loss = 0.97878193
Iteration 206, loss = 0.90731663
Iteration 207, loss = 1.00205628
Iteration 208, loss = 0.95770691
Iteration 209, loss = 0.90397636
Iteration 210, loss = 0.97028007
Iteration 211, loss = 0.93214048
Iteration 212, loss = 0.89952335
Iteration 213, loss = 0.95040560
Iteration 214, loss = 0.91823529
Iteration 215, loss = 0.90054499
Iteration 216, loss = 0.93546931
Iteration 217, loss = 0.90554302
Iteration 218, loss = 0.89641911
Iteration 219, loss = 0.91882411
Iteration 220, loss = 0.89223996
Iteration 221, loss = 0.89041492
Iteration 222, loss = 0.90103927
Iteration 223, loss = 0.87759727
Iteration 224, loss = 0.85967648
Iteration 225, loss = 0.95238708
Iteration 226, loss = 0.91681606
Iteration 227, loss = 0.89667393
Iteration 228, loss = 0.88258361
Iteration 229, loss = 1.65604693
Iteration 230, loss = 1.07915932
Iteration 231, loss = 1.20913001
Iteration 232, loss = 1.55248742
Iteration 233, loss = 1.27123921
Iteration 234, loss = 0.94871051
Iteration 235, loss = 1.26180990
Iteration 236, loss = 1.26504542
Iteration 237, loss = 0.93645406
Iteration 238, loss = 1.03842491
Iteration 239, loss = 1.18883661
Iteration 240, loss = 0.98555957
Iteration 241, loss = 0.93247676
Iteration 242, loss = 1.10650576
Iteration 243, loss = 1.01129987
Iteration 244, loss = 0.89395977
Iteration 245, loss = 0.92677733
Iteration 246, loss = 0.96025068
Iteration 247, loss = 0.93056896
Iteration 248, loss = 0.98088913
Iteration 249, loss = 0.97178493
Iteration 250, loss = 0.93175322
Iteration 251, loss = 0.95341619
Iteration 252, loss = 0.94534843
Iteration 253, loss = 0.90857014
Iteration 254, loss = 0.92249797
Iteration 255, loss = 0.92334305
Iteration 256, loss = 0.90035431
Iteration 257, loss = 0.91351968
Iteration 258, loss = 0.91959599
Iteration 259, loss = 0.90342893
Iteration 260, loss = 0.91108921
Iteration 261, loss = 0.91493880
Iteration 262, loss = 0.89637781
Iteration 263, loss = 0.90450994
Iteration 264, loss = 0.91116663
Iteration 265, loss = 0.91234976
Iteration 266, loss = 0.92241587
Iteration 267, loss = 0.92594836
Iteration 268, loss = 0.91700339
Iteration 269, loss = 0.91346677
Iteration 270, loss = 0.90842609
Iteration 271, loss = 0.90013796
Iteration 272, loss = 0.89968857
Iteration 273, loss = 0.89981730
Iteration 274, loss = 0.89730818
Iteration 275, loss = 0.89830502
Iteration 276, loss = 0.89678713
Iteration 277, loss = 0.88252633
Iteration 278, loss = 0.99566101
Iteration 279, loss = 0.90459604
Iteration 280, loss = 0.97070293
Iteration 281, loss = 0.90682995
Iteration 282, loss = 0.93992940
Iteration 283, loss = 0.91460650
Iteration 284, loss = 0.90311212
Iteration 285, loss = 0.91988697
Iteration 286, loss = 0.88548687
Iteration 287, loss = 0.91613855
Iteration 288, loss = 0.88193300
Iteration 289, loss = 0.89743285
Iteration 290, loss = 0.88160631
Iteration 291, loss = 0.92474333
Iteration 292, loss = 0.95268537
Iteration 293, loss = 0.98758998
Iteration 294, loss = 0.88394145
Iteration 295, loss = 0.97644441
Iteration 296, loss = 0.93091059
Iteration 297, loss = 0.92841203
Iteration 298, loss = 0.97793828
Iteration 299, loss = 0.89690176
Iteration 300, loss = 0.96814633
Iteration 301, loss = 0.97127414
Iteration 302, loss = 0.86662156
Iteration 303, loss = 1.30652583
Iteration 304, loss = 0.91245448
Iteration 305, loss = 1.10741647
Iteration 306, loss = 1.08106975
Iteration 307, loss = 0.85946739
Iteration 308, loss = 1.01514749
Iteration 309, loss = 0.94135835
Iteration 310, loss = 1.02515826
Iteration 311, loss = 0.97476767
Iteration 312, loss = 0.86944187
Iteration 313, loss = 0.97121122
Iteration 314, loss = 0.92595940
Iteration 315, loss = 0.88696251
Iteration 316, loss = 0.88809793
Iteration 317, loss = 0.90748334
Iteration 318, loss = 0.87610847
Iteration 319, loss = 0.87686618
Iteration 320, loss = 0.89185323
Iteration 321, loss = 0.87044307
Iteration 322, loss = 0.87388202
Iteration 323, loss = 0.88571809
Iteration 324, loss = 0.86983582
Iteration 325, loss = 0.85071394
Iteration 326, loss = 0.87611515
Iteration 327, loss = 0.88655702
Iteration 328, loss = 0.90267149
Iteration 329, loss = 0.90207642
Iteration 330, loss = 0.89792441
Iteration 331, loss = 0.89763388
Iteration 332, loss = 0.88779558
Iteration 333, loss = 0.87886777
Iteration 334, loss = 0.87830285
Iteration 335, loss = 0.87449761
Iteration 336, loss = 0.87161093
Iteration 337, loss = 0.87377314
Iteration 338, loss = 0.86418844
Iteration 339, loss = 0.87406618
Iteration 340, loss = 0.87443606
Iteration 341, loss = 0.87707908
Iteration 342, loss = 0.87595237
Iteration 343, loss = 0.87483849
Iteration 344, loss = 0.87385981
Iteration 345, loss = 0.87019341
Iteration 346, loss = 0.86878587
Iteration 347, loss = 0.86027894
Iteration 348, loss = 1.25195561
Iteration 349, loss = 1.16711230
Iteration 350, loss = 1.00974817
Iteration 351, loss = 1.36847383
Iteration 352, loss = 1.16754770
Iteration 353, loss = 1.02489987
Iteration 354, loss = 1.31499704
Iteration 355, loss = 1.12436958
Iteration 356, loss = 1.04719394
Iteration 357, loss = 1.22547780
Iteration 358, loss = 1.03070865
Iteration 359, loss = 1.01737759
Iteration 360, loss = 1.10562072
Iteration 361, loss = 0.96861814
Iteration 362, loss = 0.98127614
Iteration 363, loss = 1.03036862
Iteration 364, loss = 0.92050041
Iteration 365, loss = 0.88065901
Iteration 366, loss = 1.16469236
Iteration 367, loss = 1.01283966
Iteration 368, loss = 0.97035121
Iteration 369, loss = 1.10861637
Iteration 370, loss = 0.92520432
Iteration 371, loss = 0.94536670
Iteration 372, loss = 1.32072693
Iteration 373, loss = 0.95299182
Iteration 374, loss = 1.06839290
Iteration 375, loss = 1.00197480
Iteration 376, loss = 1.01775917
Iteration 377, loss = 1.03144209
Iteration 378, loss = 0.91307068
Iteration 379, loss = 1.20689161
Iteration 380, loss = 0.99443608
Iteration 381, loss = 1.08898948
Iteration 382, loss = 1.11770491
Iteration 383, loss = 0.96025225
Iteration 384, loss = 1.09208119
Iteration 385, loss = 1.01941592
Iteration 386, loss = 0.98782511
Iteration 387, loss = 1.07502375
Iteration 388, loss = 0.95852984
Iteration 389, loss = 0.98762508
Iteration 390, loss = 1.08861388
Iteration 391, loss = 1.03985209
Iteration 392, loss = 0.99841533
Iteration 393, loss = 1.05994712
Iteration 394, loss = 0.99321064
Iteration 395, loss = 1.00491764
Iteration 396, loss = 1.03141016
Iteration 397, loss = 0.97911006
Iteration 398, loss = 1.01253865
Iteration 399, loss = 1.00644235
Iteration 400, loss = 0.97829090
Iteration 401, loss = 1.00858717
Iteration 402, loss = 0.98492771
Iteration 403, loss = 0.97969483
Iteration 404, loss = 0.99492426
Iteration 405, loss = 0.96987811
Iteration 406, loss = 0.97891764
Iteration 407, loss = 0.97946514
Iteration 408, loss = 0.96376689
Iteration 409, loss = 0.97584562
Iteration 410, loss = 0.96676295
Iteration 411, loss = 0.96160708
Iteration 412, loss = 0.96856329
Iteration 413, loss = 0.95580120
Iteration 414, loss = 0.98943721
Iteration 415, loss = 0.96519259
Iteration 416, loss = 0.98898650
Iteration 417, loss = 0.97223552
Iteration 418, loss = 0.96633956
Iteration 419, loss = 0.97147002
Iteration 420, loss = 0.95493830
Iteration 421, loss = 0.96692808
Iteration 422, loss = 0.96103746
Iteration 423, loss = 0.95746840
Iteration 424, loss = 0.96196261
Iteration 425, loss = 0.94750109
Iteration 426, loss = 0.86633275
Iteration 427, loss = 1.15998647
Iteration 428, loss = 1.04918327
Iteration 429, loss = 1.02552616
Iteration 430, loss = 1.13474145
Iteration 431, loss = 0.99105291
Iteration 432, loss = 1.05565169
Iteration 433, loss = 1.05492640
Iteration 434, loss = 0.95886022
Iteration 435, loss = 1.04583019
Iteration 436, loss = 0.98562371
Iteration 437, loss = 0.97528311
Iteration 438, loss = 1.01596767
Iteration 439, loss = 0.94654329
Iteration 440, loss = 0.99931672
Iteration 441, loss = 0.96990826
Iteration 442, loss = 0.96120219
Iteration 443, loss = 0.98765954
Iteration 444, loss = 0.94414350
Iteration 445, loss = 0.97268664
Iteration 446, loss = 0.95183715
Iteration 447, loss = 0.94397150
Iteration 448, loss = 0.95708684
Iteration 449, loss = 0.93004028
Iteration 450, loss = 0.94714512
Iteration 451, loss = 0.93399117
Iteration 452, loss = 0.93118794
Iteration 453, loss = 0.93835854
Iteration 454, loss = 0.92251825
Iteration 455, loss = 0.93236385
Iteration 456, loss = 0.92217963
Iteration 457, loss = 0.92027105
Iteration 458, loss = 0.92192661
Iteration 459, loss = 0.91122569
Iteration 460, loss = 0.91570638
Iteration 461, loss = 0.90723264
Iteration 462, loss = 0.90451793
Iteration 463, loss = 0.89176994
Iteration 464, loss = 1.00257570
Iteration 465, loss = 0.91323883
Iteration 466, loss = 0.99029871
Iteration 467, loss = 0.94543626
Iteration 468, loss = 0.91731554
Iteration 469, loss = 0.96115402
Iteration 470, loss = 0.88020568
Iteration 471, loss = 0.93668470
Iteration 472, loss = 0.99971228
Iteration 473, loss = 1.03287499
Iteration 474, loss = 0.93333197
Iteration 475, loss = 1.00528223
Iteration 476, loss = 0.97474328
Iteration 477, loss = 0.92565685
Iteration 478, loss = 0.97800529
Iteration 479, loss = 0.90981510
Iteration 480, loss = 0.94115289
Iteration 481, loss = 0.93205967
Iteration 482, loss = 0.96266220
Iteration 483, loss = 0.94470556
Iteration 484, loss = 0.92964637
Iteration 485, loss = 0.93777275
Iteration 486, loss = 0.91808985
Iteration 487, loss = 0.91768109
Iteration 488, loss = 0.92692107
Iteration 489, loss = 0.91485006
Iteration 490, loss = 0.91858881
Iteration 491, loss = 0.91831765
Iteration 492, loss = 0.90559816
Iteration 493, loss = 0.88829339
Iteration 494, loss = 0.93200322
Iteration 495, loss = 0.92683116
Iteration 496, loss = 0.94630937
Iteration 497, loss = 0.96037355
Iteration 498, loss = 0.94534736
Iteration 499, loss = 0.94707102
Iteration 500, loss = 0.93762012
Iteration 501, loss = 0.91932270
Iteration 502, loss = 0.92111918
Iteration 503, loss = 0.91376895
Iteration 504, loss = 0.90918372
Iteration 505, loss = 0.91600392
Iteration 506, loss = 0.91150255
Iteration 507, loss = 0.91168010
Iteration 508, loss = 0.91471419
Iteration 509, loss = 0.90877100
Iteration 510, loss = 0.90890404
Iteration 511, loss = 0.90801142
Iteration 512, loss = 0.90306523
Iteration 513, loss = 0.90405562
Iteration 514, loss = 0.90202616
Iteration 515, loss = 0.89911212
Iteration 516, loss = 0.89979783
Iteration 517, loss = 0.89683451
Iteration 518, loss = 0.89490813
Iteration 519, loss = 0.89441240
Iteration 520, loss = 0.89076885
Iteration 521, loss = 0.89646870
Iteration 522, loss = 0.88884148
Iteration 523, loss = 0.89143888
Iteration 524, loss = 0.88928287
Iteration 525, loss = 0.88473952
Iteration 526, loss = 0.88513852
Iteration 527, loss = 0.87302985
Iteration 528, loss = 0.89477652
Iteration 529, loss = 0.89737675
Iteration 530, loss = 0.89957582
Iteration 531, loss = 0.88941735
Iteration 532, loss = 0.88706111
Iteration 533, loss = 0.82100378
Iteration 534, loss = 1.08134056
Iteration 535, loss = 0.88779126
Iteration 536, loss = 1.05133732
Iteration 537, loss = 0.97763784
Iteration 538, loss = 0.89649270
Iteration 539, loss = 1.02025615
Iteration 540, loss = 0.91034177
Iteration 541, loss = 0.93027152
Iteration 542, loss = 0.97658671
Iteration 543, loss = 0.87957723
Iteration 544, loss = 0.94315984
Iteration 545, loss = 0.92351930
Iteration 546, loss = 0.88131721
Iteration 547, loss = 0.93772271
Iteration 548, loss = 0.88814526
Iteration 549, loss = 0.89601853
Iteration 550, loss = 0.91466489
Iteration 551, loss = 0.87194090
Iteration 552, loss = 0.90131365
Iteration 553, loss = 0.88804885
Iteration 554, loss = 0.87305266
Iteration 555, loss = 0.89523101
Iteration 556, loss = 0.87011717
Iteration 557, loss = 0.87736348
Iteration 558, loss = 0.87961641
Iteration 559, loss = 0.86159857
Iteration 560, loss = 0.87356309
Iteration 561, loss = 0.85780517
Iteration 562, loss = 0.88137905
Iteration 563, loss = 0.86976200
Iteration 564, loss = 0.91022973
Iteration 565, loss = 0.89658005
Iteration 566, loss = 0.90378196
Iteration 567, loss = 0.89564047
Iteration 568, loss = 0.87774460
Iteration 569, loss = 0.88462285
Iteration 570, loss = 0.87218500
Iteration 571, loss = 0.87368502
Iteration 572, loss = 0.87971465
Iteration 573, loss = 0.87508803
Iteration 574, loss = 0.88054147
Iteration 575, loss = 0.87457188
Iteration 576, loss = 0.86891856
Iteration 577, loss = 0.86945395
Iteration 578, loss = 0.86121985
Iteration 579, loss = 0.86202373
Iteration 580, loss = 0.86095908
Iteration 581, loss = 0.85742827
Iteration 582, loss = 0.85862294
Iteration 583, loss = 0.85363067
Iteration 584, loss = 0.85147584
Iteration 585, loss = 0.84955173
Iteration 586, loss = 0.84546849
Iteration 587, loss = 0.84565659
Iteration 588, loss = 0.84236308
Iteration 589, loss = 0.84020645
Iteration 590, loss = 0.83533176
Iteration 591, loss = 0.72182244
Iteration 592, loss = 0.93496612
Iteration 593, loss = 0.92264016
Iteration 594, loss = 0.95923482
Iteration 595, loss = 0.87026279
Iteration 596, loss = 0.95537797
Iteration 597, loss = 0.85053507
Iteration 598, loss = 0.93556269
Iteration 599, loss = 0.85705611
Iteration 600, loss = 0.90559780
Iteration 601, loss = 0.87522917
Iteration 602, loss = 0.87732055
Iteration 603, loss = 0.88995299
Iteration 604, loss = 0.85802210
Iteration 605, loss = 0.91651222
Iteration 606, loss = 0.84649265
Iteration 607, loss = 0.93862533
Iteration 608, loss = 0.85946558
Iteration 609, loss = 0.91289808
Iteration 610, loss = 0.87294740
Iteration 611, loss = 0.87626082
Iteration 612, loss = 0.88414878
Iteration 613, loss = 0.85244858
Iteration 614, loss = 0.88552221
Iteration 615, loss = 0.84441950
Iteration 616, loss = 0.87123903
Iteration 617, loss = 0.91018593
Iteration 618, loss = 0.87471536
Iteration 619, loss = 1.11620948
Iteration 620, loss = 0.87437740
Iteration 621, loss = 1.10282244
Iteration 622, loss = 0.92697569
Iteration 623, loss = 0.96204682
Iteration 624, loss = 0.99707026
Iteration 625, loss = 0.85279534
Iteration 626, loss = 0.99207707
Iteration 627, loss = 0.87393419
Iteration 628, loss = 0.93002447
Iteration 629, loss = 0.92924463
Iteration 630, loss = 0.86344721
Iteration 631, loss = 0.93652615
Iteration 632, loss = 0.85053574
Iteration 633, loss = 0.90124058
Iteration 634, loss = 0.87546175
Iteration 635, loss = 0.85932768
Iteration 636, loss = 0.89153800
Iteration 637, loss = 0.84235402
Iteration 638, loss = 0.88167290
Iteration 639, loss = 0.85006277
Iteration 640, loss = 0.85676708
Iteration 641, loss = 0.86089095
Iteration 642, loss = 0.83835016
Iteration 643, loss = 0.86049310
Iteration 644, loss = 0.83543956
Iteration 645, loss = 0.84881529
Iteration 646, loss = 0.84033037
Iteration 647, loss = 0.83391708
Iteration 648, loss = 0.82853609
Iteration 649, loss = 0.83531698
Iteration 650, loss = 0.84188665
Iteration 651, loss = 0.83590870
Iteration 652, loss = 0.83936516
Iteration 653, loss = 0.83417093
Iteration 654, loss = 0.83175690
Iteration 655, loss = 0.83357218
Iteration 656, loss = 0.83007691
Iteration 657, loss = 0.83382865
Iteration 658, loss = 0.83242837
Iteration 659, loss = 0.83223498
Iteration 660, loss = 0.83296592
Iteration 661, loss = 0.83001139
Iteration 662, loss = 0.83115512
Iteration 663, loss = 0.82929850
Iteration 664, loss = 0.82894600
Iteration 665, loss = 0.82902808
Iteration 666, loss = 0.82706792
Iteration 667, loss = 0.82689808
Iteration 668, loss = 0.82241211
Iteration 669, loss = 0.83137650
Iteration 670, loss = 0.82192887
Iteration 671, loss = 0.81259206
Iteration 672, loss = 0.85489080
Iteration 673, loss = 0.85757906
Iteration 674, loss = 0.84797056
Iteration 675, loss = 0.84631739
Iteration 676, loss = 0.83003476
Iteration 677, loss = 0.84077085
Iteration 678, loss = 0.83271154
Iteration 679, loss = 0.84368175
Iteration 680, loss = 0.83580830
Iteration 681, loss = 0.83860656
Iteration 682, loss = 0.83500366
Iteration 683, loss = 0.83502805
Iteration 684, loss = 0.83664370
Iteration 685, loss = 0.83303144
Iteration 686, loss = 0.83522431
Iteration 687, loss = 0.82974125
Iteration 688, loss = 0.83234302
Iteration 689, loss = 0.82819688
Iteration 690, loss = 0.82988549
Iteration 691, loss = 0.82716136
Iteration 692, loss = 0.82560637
Iteration 693, loss = 0.84003652
Iteration 694, loss = 0.82728059
Iteration 695, loss = 0.80962715
Iteration 696, loss = 0.83951334
Iteration 697, loss = 0.87503136
Iteration 698, loss = 0.85852168
Iteration 699, loss = 0.85265471
Iteration 700, loss = 0.85924102
Iteration 701, loss = 0.83102746
Iteration 702, loss = 0.85159734
Iteration 703, loss = 0.82090219
Iteration 704, loss = 0.81513328
Iteration 705, loss = 0.86327585
Iteration 706, loss = 1.04651351
Iteration 707, loss = 0.88834215
Iteration 708, loss = 0.95615923
Iteration 709, loss = 0.93578698
Iteration 710, loss = 1.01232090
Iteration 711, loss = 1.02079290
Iteration 712, loss = 0.97618217
Iteration 713, loss = 1.02791780
Iteration 714, loss = 0.94667960
Iteration 715, loss = 0.97529934
Iteration 716, loss = 0.94550965
Iteration 717, loss = 0.92426447
Iteration 718, loss = 0.94549396
Iteration 719, loss = 0.87898146
Iteration 720, loss = 1.09262991
Iteration 721, loss = 0.96349305
Iteration 722, loss = 1.06258039
Iteration 723, loss = 0.93658084
Iteration 724, loss = 1.03526966
Iteration 725, loss = 0.93543785
Iteration 726, loss = 1.01879823
Iteration 727, loss = 0.94998592
Iteration 728, loss = 1.01219929
Iteration 729, loss = 0.93922636
Iteration 730, loss = 0.98649978
Iteration 731, loss = 0.93526438
Iteration 732, loss = 0.95395936
Iteration 733, loss = 0.93923309
Iteration 734, loss = 0.95529246
Iteration 735, loss = 0.94303378
Iteration 736, loss = 0.94498874
Iteration 737, loss = 0.94250657
Iteration 738, loss = 0.94713289
Iteration 739, loss = 0.93886574
Iteration 740, loss = 0.94547040
Iteration 741, loss = 0.93992238
Iteration 742, loss = 0.94472838
Iteration 743, loss = 0.93521734
Iteration 744, loss = 0.86336394
Iteration 745, loss = 1.01302103
Iteration 746, loss = 1.12723590
Iteration 747, loss = 0.98913665
Iteration 748, loss = 1.11499949
Iteration 749, loss = 0.97211300
Iteration 750, loss = 1.07373096
Iteration 751, loss = 0.97315809
Iteration 752, loss = 1.03697768
Iteration 753, loss = 0.98318259
Iteration 754, loss = 1.01446747
Iteration 755, loss = 0.99820044
Iteration 756, loss = 0.99873015
Iteration 757, loss = 1.00206317
Iteration 758, loss = 0.98120946
Iteration 759, loss = 0.99707033
Iteration 760, loss = 0.96816578
Iteration 761, loss = 0.99137873
Iteration 762, loss = 0.96228661
Iteration 763, loss = 0.99926479
Iteration 764, loss = 0.97445745
Iteration 765, loss = 0.98321763
Iteration 766, loss = 0.97349463
Iteration 767, loss = 0.96539913
Iteration 768, loss = 0.96214316
Iteration 769, loss = 0.95311449
Iteration 770, loss = 0.95859941
Iteration 771, loss = 0.94596418
Iteration 772, loss = 0.95097749
Iteration 773, loss = 0.93073439
Iteration 774, loss = 0.89884469
Iteration 775, loss = 0.99045163
Iteration 776, loss = 1.55836309
Iteration 777, loss = 1.05781108
Iteration 778, loss = 1.43975819
Iteration 779, loss = 1.32040545
Iteration 780, loss = 1.09455107
Iteration 781, loss = 1.32913857
Iteration 782, loss = 0.92996598
Iteration 783, loss = 1.22879481
Iteration 784, loss = 1.07146659
Iteration 785, loss = 1.44126303
Iteration 786, loss = 1.39895139
Iteration 787, loss = 0.98863984
Iteration 788, loss = 1.07728371
Iteration 789, loss = 1.20889835
Iteration 790, loss = 1.12105304
Iteration 791, loss = 1.33468475
Iteration 792, loss = 0.98768583
Iteration 793, loss = 1.25115711
Iteration 794, loss = 1.09590693
Iteration 795, loss = 1.06141714
Iteration 796, loss = 1.16130611
Iteration 797, loss = 0.96019570
Iteration 798, loss = 1.13984605
Iteration 799, loss = 1.00448865
Iteration 800, loss = 1.05614099
Iteration 801, loss = 1.05999982
Iteration 802, loss = 0.96826281
Iteration 803, loss = 1.11685486
Iteration 804, loss = 1.00348967
Iteration 805, loss = 1.11088055
Iteration 806, loss = 0.99393509
Iteration 807, loss = 1.07853538
Iteration 808, loss = 1.01208816
Iteration 809, loss = 1.01495680
Iteration 810, loss = 1.02926605
Iteration 811, loss = 0.97252036
Iteration 812, loss = 1.02778762
Iteration 813, loss = 0.97007651
Iteration 814, loss = 1.00817098
Iteration 815, loss = 0.98698180
Iteration 816, loss = 0.98440361
Iteration 817, loss = 0.99589969
Iteration 818, loss = 0.96443442
Iteration 819, loss = 0.96590985
Iteration 820, loss = 0.96229884
Iteration 821, loss = 0.96540986
Iteration 822, loss = 1.00192918
Iteration 823, loss = 1.01371934
Iteration 824, loss = 1.02050487
Iteration 825, loss = 0.97097832
Iteration 826, loss = 0.98278800
Iteration 827, loss = 1.01229615
Iteration 828, loss = 0.95797574
Iteration 829, loss = 0.98910581
Iteration 830, loss = 0.97655759
Iteration 831, loss = 0.95978836
Iteration 832, loss = 0.98445143
Iteration 833, loss = 0.94808548
Iteration 834, loss = 0.97054393
Iteration 835, loss = 0.95123674
Iteration 836, loss = 0.96401349
Iteration 837, loss = 0.95940442
Iteration 838, loss = 0.94765744
Iteration 839, loss = 0.96178011
Iteration 840, loss = 0.93989243
Iteration 841, loss = 0.94770651
Iteration 842, loss = 0.94307874
Iteration 843, loss = 0.93513088
Iteration 844, loss = 0.94388637
Iteration 845, loss = 0.93126001
Iteration 846, loss = 0.93564370
Iteration 847, loss = 0.93158130
Iteration 848, loss = 0.92581919
Iteration 849, loss = 0.92404568
Iteration 850, loss = 0.93154149
Iteration 851, loss = 0.94618672
Iteration 852, loss = 0.95904213
Iteration 853, loss = 0.95688566
Iteration 854, loss = 0.94753792
Iteration 855, loss = 0.93622324
Iteration 856, loss = 0.92663375
Iteration 857, loss = 0.92294815
Iteration 858, loss = 0.92067950
Iteration 859, loss = 0.92215795
Iteration 860, loss = 0.92182944
Iteration 861, loss = 0.92125527
Iteration 862, loss = 0.91918523
Iteration 863, loss = 0.91604464
Iteration 864, loss = 0.91360635
Iteration 865, loss = 0.91063014
Iteration 866, loss = 0.90945795
Iteration 867, loss = 0.90731579
Iteration 868, loss = 0.90628810
Iteration 869, loss = 0.90598732
Iteration 870, loss = 0.90436012
Iteration 871, loss = 0.90080785
Iteration 872, loss = 0.90030304
Iteration 873, loss = 0.89595297
Iteration 874, loss = 0.89714691
Iteration 875, loss = 0.89347135
Iteration 876, loss = 0.89465494
Iteration 877, loss = 0.89082225
Iteration 878, loss = 0.89069351
Iteration 879, loss = 0.88704166
Iteration 880, loss = 0.88618988
Iteration 881, loss = 0.88367398
Iteration 882, loss = 0.88261750
Iteration 883, loss = 0.88102089
Iteration 884, loss = 0.87945067
Iteration 885, loss = 0.87815200
Iteration 886, loss = 0.87612910
Iteration 887, loss = 0.87504291
Iteration 888, loss = 0.87293615
Iteration 889, loss = 0.87198774
Iteration 890, loss = 0.86991881
Iteration 891, loss = 0.86888715
Iteration 892, loss = 0.86686935
Iteration 893, loss = 0.86571501
Iteration 894, loss = 0.86392016
Iteration 895, loss = 0.86275229
Iteration 896, loss = 0.86123951
Iteration 897, loss = 0.86009602
Iteration 898, loss = 0.85883825
Iteration 899, loss = 0.85762131
Iteration 900, loss = 0.85631327
Iteration 901, loss = 0.85435281
Iteration 902, loss = 0.85623674
Iteration 903, loss = 0.85350784
Iteration 904, loss = 0.85486332
Iteration 905, loss = 0.85236235
Iteration 906, loss = 0.85237524
Iteration 907, loss = 0.84972824
Iteration 908, loss = 0.84882897
Iteration 909, loss = 0.84681772
Iteration 910, loss = 0.84584673
Iteration 911, loss = 0.84468003
Iteration 912, loss = 0.84364412
Iteration 913, loss = 0.84286445
Iteration 914, loss = 0.84149102
Iteration 915, loss = 0.84068480
Iteration 916, loss = 0.83922702
Iteration 917, loss = 0.83858036
Iteration 918, loss = 0.83706382
Iteration 919, loss = 0.83620640
Iteration 920, loss = 0.83442422
Iteration 921, loss = 0.83335795
Iteration 922, loss = 0.83146223
Iteration 923, loss = 0.82955446
Iteration 924, loss = 0.82750111
Iteration 925, loss = 0.82485400
Iteration 926, loss = 0.82264164
Iteration 927, loss = 0.80946719
Iteration 928, loss = 0.89628073
Iteration 929, loss = 0.87130933
Iteration 930, loss = 0.91949006
Iteration 931, loss = 0.84391805
Iteration 932, loss = 0.90008987
Iteration 933, loss = 0.83249321
Iteration 934, loss = 0.86697047
Iteration 935, loss = 0.86976346
Iteration 936, loss = 1.05500175
Iteration 937, loss = 0.84636444
Iteration 938, loss = 1.02689248
Iteration 939, loss = 0.86199282
Iteration 940, loss = 0.98333342
Iteration 941, loss = 0.87311165
Iteration 942, loss = 0.94018997
Iteration 943, loss = 0.88428835
Iteration 944, loss = 0.90413128
Iteration 945, loss = 0.89033544
Iteration 946, loss = 0.87414705
Iteration 947, loss = 0.88931996
Iteration 948, loss = 0.85203220
Iteration 949, loss = 0.88390300
Iteration 950, loss = 0.83716916
Iteration 951, loss = 0.87530402
Iteration 952, loss = 0.82752597
Iteration 953, loss = 0.86567191
Iteration 954, loss = 0.82234395
Iteration 955, loss = 0.85649960
Iteration 956, loss = 0.81986940
Iteration 957, loss = 0.84774482
Iteration 958, loss = 0.81845125
Iteration 959, loss = 0.83960731
Iteration 960, loss = 0.81758325
Iteration 961, loss = 0.83246413
Iteration 962, loss = 0.81675623
Iteration 963, loss = 0.82612020
Iteration 964, loss = 0.81558531
Iteration 965, loss = 0.82055892
Iteration 966, loss = 0.81413110
Iteration 967, loss = 0.81587257
Iteration 968, loss = 0.81251071
Iteration 969, loss = 0.81197420
Iteration 970, loss = 0.81074467
Iteration 971, loss = 0.80871888
Iteration 972, loss = 0.80884689
Iteration 973, loss = 0.80588733
Iteration 974, loss = 0.80679377
Iteration 975, loss = 0.80347245
Iteration 976, loss = 0.80480005
Iteration 977, loss = 0.80134920
Iteration 978, loss = 0.80277390
Iteration 979, loss = 0.79948208
Iteration 980, loss = 0.80087207
Iteration 981, loss = 0.79778419
Iteration 982, loss = 0.79897222
Iteration 983, loss = 0.79622940
Iteration 984, loss = 0.79722011
Iteration 985, loss = 0.79477693
Iteration 986, loss = 0.79550246
Iteration 987, loss = 0.79335983
Iteration 988, loss = 0.79368333
Iteration 989, loss = 0.79186396
Iteration 990, loss = 0.79217221
Iteration 991, loss = 0.79053243
Iteration 992, loss = 0.79062264
Iteration 993, loss = 0.78934007
Iteration 994, loss = 0.78923840
Iteration 995, loss = 0.78811910
Iteration 996, loss = 0.78778448
Iteration 997, loss = 0.78685538
Iteration 998, loss = 0.78655361
Iteration 999, loss = 0.78528137
Iteration 1000, loss = 0.78473578
Iteration 1001, loss = 0.78350723
Iteration 1002, loss = 0.78279825
Iteration 1003, loss = 0.78152975
Iteration 1004, loss = 0.77953775
Iteration 1005, loss = 0.77675254
Iteration 1006, loss = 0.76944404
Iteration 1007, loss = 0.72123962
Iteration 1008, loss = 0.79873162
Iteration 1009, loss = 0.80564295
Iteration 1010, loss = 0.80442765
Iteration 1011, loss = 0.80268230
Iteration 1012, loss = 0.79238176
Iteration 1013, loss = 0.79507329
Iteration 1014, loss = 0.79155659
Iteration 1015, loss = 0.79325961
Iteration 1016, loss = 0.79371535
Iteration 1017, loss = 0.79217185
Iteration 1018, loss = 0.79509575
Iteration 1019, loss = 0.79295782
Iteration 1020, loss = 0.79424337
Iteration 1021, loss = 0.79270962
Iteration 1022, loss = 0.79161954
Iteration 1023, loss = 0.79221655
Iteration 1024, loss = 0.79077723
Iteration 1025, loss = 0.79217067
Iteration 1026, loss = 0.79133854
Iteration 1027, loss = 0.79091929
Iteration 1028, loss = 0.80239715
Iteration 1029, loss = 0.84053870
Iteration 1030, loss = 0.80366487
Iteration 1031, loss = 0.83200983
Iteration 1032, loss = 0.82300683
Iteration 1033, loss = 0.81229147
Iteration 1034, loss = 0.82523109
Iteration 1035, loss = 0.79793763
Iteration 1036, loss = 0.81982376
Iteration 1037, loss = 0.80008959
Iteration 1038, loss = 0.81350296
Iteration 1039, loss = 0.80857537
Iteration 1040, loss = 0.80603626
Iteration 1041, loss = 0.81250987
Iteration 1042, loss = 0.80079499
Iteration 1043, loss = 0.81096177
Iteration 1044, loss = 0.80027750
Iteration 1045, loss = 0.80621722
Iteration 1046, loss = 0.80202219
Iteration 1047, loss = 0.80084353
Iteration 1048, loss = 0.80286724
Iteration 1049, loss = 0.79709633
Iteration 1050, loss = 0.80130801
Iteration 1051, loss = 0.79540597
Iteration 1052, loss = 0.79775005
Iteration 1053, loss = 0.79484982
Iteration 1054, loss = 0.79390629
Iteration 1055, loss = 0.79423570
Iteration 1056, loss = 0.79102249
Iteration 1057, loss = 0.79246414
Iteration 1058, loss = 0.78898889
Iteration 1059, loss = 0.78945124
Iteration 1060, loss = 0.78740538
Iteration 1061, loss = 0.78630828
Iteration 1062, loss = 0.78595136
Iteration 1063, loss = 0.78387686
Iteration 1064, loss = 0.78412828
Iteration 1065, loss = 0.78203904
Iteration 1066, loss = 0.78178127
Iteration 1067, loss = 0.78042976
Iteration 1068, loss = 0.77936207
Iteration 1069, loss = 0.77878964
Iteration 1070, loss = 0.77727374
Iteration 1071, loss = 0.77695662
Iteration 1072, loss = 0.77556462
Iteration 1073, loss = 0.77499978
Iteration 1074, loss = 0.77405894
Iteration 1075, loss = 0.77311457
Iteration 1076, loss = 0.77253791
Iteration 1077, loss = 0.77141735
Iteration 1078, loss = 0.77089174
Iteration 1079, loss = 0.76988377
Iteration 1080, loss = 0.76919717
Iteration 1081, loss = 0.76842145
Iteration 1082, loss = 0.76749444
Iteration 1083, loss = 0.76672374
Iteration 1084, loss = 0.76536421
Iteration 1085, loss = 0.76325999
Iteration 1086, loss = 0.75193750
Iteration 1087, loss = 0.78274404
Iteration 1088, loss = 0.80368001
Iteration 1089, loss = 0.77248353
Iteration 1090, loss = 0.78618494
Iteration 1091, loss = 0.78377864
Iteration 1092, loss = 0.76448849
Iteration 1093, loss = 0.78202114
Iteration 1094, loss = 0.77292931
Iteration 1095, loss = 0.76696442
Iteration 1096, loss = 0.77787814
Iteration 1097, loss = 0.76513454
Iteration 1098, loss = 0.76705556
Iteration 1099, loss = 0.77183174
Iteration 1100, loss = 0.76188950
Iteration 1101, loss = 0.76683539
Iteration 1102, loss = 0.76565370
Iteration 1103, loss = 0.75958788
Iteration 1104, loss = 0.76469281
Iteration 1105, loss = 0.76122716
Iteration 1106, loss = 0.75906493
Iteration 1107, loss = 0.76185308
Iteration 1108, loss = 0.75625400
Iteration 1109, loss = 0.73338961
Iteration 1110, loss = 0.77527904
Iteration 1111, loss = 0.78258269
Iteration 1112, loss = 0.76624046
Iteration 1113, loss = 0.78047167
Iteration 1114, loss = 0.76799667
Iteration 1115, loss = 0.76589729
Iteration 1116, loss = 0.77406957
Iteration 1117, loss = 0.76294995
Iteration 1118, loss = 0.77105463
Iteration 1119, loss = 0.76987102
Iteration 1120, loss = 0.76542472
Iteration 1121, loss = 0.77224344
Iteration 1122, loss = 0.76596412
Iteration 1123, loss = 0.76770386
Iteration 1124, loss = 0.76956126
Iteration 1125, loss = 0.76501504
Iteration 1126, loss = 0.76895554
Iteration 1127, loss = 0.76675146
Iteration 1128, loss = 0.76548034
Iteration 1129, loss = 0.76738895
Iteration 1130, loss = 0.75604230
Iteration 1131, loss = 0.79539830
Iteration 1132, loss = 0.85683834
Iteration 1133, loss = 0.82207958
Iteration 1134, loss = 0.77938000
Iteration 1135, loss = 0.80628320
Iteration 1136, loss = 0.81769645
Iteration 1137, loss = 0.78188985
Iteration 1138, loss = 0.78629375
Iteration 1139, loss = 0.81392352
Iteration 1140, loss = 0.79597017
Iteration 1141, loss = 0.77874667
Iteration 1142, loss = 0.79733824
Iteration 1143, loss = 0.79917949
Iteration 1144, loss = 0.78146990
Iteration 1145, loss = 0.78800515
Iteration 1146, loss = 0.79718199
Iteration 1147, loss = 0.78445467
Iteration 1148, loss = 0.78149444
Iteration 1149, loss = 0.79175879
Iteration 1150, loss = 0.78771622
Iteration 1151, loss = 0.78057044
Iteration 1152, loss = 0.78587699
Iteration 1153, loss = 0.78610918
Iteration 1154, loss = 0.79685189
Iteration 1155, loss = 0.81816111
Iteration 1156, loss = 0.78858965
Iteration 1157, loss = 0.78187092
Iteration 1158, loss = 0.80493577
Iteration 1159, loss = 0.79610652
Iteration 1160, loss = 0.77668559
Iteration 1161, loss = 0.78796656
Iteration 1162, loss = 0.79507901
Iteration 1163, loss = 0.77941438
Iteration 1164, loss = 0.77793356
Iteration 1165, loss = 0.78837908
Iteration 1166, loss = 0.78182484
Iteration 1167, loss = 0.77326646
Iteration 1168, loss = 0.77945749
Iteration 1169, loss = 0.78092198
Iteration 1170, loss = 0.77262602
Iteration 1171, loss = 0.77259664
Iteration 1172, loss = 0.77681992
Iteration 1173, loss = 0.77249046
Iteration 1174, loss = 0.76855653
Iteration 1175, loss = 0.77144184
Iteration 1176, loss = 0.77111643
Iteration 1177, loss = 0.76664832
Iteration 1178, loss = 0.76659132
Iteration 1179, loss = 0.76809689
Iteration 1180, loss = 0.76546284
Iteration 1181, loss = 0.76321948
Iteration 1182, loss = 0.76323254
Iteration 1183, loss = 0.76012870
Iteration 1184, loss = 0.78170028
Iteration 1185, loss = 0.78763702
Iteration 1186, loss = 0.76733289
Iteration 1187, loss = 0.76695449
Iteration 1188, loss = 0.77613180
Iteration 1189, loss = 0.76656398
Iteration 1190, loss = 0.76120895
Iteration 1191, loss = 0.76904946
Iteration 1192, loss = 0.76654218
Iteration 1193, loss = 0.75834667
Iteration 1194, loss = 0.76167064
Iteration 1195, loss = 0.76419524
Iteration 1196, loss = 0.75735384
Iteration 1197, loss = 0.75596498
Iteration 1198, loss = 0.75994235
Iteration 1199, loss = 0.75788371
Iteration 1200, loss = 0.75330263
Iteration 1201, loss = 0.75507744
Iteration 1202, loss = 0.75486461
Iteration 1203, loss = 0.75174070
Iteration 1204, loss = 0.75286783
Iteration 1205, loss = 0.75253460
Iteration 1206, loss = 0.74968203
Iteration 1207, loss = 0.75020503
Iteration 1208, loss = 0.75030186
Iteration 1209, loss = 0.74802202
Iteration 1210, loss = 0.74721286
Iteration 1211, loss = 0.74659676
Iteration 1212, loss = 0.74124586
Iteration 1213, loss = 0.74628241
Iteration 1214, loss = 0.74614649
Iteration 1215, loss = 0.74508524
Iteration 1216, loss = 0.74388040
Iteration 1217, loss = 0.74121486
Iteration 1218, loss = 0.73904340
Iteration 1219, loss = 0.71998736
Iteration 1220, loss = 0.78465793
Iteration 1221, loss = 0.90972607
Iteration 1222, loss = 0.77766525
Iteration 1223, loss = 0.83944059
Iteration 1224, loss = 0.82865308
Iteration 1225, loss = 0.76304865
Iteration 1226, loss = 0.84085280
Iteration 1227, loss = 0.77312506
Iteration 1228, loss = 0.79799440
Iteration 1229, loss = 0.81595976
Iteration 1230, loss = 0.76911887
Iteration 1231, loss = 0.81455486
Iteration 1232, loss = 0.77966446
Iteration 1233, loss = 0.78128058
Iteration 1234, loss = 0.79936186
Iteration 1235, loss = 0.76773358
Iteration 1236, loss = 0.79324854
Iteration 1237, loss = 0.77897261
Iteration 1238, loss = 0.77321858
Iteration 1239, loss = 0.78787721
Iteration 1240, loss = 0.76757777
Iteration 1241, loss = 0.77957213
Iteration 1242, loss = 0.77510864
Iteration 1243, loss = 0.76707340
Iteration 1244, loss = 0.77705278
Iteration 1245, loss = 0.76484222
Iteration 1246, loss = 0.76882823
Iteration 1247, loss = 0.76885490
Iteration 1248, loss = 0.76153344
Iteration 1249, loss = 0.76763799
Iteration 1250, loss = 0.76111953
Iteration 1251, loss = 0.76084316
Iteration 1252, loss = 0.76206887
Iteration 1253, loss = 0.75605031
Iteration 1254, loss = 0.75728293
Iteration 1255, loss = 0.75646066
Iteration 1256, loss = 0.75275461
Iteration 1257, loss = 0.75331538
Iteration 1258, loss = 0.75106991
Iteration 1259, loss = 0.74691609
Iteration 1260, loss = 0.72842140
Iteration 1261, loss = 0.75823315
Iteration 1262, loss = 0.77369644
Iteration 1263, loss = 0.76630565
Iteration 1264, loss = 0.76472626
Iteration 1265, loss = 0.77303013
Iteration 1266, loss = 0.76627714
Iteration 1267, loss = 0.76111249
Iteration 1268, loss = 0.77519684
Iteration 1269, loss = 0.77588994
Iteration 1270, loss = 0.76878969
Iteration 1271, loss = 0.77645802
Iteration 1272, loss = 0.77822741
Iteration 1273, loss = 0.77166973
Iteration 1274, loss = 0.77637747
Iteration 1275, loss = 0.77924509
Iteration 1276, loss = 0.77347161
Iteration 1277, loss = 0.77419038
Iteration 1278, loss = 0.77734191
Iteration 1279, loss = 0.77335227
Iteration 1280, loss = 0.77137042
Iteration 1281, loss = 0.77264183
Iteration 1282, loss = 0.76930785
Iteration 1283, loss = 0.76482433
Iteration 1284, loss = 0.76174361
Iteration 1285, loss = 0.74125774
Iteration 1286, loss = 0.90964132
Iteration 1287, loss = 0.96334150
Iteration 1288, loss = 0.81616055
Iteration 1289, loss = 0.95194431
Iteration 1290, loss = 0.84978532
Iteration 1291, loss = 0.82159691
Iteration 1292, loss = 0.91126879
Iteration 1293, loss = 0.81123842
Iteration 1294, loss = 0.86644617
Iteration 1295, loss = 0.87844349
Iteration 1296, loss = 0.81740675
Iteration 1297, loss = 0.87883787
Iteration 1298, loss = 0.84030769
Iteration 1299, loss = 0.82714984
Iteration 1300, loss = 0.86632820
Iteration 1301, loss = 0.82215256
Iteration 1302, loss = 0.83960763
Iteration 1303, loss = 0.84894645
Iteration 1304, loss = 0.81903324
Iteration 1305, loss = 0.84408722
Iteration 1306, loss = 0.83292360
Iteration 1307, loss = 0.82044616
Iteration 1308, loss = 0.83829165
Iteration 1309, loss = 0.81999678
Iteration 1310, loss = 0.82092413
Iteration 1311, loss = 0.82857300
Iteration 1312, loss = 0.81301496
Iteration 1313, loss = 0.81995317
Iteration 1314, loss = 0.81880232
Iteration 1315, loss = 0.80900353
Iteration 1316, loss = 0.81587653
Iteration 1317, loss = 0.80969388
Iteration 1318, loss = 0.80524099
Iteration 1319, loss = 0.80943041
Iteration 1320, loss = 0.80231280
Iteration 1321, loss = 0.80169616
Iteration 1322, loss = 0.80275461
Iteration 1323, loss = 0.79654309
Iteration 1324, loss = 0.79708641
Iteration 1325, loss = 0.79892277
Iteration 1326, loss = 0.79443888
Iteration 1327, loss = 0.79741083
Iteration 1328, loss = 0.79632047
Iteration 1329, loss = 0.79158518
Iteration 1330, loss = 0.79163026
Iteration 1331, loss = 0.78738937
Iteration 1332, loss = 0.78386210
Iteration 1333, loss = 0.78387670
Iteration 1334, loss = 0.78069000
Iteration 1335, loss = 0.77952209
Iteration 1336, loss = 0.77937283
Iteration 1337, loss = 0.77652248
Iteration 1338, loss = 0.77559675
Iteration 1339, loss = 0.77437207
Iteration 1340, loss = 0.77176452
Iteration 1341, loss = 0.77102752
Iteration 1342, loss = 0.76957031
Iteration 1343, loss = 0.76763130
Iteration 1344, loss = 0.76695237
Iteration 1345, loss = 0.76531928
Iteration 1346, loss = 0.76371370
Iteration 1347, loss = 0.76287956
Iteration 1348, loss = 0.76127169
Iteration 1349, loss = 0.76003110
Iteration 1350, loss = 0.75918973
Iteration 1351, loss = 0.75776185
Iteration 1352, loss = 0.75673252
Iteration 1353, loss = 0.75578444
Iteration 1354, loss = 0.75442857
Iteration 1355, loss = 0.75344286
Iteration 1356, loss = 0.75233037
Iteration 1357, loss = 0.75110868
Iteration 1358, loss = 0.75415978
Iteration 1359, loss = 0.76247699
Iteration 1360, loss = 0.75234154
Iteration 1361, loss = 0.75555782
Iteration 1362, loss = 0.74915587
Iteration 1363, loss = 0.75345689
Iteration 1364, loss = 0.76276400
Iteration 1365, loss = 0.75478541
Iteration 1366, loss = 1.50306118
Iteration 1367, loss = 0.80160069
Iteration 1368, loss = 1.51523445
Iteration 1369, loss = 0.82896482
Iteration 1370, loss = 1.50586240
Iteration 1371, loss = 0.97950705
Iteration 1372, loss = 1.51834741
Iteration 1373, loss = 1.26753720
Iteration 1374, loss = 1.24635851
Iteration 1375, loss = 1.25381580
Iteration 1376, loss = 0.93648657
Iteration 1377, loss = 1.12777742
Iteration 1378, loss = 0.82442805
Iteration 1379, loss = 1.04757439
Iteration 1380, loss = 0.80385286
Iteration 1381, loss = 0.94801406
Iteration 1382, loss = 0.78363751
Iteration 1383, loss = 0.91754006
Iteration 1384, loss = 0.78465869
Iteration 1385, loss = 0.90037428
Iteration 1386, loss = 0.79375085
Iteration 1387, loss = 0.88599398
Iteration 1388, loss = 0.79970656
Iteration 1389, loss = 0.87074054
Iteration 1390, loss = 0.80330728
Iteration 1391, loss = 0.85844327
Iteration 1392, loss = 0.80697462
Iteration 1393, loss = 0.84917984
Iteration 1394, loss = 0.80951629
Iteration 1395, loss = 0.84063791
Iteration 1396, loss = 0.80983715
Iteration 1397, loss = 0.83250354
Iteration 1398, loss = 0.80885882
Iteration 1399, loss = 0.82578950
Iteration 1400, loss = 0.80776311
Iteration 1401, loss = 0.81961821
Iteration 1402, loss = 0.80582989
Iteration 1403, loss = 0.81450908
Iteration 1404, loss = 0.80351516
Iteration 1405, loss = 0.80977115
Iteration 1406, loss = 0.80095422
Iteration 1407, loss = 0.80520821
Iteration 1408, loss = 0.79810472
Iteration 1409, loss = 0.80112968
Iteration 1410, loss = 0.79509668
Iteration 1411, loss = 0.79688818
Iteration 1412, loss = 0.79139084
Iteration 1413, loss = 0.79180991
Iteration 1414, loss = 0.78607667
Iteration 1415, loss = 0.78444114
Iteration 1416, loss = 0.74591129
Iteration 1417, loss = 0.81561343
Iteration 1418, loss = 0.81481573
Iteration 1419, loss = 0.81676732
Iteration 1420, loss = 0.81075489
Iteration 1421, loss = 0.79933739
Iteration 1422, loss = 0.80000444
Iteration 1423, loss = 0.78250220
Iteration 1424, loss = 0.89799577
Iteration 1425, loss = 1.55895165
Iteration 1426, loss = 1.07220511
Iteration 1427, loss = 1.40063216
Iteration 1428, loss = 1.40331246
Iteration 1429, loss = 0.92867928
Iteration 1430, loss = 1.30070062
Iteration 1431, loss = 0.82146374
Iteration 1432, loss = 1.21395562
Iteration 1433, loss = 0.92680117
Iteration 1434, loss = 1.11069349
Iteration 1435, loss = 1.03904587
Iteration 1436, loss = 0.96391291
Iteration 1437, loss = 1.05664927
Iteration 1438, loss = 0.85787275
Iteration 1439, loss = 1.02073333
Iteration 1440, loss = 0.81478914
Iteration 1441, loss = 0.97923102
Iteration 1442, loss = 0.81339871
Iteration 1443, loss = 0.94547352
Iteration 1444, loss = 0.82850247
Iteration 1445, loss = 0.91324422
Iteration 1446, loss = 0.84187945
Iteration 1447, loss = 0.87996541
Iteration 1448, loss = 0.84624240
Iteration 1449, loss = 0.84981260
Iteration 1450, loss = 0.84597972
Iteration 1451, loss = 0.82821630
Iteration 1452, loss = 0.84301009
Iteration 1453, loss = 0.81303570
Iteration 1454, loss = 0.83706619
Iteration 1455, loss = 0.80220988
Iteration 1456, loss = 0.82932592
Iteration 1457, loss = 0.79467095
Iteration 1458, loss = 0.82124472
Iteration 1459, loss = 0.78979132
Iteration 1460, loss = 0.81359551
Iteration 1461, loss = 0.78633929
Iteration 1462, loss = 0.80619592
Iteration 1463, loss = 0.78370661
Iteration 1464, loss = 0.79973206
Iteration 1465, loss = 0.78160475
Iteration 1466, loss = 0.79342056
Iteration 1467, loss = 0.77930620
Iteration 1468, loss = 0.78803129
Iteration 1469, loss = 0.77733157
Iteration 1470, loss = 0.78315638
Iteration 1471, loss = 0.77524274
Iteration 1472, loss = 0.77871311
Iteration 1473, loss = 0.77302579
Iteration 1474, loss = 0.77483791
Iteration 1475, loss = 0.77072539
Iteration 1476, loss = 0.77113372
Iteration 1477, loss = 0.76825241
Iteration 1478, loss = 0.76768259
Iteration 1479, loss = 0.76544773
Iteration 1480, loss = 0.76337615
Iteration 1481, loss = 0.75836986
Iteration 1482, loss = 0.75640116
Iteration 1483, loss = 0.81343945
Iteration 1484, loss = 0.80188448
Iteration 1485, loss = 0.82438616
Iteration 1486, loss = 0.79329470
Iteration 1487, loss = 0.79759277
Iteration 1488, loss = 0.77512297
Iteration 1489, loss = 0.78539147
Iteration 1490, loss = 0.77783782
Iteration 1491, loss = 0.78861123
Iteration 1492, loss = 0.78355547
Iteration 1493, loss = 0.78778241
Iteration 1494, loss = 0.78178446
Iteration 1495, loss = 0.78192830
Iteration 1496, loss = 0.77781745
Iteration 1497, loss = 0.77751471
Iteration 1498, loss = 0.77602917
Iteration 1499, loss = 0.77526795
Iteration 1500, loss = 0.77406791
Iteration 1501, loss = 0.77162826
Iteration 1502, loss = 0.76860247
Iteration 1503, loss = 0.75783613
Iteration 1504, loss = 0.82849274
Iteration 1505, loss = 0.81196103
Iteration 1506, loss = 0.83827262
Iteration 1507, loss = 0.79233425
Iteration 1508, loss = 0.82884504
Iteration 1509, loss = 0.77742850
Iteration 1510, loss = 0.81621785
Iteration 1511, loss = 0.77291022
Iteration 1512, loss = 0.80759396
Iteration 1513, loss = 0.77632317
Iteration 1514, loss = 0.80003626
Iteration 1515, loss = 0.77892514
Iteration 1516, loss = 0.78989048
Iteration 1517, loss = 0.77831066
Iteration 1518, loss = 0.78015636
Iteration 1519, loss = 0.77758479
Iteration 1520, loss = 0.77384983
Iteration 1521, loss = 0.77732110
Iteration 1522, loss = 0.76981691
Iteration 1523, loss = 0.77591621
Iteration 1524, loss = 0.76650075
Iteration 1525, loss = 0.77332981
Iteration 1526, loss = 0.76395077
Iteration 1527, loss = 0.77035270
Iteration 1528, loss = 0.76214239
Iteration 1529, loss = 0.76734575
Iteration 1530, loss = 0.76081806
Iteration 1531, loss = 0.76450977
Iteration 1532, loss = 0.75977897
Iteration 1533, loss = 0.76191825
Iteration 1534, loss = 0.75875152
Iteration 1535, loss = 0.75947042
Iteration 1536, loss = 0.75755931
Iteration 1537, loss = 0.75719910
Iteration 1538, loss = 0.75627486
Iteration 1539, loss = 0.75521670
Iteration 1540, loss = 0.75497473
Iteration 1541, loss = 0.75350214
Iteration 1542, loss = 0.75364169
Iteration 1543, loss = 0.75197324
Iteration 1544, loss = 0.75226109
Iteration 1545, loss = 0.75055990
Iteration 1546, loss = 0.75083832
Iteration 1547, loss = 0.74921277
Iteration 1548, loss = 0.74900087
Iteration 1549, loss = 0.74077524
Iteration 1550, loss = 0.78046684
Iteration 1551, loss = 0.78011765
Iteration 1552, loss = 0.75349953
Iteration 1553, loss = 0.78668089
Iteration 1554, loss = 0.77272564
Iteration 1555, loss = 0.75796533
Iteration 1556, loss = 0.77141437
Iteration 1557, loss = 0.76350361
Iteration 1558, loss = 0.75168949
Iteration 1559, loss = 0.76144662
Iteration 1560, loss = 0.75305983
Iteration 1561, loss = 0.75804085
Iteration 1562, loss = 0.75731114
Iteration 1563, loss = 0.75010167
Iteration 1564, loss = 0.75685421
Iteration 1565, loss = 0.75101116
Iteration 1566, loss = 0.75115432
Iteration 1567, loss = 0.75246834
Iteration 1568, loss = 0.74786582
Iteration 1569, loss = 0.75115877
Iteration 1570, loss = 0.74805649
Iteration 1571, loss = 0.74680503
Iteration 1572, loss = 0.74888407
Iteration 1573, loss = 0.74371318
Iteration 1574, loss = 0.74422598
Iteration 1575, loss = 0.74829856
Iteration 1576, loss = 0.75178380
Iteration 1577, loss = 0.75047815
Iteration 1578, loss = 0.74682975
Iteration 1579, loss = 0.74349052
Iteration 1580, loss = 0.74285171
Iteration 1581, loss = 0.74499314
Iteration 1582, loss = 0.74431833
Iteration 1583, loss = 0.74345272
Iteration 1584, loss = 0.74192966
Iteration 1585, loss = 0.74118759
Iteration 1586, loss = 0.74054636
Iteration 1587, loss = 0.74003503
Iteration 1588, loss = 0.73955501
Iteration 1589, loss = 0.73831498
Iteration 1590, loss = 0.73725303
Iteration 1591, loss = 0.73682161
Iteration 1592, loss = 0.73601489
Iteration 1593, loss = 0.73504573
Iteration 1594, loss = 0.73392379
Iteration 1595, loss = 0.73281965
Iteration 1596, loss = 0.73236104
Iteration 1597, loss = 0.73140534
Iteration 1598, loss = 0.73031512
Iteration 1599, loss = 0.72943975
Iteration 1600, loss = 0.72856686
Iteration 1601, loss = 0.72776373
Iteration 1602, loss = 0.72647119
Iteration 1603, loss = 0.72542284
Iteration 1604, loss = 0.72418353
Iteration 1605, loss = 0.72292393
Iteration 1606, loss = 0.72053181
Iteration 1607, loss = 0.71908290
Iteration 1608, loss = 0.71644815
Iteration 1609, loss = 0.71437588
Iteration 1610, loss = 0.70924451
Iteration 1611, loss = 0.70064044
Iteration 1612, loss = 1.06883933
Iteration 1613, loss = 1.43938649
Iteration 1614, loss = 0.91116051
Iteration 1615, loss = 1.59824842
Iteration 1616, loss = 1.08188369
Iteration 1617, loss = 1.52938374
Iteration 1618, loss = 1.39574631
Iteration 1619, loss = 1.07161787
Iteration 1620, loss = 1.29646077
Iteration 1621, loss = 0.83548597
Iteration 1622, loss = 1.12201827
Iteration 1623, loss = 0.75950176
Iteration 1624, loss = 1.00523715
Iteration 1625, loss = 0.74485643
Iteration 1626, loss = 0.93170835
Iteration 1627, loss = 0.74414944
Iteration 1628, loss = 0.87513141
Iteration 1629, loss = 0.74472733
Iteration 1630, loss = 0.82844279
Iteration 1631, loss = 0.74918166
Iteration 1632, loss = 0.79256399
Iteration 1633, loss = 0.75529510
Iteration 1634, loss = 0.76515535
Iteration 1635, loss = 0.76068424
Iteration 1636, loss = 0.74617565
Iteration 1637, loss = 0.76402998
Iteration 1638, loss = 0.73399105
Iteration 1639, loss = 0.76326806
Iteration 1640, loss = 0.72578377
Iteration 1641, loss = 0.75827034
Iteration 1642, loss = 0.72201454
Iteration 1643, loss = 0.75103084
Iteration 1644, loss = 0.72068697
Iteration 1645, loss = 0.74340476
Iteration 1646, loss = 0.72120664
Iteration 1647, loss = 0.73124132
Iteration 1648, loss = 0.81351244
Iteration 1649, loss = 0.89446245
Iteration 1650, loss = 0.77357958
Iteration 1651, loss = 0.89693037
Iteration 1652, loss = 0.75858550
Iteration 1653, loss = 0.84813631
Iteration 1654, loss = 0.73433682
Iteration 1655, loss = 0.82221078
Iteration 1656, loss = 0.74362197
Iteration 1657, loss = 0.81887847
Iteration 1658, loss = 0.75462240
Iteration 1659, loss = 0.80406467
Iteration 1660, loss = 0.75253735
Iteration 1661, loss = 0.78492861
Iteration 1662, loss = 0.75315089
Iteration 1663, loss = 0.77437414
Iteration 1664, loss = 0.75865001
Iteration 1665, loss = 0.76670839
Iteration 1666, loss = 0.76072547
Iteration 1667, loss = 0.75824205
Iteration 1668, loss = 0.76205984
Iteration 1669, loss = 0.75117883
Iteration 1670, loss = 0.76180152
Iteration 1671, loss = 0.75108109
Iteration 1672, loss = 0.76118063
Iteration 1673, loss = 0.74882682
Iteration 1674, loss = 0.75681201
Iteration 1675, loss = 0.74641900
Iteration 1676, loss = 0.75351101
Iteration 1677, loss = 0.74665085
Iteration 1678, loss = 0.76890372
Iteration 1679, loss = 0.79879546
Iteration 1680, loss = 0.76440864
Iteration 1681, loss = 0.80630470
Iteration 1682, loss = 0.76115596
Iteration 1683, loss = 0.78812852
Iteration 1684, loss = 0.75241790
Iteration 1685, loss = 0.78028285
Iteration 1686, loss = 0.75878429
Iteration 1687, loss = 0.77837256
Iteration 1688, loss = 0.76205574
Iteration 1689, loss = 0.77110693
Iteration 1690, loss = 0.76189441
Iteration 1691, loss = 0.76505627
Iteration 1692, loss = 0.76289052
Iteration 1693, loss = 0.76109874
Iteration 1694, loss = 0.76268971
Iteration 1695, loss = 0.75694914
Iteration 1696, loss = 0.76083527
Iteration 1697, loss = 0.75389976
Iteration 1698, loss = 0.75911471
Iteration 1699, loss = 0.75195013
Iteration 1700, loss = 0.75610721
Iteration 1701, loss = 0.74910806
Iteration 1702, loss = 0.75195562
Iteration 1703, loss = 0.74676305
Iteration 1704, loss = 0.74861278
Iteration 1705, loss = 0.74516248
Iteration 1706, loss = 0.74530403
Iteration 1707, loss = 0.74298246
Iteration 1708, loss = 0.74172478
Iteration 1709, loss = 0.74054954
Iteration 1710, loss = 0.73853277
Iteration 1711, loss = 0.73815938
Iteration 1712, loss = 0.73578294
Iteration 1713, loss = 0.73579861
Iteration 1714, loss = 0.73337166
Iteration 1715, loss = 0.73334967
Iteration 1716, loss = 0.73106849
Iteration 1717, loss = 0.73082997
Iteration 1718, loss = 0.72895119
Iteration 1719, loss = 0.72848050
Iteration 1720, loss = 0.72705850
Iteration 1721, loss = 0.72631599
Iteration 1722, loss = 0.72527254
Iteration 1723, loss = 0.72430335
Iteration 1724, loss = 0.72353283
Iteration 1725, loss = 0.72242118
Iteration 1726, loss = 0.72181546
Iteration 1727, loss = 0.72068712
Iteration 1728, loss = 0.72015555
Iteration 1729, loss = 0.71902172
Iteration 1730, loss = 0.71825741
Iteration 1731, loss = 0.71655943
Iteration 1732, loss = 0.71217879
Iteration 1733, loss = 0.72524550
Iteration 1734, loss = 0.74319796
Iteration 1735, loss = 0.74329517
Iteration 1736, loss = 0.75094374
Iteration 1737, loss = 0.75516127
Iteration 1738, loss = 0.73829816
Iteration 1739, loss = 0.74701588
Iteration 1740, loss = 0.72742844
Iteration 1741, loss = 0.73512012
Iteration 1742, loss = 0.72640969
Iteration 1743, loss = 0.72988912
Iteration 1744, loss = 0.73225503
Iteration 1745, loss = 0.72688359
Iteration 1746, loss = 0.73256674
Iteration 1747, loss = 0.72519530
Iteration 1748, loss = 0.73109737
Iteration 1749, loss = 0.72712155
Iteration 1750, loss = 0.72765364
Iteration 1751, loss = 0.72712263
Iteration 1752, loss = 0.72381663
Iteration 1753, loss = 0.72661673
Iteration 1754, loss = 0.72308738
Iteration 1755, loss = 0.72556996
Iteration 1756, loss = 0.72355521
Iteration 1757, loss = 0.72399223
Iteration 1758, loss = 0.72436740
Iteration 1759, loss = 0.72287537
Iteration 1760, loss = 0.72408068
Iteration 1761, loss = 0.72200459
Iteration 1762, loss = 0.72279315
Iteration 1763, loss = 0.72165433
Iteration 1764, loss = 0.72139006
Iteration 1765, loss = 0.72143181
Iteration 1766, loss = 0.72047008
Iteration 1767, loss = 0.72106742
Iteration 1768, loss = 0.72005017
Iteration 1769, loss = 0.72026813
Iteration 1770, loss = 0.71974332
Iteration 1771, loss = 0.71942247
Iteration 1772, loss = 0.71943710
Iteration 1773, loss = 0.71872844
Iteration 1774, loss = 0.71869126
Iteration 1775, loss = 0.71787318
Iteration 1776, loss = 0.71792151
Iteration 1777, loss = 0.71753698
Iteration 1778, loss = 0.71693161
Iteration 1779, loss = 0.71708910
Iteration 1780, loss = 0.71636598
Iteration 1781, loss = 0.71585841
Iteration 1782, loss = 0.71548918
Iteration 1783, loss = 0.71571201
Iteration 1784, loss = 0.71479615
Iteration 1785, loss = 0.71327006
Iteration 1786, loss = 0.71203146
Iteration 1787, loss = 0.70402603
Iteration 1788, loss = 0.79873605
Iteration 1789, loss = 0.81761788
Iteration 1790, loss = 0.78168725
Iteration 1791, loss = 0.82185150
Iteration 1792, loss = 0.75293133
Iteration 1793, loss = 0.81004828
Iteration 1794, loss = 0.73329294
Iteration 1795, loss = 0.80626826
Iteration 1796, loss = 0.73088212
Iteration 1797, loss = 0.80329624
Iteration 1798, loss = 0.72552218
Iteration 1799, loss = 0.78974089
Iteration 1800, loss = 0.71890615
Iteration 1801, loss = 0.77798031
Iteration 1802, loss = 0.71772434
Iteration 1803, loss = 0.76641000
Iteration 1804, loss = 0.71847859
Iteration 1805, loss = 0.75501065
Iteration 1806, loss = 0.71849895
Iteration 1807, loss = 0.74361324
Iteration 1808, loss = 0.71990970
Iteration 1809, loss = 0.73518244
Iteration 1810, loss = 0.72189394
Iteration 1811, loss = 0.72773915
Iteration 1812, loss = 0.72254967
Iteration 1813, loss = 0.72127826
Iteration 1814, loss = 0.72277153
Iteration 1815, loss = 0.71759277
Iteration 1816, loss = 0.72301372
Iteration 1817, loss = 0.71498548
Iteration 1818, loss = 0.72181424
Iteration 1819, loss = 0.71299836
Iteration 1820, loss = 0.72011500
Iteration 1821, loss = 0.71215597
Iteration 1822, loss = 0.71837977
Iteration 1823, loss = 0.71190159
Iteration 1824, loss = 0.71649037
Iteration 1825, loss = 0.71184901
Iteration 1826, loss = 0.71460383
Iteration 1827, loss = 0.71189328
Iteration 1828, loss = 0.71294088
Iteration 1829, loss = 0.71182624
Iteration 1830, loss = 0.71155112
Iteration 1831, loss = 0.71172773
Iteration 1832, loss = 0.71057945
Iteration 1833, loss = 0.71142578
Iteration 1834, loss = 0.70975788
Iteration 1835, loss = 0.71089743
Iteration 1836, loss = 0.70918495
Iteration 1837, loss = 0.71032760
Iteration 1838, loss = 0.70884249
Iteration 1839, loss = 0.70971016
Iteration 1840, loss = 0.70855018
Iteration 1841, loss = 0.70903980
Iteration 1842, loss = 0.70831010
Iteration 1843, loss = 0.70845100
Iteration 1844, loss = 0.70808179
Iteration 1845, loss = 0.70791153
Iteration 1846, loss = 0.70782699
Iteration 1847, loss = 0.70744448
Iteration 1848, loss = 0.70750919
Iteration 1849, loss = 0.70700695
Iteration 1850, loss = 0.70709799
Iteration 1851, loss = 0.70493763
Iteration 1852, loss = 0.70726530
Iteration 1853, loss = 0.71368312
Iteration 1854, loss = 0.70676641
Iteration 1855, loss = 0.71531675
Iteration 1856, loss = 0.71569207
Iteration 1857, loss = 0.71128761
Iteration 1858, loss = 0.71107979
Iteration 1859, loss = 0.70753045
Iteration 1860, loss = 0.71134179
Iteration 1861, loss = 0.70765960
Iteration 1862, loss = 0.70980725
Iteration 1863, loss = 0.70688896
Iteration 1864, loss = 0.70916699
Iteration 1865, loss = 0.70635009
Iteration 1866, loss = 0.70610039
Iteration 1867, loss = 0.70410109
Iteration 1868, loss = 0.70394552
Iteration 1869, loss = 0.70278329
Iteration 1870, loss = 0.69948291
Iteration 1871, loss = 0.69472626
Iteration 1872, loss = 0.65381675
Iteration 1873, loss = 0.77219403
Iteration 1874, loss = 0.91458448
Iteration 1875, loss = 0.75018140
Iteration 1876, loss = 0.92133495
Iteration 1877, loss = 0.72844177
Iteration 1878, loss = 0.88646533
Iteration 1879, loss = 0.72933004
Iteration 1880, loss = 0.84533930
Iteration 1881, loss = 0.75435717
Iteration 1882, loss = 0.80415931
Iteration 1883, loss = 0.78443310
Iteration 1884, loss = 0.76977339
Iteration 1885, loss = 0.80412610
Iteration 1886, loss = 0.75082348
Iteration 1887, loss = 0.80651586
Iteration 1888, loss = 0.74745124
Iteration 1889, loss = 0.79409448
Iteration 1890, loss = 0.75604227
Iteration 1891, loss = 0.77677474
Iteration 1892, loss = 0.76903907
Iteration 1893, loss = 0.76227092
Iteration 1894, loss = 0.77717958
Iteration 1895, loss = 0.75420015
Iteration 1896, loss = 0.77621051
Iteration 1897, loss = 0.75309586
Iteration 1898, loss = 0.76888150
Iteration 1899, loss = 0.75694498
Iteration 1900, loss = 0.76032803
Iteration 1901, loss = 0.76132969
Iteration 1902, loss = 0.75407040
Iteration 1903, loss = 0.76239486
Iteration 1904, loss = 0.75122112
Iteration 1905, loss = 0.75944514
Iteration 1906, loss = 0.75127961
Iteration 1907, loss = 0.75464784
Iteration 1908, loss = 0.75250173
Iteration 1909, loss = 0.75027145
Iteration 1910, loss = 0.75272096
Iteration 1911, loss = 0.74747127
Iteration 1912, loss = 0.75107469
Iteration 1913, loss = 0.74636877
Iteration 1914, loss = 0.74826080
Iteration 1915, loss = 0.74618248
Iteration 1916, loss = 0.74533822
Iteration 1917, loss = 0.74567675
Iteration 1918, loss = 0.74300856
Iteration 1919, loss = 0.74428604
Iteration 1920, loss = 0.74158344
Iteration 1921, loss = 0.74229357
Iteration 1922, loss = 0.74076068
Iteration 1923, loss = 0.74020226
Iteration 1924, loss = 0.73991431
Iteration 1925, loss = 0.73840006
Iteration 1926, loss = 0.73866453
Iteration 1927, loss = 0.73702731
Iteration 1928, loss = 0.73706129
Iteration 1929, loss = 0.73594590
Iteration 1930, loss = 0.73532868
Iteration 1931, loss = 0.73475229
Iteration 1932, loss = 0.73312526
Iteration 1933, loss = 0.74665872
Iteration 1934, loss = 0.72757581
Iteration 1935, loss = 0.76474793
Iteration 1936, loss = 0.77246724
Iteration 1937, loss = 0.74359283
Iteration 1938, loss = 0.76549700
Iteration 1939, loss = 0.73606335
Iteration 1940, loss = 0.74982184
Iteration 1941, loss = 0.74837248
Iteration 1942, loss = 0.73906715
Iteration 1943, loss = 0.75304713
Iteration 1944, loss = 0.73571247
Iteration 1945, loss = 0.74622616
Iteration 1946, loss = 0.74130074
Iteration 1947, loss = 0.73532888
Iteration 1948, loss = 0.74255571
Iteration 1949, loss = 0.73175549
Iteration 1950, loss = 0.73309903
Iteration 1951, loss = 0.64453644
Iteration 1952, loss = 0.75188059
Iteration 1953, loss = 0.84836643
Iteration 1954, loss = 0.75771999
Iteration 1955, loss = 0.80550210
Iteration 1956, loss = 0.79730919
Iteration 1957, loss = 0.75472839
Iteration 1958, loss = 0.81123262
Iteration 1959, loss = 0.76203083
Iteration 1960, loss = 0.78897586
Iteration 1961, loss = 0.79610351
Iteration 1962, loss = 0.76700624
Iteration 1963, loss = 0.80133674
Iteration 1964, loss = 0.77448048
Iteration 1965, loss = 0.78154013
Iteration 1966, loss = 0.79355947
Iteration 1967, loss = 0.77275040
Iteration 1968, loss = 0.79290917
Iteration 1969, loss = 0.78252644
Iteration 1970, loss = 0.77980514
Iteration 1971, loss = 0.79136928
Iteration 1972, loss = 0.77737382
Iteration 1973, loss = 0.78621692
Iteration 1974, loss = 0.78461790
Iteration 1975, loss = 0.77829659
Iteration 1976, loss = 0.78672656
Iteration 1977, loss = 0.77917468
Iteration 1978, loss = 0.78101015
Iteration 1979, loss = 0.78328028
Iteration 1980, loss = 0.77725361
Iteration 1981, loss = 0.78165377
Iteration 1982, loss = 0.77863884
Iteration 1983, loss = 0.77677924
Iteration 1984, loss = 0.77944803
Iteration 1985, loss = 0.77537908
Iteration 1986, loss = 0.77661571
Iteration 1987, loss = 0.77628736
Iteration 1988, loss = 0.77351276
Iteration 1989, loss = 0.77503894
Iteration 1990, loss = 0.77287087
Iteration 1991, loss = 0.77205812
Iteration 1992, loss = 0.77251527
Iteration 1993, loss = 0.77017917
Iteration 1994, loss = 0.77024474
Iteration 1995, loss = 0.76884343
Iteration 1996, loss = 0.76064537
Iteration 1997, loss = 0.77984777
Iteration 1998, loss = 0.83810248
Iteration 1999, loss = 0.85683077
Iteration 2000, loss = 0.80481493
Iteration 2001, loss = 0.77171499
Iteration 2002, loss = 0.79825345
Iteration 2003, loss = 0.82131620
Iteration 2004, loss = 0.79166790
Iteration 2005, loss = 0.76665184
Iteration 2006, loss = 0.78401580
Iteration 2007, loss = 0.80051039
Iteration 2008, loss = 0.77956513
Iteration 2009, loss = 0.75385257
Iteration 2010, loss = 0.84773420
Iteration 2011, loss = 1.23508081
Iteration 2012, loss = 0.98824717
Iteration 2013, loss = 0.76237623
Iteration 2014, loss = 0.95625048
Iteration 2015, loss = 0.99153231
Iteration 2016, loss = 1.01571248
Iteration 2017, loss = 0.83880062
Iteration 2018, loss = 0.87564529
Iteration 2019, loss = 0.96175458
Iteration 2020, loss = 0.78101800
Iteration 2021, loss = 0.87303962
Iteration 2022, loss = 0.81542923
Iteration 2023, loss = 0.78387712
Iteration 2024, loss = 0.84645924
Iteration 2025, loss = 0.77701817
Iteration 2026, loss = 0.82062190
Iteration 2027, loss = 0.79176745
Iteration 2028, loss = 0.78081947
Iteration 2029, loss = 0.80164449
Iteration 2030, loss = 0.76383603
Iteration 2031, loss = 0.79658645
Iteration 2032, loss = 0.76764222
Iteration 2033, loss = 0.77901725
Iteration 2034, loss = 0.77785785
Iteration 2035, loss = 0.76384509
Iteration 2036, loss = 0.77842553
Iteration 2037, loss = 0.75875072
Iteration 2038, loss = 0.77272062
Iteration 2039, loss = 0.75780020
Iteration 2040, loss = 0.76329720
Iteration 2041, loss = 0.75851061
Iteration 2042, loss = 0.75449654
Iteration 2043, loss = 0.75843028
Iteration 2044, loss = 0.74945888
Iteration 2045, loss = 0.75334984
Iteration 2046, loss = 0.79181933
Iteration 2047, loss = 0.87462923
Iteration 2048, loss = 0.76106507
Iteration 2049, loss = 0.86318683
Iteration 2050, loss = 0.75837362
Iteration 2051, loss = 0.82444125
Iteration 2052, loss = 0.77752536
Iteration 2053, loss = 0.78289047
Iteration 2054, loss = 0.79783315
Iteration 2055, loss = 0.75595218
Iteration 2056, loss = 0.80041794
Iteration 2057, loss = 0.74973771
Iteration 2058, loss = 0.78551969
Iteration 2059, loss = 0.75792451
Iteration 2060, loss = 0.76467935
Iteration 2061, loss = 0.76725926
Iteration 2062, loss = 0.74801916
Iteration 2063, loss = 0.76743653
Iteration 2064, loss = 0.74261785
Iteration 2065, loss = 0.75919922
Iteration 2066, loss = 0.74466592
Iteration 2067, loss = 0.74695219
Iteration 2068, loss = 0.74592720
Iteration 2069, loss = 0.72571537
Iteration 2070, loss = 0.78630850
Iteration 2071, loss = 0.76932160
Iteration 2072, loss = 0.76852258
Iteration 2073, loss = 0.77374628
Iteration 2074, loss = 0.71726402
Iteration 2075, loss = 0.86479424
Iteration 2076, loss = 0.76175082
Iteration 2077, loss = 0.84497895
Iteration 2078, loss = 0.76023822
Iteration 2079, loss = 0.82130703
Iteration 2080, loss = 0.77322127
Iteration 2081, loss = 0.80327468
Iteration 2082, loss = 0.78682941
Iteration 2083, loss = 0.78767056
Iteration 2084, loss = 0.79493587
Iteration 2085, loss = 0.77574084
Iteration 2086, loss = 0.79833557
Iteration 2087, loss = 0.77182330
Iteration 2088, loss = 0.79922040
Iteration 2089, loss = 0.77351700
Iteration 2090, loss = 0.79476096
Iteration 2091, loss = 0.77505746
Iteration 2092, loss = 0.78658592
Iteration 2093, loss = 0.77746711
Iteration 2094, loss = 0.77998400
Iteration 2095, loss = 0.77958189
Iteration 2096, loss = 0.78521751
Iteration 2097, loss = 0.89688282
Iteration 2098, loss = 0.91979555
Iteration 2099, loss = 0.77996712
Iteration 2100, loss = 0.82664189
Iteration 2101, loss = 0.87303194
Iteration 2102, loss = 0.77312570
Iteration 2103, loss = 0.81635982
Iteration 2104, loss = 0.83256765
Iteration 2105, loss = 0.76508118
Iteration 2106, loss = 0.81162757
Iteration 2107, loss = 0.79981280
Iteration 2108, loss = 0.76315408
Iteration 2109, loss = 0.80313606
Iteration 2110, loss = 0.77553222
Iteration 2111, loss = 0.76439554
Iteration 2112, loss = 0.78953663
Iteration 2113, loss = 0.75992973
Iteration 2114, loss = 0.76796191
Iteration 2115, loss = 0.80326033
Iteration 2116, loss = 0.76375781
Iteration 2117, loss = 0.77531781
Iteration 2118, loss = 0.77023172
Iteration 2119, loss = 0.81291435
Iteration 2120, loss = 1.11665669
Iteration 2121, loss = 0.84168172
Iteration 2122, loss = 1.01110565
Iteration 2123, loss = 0.89616776
Iteration 2124, loss = 0.84827310
Iteration 2125, loss = 0.92319360
Iteration 2126, loss = 0.77295001
Iteration 2127, loss = 0.92906414
Iteration 2128, loss = 0.78017542
Iteration 2129, loss = 0.89409377
Iteration 2130, loss = 0.81316619
Iteration 2131, loss = 0.82677220
Iteration 2132, loss = 0.83574118
Iteration 2133, loss = 0.77279233
Iteration 2134, loss = 1.11908372
Iteration 2135, loss = 1.05065994
Iteration 2136, loss = 0.84076726
Iteration 2137, loss = 1.10517356
Iteration 2138, loss = 0.83648753
Iteration 2139, loss = 1.09289357
Iteration 2140, loss = 0.80534951
Iteration 2141, loss = 1.06488552
Iteration 2142, loss = 0.79294829
Iteration 2143, loss = 1.06007600
Iteration 2144, loss = 0.79835543
Iteration 2145, loss = 1.04968670
Iteration 2146, loss = 0.76863245
Iteration 2147, loss = 1.28868498
Iteration 2148, loss = 0.80906147
Iteration 2149, loss = 1.22992523
Iteration 2150, loss = 0.81271757
Iteration 2151, loss = 1.18944423
Iteration 2152, loss = 0.82999563
Iteration 2153, loss = 1.18533524
Iteration 2154, loss = 0.87988145
Iteration 2155, loss = 1.18339918
Iteration 2156, loss = 0.93048875
Iteration 2157, loss = 1.15091834
Iteration 2158, loss = 0.97319880
Iteration 2159, loss = 1.09174696
Iteration 2160, loss = 0.99139828
Iteration 2161, loss = 1.02515945
Iteration 2162, loss = 0.98182742
Iteration 2163, loss = 0.96699178
Iteration 2164, loss = 0.95128019
Iteration 2165, loss = 0.92596945
Iteration 2166, loss = 0.91573072
Iteration 2167, loss = 0.89918228
Iteration 2168, loss = 0.88237683
Iteration 2169, loss = 0.88278987
Iteration 2170, loss = 0.85477060
Iteration 2171, loss = 0.87125506
Iteration 2172, loss = 0.83176838
Iteration 2173, loss = 0.86213867
Iteration 2174, loss = 0.81317897
Iteration 2175, loss = 0.85389074
Iteration 2176, loss = 0.79828971
Iteration 2177, loss = 0.84614723
Iteration 2178, loss = 0.78667410
Iteration 2179, loss = 0.83780777
Iteration 2180, loss = 0.77705148
Iteration 2181, loss = 0.82893071
Iteration 2182, loss = 0.76935758
Iteration 2183, loss = 0.81959401
Iteration 2184, loss = 0.76329972
Iteration 2185, loss = 0.81004556
Iteration 2186, loss = 0.75868554
Iteration 2187, loss = 0.80050291
Iteration 2188, loss = 0.75529428
Iteration 2189, loss = 0.79094149
Iteration 2190, loss = 0.75266539
Iteration 2191, loss = 0.78169768
Iteration 2192, loss = 0.75086272
Iteration 2193, loss = 0.77322036
Iteration 2194, loss = 0.74968924
Iteration 2195, loss = 0.76554601
Iteration 2196, loss = 0.74868990
Iteration 2197, loss = 0.75829365
Iteration 2198, loss = 0.76076515
Iteration 2199, loss = 0.89691732
Iteration 2200, loss = 1.03378115
Iteration 2201, loss = 0.74074962
Iteration 2202, loss = 0.94609226
Iteration 2203, loss = 0.81014611
Iteration 2204, loss = 0.79455203
Iteration 2205, loss = 0.88265578
Iteration 2206, loss = 0.73246218
Iteration 2207, loss = 0.86570160
Iteration 2208, loss = 0.74011889
Iteration 2209, loss = 0.78930750
Iteration 2210, loss = 0.76868634
Iteration 2211, loss = 0.66740540
Iteration 2212, loss = 1.35128932
Iteration 2213, loss = 0.83205161
Iteration 2214, loss = 1.47648797
Iteration 2215, loss = 0.97784064
Iteration 2216, loss = 1.37816786
Iteration 2217, loss = 1.14249595
Iteration 2218, loss = 1.17196529
Iteration 2219, loss = 1.17562240
Iteration 2220, loss = 0.97654191
Iteration 2221, loss = 1.10740570
Iteration 2222, loss = 0.88806533
Iteration 2223, loss = 1.01967441
Iteration 2224, loss = 0.85444424
Iteration 2225, loss = 0.94857611
Iteration 2226, loss = 0.84464359
Iteration 2227, loss = 0.89356335
Iteration 2228, loss = 0.84460891
Iteration 2229, loss = 0.85814891
Iteration 2230, loss = 0.84933785
Iteration 2231, loss = 0.82592741
Iteration 2232, loss = 0.84673341
Iteration 2233, loss = 0.80830779
Iteration 2234, loss = 0.85113894
Iteration 2235, loss = 0.79960803
Iteration 2236, loss = 0.84948479
Iteration 2237, loss = 0.78980483
Iteration 2238, loss = 0.84116440
Iteration 2239, loss = 0.78261858
Iteration 2240, loss = 0.83118312
Iteration 2241, loss = 0.78077844
Iteration 2242, loss = 0.82133267
Iteration 2243, loss = 0.77842753
Iteration 2244, loss = 0.80881103
Iteration 2245, loss = 0.77688541
Iteration 2246, loss = 0.77220313
Iteration 2247, loss = 0.93746635
Iteration 2248, loss = 0.82654067
Iteration 2249, loss = 0.92862581
Iteration 2250, loss = 0.81121122
Iteration 2251, loss = 0.88766523
Iteration 2252, loss = 0.78892969
Iteration 2253, loss = 0.86145513
Iteration 2254, loss = 0.78962296
Iteration 2255, loss = 0.85562526
Iteration 2256, loss = 0.79555487
Iteration 2257, loss = 0.84485985
Iteration 2258, loss = 0.79114364
Iteration 2259, loss = 0.82933224
Iteration 2260, loss = 0.78644831
Iteration 2261, loss = 0.81993610
Iteration 2262, loss = 0.78801113
Iteration 2263, loss = 0.81612919
Iteration 2264, loss = 0.78865948
Iteration 2265, loss = 0.80940457
Iteration 2266, loss = 0.78584934
Iteration 2267, loss = 0.80278365
Iteration 2268, loss = 0.78437744
Iteration 2269, loss = 0.79864591
Iteration 2270, loss = 0.78377873
Iteration 2271, loss = 0.79525562
Iteration 2272, loss = 0.78262938
Iteration 2273, loss = 0.79093860
Iteration 2274, loss = 0.78087229
Iteration 2275, loss = 0.78813187
Iteration 2276, loss = 0.78011222
Iteration 2277, loss = 0.78461652
Iteration 2278, loss = 0.77949418
Iteration 2279, loss = 0.78846777
Iteration 2280, loss = 0.78076053
Iteration 2281, loss = 0.78588813
Iteration 2282, loss = 0.77812059
Iteration 2283, loss = 0.78162461
Iteration 2284, loss = 0.77654067
Iteration 2285, loss = 0.77982022
Iteration 2286, loss = 0.77601627
Iteration 2287, loss = 0.77782539
Iteration 2288, loss = 0.77455953
Iteration 2289, loss = 0.77569695
Iteration 2290, loss = 0.77336719
Iteration 2291, loss = 0.77401956
Iteration 2292, loss = 0.77203484
Iteration 2293, loss = 0.77215379
Iteration 2294, loss = 0.77070568
Iteration 2295, loss = 0.76694846
Iteration 2296, loss = 0.76456838
Iteration 2297, loss = 0.79325356
Iteration 2298, loss = 0.80425954
Iteration 2299, loss = 0.81422499
Iteration 2300, loss = 0.80781586
Iteration 2301, loss = 0.80188094
Iteration 2302, loss = 0.79169064
Iteration 2303, loss = 0.78915626
Iteration 2304, loss = 0.78866298
Iteration 2305, loss = 0.79312901
Iteration 2306, loss = 0.79693666
Iteration 2307, loss = 0.79849691
Iteration 2308, loss = 0.80257456
Iteration 2309, loss = 0.80429322
Iteration 2310, loss = 0.80355969
Iteration 2311, loss = 0.80131510
Iteration 2312, loss = 0.80162605
Iteration 2313, loss = 0.80187051
Iteration 2314, loss = 0.80302657
Iteration 2315, loss = 0.80284358
Iteration 2316, loss = 0.80260612
Iteration 2317, loss = 0.80194006
Iteration 2318, loss = 0.80138718
Iteration 2319, loss = 0.80098595
Iteration 2320, loss = 0.80049925
Iteration 2321, loss = 0.80054986
Iteration 2322, loss = 0.80033380
Iteration 2323, loss = 0.79987171
Iteration 2324, loss = 0.79856123
Iteration 2325, loss = 0.79748557
Iteration 2326, loss = 0.79633781
Iteration 2327, loss = 0.79533563
Iteration 2328, loss = 0.79443490
Iteration 2329, loss = 0.79365758
Iteration 2330, loss = 0.79279763
Iteration 2331, loss = 0.79188032
Iteration 2332, loss = 0.79104466
Iteration 2333, loss = 0.78995254
Iteration 2334, loss = 0.78871630
Iteration 2335, loss = 0.78745021
Iteration 2336, loss = 0.78626657
Iteration 2337, loss = 0.78477956
Iteration 2338, loss = 0.78557003
Iteration 2339, loss = 0.78582176
Iteration 2340, loss = 0.78552617
Iteration 2341, loss = 0.78352620
Iteration 2342, loss = 0.78144809
Iteration 2343, loss = 0.77971472
Iteration 2344, loss = 0.77863556
Iteration 2345, loss = 0.77798076
Iteration 2346, loss = 0.77708910
Iteration 2347, loss = 0.77607878
Iteration 2348, loss = 0.77478862
Iteration 2349, loss = 0.77377561
Iteration 2350, loss = 0.77271180
Iteration 2351, loss = 0.77173659
Iteration 2352, loss = 0.77068810
Iteration 2353, loss = 0.76966298
Iteration 2354, loss = 0.76876618
Iteration 2355, loss = 0.76786993
Iteration 2356, loss = 0.76706882
Iteration 2357, loss = 0.76613071
Iteration 2358, loss = 0.76520907
Iteration 2359, loss = 0.76425492
Iteration 2360, loss = 0.76340628
Iteration 2361, loss = 0.76261872
Iteration 2362, loss = 0.76182580
Iteration 2363, loss = 0.76103293
Iteration 2364, loss = 0.76019597
Iteration 2365, loss = 0.75942287
Iteration 2366, loss = 0.75865917
Iteration 2367, loss = 0.75793561
Iteration 2368, loss = 0.75719270
Iteration 2369, loss = 0.75645594
Iteration 2370, loss = 0.75574871
Iteration 2371, loss = 0.75506018
Iteration 2372, loss = 0.75440083
Iteration 2373, loss = 0.75372754
Iteration 2374, loss = 0.75306772
Iteration 2375, loss = 0.75240571
Iteration 2376, loss = 0.75176828
Iteration 2377, loss = 0.75115283
Iteration 2378, loss = 0.75055218
Iteration 2379, loss = 0.74996325
Iteration 2380, loss = 0.74937084
Iteration 2381, loss = 0.74879123
Iteration 2382, loss = 0.74821707
Iteration 2383, loss = 0.74766118
Iteration 2384, loss = 0.74711668
Iteration 2385, loss = 0.74658237
Iteration 2386, loss = 0.74605684
Iteration 2387, loss = 0.74553673
Iteration 2388, loss = 0.74502885
Iteration 2389, loss = 0.74452712
Iteration 2390, loss = 0.74403617
Iteration 2391, loss = 0.74355286
Iteration 2392, loss = 0.74307991
Iteration 2393, loss = 0.74261602
Iteration 2394, loss = 0.74215818
Iteration 2395, loss = 0.74170764
Iteration 2396, loss = 0.74126259
Iteration 2397, loss = 0.74082728
Iteration 2398, loss = 0.74040020
Iteration 2399, loss = 0.73998129
Iteration 2400, loss = 0.73956851
Iteration 2401, loss = 0.73916127
Iteration 2402, loss = 0.73876110
Iteration 2403, loss = 0.73836729
Iteration 2404, loss = 0.73798101
Iteration 2405, loss = 0.73760083
Iteration 2406, loss = 0.73722692
Iteration 2407, loss = 0.73685873
Iteration 2408, loss = 0.73649621
Iteration 2409, loss = 0.73613982
Iteration 2410, loss = 0.73578891
Iteration 2411, loss = 0.73544385
Iteration 2412, loss = 0.73510397
Iteration 2413, loss = 0.73476945
Iteration 2414, loss = 0.73444006
Iteration 2415, loss = 0.73411573
Iteration 2416, loss = 0.73379644
Iteration 2417, loss = 0.73348165
Iteration 2418, loss = 0.73317147
Iteration 2419, loss = 0.73286553
Iteration 2420, loss = 0.73256379
Iteration 2421, loss = 0.73226571
Iteration 2422, loss = 0.73197021
Iteration 2423, loss = 0.73167464
Iteration 2424, loss = 0.73136623
Iteration 2425, loss = 0.73063148
Iteration 2426, loss = 0.73921747
Iteration 2427, loss = 0.74978526
Iteration 2428, loss = 0.73252691
Iteration 2429, loss = 0.74713539
Iteration 2430, loss = 0.73441222
Iteration 2431, loss = 0.73720890
Iteration 2432, loss = 0.74054907
Iteration 2433, loss = 0.73065617
Iteration 2434, loss = 0.73970609
Iteration 2435, loss = 0.73162340
Iteration 2436, loss = 0.73434701
Iteration 2437, loss = 0.73496102
Iteration 2438, loss = 0.72950044
Iteration 2439, loss = 0.73483535
Iteration 2440, loss = 0.72974190
Iteration 2441, loss = 0.73163668
Iteration 2442, loss = 0.73151110
Iteration 2443, loss = 0.72853122
Iteration 2444, loss = 0.73150962
Iteration 2445, loss = 0.72822094
Iteration 2446, loss = 0.72939545
Iteration 2447, loss = 0.72908666
Iteration 2448, loss = 0.72609347
Iteration 2449, loss = 0.72975673
Iteration 2450, loss = 0.73459692
Iteration 2451, loss = 0.73620199
Iteration 2452, loss = 0.73437517
Iteration 2453, loss = 0.73037066
Iteration 2454, loss = 0.72773142
Iteration 2455, loss = 0.72748245
Iteration 2456, loss = 0.72846769
Iteration 2457, loss = 0.72932354
Iteration 2458, loss = 0.72891648
Iteration 2459, loss = 0.72771864
Iteration 2460, loss = 0.72650112
Iteration 2461, loss = 0.72593050
Iteration 2462, loss = 0.72580933
Iteration 2463, loss = 0.72536873
Iteration 2464, loss = 0.72517172
Iteration 2465, loss = 0.72469985
Iteration 2466, loss = 0.72423655
Iteration 2467, loss = 0.72416739
Iteration 2468, loss = 0.72408048
Iteration 2469, loss = 0.72283238
Iteration 2470, loss = 0.72258618
Iteration 2471, loss = 0.72257199
Iteration 2472, loss = 0.72122403
Iteration 2473, loss = 0.71978588
Iteration 2474, loss = 0.69674604
Iteration 2475, loss = 0.79199177
Iteration 2476, loss = 0.80714152
Iteration 2477, loss = 0.77683587
Iteration 2478, loss = 0.79269172
Iteration 2479, loss = 0.75059055
Iteration 2480, loss = 0.78886266
Iteration 2481, loss = 0.74720622
Iteration 2482, loss = 0.79107422
Iteration 2483, loss = 0.74042784
Iteration 2484, loss = 0.78211684
Iteration 2485, loss = 0.73160451
Iteration 2486, loss = 0.77516513
Iteration 2487, loss = 0.73171481
Iteration 2488, loss = 0.77076793
Iteration 2489, loss = 0.73028524
Iteration 2490, loss = 0.76235851
Iteration 2491, loss = 0.72869382
Iteration 2492, loss = 0.75543586
Iteration 2493, loss = 0.72966420
Iteration 2494, loss = 0.74965800
Iteration 2495, loss = 0.72916636
Iteration 2496, loss = 0.75059469
Iteration 2497, loss = 0.74511980
Iteration 2498, loss = 0.74011987
Iteration 2499, loss = 0.74769098
Iteration 2500, loss = 0.73507521
Iteration 2501, loss = 0.74425453
Iteration 2502, loss = 0.72984659
Iteration 2503, loss = 0.74160916
Iteration 2504, loss = 0.72824777
Iteration 2505, loss = 0.73999425
Iteration 2506, loss = 0.72767719
Iteration 2507, loss = 0.73745282
Iteration 2508, loss = 0.72687141
Iteration 2509, loss = 0.73430773
Iteration 2510, loss = 0.72626045
Iteration 2511, loss = 0.73150987
Iteration 2512, loss = 0.72614484
Iteration 2513, loss = 0.72919809
Iteration 2514, loss = 0.72609677
Iteration 2515, loss = 0.72719319
Iteration 2516, loss = 0.72583606
Iteration 2517, loss = 0.72529304
Iteration 2518, loss = 0.72509260
Iteration 2519, loss = 0.72327017
Iteration 2520, loss = 0.72263477
Iteration 2521, loss = 0.71641186
Iteration 2522, loss = 0.73392461
Iteration 2523, loss = 0.73153329
Iteration 2524, loss = 0.73607323
Iteration 2525, loss = 0.72929278
Iteration 2526, loss = 0.72808549
Iteration 2527, loss = 0.72592325
Iteration 2528, loss = 0.72697817
Iteration 2529, loss = 0.72870262
Iteration 2530, loss = 0.72778669
Iteration 2531, loss = 0.72993460
Iteration 2532, loss = 0.72608759
Iteration 2533, loss = 0.72801763
Iteration 2534, loss = 0.72555666
Iteration 2535, loss = 0.72692073
Iteration 2536, loss = 0.72521902
Iteration 2537, loss = 0.72642869
Iteration 2538, loss = 0.72504239
Iteration 2539, loss = 0.72532599
Iteration 2540, loss = 0.72472472
Iteration 2541, loss = 0.72500669
Iteration 2542, loss = 0.72470438
Iteration 2543, loss = 0.72412241
Iteration 2544, loss = 0.72384871
Iteration 2545, loss = 0.72316400
Iteration 2546, loss = 0.72324368
Iteration 2547, loss = 0.72249883
Iteration 2548, loss = 0.72259154
Iteration 2549, loss = 0.72178760
Iteration 2550, loss = 0.72179754
Iteration 2551, loss = 0.72097384
Iteration 2552, loss = 0.72085228
Iteration 2553, loss = 0.71992484
Iteration 2554, loss = 0.71970836
Iteration 2555, loss = 0.71984697
Iteration 2556, loss = 0.71877066
Iteration 2557, loss = 0.71737800
Iteration 2558, loss = 0.71683553
Iteration 2559, loss = 0.71332297
Iteration 2560, loss = 0.73731935
Iteration 2561, loss = 0.68279150
Iteration 2562, loss = 0.69539817
Iteration 2563, loss = 0.73743616
Iteration 2564, loss = 0.74868468
Iteration 2565, loss = 0.74529953
Iteration 2566, loss = 0.73655501
Iteration 2567, loss = 0.74669870
Iteration 2568, loss = 0.73955737
Iteration 2569, loss = 0.74518737
Iteration 2570, loss = 0.73852388
Iteration 2571, loss = 0.74454737
Iteration 2572, loss = 0.74128228
Iteration 2573, loss = 0.74580597
Iteration 2574, loss = 0.74124021
Iteration 2575, loss = 0.74196163
Iteration 2576, loss = 0.76116587
Iteration 2577, loss = 0.78917397
Iteration 2578, loss = 0.77049474
Iteration 2579, loss = 1.00040760
Iteration 2580, loss = 0.78181025
Iteration 2581, loss = 0.98483725
Iteration 2582, loss = 0.78628101
Iteration 2583, loss = 0.95869037
Iteration 2584, loss = 0.78517654
Iteration 2585, loss = 0.93986220
Iteration 2586, loss = 0.78889634
Iteration 2587, loss = 0.92832255
Iteration 2588, loss = 0.79407505
Iteration 2589, loss = 0.91783773
Iteration 2590, loss = 0.79647357
Iteration 2591, loss = 0.90647807
Iteration 2592, loss = 0.79496530
Iteration 2593, loss = 0.89174756
Iteration 2594, loss = 0.79053579
Iteration 2595, loss = 0.87998002
Iteration 2596, loss = 0.78765325
Iteration 2597, loss = 0.86879644
Iteration 2598, loss = 0.78350907
Iteration 2599, loss = 0.85612787
Iteration 2600, loss = 0.77623975
Iteration 2601, loss = 0.82067225
Iteration 2602, loss = 0.78603437
Iteration 2603, loss = 0.79004282
Iteration 2604, loss = 0.79387197
Iteration 2605, loss = 0.78203218
Iteration 2606, loss = 0.78361919
Iteration 2607, loss = 0.77271612
Iteration 2608, loss = 0.78125432
Iteration 2609, loss = 0.77628412
Iteration 2610, loss = 0.78290445
Iteration 2611, loss = 0.77635934
Iteration 2612, loss = 0.77746303
Iteration 2613, loss = 0.77299206
Iteration 2614, loss = 0.77309074
Iteration 2615, loss = 0.77296262
Iteration 2616, loss = 0.77148786
Iteration 2617, loss = 0.77190055
Iteration 2618, loss = 0.76831495
Iteration 2619, loss = 0.76914945
Iteration 2620, loss = 0.76590993
Iteration 2621, loss = 0.76575816
Iteration 2622, loss = 0.76464227
Iteration 2623, loss = 0.76373619
Iteration 2624, loss = 0.76175131
Iteration 2625, loss = 0.75801766
Iteration 2626, loss = 0.76519912
Iteration 2627, loss = 0.76621411
Iteration 2628, loss = 0.76025093
Iteration 2629, loss = 0.69627902
Iteration 2630, loss = 0.79425620
Iteration 2631, loss = 0.77215098
Iteration 2632, loss = 0.77671203
Iteration 2633, loss = 0.77386062
Iteration 2634, loss = 0.76401556
Iteration 2635, loss = 0.77664492
Iteration 2636, loss = 0.75929008
Iteration 2637, loss = 0.77749214
Iteration 2638, loss = 0.75749623
Iteration 2639, loss = 0.77376194
Iteration 2640, loss = 0.75655675
Iteration 2641, loss = 0.76826505
Iteration 2642, loss = 0.75787425
Iteration 2643, loss = 0.76321606
Iteration 2644, loss = 0.75933090
Iteration 2645, loss = 0.75853275
Iteration 2646, loss = 0.75968232
Iteration 2647, loss = 0.75446545
Iteration 2648, loss = 0.75794556
Iteration 2649, loss = 0.75133399
Iteration 2650, loss = 0.75539668
Iteration 2651, loss = 0.74880430
Iteration 2652, loss = 0.75118031
Iteration 2653, loss = 0.74568939
Iteration 2654, loss = 0.74455296
Iteration 2655, loss = 0.73878927
Iteration 2656, loss = 0.75610564
Iteration 2657, loss = 0.82528607
Iteration 2658, loss = 0.86160666
Iteration 2659, loss = 1.69863585
Iteration 2660, loss = 1.15850020
Iteration 2661, loss = 1.43047155
Iteration 2662, loss = 1.50768021
Iteration 2663, loss = 0.83672843
Iteration 2664, loss = 1.33739871
Iteration 2665, loss = 0.77937580
Iteration 2666, loss = 1.27165413
Iteration 2667, loss = 0.93800006
Iteration 2668, loss = 1.16066885
Iteration 2669, loss = 1.07356265
Iteration 2670, loss = 0.96261654
Iteration 2671, loss = 1.06207136
Iteration 2672, loss = 0.82060229
Iteration 2673, loss = 1.00258326
Iteration 2674, loss = 0.76400094
Iteration 2675, loss = 0.96084657
Iteration 2676, loss = 0.75954180
Iteration 2677, loss = 0.92216732
Iteration 2678, loss = 0.77184792
Iteration 2679, loss = 0.88554429
Iteration 2680, loss = 0.78560499
Iteration 2681, loss = 0.85188708
Iteration 2682, loss = 0.79607167
Iteration 2683, loss = 0.82273474
Iteration 2684, loss = 0.79914993
Iteration 2685, loss = 0.79759174
Iteration 2686, loss = 0.79629045
Iteration 2687, loss = 0.77864329
Iteration 2688, loss = 0.79167231
Iteration 2689, loss = 0.76617543
Iteration 2690, loss = 0.78594961
Iteration 2691, loss = 0.75699260
Iteration 2692, loss = 0.77880812
Iteration 2693, loss = 0.75004488
Iteration 2694, loss = 0.77185285
Iteration 2695, loss = 0.74551403
Iteration 2696, loss = 0.76593693
Iteration 2697, loss = 0.74257810
Iteration 2698, loss = 0.76058572
Iteration 2699, loss = 0.74026992
Iteration 2700, loss = 0.75565411
Iteration 2701, loss = 0.73834137
Iteration 2702, loss = 0.75120879
Iteration 2703, loss = 0.73667189
Iteration 2704, loss = 0.74727666
Iteration 2705, loss = 0.73523167
Iteration 2706, loss = 0.74388473
Iteration 2707, loss = 0.73399001
Iteration 2708, loss = 0.74094699
Iteration 2709, loss = 0.73281476
Iteration 2710, loss = 0.73830016
Iteration 2711, loss = 0.73161052
Iteration 2712, loss = 0.73590162
Iteration 2713, loss = 0.73044639
Iteration 2714, loss = 0.73380529
Iteration 2715, loss = 0.72936514
Iteration 2716, loss = 0.73195320
Iteration 2717, loss = 0.72831349
Iteration 2718, loss = 0.73027278
Iteration 2719, loss = 0.72727866
Iteration 2720, loss = 0.72874323
Iteration 2721, loss = 0.72627174
Iteration 2722, loss = 0.72734392
Iteration 2723, loss = 0.72528930
Iteration 2724, loss = 0.72605526
Iteration 2725, loss = 0.72433992
Iteration 2726, loss = 0.72486705
Iteration 2727, loss = 0.72339042
Iteration 2728, loss = 0.72253350
Iteration 2729, loss = 0.72114322
Iteration 2730, loss = 0.71977004
Iteration 2731, loss = 0.73406944
Iteration 2732, loss = 0.72952210
Iteration 2733, loss = 0.73202855
Iteration 2734, loss = 0.72814573
Iteration 2735, loss = 0.72499488
Iteration 2736, loss = 0.72822845
Iteration 2737, loss = 0.72423585
Iteration 2738, loss = 0.72950627
Iteration 2739, loss = 0.72399815
Iteration 2740, loss = 0.72801987
Iteration 2741, loss = 0.72370200
Iteration 2742, loss = 0.72617057
Iteration 2743, loss = 0.72412880
Iteration 2744, loss = 0.72444583
Iteration 2745, loss = 0.72442889
Iteration 2746, loss = 0.72300429
Iteration 2747, loss = 0.72403342
Iteration 2748, loss = 0.72181030
Iteration 2749, loss = 0.72320352
Iteration 2750, loss = 0.72115942
Iteration 2751, loss = 0.72199272
Iteration 2752, loss = 0.72043675
Iteration 2753, loss = 0.72041282
Iteration 2754, loss = 0.71974588
Iteration 2755, loss = 0.71911577
Iteration 2756, loss = 0.71900071
Iteration 2757, loss = 0.71779929
Iteration 2758, loss = 0.71782726
Iteration 2759, loss = 0.71662723
Iteration 2760, loss = 0.71666520
Iteration 2761, loss = 0.71570223
Iteration 2762, loss = 0.71542817
Iteration 2763, loss = 0.71472770
Iteration 2764, loss = 0.71414584
Iteration 2765, loss = 0.71368899
Iteration 2766, loss = 0.71292121
Iteration 2767, loss = 0.71261346
Iteration 2768, loss = 0.71184443
Iteration 2769, loss = 0.71154847
Iteration 2770, loss = 0.71081417
Iteration 2771, loss = 0.71026520
Iteration 2772, loss = 0.70945155
Iteration 2773, loss = 0.70885026
Iteration 2774, loss = 0.70820192
Iteration 2775, loss = 0.70696214
Iteration 2776, loss = 0.70532009
Iteration 2777, loss = 0.70687702
Iteration 2778, loss = 0.70387532
Iteration 2779, loss = 0.70258726
Iteration 2780, loss = 0.70266359
Iteration 2781, loss = 0.68375741
Iteration 2782, loss = 0.85762758
Iteration 2783, loss = 0.92597867
Iteration 2784, loss = 0.76438461
Iteration 2785, loss = 0.97308506
Iteration 2786, loss = 0.71898879
Iteration 2787, loss = 0.96019188
Iteration 2788, loss = 0.68918857
Iteration 2789, loss = 1.01351256
Iteration 2790, loss = 0.75958923
Iteration 2791, loss = 0.86497636
Iteration 2792, loss = 0.70431370
Iteration 2793, loss = 1.68307411
Iteration 2794, loss = 0.83339006
Iteration 2795, loss = 1.70568794
Iteration 2796, loss = 1.33222596
Iteration 2797, loss = 1.25843756
Iteration 2798, loss = 1.41216521
Iteration 2799, loss = 0.85935242
Iteration 2800, loss = 1.22986197
Iteration 2801, loss = 0.75998335
Iteration 2802, loss = 1.09819313
Iteration 2803, loss = 0.73668791
Iteration 2804, loss = 1.01972381
Iteration 2805, loss = 0.73377417
Iteration 2806, loss = 0.96702555
Iteration 2807, loss = 0.73297819
Iteration 2808, loss = 0.92037297
Iteration 2809, loss = 0.72925261
Iteration 2810, loss = 0.87801904
Iteration 2811, loss = 0.72426062
Iteration 2812, loss = 0.82552323
Iteration 2813, loss = 0.85598647
Iteration 2814, loss = 0.73781377
Iteration 2815, loss = 0.83533564
Iteration 2816, loss = 0.73520700
Iteration 2817, loss = 0.81606842
Iteration 2818, loss = 0.73452047
Iteration 2819, loss = 0.80071421
Iteration 2820, loss = 0.73204309
Iteration 2821, loss = 0.78766113
Iteration 2822, loss = 0.73169014
Iteration 2823, loss = 0.77834889
Iteration 2824, loss = 0.72981808
Iteration 2825, loss = 0.76730997
Iteration 2826, loss = 0.72624212
Iteration 2827, loss = 0.75874453
Iteration 2828, loss = 0.72574117
Iteration 2829, loss = 0.75310356
Iteration 2830, loss = 0.72481915
Iteration 2831, loss = 0.74624468
Iteration 2832, loss = 0.72246562
Iteration 2833, loss = 0.74027290
Iteration 2834, loss = 0.72157379
Iteration 2835, loss = 0.73614959
Iteration 2836, loss = 0.72098682
Iteration 2837, loss = 0.73202628
Iteration 2838, loss = 0.71981268
Iteration 2839, loss = 0.72816227
Iteration 2840, loss = 0.71885707
Iteration 2841, loss = 0.72512652
Iteration 2842, loss = 0.71821548
Iteration 2843, loss = 0.72253800
Iteration 2844, loss = 0.71740811
Iteration 2845, loss = 0.72011286
Iteration 2846, loss = 0.71653650
Iteration 2847, loss = 0.71808687
Iteration 2848, loss = 0.71578342
Iteration 2849, loss = 0.71639971
Iteration 2850, loss = 0.71500130
Iteration 2851, loss = 0.71488259
Iteration 2852, loss = 0.71414801
Iteration 2853, loss = 0.71354581
Iteration 2854, loss = 0.71333346
Iteration 2855, loss = 0.71245826
Iteration 2856, loss = 0.71257130
Iteration 2857, loss = 0.71148460
Iteration 2858, loss = 0.71174029
Iteration 2859, loss = 0.71057373
Iteration 2860, loss = 0.71094330
Iteration 2861, loss = 0.70982502
Iteration 2862, loss = 0.71021868
Iteration 2863, loss = 0.70914758
Iteration 2864, loss = 0.70947612
Iteration 2865, loss = 0.70849866
Iteration 2866, loss = 0.70877102
Iteration 2867, loss = 0.70792968
Iteration 2868, loss = 0.70811872
Iteration 2869, loss = 0.70739353
Iteration 2870, loss = 0.70748626
Iteration 2871, loss = 0.70688680
Iteration 2872, loss = 0.70690235
Iteration 2873, loss = 0.70641630
Iteration 2874, loss = 0.70635131
Iteration 2875, loss = 0.70595651
Iteration 2876, loss = 0.70582971
Iteration 2877, loss = 0.70552106
Iteration 2878, loss = 0.70535198
Iteration 2879, loss = 0.70510760
Iteration 2880, loss = 0.70490191
Iteration 2881, loss = 0.70470254
Iteration 2882, loss = 0.70447727
Iteration 2883, loss = 0.70431520
Iteration 2884, loss = 0.70408424
Iteration 2885, loss = 0.70394494
Iteration 2886, loss = 0.70371234
Iteration 2887, loss = 0.70358358
Iteration 2888, loss = 0.70335775
Iteration 2889, loss = 0.70323724
Iteration 2890, loss = 0.70302592
Iteration 2891, loss = 0.70290790
Iteration 2892, loss = 0.70271019
Iteration 2893, loss = 0.70258996
Iteration 2894, loss = 0.70240831
Iteration 2895, loss = 0.70228693
Iteration 2896, loss = 0.70212090
Iteration 2897, loss = 0.70199603
Iteration 2898, loss = 0.70184341
Iteration 2899, loss = 0.70171715
Iteration 2900, loss = 0.70157773
Iteration 2901, loss = 0.70145010
Iteration 2902, loss = 0.70131859
Iteration 2903, loss = 0.70118690
Iteration 2904, loss = 0.70105238
Iteration 2905, loss = 0.70086716
Iteration 2906, loss = 0.70040781
Iteration 2907, loss = 0.70024223
Iteration 2908, loss = 0.70029199
Iteration 2909, loss = 0.70004572
Iteration 2910, loss = 0.69944675
Iteration 2911, loss = 0.69921164
Iteration 2912, loss = 0.70122494
Iteration 2913, loss = 0.70196619
Iteration 2914, loss = 0.70174549
Iteration 2915, loss = 0.69573994
Iteration 2916, loss = 0.80913632
Iteration 2917, loss = 0.76114294
Iteration 2918, loss = 1.08908539
Iteration 2919, loss = 0.83968688
Iteration 2920, loss = 1.02646278
Iteration 2921, loss = 0.74921751
Iteration 2922, loss = 0.95182697
Iteration 2923, loss = 0.73795680
Iteration 2924, loss = 0.92070181
Iteration 2925, loss = 0.74005270
Iteration 2926, loss = 0.87860312
Iteration 2927, loss = 0.74847489
Iteration 2928, loss = 0.84940960
Iteration 2929, loss = 0.76794996
Iteration 2930, loss = 0.82917626
Iteration 2931, loss = 0.78239520
Iteration 2932, loss = 0.80906571
Iteration 2933, loss = 0.78682608
Iteration 2934, loss = 0.79044819
Iteration 2935, loss = 0.78651343
Iteration 2936, loss = 0.77718957
Iteration 2937, loss = 0.78513848
Iteration 2938, loss = 0.76906093
Iteration 2939, loss = 0.78307466
Iteration 2940, loss = 0.76494976
Iteration 2941, loss = 0.77822336
Iteration 2942, loss = 0.75843622
Iteration 2943, loss = 0.77807688
Iteration 2944, loss = 0.75413308
Iteration 2945, loss = 0.77503769
Iteration 2946, loss = 0.75349270
Iteration 2947, loss = 0.76303241
Iteration 2948, loss = 0.76264347
Iteration 2949, loss = 0.75196987
Iteration 2950, loss = 0.76051650
Iteration 2951, loss = 0.75115990
Iteration 2952, loss = 0.75319729
Iteration 2953, loss = 0.75234441
Iteration 2954, loss = 0.74166611
Iteration 2955, loss = 0.74064307
Iteration 2956, loss = 0.64422413
Iteration 2957, loss = 0.84514413
Iteration 2958, loss = 0.90903696
Iteration 2959, loss = 0.91791762
Iteration 2960, loss = 0.86262399
Iteration 2961, loss = 0.91011607
Iteration 2962, loss = 0.80275246
Iteration 2963, loss = 0.88186940
Iteration 2964, loss = 0.78837303
Iteration 2965, loss = 0.87463243
Iteration 2966, loss = 0.80726643
Iteration 2967, loss = 0.87131015
Iteration 2968, loss = 0.82711620
Iteration 2969, loss = 0.86007787
Iteration 2970, loss = 0.83805908
Iteration 2971, loss = 0.84492761
Iteration 2972, loss = 0.84148764
Iteration 2973, loss = 0.83107227
Iteration 2974, loss = 0.84173700
Iteration 2975, loss = 0.82397952
Iteration 2976, loss = 0.84338014
Iteration 2977, loss = 0.82306163
Iteration 2978, loss = 0.85236008
Iteration 2979, loss = 0.78817059
Iteration 2980, loss = 0.90051070
Iteration 2981, loss = 0.83438830
Iteration 2982, loss = 0.89016570
Iteration 2983, loss = 0.83573275
Iteration 2984, loss = 0.87796694
Iteration 2985, loss = 0.83502577
Iteration 2986, loss = 0.86902382
Iteration 2987, loss = 0.83685257
Iteration 2988, loss = 0.86409257
Iteration 2989, loss = 0.84008006
Iteration 2990, loss = 0.86047349
Iteration 2991, loss = 0.84122565
Iteration 2992, loss = 0.85455202
Iteration 2993, loss = 0.83939479
Iteration 2994, loss = 0.84398956
Iteration 2995, loss = 0.82505488
Iteration 2996, loss = 1.01073777
Iteration 2997, loss = 0.87594735
Iteration 2998, loss = 0.99075160
Iteration 2999, loss = 0.86331387
Iteration 3000, loss = 0.94906009
Iteration 3001, loss = 0.86220631
Iteration 3002, loss = 0.93749775
Iteration 3003, loss = 0.87640926
Iteration 3004, loss = 0.93006545
Iteration 3005, loss = 0.88217661
Iteration 3006, loss = 0.91607405
Iteration 3007, loss = 0.88213444
Iteration 3008, loss = 0.90352532
Iteration 3009, loss = 0.88375431
Iteration 3010, loss = 0.89757255
Iteration 3011, loss = 0.88691691
Iteration 3012, loss = 0.89115142
Iteration 3013, loss = 0.88503246
Iteration 3014, loss = 0.88425406
Iteration 3015, loss = 0.88247552
Iteration 3016, loss = 0.87922091
Iteration 3017, loss = 0.88059262
Iteration 3018, loss = 0.87406363
Iteration 3019, loss = 0.87580077
Iteration 3020, loss = 0.86985825
Iteration 3021, loss = 0.87256246
Iteration 3022, loss = 0.86510025
Iteration 3023, loss = 0.86679604
Iteration 3024, loss = 0.85786139
Iteration 3025, loss = 0.84925572
Iteration 3026, loss = 0.90001184
Iteration 3027, loss = 0.94971631
Iteration 3028, loss = 0.90101680
Iteration 3029, loss = 0.93040308
Iteration 3030, loss = 0.88791880
Iteration 3031, loss = 0.91383011
Iteration 3032, loss = 0.87463266
Iteration 3033, loss = 0.89802955
Iteration 3034, loss = 0.86944707
Iteration 3035, loss = 0.89250809
Iteration 3036, loss = 0.86399943
Iteration 3037, loss = 0.88144786
Iteration 3038, loss = 0.85316013
Iteration 3039, loss = 0.86964434
Iteration 3040, loss = 0.84516343
Iteration 3041, loss = 0.86240455
Iteration 3042, loss = 0.84061316
Iteration 3043, loss = 0.85555631
Iteration 3044, loss = 0.83454242
Iteration 3045, loss = 0.84727312
Iteration 3046, loss = 0.82848506
Iteration 3047, loss = 0.84070393
Iteration 3048, loss = 0.82398272
Iteration 3049, loss = 0.83490673
Iteration 3050, loss = 0.81972840
Iteration 3051, loss = 0.82733066
Iteration 3052, loss = 0.81357616
Iteration 3053, loss = 0.82006357
Iteration 3054, loss = 0.80773960
Iteration 3055, loss = 0.81244174
Iteration 3056, loss = 0.80178234
Iteration 3057, loss = 0.80532881
Iteration 3058, loss = 0.78062508
Iteration 3059, loss = 0.82634971
Iteration 3060, loss = 0.84838688
Iteration 3061, loss = 0.83062801
Iteration 3062, loss = 0.83719936
Iteration 3063, loss = 0.77568226
Iteration 3064, loss = 1.06809668
Iteration 3065, loss = 0.87439178
Iteration 3066, loss = 1.00313822
Iteration 3067, loss = 0.84361609
Iteration 3068, loss = 0.94332376
Iteration 3069, loss = 0.83040572
Iteration 3070, loss = 0.83411081
Iteration 3071, loss = 0.75966843
Iteration 3072, loss = 0.83165422
Iteration 3073, loss = 0.84784571
Iteration 3074, loss = 0.83376171
Iteration 3075, loss = 0.83743337
Iteration 3076, loss = 0.82971622
Iteration 3077, loss = 0.83387435
Iteration 3078, loss = 0.83566912
Iteration 3079, loss = 0.83853999
Iteration 3080, loss = 0.84117362
Iteration 3081, loss = 0.84027518
Iteration 3082, loss = 0.84113060
Iteration 3083, loss = 0.84001819
Iteration 3084, loss = 0.84523134
Iteration 3085, loss = 0.84041649
Iteration 3086, loss = 0.84628225
Iteration 3087, loss = 0.84087079
Iteration 3088, loss = 0.84385974
Iteration 3089, loss = 0.83250513
Iteration 3090, loss = 0.87519776
Iteration 3091, loss = 0.84857822
Iteration 3092, loss = 0.87547078
Iteration 3093, loss = 0.84372861
Iteration 3094, loss = 0.86706786
Iteration 3095, loss = 0.83869219
Iteration 3096, loss = 0.85930183
Iteration 3097, loss = 0.83822713
Iteration 3098, loss = 0.85385769
Iteration 3099, loss = 0.83776883
Iteration 3100, loss = 0.84630094
Iteration 3101, loss = 0.83531245
Iteration 3102, loss = 0.83985806
Iteration 3103, loss = 0.83416388
Iteration 3104, loss = 0.83473097
Iteration 3105, loss = 0.83205475
Iteration 3106, loss = 0.82952680
Iteration 3107, loss = 0.82913039
Iteration 3108, loss = 0.82507893
Iteration 3109, loss = 0.82601988
Iteration 3110, loss = 0.82107235
Iteration 3111, loss = 0.82258675
Iteration 3112, loss = 0.81738852
Iteration 3113, loss = 0.81911049
Iteration 3114, loss = 0.81420700
Iteration 3115, loss = 0.81556160
Iteration 3116, loss = 0.81099601
Iteration 3117, loss = 0.81182871
Iteration 3118, loss = 0.80784887
Iteration 3119, loss = 0.80830554
Iteration 3120, loss = 0.80504347
Iteration 3121, loss = 0.80500189
Iteration 3122, loss = 0.80219992
Iteration 3123, loss = 0.80155697
Iteration 3124, loss = 0.79922964
Iteration 3125, loss = 0.79835335
Iteration 3126, loss = 0.79654499
Iteration 3127, loss = 0.79539989
Iteration 3128, loss = 0.79383536
Iteration 3129, loss = 0.79250016
Iteration 3130, loss = 0.79118030
Iteration 3131, loss = 0.78971955
Iteration 3132, loss = 0.78855369
Iteration 3133, loss = 0.78707379
Iteration 3134, loss = 0.78596402
Iteration 3135, loss = 0.78404721
Iteration 3136, loss = 0.78079861
Iteration 3137, loss = 0.76696826
Iteration 3138, loss = 0.87837975
Iteration 3139, loss = 0.88759749
Iteration 3140, loss = 0.86781225
Iteration 3141, loss = 0.88560860
Iteration 3142, loss = 0.81841629
Iteration 3143, loss = 0.84487534
Iteration 3144, loss = 0.82680479
Iteration 3145, loss = 0.82818679
Iteration 3146, loss = 0.84969468
Iteration 3147, loss = 0.82657902
Iteration 3148, loss = 0.84926740
Iteration 3149, loss = 0.82779946
Iteration 3150, loss = 0.83314635
Iteration 3151, loss = 0.83285971
Iteration 3152, loss = 0.81410143
Iteration 3153, loss = 0.90341345
Iteration 3154, loss = 1.53547269
Iteration 3155, loss = 0.92927365
Iteration 3156, loss = 1.92563893
Iteration 3157, loss = 1.22027536
Iteration 3158, loss = 1.79200076
Iteration 3159, loss = 1.65264692
Iteration 3160, loss = 1.08258669
Iteration 3161, loss = 1.48643348
Iteration 3162, loss = 0.89925123
Iteration 3163, loss = 1.40565266
Iteration 3164, loss = 1.04247785
Iteration 3165, loss = 1.33080229
Iteration 3166, loss = 1.21411949
Iteration 3167, loss = 1.14109368
Iteration 3168, loss = 1.23054643
Iteration 3169, loss = 0.98631583
Iteration 3170, loss = 1.17236840
Iteration 3171, loss = 0.92365004
Iteration 3172, loss = 1.12335674
Iteration 3173, loss = 0.91889067
Iteration 3174, loss = 1.08917544
Iteration 3175, loss = 0.93187338
Iteration 3176, loss = 1.05736512
Iteration 3177, loss = 0.94164759
Iteration 3178, loss = 1.02277921
Iteration 3179, loss = 0.94578587
Iteration 3180, loss = 0.99196683
Iteration 3181, loss = 0.94713937
Iteration 3182, loss = 0.96837560
Iteration 3183, loss = 0.94705637
Iteration 3184, loss = 0.94981398
Iteration 3185, loss = 0.94274900
Iteration 3186, loss = 0.93154711
Iteration 3187, loss = 0.93301202
Iteration 3188, loss = 0.89596364
Iteration 3189, loss = 0.93679203
Iteration 3190, loss = 0.94139562
Iteration 3191, loss = 0.93061363
Iteration 3192, loss = 0.92619127
Iteration 3193, loss = 0.92212209
Iteration 3194, loss = 0.92355647
Iteration 3195, loss = 0.91775324
Iteration 3196, loss = 0.92059040
Iteration 3197, loss = 0.91955360
Iteration 3198, loss = 0.92374910
Iteration 3199, loss = 0.91832670
Iteration 3200, loss = 0.91634945
Iteration 3201, loss = 0.90958956
Iteration 3202, loss = 0.91117005
Iteration 3203, loss = 0.90986716
Iteration 3204, loss = 0.91328644
Iteration 3205, loss = 0.91113291
Iteration 3206, loss = 0.91105280
Iteration 3207, loss = 0.90622723
Iteration 3208, loss = 0.90532512
Iteration 3209, loss = 0.90255474
Iteration 3210, loss = 0.90361569
Iteration 3211, loss = 0.90200381
Iteration 3212, loss = 0.90200666
Iteration 3213, loss = 0.89919667
Iteration 3214, loss = 0.89836417
Iteration 3215, loss = 0.89581730
Iteration 3216, loss = 0.89503000
Iteration 3217, loss = 0.89298192
Iteration 3218, loss = 0.89241842
Iteration 3219, loss = 0.89054101
Iteration 3220, loss = 0.88960557
Iteration 3221, loss = 0.88754035
Iteration 3222, loss = 0.88634213
Iteration 3223, loss = 0.88438473
Iteration 3224, loss = 0.88323161
Iteration 3225, loss = 0.88151178
Iteration 3226, loss = 0.88034798
Iteration 3227, loss = 0.87861661
Iteration 3228, loss = 0.87727707
Iteration 3229, loss = 0.87554167
Iteration 3230, loss = 0.87418907
Iteration 3231, loss = 0.87255923
Iteration 3232, loss = 0.87119780
Iteration 3233, loss = 0.86957583
Iteration 3234, loss = 0.86813013
Iteration 3235, loss = 0.86647515
Iteration 3236, loss = 0.86494018
Iteration 3237, loss = 0.86319056
Iteration 3238, loss = 0.86137910
Iteration 3239, loss = 0.85910344
Iteration 3240, loss = 0.85627220
Iteration 3241, loss = 0.85133978
Iteration 3242, loss = 0.86659216
Iteration 3243, loss = 0.90834875
Iteration 3244, loss = 0.85494880
Iteration 3245, loss = 0.97286792
Iteration 3246, loss = 0.87106886
Iteration 3247, loss = 0.94038959
Iteration 3248, loss = 0.86349918
Iteration 3249, loss = 0.91244098
Iteration 3250, loss = 0.86318118
Iteration 3251, loss = 0.89477959
Iteration 3252, loss = 0.86338039
Iteration 3253, loss = 0.87782054
Iteration 3254, loss = 0.86113862
Iteration 3255, loss = 0.86464278
Iteration 3256, loss = 0.85964765
Iteration 3257, loss = 0.85427186
Iteration 3258, loss = 0.85680579
Iteration 3259, loss = 0.84597056
Iteration 3260, loss = 0.85422853
Iteration 3261, loss = 0.84066853
Iteration 3262, loss = 0.85137093
Iteration 3263, loss = 0.83625365
Iteration 3264, loss = 0.84707958
Iteration 3265, loss = 0.83217909
Iteration 3266, loss = 0.84233227
Iteration 3267, loss = 0.82937356
Iteration 3268, loss = 0.83828831
Iteration 3269, loss = 0.82813369
Iteration 3270, loss = 0.83389353
Iteration 3271, loss = 0.82518460
Iteration 3272, loss = 0.82976533
Iteration 3273, loss = 0.82412511
Iteration 3274, loss = 0.82612199
Iteration 3275, loss = 0.82156826
Iteration 3276, loss = 0.83169083
Iteration 3277, loss = 0.94027632
Iteration 3278, loss = 0.83082446
Iteration 3279, loss = 0.93063053
Iteration 3280, loss = 0.83472323
Iteration 3281, loss = 0.89807789
Iteration 3282, loss = 0.81255832
Iteration 3283, loss = 0.96821463
Iteration 3284, loss = 0.83086141
Iteration 3285, loss = 0.94402591
Iteration 3286, loss = 0.81584465
Iteration 3287, loss = 0.91819060
Iteration 3288, loss = 0.81168380
Iteration 3289, loss = 0.89688588
Iteration 3290, loss = 0.80966756
Iteration 3291, loss = 0.87882780
Iteration 3292, loss = 0.80922307
Iteration 3293, loss = 0.86375441
Iteration 3294, loss = 0.80875268
Iteration 3295, loss = 0.85106211
Iteration 3296, loss = 0.80803784
Iteration 3297, loss = 0.84042963
Iteration 3298, loss = 0.80682120
Iteration 3299, loss = 0.83148078
Iteration 3300, loss = 0.80532987
Iteration 3301, loss = 0.82398139
Iteration 3302, loss = 0.80349441
Iteration 3303, loss = 0.81754406
Iteration 3304, loss = 0.80148937
Iteration 3305, loss = 0.81213846
Iteration 3306, loss = 0.79952786
Iteration 3307, loss = 0.80761537
Iteration 3308, loss = 0.79758899
Iteration 3309, loss = 0.80367701
Iteration 3310, loss = 0.79559167
Iteration 3311, loss = 0.80018938
Iteration 3312, loss = 0.79363833
Iteration 3313, loss = 0.79715895
Iteration 3314, loss = 0.79182946
Iteration 3315, loss = 0.79453726
Iteration 3316, loss = 0.79010821
Iteration 3317, loss = 0.79212940
Iteration 3318, loss = 0.78837291
Iteration 3319, loss = 0.78988553
Iteration 3320, loss = 0.78657242
Iteration 3321, loss = 0.79576256
Iteration 3322, loss = 0.78536637
Iteration 3323, loss = 0.79141804
Iteration 3324, loss = 0.78465623
Iteration 3325, loss = 0.78401891
Iteration 3326, loss = 0.78372099
Iteration 3327, loss = 0.78306271
Iteration 3328, loss = 0.78154778
Iteration 3329, loss = 0.78059406
Iteration 3330, loss = 0.77964168
Iteration 3331, loss = 0.77931949
Iteration 3332, loss = 0.77891079
Iteration 3333, loss = 0.77835213
Iteration 3334, loss = 0.77730404
Iteration 3335, loss = 0.77645796
Iteration 3336, loss = 0.77550828
Iteration 3337, loss = 0.77482328
Iteration 3338, loss = 0.77411915
Iteration 3339, loss = 0.77308857
Iteration 3340, loss = 0.77178475
Iteration 3341, loss = 0.77033561
Iteration 3342, loss = 0.76824271
Iteration 3343, loss = 0.76421806
Iteration 3344, loss = 0.74364004
Iteration 3345, loss = 0.82462850
Iteration 3346, loss = 0.85518836
Iteration 3347, loss = 0.80701501
Iteration 3348, loss = 0.85361708
Iteration 3349, loss = 0.78650599
Iteration 3350, loss = 0.84852531
Iteration 3351, loss = 0.78194713
Iteration 3352, loss = 0.84521012
Iteration 3353, loss = 0.78455118
Iteration 3354, loss = 0.83618146
Iteration 3355, loss = 0.78688714
Iteration 3356, loss = 0.82239561
Iteration 3357, loss = 0.79033937
Iteration 3358, loss = 0.81028214
Iteration 3359, loss = 0.79594032
Iteration 3360, loss = 0.80055345
Iteration 3361, loss = 0.79957361
Iteration 3362, loss = 0.79262361
Iteration 3363, loss = 0.80124863
Iteration 3364, loss = 0.78815415
Iteration 3365, loss = 0.80060226
Iteration 3366, loss = 0.78510247
Iteration 3367, loss = 0.79691236
Iteration 3368, loss = 0.78368154
Iteration 3369, loss = 0.79296183
Iteration 3370, loss = 0.78416226
Iteration 3371, loss = 0.78874975
Iteration 3372, loss = 0.78405158
Iteration 3373, loss = 0.78400129
Iteration 3374, loss = 0.78324265
Iteration 3375, loss = 0.78026737
Iteration 3376, loss = 0.78220462
Iteration 3377, loss = 0.77766731
Iteration 3378, loss = 0.78045523
Iteration 3379, loss = 0.77563507
Iteration 3380, loss = 0.77794002
Iteration 3381, loss = 0.77394564
Iteration 3382, loss = 0.77515297
Iteration 3383, loss = 0.77261456
Iteration 3384, loss = 0.77254904
Iteration 3385, loss = 0.77133911
Iteration 3386, loss = 0.77008535
Iteration 3387, loss = 0.76978783
Iteration 3388, loss = 0.76788295
Iteration 3389, loss = 0.76808757
Iteration 3390, loss = 0.76605171
Iteration 3391, loss = 0.76623967
Iteration 3392, loss = 0.76441137
Iteration 3393, loss = 0.76429164
Iteration 3394, loss = 0.76292090
Iteration 3395, loss = 0.76240470
Iteration 3396, loss = 0.76147953
Iteration 3397, loss = 0.76058649
Iteration 3398, loss = 0.75999306
Iteration 3399, loss = 0.75889840
Iteration 3400, loss = 0.75847640
Iteration 3401, loss = 0.75734619
Iteration 3402, loss = 0.75693459
Iteration 3403, loss = 0.75589815
Iteration 3404, loss = 0.75537816
Iteration 3405, loss = 0.75448354
Iteration 3406, loss = 0.75381290
Iteration 3407, loss = 0.75304946
Iteration 3408, loss = 0.75224780
Iteration 3409, loss = 0.75158964
Iteration 3410, loss = 0.75074949
Iteration 3411, loss = 0.75015480
Iteration 3412, loss = 0.74932228
Iteration 3413, loss = 0.74871792
Iteration 3414, loss = 0.74793591
Iteration 3415, loss = 0.74730825
Iteration 3416, loss = 0.74661220
Iteration 3417, loss = 0.74600854
Iteration 3418, loss = 0.74546784
Iteration 3419, loss = 0.74488950
Iteration 3420, loss = 0.74434628
Iteration 3421, loss = 0.74371398
Iteration 3422, loss = 0.74317254
Iteration 3423, loss = 0.74256336
Iteration 3424, loss = 0.74204948
Iteration 3425, loss = 0.74151177
Iteration 3426, loss = 0.74102290
Iteration 3427, loss = 0.74053670
Iteration 3428, loss = 0.74005236
Iteration 3429, loss = 0.73959297
Iteration 3430, loss = 0.73911235
Iteration 3431, loss = 0.73865962
Iteration 3432, loss = 0.73818100
Iteration 3433, loss = 0.73773469
Iteration 3434, loss = 0.73726451
Iteration 3435, loss = 0.73680929
Iteration 3436, loss = 0.73634847
Iteration 3437, loss = 0.73588395
Iteration 3438, loss = 0.73542894
Iteration 3439, loss = 0.73498537
Iteration 3440, loss = 0.73455278
Iteration 3441, loss = 0.73410846
Iteration 3442, loss = 0.73367753
Iteration 3443, loss = 0.73322910
Iteration 3444, loss = 0.73275993
Iteration 3445, loss = 0.73220692
Iteration 3446, loss = 0.73139088
Iteration 3447, loss = 0.72906017
Iteration 3448, loss = 0.73399425
Iteration 3449, loss = 0.70771834
Iteration 3450, loss = 0.74739552
Iteration 3451, loss = 0.74445180
Iteration 3452, loss = 0.75268096
Iteration 3453, loss = 0.73872967
Iteration 3454, loss = 0.74689404
Iteration 3455, loss = 0.74105493
Iteration 3456, loss = 0.74592803
Iteration 3457, loss = 0.74920826
Iteration 3458, loss = 0.74621769
Iteration 3459, loss = 0.75211896
Iteration 3460, loss = 0.74705045
Iteration 3461, loss = 0.75139314
Iteration 3462, loss = 0.74962434
Iteration 3463, loss = 0.74904466
Iteration 3464, loss = 0.75066015
Iteration 3465, loss = 0.74736892
Iteration 3466, loss = 0.74826278
Iteration 3467, loss = 0.74609538
Iteration 3468, loss = 0.74366731
Iteration 3469, loss = 0.73705705
Iteration 3470, loss = 0.85572628
Iteration 3471, loss = 0.94728463
Iteration 3472, loss = 0.79881191
Iteration 3473, loss = 0.97032693
Iteration 3474, loss = 0.76278645
Iteration 3475, loss = 0.90778889
Iteration 3476, loss = 0.78696099
Iteration 3477, loss = 0.83639583
Iteration 3478, loss = 0.84141404
Iteration 3479, loss = 0.77606835
Iteration 3480, loss = 0.85288397
Iteration 3481, loss = 0.75892754
Iteration 3482, loss = 0.82415435
Iteration 3483, loss = 0.77946891
Iteration 3484, loss = 0.78057514
Iteration 3485, loss = 0.80308325
Iteration 3486, loss = 0.75711189
Iteration 3487, loss = 0.79996497
Iteration 3488, loss = 0.75923804
Iteration 3489, loss = 0.77401128
Iteration 3490, loss = 0.77306144
Iteration 3491, loss = 0.75393238
Iteration 3492, loss = 0.77757562
Iteration 3493, loss = 0.75113862
Iteration 3494, loss = 0.76508395
Iteration 3495, loss = 0.75818345
Iteration 3496, loss = 0.75048156
Iteration 3497, loss = 0.76195775
Iteration 3498, loss = 0.74589767
Iteration 3499, loss = 0.75576165
Iteration 3500, loss = 0.74933152
Iteration 3501, loss = 0.74654116
Iteration 3502, loss = 0.75192226
Iteration 3503, loss = 0.74229572
Iteration 3504, loss = 0.74831263
Iteration 3505, loss = 0.74331649
Iteration 3506, loss = 0.74158291
Iteration 3507, loss = 0.77922857
Iteration 3508, loss = 0.76493874
Iteration 3509, loss = 0.75439303
Iteration 3510, loss = 0.78000113
Iteration 3511, loss = 0.74234407
Iteration 3512, loss = 0.77450396
Iteration 3513, loss = 0.74095972
Iteration 3514, loss = 0.75798375
Iteration 3515, loss = 0.74912932
Iteration 3516, loss = 0.74315743
Iteration 3517, loss = 0.75431255
Iteration 3518, loss = 0.73550220
Iteration 3519, loss = 0.75113465
Iteration 3520, loss = 0.73578052
Iteration 3521, loss = 0.74263627
Iteration 3522, loss = 0.73960645
Iteration 3523, loss = 0.73479000
Iteration 3524, loss = 0.74094822
Iteration 3525, loss = 0.73100749
Iteration 3526, loss = 0.73822157
Iteration 3527, loss = 0.73176376
Iteration 3528, loss = 0.73357356
Iteration 3529, loss = 0.73330139
Iteration 3530, loss = 0.72938099
Iteration 3531, loss = 0.73296640
Iteration 3532, loss = 0.72796655
Iteration 3533, loss = 0.73086959
Iteration 3534, loss = 0.72835473
Iteration 3535, loss = 0.72791048
Iteration 3536, loss = 0.72856180
Iteration 3537, loss = 0.72593017
Iteration 3538, loss = 0.72778722
Iteration 3539, loss = 0.72535257
Iteration 3540, loss = 0.72604109
Iteration 3541, loss = 0.72528397
Iteration 3542, loss = 0.72430563
Iteration 3543, loss = 0.72495258
Iteration 3544, loss = 0.72330929
Iteration 3545, loss = 0.72421029
Iteration 3546, loss = 0.73745603
Iteration 3547, loss = 0.74842609
Iteration 3548, loss = 0.75705441
Iteration 3549, loss = 0.74714640
Iteration 3550, loss = 0.73656761
Iteration 3551, loss = 0.73165350
Iteration 3552, loss = 0.72948714
Iteration 3553, loss = 0.73485140
Iteration 3554, loss = 0.73477849
Iteration 3555, loss = 0.73585394
Iteration 3556, loss = 0.73418763
Iteration 3557, loss = 0.73200577
Iteration 3558, loss = 0.73225509
Iteration 3559, loss = 0.73053726
Iteration 3560, loss = 0.73123025
Iteration 3561, loss = 0.72988163
Iteration 3562, loss = 0.72903278
Iteration 3563, loss = 0.72891904
Iteration 3564, loss = 0.72831043
Iteration 3565, loss = 0.72926556
Iteration 3566, loss = 0.72860179
Iteration 3567, loss = 0.72802173
Iteration 3568, loss = 0.72712496
Iteration 3569, loss = 0.72603861
Iteration 3570, loss = 0.72595788
Iteration 3571, loss = 0.72540094
Iteration 3572, loss = 0.72558368
Iteration 3573, loss = 0.72544089
Iteration 3574, loss = 0.72473564
Iteration 3575, loss = 0.72433882
Iteration 3576, loss = 0.72353338
Iteration 3577, loss = 0.72303547
Iteration 3578, loss = 0.72225406
Iteration 3579, loss = 0.72168429
Iteration 3580, loss = 0.71978860
Iteration 3581, loss = 0.70806026
Iteration 3582, loss = 0.74584961
Iteration 3583, loss = 0.77160511
Iteration 3584, loss = 0.73423465
Iteration 3585, loss = 0.77262405
Iteration 3586, loss = 0.72605393
Iteration 3587, loss = 0.75713569
Iteration 3588, loss = 0.72855574
Iteration 3589, loss = 0.74137509
Iteration 3590, loss = 0.73849009
Iteration 3591, loss = 0.73077016
Iteration 3592, loss = 0.74342376
Iteration 3593, loss = 0.72415540
Iteration 3594, loss = 0.74018393
Iteration 3595, loss = 0.72345276
Iteration 3596, loss = 0.73307407
Iteration 3597, loss = 0.72686949
Iteration 3598, loss = 0.72640047
Iteration 3599, loss = 0.72962062
Iteration 3600, loss = 0.72198803
Iteration 3601, loss = 0.72928299
Iteration 3602, loss = 0.72095128
Iteration 3603, loss = 0.72641855
Iteration 3604, loss = 0.72196057
Iteration 3605, loss = 0.72259123
Iteration 3606, loss = 0.72294816
Iteration 3607, loss = 0.71975995
Iteration 3608, loss = 0.72284452
Iteration 3609, loss = 0.71877327
Iteration 3610, loss = 0.72152186
Iteration 3611, loss = 0.71899432
Iteration 3612, loss = 0.71947267
Iteration 3613, loss = 0.71919598
Iteration 3614, loss = 0.71766374
Iteration 3615, loss = 0.71889287
Iteration 3616, loss = 0.71682803
Iteration 3617, loss = 0.71806044
Iteration 3618, loss = 0.71666220
Iteration 3619, loss = 0.71678421
Iteration 3620, loss = 0.71646515
Iteration 3621, loss = 0.71563285
Iteration 3622, loss = 0.71605209
Iteration 3623, loss = 0.71489872
Iteration 3624, loss = 0.71537730
Iteration 3625, loss = 0.71459658
Iteration 3626, loss = 0.71450407
Iteration 3627, loss = 0.71425423
Iteration 3628, loss = 0.71367268
Iteration 3629, loss = 0.71372843
Iteration 3630, loss = 0.71304427
Iteration 3631, loss = 0.71338089
Iteration 3632, loss = 0.71287764
Iteration 3633, loss = 0.71221177
Iteration 3634, loss = 0.71159831
Iteration 3635, loss = 0.71114976
Iteration 3636, loss = 0.71053262
Iteration 3637, loss = 0.70255814
Iteration 3638, loss = 0.73118312
Iteration 3639, loss = 0.75304673
Iteration 3640, loss = 0.71632912
Iteration 3641, loss = 0.75233748
Iteration 3642, loss = 0.71840688
Iteration 3643, loss = 0.73053399
Iteration 3644, loss = 0.72971052
Iteration 3645, loss = 0.71380823
Iteration 3646, loss = 0.73418321
Iteration 3647, loss = 0.71248229
Iteration 3648, loss = 0.72459061
Iteration 3649, loss = 0.71965518
Iteration 3650, loss = 0.71182771
Iteration 3651, loss = 0.72420314
Iteration 3652, loss = 0.71252003
Iteration 3653, loss = 0.72261325
Iteration 3654, loss = 0.71655266
Iteration 3655, loss = 0.71451193
Iteration 3656, loss = 0.71623939
Iteration 3657, loss = 0.70924094
Iteration 3658, loss = 0.71597157
Iteration 3659, loss = 0.70974409
Iteration 3660, loss = 0.71367758
Iteration 3661, loss = 0.71086393
Iteration 3662, loss = 0.70974089
Iteration 3663, loss = 0.71108487
Iteration 3664, loss = 0.70741141
Iteration 3665, loss = 0.71047466
Iteration 3666, loss = 0.70726761
Iteration 3667, loss = 0.70856822
Iteration 3668, loss = 0.70736435
Iteration 3669, loss = 0.70645285
Iteration 3670, loss = 0.70729114
Iteration 3671, loss = 0.70513104
Iteration 3672, loss = 0.70619270
Iteration 3673, loss = 0.70441562
Iteration 3674, loss = 0.70414767
Iteration 3675, loss = 0.70273550
Iteration 3676, loss = 0.70157472
Iteration 3677, loss = 0.70087905
Iteration 3678, loss = 0.69790323
Iteration 3679, loss = 0.69734513
Iteration 3680, loss = 0.69039136
Iteration 3681, loss = 0.79270549
Iteration 3682, loss = 0.82979519
Iteration 3683, loss = 0.75613617
Iteration 3684, loss = 0.84112949
Iteration 3685, loss = 0.72638366
Iteration 3686, loss = 0.83551704
Iteration 3687, loss = 0.71265629
Iteration 3688, loss = 0.82500452
Iteration 3689, loss = 0.71217907
Iteration 3690, loss = 0.80605050
Iteration 3691, loss = 0.71593347
Iteration 3692, loss = 0.77965026
Iteration 3693, loss = 0.72238044
Iteration 3694, loss = 0.75304399
Iteration 3695, loss = 0.73120104
Iteration 3696, loss = 0.73228042
Iteration 3697, loss = 0.73899266
Iteration 3698, loss = 0.71883074
Iteration 3699, loss = 0.74196503
Iteration 3700, loss = 0.71206034
Iteration 3701, loss = 0.73920808
Iteration 3702, loss = 0.71051549
Iteration 3703, loss = 0.73215114
Iteration 3704, loss = 0.71220503
Iteration 3705, loss = 0.72358049
Iteration 3706, loss = 0.71536087
Iteration 3707, loss = 0.71622382
Iteration 3708, loss = 0.71801739
Iteration 3709, loss = 0.71115655
Iteration 3710, loss = 0.71857585
Iteration 3711, loss = 0.70843652
Iteration 3712, loss = 0.71688551
Iteration 3713, loss = 0.70776384
Iteration 3714, loss = 0.71391649
Iteration 3715, loss = 0.70840098
Iteration 3716, loss = 0.71071672
Iteration 3717, loss = 0.70927331
Iteration 3718, loss = 0.70799325
Iteration 3719, loss = 0.70951173
Iteration 3720, loss = 0.70607289
Iteration 3721, loss = 0.70863401
Iteration 3722, loss = 0.70489249
Iteration 3723, loss = 0.70750292
Iteration 3724, loss = 0.70472508
Iteration 3725, loss = 0.70540430
Iteration 3726, loss = 0.70451831
Iteration 3727, loss = 0.70509221
Iteration 3728, loss = 0.70510640
Iteration 3729, loss = 0.70285941
Iteration 3730, loss = 0.70307866
Iteration 3731, loss = 0.70149473
Iteration 3732, loss = 0.70198759
Iteration 3733, loss = 0.70051406
Iteration 3734, loss = 0.69937946
Iteration 3735, loss = 0.69453392
Iteration 3736, loss = 0.56523242
Iteration 3737, loss = 0.83482766
Iteration 3738, loss = 0.76177210
Iteration 3739, loss = 0.84546429
Iteration 3740, loss = 0.76850918
Iteration 3741, loss = 0.88490459
Iteration 3742, loss = 0.95257523
Iteration 3743, loss = 0.81079058
Iteration 3744, loss = 0.96757961
Iteration 3745, loss = 0.77707210
Iteration 3746, loss = 0.97802519
Iteration 3747, loss = 0.77411616
Iteration 3748, loss = 0.97584377
Iteration 3749, loss = 0.77800486
Iteration 3750, loss = 0.94774698
Iteration 3751, loss = 0.78017911
Iteration 3752, loss = 0.90213417
Iteration 3753, loss = 0.79053134
Iteration 3754, loss = 0.85626870
Iteration 3755, loss = 0.81217360
Iteration 3756, loss = 0.82015109
Iteration 3757, loss = 0.83255085
Iteration 3758, loss = 0.79571398
Iteration 3759, loss = 0.83993741
Iteration 3760, loss = 0.78420185
Iteration 3761, loss = 0.83441914
Iteration 3762, loss = 0.78590572
Iteration 3763, loss = 0.82134820
Iteration 3764, loss = 0.79467054
Iteration 3765, loss = 0.80478280
Iteration 3766, loss = 0.80200712
Iteration 3767, loss = 0.79030113
Iteration 3768, loss = 0.80445583
Iteration 3769, loss = 0.78321049
Iteration 3770, loss = 0.80226692
Iteration 3771, loss = 0.78336465
Iteration 3772, loss = 0.79621399
Iteration 3773, loss = 0.78647012
Iteration 3774, loss = 0.78852633
Iteration 3775, loss = 0.78881443
Iteration 3776, loss = 0.78229063
Iteration 3777, loss = 0.78867914
Iteration 3778, loss = 0.77918193
Iteration 3779, loss = 0.78605414
Iteration 3780, loss = 0.77873806
Iteration 3781, loss = 0.78193664
Iteration 3782, loss = 0.77880464
Iteration 3783, loss = 0.77512402
Iteration 3784, loss = 0.77238553
Iteration 3785, loss = 0.80141536
Iteration 3786, loss = 0.78568993
Iteration 3787, loss = 0.79925455
Iteration 3788, loss = 0.78000391
Iteration 3789, loss = 0.78595264
Iteration 3790, loss = 0.78086189
Iteration 3791, loss = 0.77985084
Iteration 3792, loss = 0.78348082
Iteration 3793, loss = 0.77526574
Iteration 3794, loss = 0.78210441
Iteration 3795, loss = 0.77388778
Iteration 3796, loss = 0.77877471
Iteration 3797, loss = 0.77306382
Iteration 3798, loss = 0.77299772
Iteration 3799, loss = 0.77263051
Iteration 3800, loss = 0.77018903
Iteration 3801, loss = 0.77307493
Iteration 3802, loss = 0.76879098
Iteration 3803, loss = 0.77077573
Iteration 3804, loss = 0.76727674
Iteration 3805, loss = 0.76797624
Iteration 3806, loss = 0.76702086
Iteration 3807, loss = 0.76593727
Iteration 3808, loss = 0.76653313
Iteration 3809, loss = 0.76430759
Iteration 3810, loss = 0.76512804
Iteration 3811, loss = 0.76313202
Iteration 3812, loss = 0.76341072
Iteration 3813, loss = 0.76244343
Iteration 3814, loss = 0.76181966
Iteration 3815, loss = 0.76174728
Iteration 3816, loss = 0.76053826
Iteration 3817, loss = 0.76065131
Iteration 3818, loss = 0.75936268
Iteration 3819, loss = 0.75930743
Iteration 3820, loss = 0.75861320
Iteration 3821, loss = 0.75819160
Iteration 3822, loss = 0.75785176
Iteration 3823, loss = 0.75698928
Iteration 3824, loss = 0.75677340
Iteration 3825, loss = 0.75596180
Iteration 3826, loss = 0.75577488
Iteration 3827, loss = 0.75521380
Iteration 3828, loss = 0.75476852
Iteration 3829, loss = 0.75434234
Iteration 3830, loss = 0.75371698
Iteration 3831, loss = 0.75342784
Iteration 3832, loss = 0.75284153
Iteration 3833, loss = 0.75252731
Iteration 3834, loss = 0.75202857
Iteration 3835, loss = 0.75160381
Iteration 3836, loss = 0.75120793
Iteration 3837, loss = 0.75070884
Iteration 3838, loss = 0.75036181
Iteration 3839, loss = 0.74987238
Iteration 3840, loss = 0.74952373
Iteration 3841, loss = 0.74909924
Iteration 3842, loss = 0.74869623
Iteration 3843, loss = 0.74830835
Iteration 3844, loss = 0.74786920
Iteration 3845, loss = 0.74751513
Iteration 3846, loss = 0.74709486
Iteration 3847, loss = 0.74673699
Iteration 3848, loss = 0.74634907
Iteration 3849, loss = 0.74596684
Iteration 3850, loss = 0.74539253
Iteration 3851, loss = 0.74939095
Iteration 3852, loss = 0.88051839
Iteration 3853, loss = 0.78341428
Iteration 3854, loss = 0.81801550
Iteration 3855, loss = 0.79776719
Iteration 3856, loss = 0.79747612
Iteration 3857, loss = 0.82548862
Iteration 3858, loss = 0.78085947
Iteration 3859, loss = 0.83007241
Iteration 3860, loss = 0.78547776
Iteration 3861, loss = 0.82107095
Iteration 3862, loss = 0.79634551
Iteration 3863, loss = 0.80378575
Iteration 3864, loss = 0.80860694
Iteration 3865, loss = 0.79281067
Iteration 3866, loss = 0.81153772
Iteration 3867, loss = 0.78691454
Iteration 3868, loss = 0.80280163
Iteration 3869, loss = 0.78767532
Iteration 3870, loss = 0.79169546
Iteration 3871, loss = 0.79042226
Iteration 3872, loss = 0.78109627
Iteration 3873, loss = 0.78720892
Iteration 3874, loss = 0.77376186
Iteration 3875, loss = 0.78036576
Iteration 3876, loss = 0.77204765
Iteration 3877, loss = 0.77233412
Iteration 3878, loss = 0.77000744
Iteration 3879, loss = 0.76374206
Iteration 3880, loss = 0.76599178
Iteration 3881, loss = 0.75898779
Iteration 3882, loss = 0.76119548
Iteration 3883, loss = 0.75620112
Iteration 3884, loss = 0.75471997
Iteration 3885, loss = 0.75328546
Iteration 3886, loss = 0.74961065
Iteration 3887, loss = 0.75039983
Iteration 3888, loss = 0.74624616
Iteration 3889, loss = 0.74632829
Iteration 3890, loss = 0.74371137
Iteration 3891, loss = 0.74243447
Iteration 3892, loss = 0.74178246
Iteration 3893, loss = 0.73937644
Iteration 3894, loss = 0.73939266
Iteration 3895, loss = 0.73717071
Iteration 3896, loss = 0.73692289
Iteration 3897, loss = 0.73574535
Iteration 3898, loss = 0.73469824
Iteration 3899, loss = 0.73434046
Iteration 3900, loss = 0.73294878
Iteration 3901, loss = 0.73289516
Iteration 3902, loss = 0.73183106
Iteration 3903, loss = 0.73147562
Iteration 3904, loss = 0.73092927
Iteration 3905, loss = 0.73020890
Iteration 3906, loss = 0.73005670
Iteration 3907, loss = 0.72930276
Iteration 3908, loss = 0.72916078
Iteration 3909, loss = 0.72861839
Iteration 3910, loss = 0.72827141
Iteration 3911, loss = 0.72801586
Iteration 3912, loss = 0.72753681
Iteration 3913, loss = 0.72739510
Iteration 3914, loss = 0.72694291
Iteration 3915, loss = 0.72674269
Iteration 3916, loss = 0.72644760
Iteration 3917, loss = 0.72614224
Iteration 3918, loss = 0.72595716
Iteration 3919, loss = 0.72560605
Iteration 3920, loss = 0.72543631
Iteration 3921, loss = 0.72514788
Iteration 3922, loss = 0.72492677
Iteration 3923, loss = 0.72471288
Iteration 3924, loss = 0.72443837
Iteration 3925, loss = 0.72425751
Iteration 3926, loss = 0.72398774
Iteration 3927, loss = 0.72378145
Iteration 3928, loss = 0.72348233
Iteration 3929, loss = 0.72286554
Iteration 3930, loss = 0.72149987
Iteration 3931, loss = 0.72546468
Iteration 3932, loss = 0.72549170
Iteration 3933, loss = 0.72447678
Iteration 3934, loss = 0.72457535
Iteration 3935, loss = 0.72237425
Iteration 3936, loss = 0.72386113
Iteration 3937, loss = 0.72321280
Iteration 3938, loss = 0.72315891
Iteration 3939, loss = 0.72311786
Iteration 3940, loss = 0.72179046
Iteration 3941, loss = 0.72245611
Iteration 3942, loss = 0.72130498
Iteration 3943, loss = 0.72185871
Iteration 3944, loss = 0.72209157
Iteration 3945, loss = 0.72151430
Iteration 3946, loss = 0.72074435
Iteration 3947, loss = 0.71980709
Iteration 3948, loss = 0.72007689
Iteration 3949, loss = 0.71980460
Iteration 3950, loss = 0.71964253
Iteration 3951, loss = 0.71925894
Iteration 3952, loss = 0.71829265
Iteration 3953, loss = 0.71771686
Iteration 3954, loss = 0.71611785
Iteration 3955, loss = 0.71490734
Iteration 3956, loss = 0.71342724
Iteration 3957, loss = 0.70935417
Iteration 3958, loss = 0.60583546
Iteration 3959, loss = 0.75342335
Iteration 3960, loss = 0.84535083
Iteration 3961, loss = 0.74400786
Iteration 3962, loss = 0.84112277
Iteration 3963, loss = 0.73320202
Iteration 3964, loss = 0.81985953
Iteration 3965, loss = 0.73411612
Iteration 3966, loss = 0.79903885
Iteration 3967, loss = 0.74781459
Iteration 3968, loss = 0.78034271
Iteration 3969, loss = 0.76278033
Iteration 3970, loss = 0.76289079
Iteration 3971, loss = 0.77186483
Iteration 3972, loss = 0.74994271
Iteration 3973, loss = 0.77436128
Iteration 3974, loss = 0.74495897
Iteration 3975, loss = 0.77280682
Iteration 3976, loss = 0.74751004
Iteration 3977, loss = 0.76811302
Iteration 3978, loss = 0.75253873
Iteration 3979, loss = 0.76041321
Iteration 3980, loss = 0.75601305
Iteration 3981, loss = 0.75308233
Iteration 3982, loss = 0.75835020
Iteration 3983, loss = 0.74965124
Iteration 3984, loss = 0.75914265
Iteration 3985, loss = 0.74903023
Iteration 3986, loss = 0.75721655
Iteration 3987, loss = 0.74932354
Iteration 3988, loss = 0.75358727
Iteration 3989, loss = 0.75026759
Iteration 3990, loss = 0.75027267
Iteration 3991, loss = 0.75072720
Iteration 3992, loss = 0.74746264
Iteration 3993, loss = 0.74989429
Iteration 3994, loss = 0.74553057
Iteration 3995, loss = 0.74815503
Iteration 3996, loss = 0.74407861
Iteration 3997, loss = 0.74521401
Iteration 3998, loss = 0.74245150
Iteration 3999, loss = 0.74163823
Iteration 4000, loss = 0.74059630
Iteration 4001, loss = 0.73854556
Iteration 4002, loss = 0.73790048
Iteration 4003, loss = 0.73299922
Iteration 4004, loss = 0.73036354
Iteration 4005, loss = 0.78770989
Iteration 4006, loss = 1.14325435
Iteration 4007, loss = 0.81699213
Iteration 4008, loss = 1.14035852
Iteration 4009, loss = 0.80932544
Iteration 4010, loss = 1.07356811
Iteration 4011, loss = 0.78794898
Iteration 4012, loss = 0.97882515
Iteration 4013, loss = 0.81964471
Iteration 4014, loss = 0.93210495
Iteration 4015, loss = 0.85510527
Iteration 4016, loss = 0.88166573
Iteration 4017, loss = 0.86601978
Iteration 4018, loss = 0.83766426
Iteration 4019, loss = 0.85879946
Iteration 4020, loss = 0.80301107
Iteration 4021, loss = 0.84750548
Iteration 4022, loss = 0.78352767
Iteration 4023, loss = 0.83668151
Iteration 4024, loss = 0.77535154
Iteration 4025, loss = 0.82732892
Iteration 4026, loss = 0.77036885
Iteration 4027, loss = 0.81596017
Iteration 4028, loss = 0.76666661
Iteration 4029, loss = 0.80447958
Iteration 4030, loss = 0.76275983
Iteration 4031, loss = 0.79489170
Iteration 4032, loss = 0.76190115
Iteration 4033, loss = 0.78820960
Iteration 4034, loss = 0.76172902
Iteration 4035, loss = 0.78163202
Iteration 4036, loss = 0.76025217
Iteration 4037, loss = 0.77505868
Iteration 4038, loss = 0.75836241
Iteration 4039, loss = 0.76963629
Iteration 4040, loss = 0.75724851
Iteration 4041, loss = 0.76544351
Iteration 4042, loss = 0.75599195
Iteration 4043, loss = 0.76189026
Iteration 4044, loss = 0.75482565
Iteration 4045, loss = 0.75745514
Iteration 4046, loss = 0.75827259
Iteration 4047, loss = 0.76990917
Iteration 4048, loss = 0.76157924
Iteration 4049, loss = 0.76979966
Iteration 4050, loss = 0.75543880
Iteration 4051, loss = 0.76153138
Iteration 4052, loss = 0.74969618
Iteration 4053, loss = 0.75865263
Iteration 4054, loss = 0.75023220
Iteration 4055, loss = 0.75791107
Iteration 4056, loss = 0.74950255
Iteration 4057, loss = 0.75453362
Iteration 4058, loss = 0.74750136
Iteration 4059, loss = 0.75094086
Iteration 4060, loss = 0.74602007
Iteration 4061, loss = 0.74872152
Iteration 4062, loss = 0.74544373
Iteration 4063, loss = 0.74659127
Iteration 4064, loss = 0.74447678
Iteration 4065, loss = 0.74464675
Iteration 4066, loss = 0.74363191
Iteration 4067, loss = 0.74297864
Iteration 4068, loss = 0.74248260
Iteration 4069, loss = 0.74104240
Iteration 4070, loss = 0.74108698
Iteration 4071, loss = 0.73981927
Iteration 4072, loss = 0.74036603
Iteration 4073, loss = 0.73885002
Iteration 4074, loss = 0.73914732
Iteration 4075, loss = 0.73753774
Iteration 4076, loss = 0.73780710
Iteration 4077, loss = 0.73647707
Iteration 4078, loss = 0.73673895
Iteration 4079, loss = 0.73569313
Iteration 4080, loss = 0.73575876
Iteration 4081, loss = 0.73478284
Iteration 4082, loss = 0.73454488
Iteration 4083, loss = 0.73378592
Iteration 4084, loss = 0.73351104
Iteration 4085, loss = 0.73300352
Iteration 4086, loss = 0.73260940
Iteration 4087, loss = 0.73217330
Iteration 4088, loss = 0.73164248
Iteration 4089, loss = 0.73126694
Iteration 4090, loss = 0.73070087
Iteration 4091, loss = 0.73039049
Iteration 4092, loss = 0.72943207
Iteration 4093, loss = 0.72932260
Iteration 4094, loss = 0.72956895
Iteration 4095, loss = 0.72914950
Iteration 4096, loss = 0.72811150
Iteration 4097, loss = 0.72714840
Iteration 4098, loss = 0.72573788
Iteration 4099, loss = 0.72388710
Iteration 4100, loss = 0.72202721
Iteration 4101, loss = 0.71735724
Iteration 4102, loss = 0.78218124
Iteration 4103, loss = 1.04094382
Iteration 4104, loss = 0.77781702
Iteration 4105, loss = 1.02448065
Iteration 4106, loss = 0.76393029
Iteration 4107, loss = 0.93990887
Iteration 4108, loss = 0.74040487
Iteration 4109, loss = 0.88181325
Iteration 4110, loss = 0.75586310
Iteration 4111, loss = 0.84734855
Iteration 4112, loss = 0.77681289
Iteration 4113, loss = 0.79922570
Iteration 4114, loss = 0.77321521
Iteration 4115, loss = 0.72568644
Iteration 4116, loss = 0.76565719
Iteration 4117, loss = 0.77134423
Iteration 4118, loss = 0.78765940
Iteration 4119, loss = 0.76548803
Iteration 4120, loss = 0.78644158
Iteration 4121, loss = 0.75792797
Iteration 4122, loss = 0.78327392
Iteration 4123, loss = 0.76875420
Iteration 4124, loss = 0.77279418
Iteration 4125, loss = 0.76171522
Iteration 4126, loss = 0.76131112
Iteration 4127, loss = 0.76719041
Iteration 4128, loss = 0.76064138
Iteration 4129, loss = 0.76248538
Iteration 4130, loss = 0.74495689
Iteration 4131, loss = 0.74353971
Iteration 4132, loss = 0.98989064
Iteration 4133, loss = 1.88368971
Iteration 4134, loss = 1.39352027
Iteration 4135, loss = 1.47072932
Iteration 4136, loss = 1.72830942
Iteration 4137, loss = 0.92551358
Iteration 4138, loss = 1.53668549
Iteration 4139, loss = 0.96292208
Iteration 4140, loss = 1.37888195
Iteration 4141, loss = 1.16905334
Iteration 4142, loss = 1.01955853
Iteration 4143, loss = 1.21234988
Iteration 4144, loss = 0.84115416
Iteration 4145, loss = 1.16067845
Iteration 4146, loss = 0.84656922
Iteration 4147, loss = 1.11152274
Iteration 4148, loss = 0.93239660
Iteration 4149, loss = 1.03742297
Iteration 4150, loss = 1.00614309
Iteration 4151, loss = 0.93363524
Iteration 4152, loss = 1.01404931
Iteration 4153, loss = 0.86966240
Iteration 4154, loss = 0.99646710
Iteration 4155, loss = 0.86188414
Iteration 4156, loss = 0.97215256
Iteration 4157, loss = 0.88001906
Iteration 4158, loss = 0.94175058
Iteration 4159, loss = 0.89926126
Iteration 4160, loss = 0.91033492
Iteration 4161, loss = 0.91049743
Iteration 4162, loss = 0.88595885
Iteration 4163, loss = 0.91387501
Iteration 4164, loss = 0.87199192
Iteration 4165, loss = 0.91008735
Iteration 4166, loss = 0.86507977
Iteration 4167, loss = 0.90105812
Iteration 4168, loss = 0.86288637
Iteration 4169, loss = 0.88969258
Iteration 4170, loss = 0.86263633
Iteration 4171, loss = 0.87782300
Iteration 4172, loss = 0.86273681
Iteration 4173, loss = 0.86750741
Iteration 4174, loss = 0.86267777
Iteration 4175, loss = 0.85937976
Iteration 4176, loss = 0.86142200
Iteration 4177, loss = 0.85286848
Iteration 4178, loss = 0.85854128
Iteration 4179, loss = 0.84759739
Iteration 4180, loss = 0.85438238
Iteration 4181, loss = 0.84338312
Iteration 4182, loss = 0.84962768
Iteration 4183, loss = 0.84010018
Iteration 4184, loss = 0.84475288
Iteration 4185, loss = 0.83730401
Iteration 4186, loss = 0.83992789
Iteration 4187, loss = 0.83468395
Iteration 4188, loss = 0.83536428
Iteration 4189, loss = 0.83208338
Iteration 4190, loss = 0.83118346
Iteration 4191, loss = 0.82944025
Iteration 4192, loss = 0.82742940
Iteration 4193, loss = 0.82669995
Iteration 4194, loss = 0.82399814
Iteration 4195, loss = 0.82378364
Iteration 4196, loss = 0.82078194
Iteration 4197, loss = 0.82074737
Iteration 4198, loss = 0.81779090
Iteration 4199, loss = 0.81772175
Iteration 4200, loss = 0.81501720
Iteration 4201, loss = 0.81475923
Iteration 4202, loss = 0.81238876
Iteration 4203, loss = 0.81186537
Iteration 4204, loss = 0.80983920
Iteration 4205, loss = 0.80903912
Iteration 4206, loss = 0.80732660
Iteration 4207, loss = 0.80628759
Iteration 4208, loss = 0.80482731
Iteration 4209, loss = 0.80358676
Iteration 4210, loss = 0.80225018
Iteration 4211, loss = 0.80066559
Iteration 4212, loss = 0.79954516
Iteration 4213, loss = 0.79823335
Iteration 4214, loss = 0.79712185
Iteration 4215, loss = 0.79563740
Iteration 4216, loss = 0.79476459
Iteration 4217, loss = 0.79334912
Iteration 4218, loss = 0.79222656
Iteration 4219, loss = 0.79069189
Iteration 4220, loss = 0.78980286
Iteration 4221, loss = 0.78832949
Iteration 4222, loss = 0.78698188
Iteration 4223, loss = 0.78548590
Iteration 4224, loss = 0.78427680
Iteration 4225, loss = 0.78238678
Iteration 4226, loss = 0.78060239
Iteration 4227, loss = 0.77243777
Iteration 4228, loss = 0.85590411
Iteration 4229, loss = 0.80789739
Iteration 4230, loss = 0.87754576
Iteration 4231, loss = 0.78911283
Iteration 4232, loss = 0.84714545
Iteration 4233, loss = 0.78939077
Iteration 4234, loss = 0.85250146
Iteration 4235, loss = 0.78813904
Iteration 4236, loss = 0.83817785
Iteration 4237, loss = 0.78670485
Iteration 4238, loss = 0.80540670
Iteration 4239, loss = 0.77708176
Iteration 4240, loss = 0.88319603
Iteration 4241, loss = 0.79458896
Iteration 4242, loss = 0.86784008
Iteration 4243, loss = 0.79563744
Iteration 4244, loss = 0.84483283
Iteration 4245, loss = 0.80115108
Iteration 4246, loss = 0.82664327
Iteration 4247, loss = 0.80719721
Iteration 4248, loss = 0.81175217
Iteration 4249, loss = 0.81179014
Iteration 4250, loss = 0.80282960
Iteration 4251, loss = 0.81394520
Iteration 4252, loss = 0.79513226
Iteration 4253, loss = 0.81099758
Iteration 4254, loss = 0.78996114
Iteration 4255, loss = 0.80770431
Iteration 4256, loss = 0.78804933
Iteration 4257, loss = 0.80433973
Iteration 4258, loss = 0.78762451
Iteration 4259, loss = 0.79985803
Iteration 4260, loss = 0.78656164
Iteration 4261, loss = 0.79478388
Iteration 4262, loss = 0.78577946
Iteration 4263, loss = 0.79060912
Iteration 4264, loss = 0.78517680
Iteration 4265, loss = 0.78672827
Iteration 4266, loss = 0.78388138
Iteration 4267, loss = 0.78308186
Iteration 4268, loss = 0.78231493
Iteration 4269, loss = 0.78006152
Iteration 4270, loss = 0.78053029
Iteration 4271, loss = 0.77732276
Iteration 4272, loss = 0.77837532
Iteration 4273, loss = 0.77485177
Iteration 4274, loss = 0.77617383
Iteration 4275, loss = 0.77275326
Iteration 4276, loss = 0.77396790
Iteration 4277, loss = 0.77077903
Iteration 4278, loss = 0.77164625
Iteration 4279, loss = 0.76883686
Iteration 4280, loss = 0.76935969
Iteration 4281, loss = 0.76704549
Iteration 4282, loss = 0.76722618
Iteration 4283, loss = 0.76533734
Iteration 4284, loss = 0.76514866
Iteration 4285, loss = 0.76361286
Iteration 4286, loss = 0.76313702
Iteration 4287, loss = 0.76191969
Iteration 4288, loss = 0.76124236
Iteration 4289, loss = 0.76027477
Iteration 4290, loss = 0.75945686
Iteration 4291, loss = 0.75866344
Iteration 4292, loss = 0.75775278
Iteration 4293, loss = 0.75707357
Iteration 4294, loss = 0.75612040
Iteration 4295, loss = 0.75551202
Iteration 4296, loss = 0.75454722
Iteration 4297, loss = 0.75395849
Iteration 4298, loss = 0.75288699
Iteration 4299, loss = 0.75218598
Iteration 4300, loss = 0.75139940
Iteration 4301, loss = 0.75081780
Iteration 4302, loss = 0.74979872
Iteration 4303, loss = 0.74919670
Iteration 4304, loss = 0.74848870
Iteration 4305, loss = 0.74770638
Iteration 4306, loss = 0.74660693
Iteration 4307, loss = 0.74601961
Iteration 4308, loss = 0.74486025
Iteration 4309, loss = 0.74347563
Iteration 4310, loss = 0.73718779
Iteration 4311, loss = 0.80391869
Iteration 4312, loss = 0.79759587
Iteration 4313, loss = 0.80273681
Iteration 4314, loss = 0.78435972
Iteration 4315, loss = 0.79020417
Iteration 4316, loss = 0.77085127
Iteration 4317, loss = 0.77938717
Iteration 4318, loss = 0.76254864
Iteration 4319, loss = 0.77037053
Iteration 4320, loss = 0.75501668
Iteration 4321, loss = 0.76179572
Iteration 4322, loss = 0.74854766
Iteration 4323, loss = 0.75171717
Iteration 4324, loss = 0.73758988
Iteration 4325, loss = 0.86176653
Iteration 4326, loss = 1.03827089
Iteration 4327, loss = 0.85084352
Iteration 4328, loss = 1.01098741
Iteration 4329, loss = 0.91089943
Iteration 4330, loss = 0.92279144
Iteration 4331, loss = 0.90692532
Iteration 4332, loss = 0.83825713
Iteration 4333, loss = 0.89204622
Iteration 4334, loss = 0.80063270
Iteration 4335, loss = 0.87059085
Iteration 4336, loss = 0.78515457
Iteration 4337, loss = 0.86876638
Iteration 4338, loss = 0.78574507
Iteration 4339, loss = 0.85420363
Iteration 4340, loss = 0.78843597
Iteration 4341, loss = 0.83488770
Iteration 4342, loss = 0.79260813
Iteration 4343, loss = 0.81710059
Iteration 4344, loss = 0.79785396
Iteration 4345, loss = 0.80465355
Iteration 4346, loss = 0.80362511
Iteration 4347, loss = 0.79751795
Iteration 4348, loss = 0.80657670
Iteration 4349, loss = 0.79107397
Iteration 4350, loss = 0.80423462
Iteration 4351, loss = 0.78487504
Iteration 4352, loss = 0.79967697
Iteration 4353, loss = 0.78151951
Iteration 4354, loss = 0.79604221
Iteration 4355, loss = 0.78081675
Iteration 4356, loss = 0.79280869
Iteration 4357, loss = 0.78063727
Iteration 4358, loss = 0.78877814
Iteration 4359, loss = 0.77957839
Iteration 4360, loss = 0.78421049
Iteration 4361, loss = 0.77825993
Iteration 4362, loss = 0.78038170
Iteration 4363, loss = 0.77728497
Iteration 4364, loss = 0.77734733
Iteration 4365, loss = 0.77610755
Iteration 4366, loss = 0.77452398
Iteration 4367, loss = 0.77443464
Iteration 4368, loss = 0.77189105
Iteration 4369, loss = 0.77255696
Iteration 4370, loss = 0.76965526
Iteration 4371, loss = 0.77069166
Iteration 4372, loss = 0.76773238
Iteration 4373, loss = 0.76872966
Iteration 4374, loss = 0.76586147
Iteration 4375, loss = 0.76663245
Iteration 4376, loss = 0.76406396
Iteration 4377, loss = 0.76458772
Iteration 4378, loss = 0.76241004
Iteration 4379, loss = 0.76264192
Iteration 4380, loss = 0.76082259
Iteration 4381, loss = 0.76074405
Iteration 4382, loss = 0.75923946
Iteration 4383, loss = 0.75889244
Iteration 4384, loss = 0.75765655
Iteration 4385, loss = 0.75709802
Iteration 4386, loss = 0.75608199
Iteration 4387, loss = 0.75536970
Iteration 4388, loss = 0.75451665
Iteration 4389, loss = 0.75370523
Iteration 4390, loss = 0.75297559
Iteration 4391, loss = 0.75210516
Iteration 4392, loss = 0.75144269
Iteration 4393, loss = 0.75053755
Iteration 4394, loss = 0.74991374
Iteration 4395, loss = 0.74900132
Iteration 4396, loss = 0.74839447
Iteration 4397, loss = 0.74750058
Iteration 4398, loss = 0.74690573
Iteration 4399, loss = 0.74603676
Iteration 4400, loss = 0.74542900
Iteration 4401, loss = 0.74458286
Iteration 4402, loss = 0.74396926
Iteration 4403, loss = 0.74316864
Iteration 4404, loss = 0.74255903
Iteration 4405, loss = 0.74180129
Iteration 4406, loss = 0.74119784
Iteration 4407, loss = 0.74049174
Iteration 4408, loss = 0.73989671
Iteration 4409, loss = 0.73921684
Iteration 4410, loss = 0.73860819
Iteration 4411, loss = 0.73794404
Iteration 4412, loss = 0.73732519
Iteration 4413, loss = 0.73667227
Iteration 4414, loss = 0.73605607
Iteration 4415, loss = 0.73543883
Iteration 4416, loss = 0.73484925
Iteration 4417, loss = 0.73426501
Iteration 4418, loss = 0.73369135
Iteration 4419, loss = 0.73312709
Iteration 4420, loss = 0.73256224
Iteration 4421, loss = 0.73200591
Iteration 4422, loss = 0.73143747
Iteration 4423, loss = 0.73086607
Iteration 4424, loss = 0.73025192
Iteration 4425, loss = 0.72959457
Iteration 4426, loss = 0.72889407
Iteration 4427, loss = 0.72825191
Iteration 4428, loss = 0.72755253
Iteration 4429, loss = 0.72669037
Iteration 4430, loss = 0.72566396
Iteration 4431, loss = 0.72458775
Iteration 4432, loss = 0.72338267
Iteration 4433, loss = 0.72210553
Iteration 4434, loss = 0.72035105
Iteration 4435, loss = 0.71865239
Iteration 4436, loss = 0.71613976
Iteration 4437, loss = 0.71214420
Iteration 4438, loss = 0.77950241
Iteration 4439, loss = 0.98480068
Iteration 4440, loss = 0.79178502
Iteration 4441, loss = 0.96411008
Iteration 4442, loss = 0.83684150
Iteration 4443, loss = 0.87448479
Iteration 4444, loss = 0.83973404
Iteration 4445, loss = 0.79781936
Iteration 4446, loss = 0.84422391
Iteration 4447, loss = 0.76741868
Iteration 4448, loss = 0.84804717
Iteration 4449, loss = 0.75630483
Iteration 4450, loss = 0.83448776
Iteration 4451, loss = 0.74687896
Iteration 4452, loss = 0.81238092
Iteration 4453, loss = 0.74433153
Iteration 4454, loss = 0.79472512
Iteration 4455, loss = 0.74919117
Iteration 4456, loss = 0.78200496
Iteration 4457, loss = 0.75440837
Iteration 4458, loss = 0.76973799
Iteration 4459, loss = 0.75650919
Iteration 4460, loss = 0.75914957
Iteration 4461, loss = 0.75700820
Iteration 4462, loss = 0.75131850
Iteration 4463, loss = 0.75608482
Iteration 4464, loss = 0.74514155
Iteration 4465, loss = 0.75365129
Iteration 4466, loss = 0.74078833
Iteration 4467, loss = 0.75132634
Iteration 4468, loss = 0.73858637
Iteration 4469, loss = 0.74915660
Iteration 4470, loss = 0.73717688
Iteration 4471, loss = 0.74633930
Iteration 4472, loss = 0.73566067
Iteration 4473, loss = 0.74312590
Iteration 4474, loss = 0.73438509
Iteration 4475, loss = 0.74029926
Iteration 4476, loss = 0.73359494
Iteration 4477, loss = 0.73793360
Iteration 4478, loss = 0.73296498
Iteration 4479, loss = 0.73582405
Iteration 4480, loss = 0.73216851
Iteration 4481, loss = 0.73375035
Iteration 4482, loss = 0.73123098
Iteration 4483, loss = 0.73181822
Iteration 4484, loss = 0.73027474
Iteration 4485, loss = 0.73011922
Iteration 4486, loss = 0.72932576
Iteration 4487, loss = 0.72905172
Iteration 4488, loss = 0.72827551
Iteration 4489, loss = 0.72728599
Iteration 4490, loss = 0.72729055
Iteration 4491, loss = 0.72611564
Iteration 4492, loss = 0.72578342
Iteration 4493, loss = 0.72270945
Iteration 4494, loss = 0.68693052
Iteration 4495, loss = 0.74416879
Iteration 4496, loss = 0.76487160
Iteration 4497, loss = 0.74816510
Iteration 4498, loss = 0.75756238
Iteration 4499, loss = 0.74261418
Iteration 4500, loss = 0.75698071
Iteration 4501, loss = 0.74902631
Iteration 4502, loss = 0.76279362
Iteration 4503, loss = 0.75372388
Iteration 4504, loss = 0.76425298
Iteration 4505, loss = 0.75674204
Iteration 4506, loss = 0.76670708
Iteration 4507, loss = 0.75987939
Iteration 4508, loss = 0.76827601
Iteration 4509, loss = 0.76222711
Iteration 4510, loss = 0.76981552
Iteration 4511, loss = 0.76467916
Iteration 4512, loss = 0.77102893
Iteration 4513, loss = 0.76605424
Iteration 4514, loss = 0.77100680
Iteration 4515, loss = 0.76642748
Iteration 4516, loss = 0.77058907
Iteration 4517, loss = 0.76680597
Iteration 4518, loss = 0.77044015
Iteration 4519, loss = 0.76713270
Iteration 4520, loss = 0.76973374
Iteration 4521, loss = 0.76645544
Iteration 4522, loss = 0.76829605
Iteration 4523, loss = 0.76556243
Iteration 4524, loss = 0.76710802
Iteration 4525, loss = 0.76482457
Iteration 4526, loss = 0.76584659
Iteration 4527, loss = 0.76370555
Iteration 4528, loss = 0.76419197
Iteration 4529, loss = 0.76226520
Iteration 4530, loss = 0.76249539
Iteration 4531, loss = 0.76090285
Iteration 4532, loss = 0.76091175
Iteration 4533, loss = 0.75946633
Iteration 4534, loss = 0.75918220
Iteration 4535, loss = 0.75786257
Iteration 4536, loss = 0.75742446
Iteration 4537, loss = 0.75626960
Iteration 4538, loss = 0.75570595
Iteration 4539, loss = 0.75465096
Iteration 4540, loss = 0.75398112
Iteration 4541, loss = 0.75301898
Iteration 4542, loss = 0.75228092
Iteration 4543, loss = 0.75138969
Iteration 4544, loss = 0.75060036
Iteration 4545, loss = 0.74976283
Iteration 4546, loss = 0.74894337
Iteration 4547, loss = 0.74815568
Iteration 4548, loss = 0.74732936
Iteration 4549, loss = 0.74657658
Iteration 4550, loss = 0.74574218
Iteration 4551, loss = 0.74501402
Iteration 4552, loss = 0.74419124
Iteration 4553, loss = 0.74348863
Iteration 4554, loss = 0.74267998
Iteration 4555, loss = 0.74199339
Iteration 4556, loss = 0.74120578
Iteration 4557, loss = 0.74053522
Iteration 4558, loss = 0.73976883
Iteration 4559, loss = 0.73911061
Iteration 4560, loss = 0.73837393
Iteration 4561, loss = 0.73773093
Iteration 4562, loss = 0.73701434
Iteration 4563, loss = 0.73637559
Iteration 4564, loss = 0.73568728
Iteration 4565, loss = 0.73506764
Iteration 4566, loss = 0.73440675
Iteration 4567, loss = 0.73379619
Iteration 4568, loss = 0.73315641
Iteration 4569, loss = 0.73255343
Iteration 4570, loss = 0.73193474
Iteration 4571, loss = 0.73135050
Iteration 4572, loss = 0.73075997
Iteration 4573, loss = 0.73018600
Iteration 4574, loss = 0.72961067
Iteration 4575, loss = 0.72905403
Iteration 4576, loss = 0.72850434
Iteration 4577, loss = 0.72796115
Iteration 4578, loss = 0.72742537
Iteration 4579, loss = 0.72689391
Iteration 4580, loss = 0.72636620
Iteration 4581, loss = 0.72582140
Iteration 4582, loss = 0.72519990
Iteration 4583, loss = 0.72462858
Iteration 4584, loss = 0.72421497
Iteration 4585, loss = 0.72369204
Iteration 4586, loss = 0.72308378
Iteration 4587, loss = 0.72263829
Iteration 4588, loss = 0.72220668
Iteration 4589, loss = 0.72162391
Iteration 4590, loss = 0.72121137
Iteration 4591, loss = 0.72077162
Iteration 4592, loss = 0.72025221
Iteration 4593, loss = 0.71964956
Iteration 4594, loss = 0.71933838
Iteration 4595, loss = 0.71889369
Iteration 4596, loss = 0.71837819
Iteration 4597, loss = 0.71794779
Iteration 4598, loss = 0.71777873
Iteration 4599, loss = 0.71733468
Iteration 4600, loss = 0.71684158
Iteration 4601, loss = 0.71628430
Iteration 4602, loss = 0.71572879
Iteration 4603, loss = 0.71519435
Iteration 4604, loss = 0.71476052
Iteration 4605, loss = 0.71399969
Iteration 4606, loss = 0.71355901
Iteration 4607, loss = 0.71272538
Iteration 4608, loss = 0.71135904
Iteration 4609, loss = 0.71002180
Iteration 4610, loss = 0.70412311
Iteration 4611, loss = 0.73179614
Iteration 4612, loss = 0.94121096
Iteration 4613, loss = 0.76712188
Iteration 4614, loss = 0.93738040
Iteration 4615, loss = 0.76000985
Iteration 4616, loss = 0.88310199
Iteration 4617, loss = 0.73372830
Iteration 4618, loss = 0.84911256
Iteration 4619, loss = 0.73756089
Iteration 4620, loss = 0.84397840
Iteration 4621, loss = 0.74736838
Iteration 4622, loss = 0.83296924
Iteration 4623, loss = 0.74336978
Iteration 4624, loss = 0.81389858
Iteration 4625, loss = 0.73535514
Iteration 4626, loss = 0.79911497
Iteration 4627, loss = 0.73343122
Iteration 4628, loss = 0.79029757
Iteration 4629, loss = 0.73325686
Iteration 4630, loss = 0.78179690
Iteration 4631, loss = 0.73136496
Iteration 4632, loss = 0.77206544
Iteration 4633, loss = 0.72875609
Iteration 4634, loss = 0.76394505
Iteration 4635, loss = 0.72835336
Iteration 4636, loss = 0.75778245
Iteration 4637, loss = 0.72785309
Iteration 4638, loss = 0.75114636
Iteration 4639, loss = 0.72657655
Iteration 4640, loss = 0.74503837
Iteration 4641, loss = 0.72617562
Iteration 4642, loss = 0.74068638
Iteration 4643, loss = 0.72659620
Iteration 4644, loss = 0.73694226
Iteration 4645, loss = 0.72634880
Iteration 4646, loss = 0.73298875
Iteration 4647, loss = 0.72561738
Iteration 4648, loss = 0.72968244
Iteration 4649, loss = 0.72527284
Iteration 4650, loss = 0.72736972
Iteration 4651, loss = 0.72507410
Iteration 4652, loss = 0.72541276
Iteration 4653, loss = 0.72449232
Iteration 4654, loss = 0.72354857
Iteration 4655, loss = 0.72366229
Iteration 4656, loss = 0.72201135
Iteration 4657, loss = 0.72285480
Iteration 4658, loss = 0.72083113
Iteration 4659, loss = 0.72202579
Iteration 4660, loss = 0.71983384
Iteration 4661, loss = 0.72109550
Iteration 4662, loss = 0.71891948
Iteration 4663, loss = 0.72009933
Iteration 4664, loss = 0.71811556
Iteration 4665, loss = 0.71913667
Iteration 4666, loss = 0.71743510
Iteration 4667, loss = 0.71822514
Iteration 4668, loss = 0.71681099
Iteration 4669, loss = 0.71732433
Iteration 4670, loss = 0.71619658
Iteration 4671, loss = 0.71646486
Iteration 4672, loss = 0.71562016
Iteration 4673, loss = 0.71567058
Iteration 4674, loss = 0.71504738
Iteration 4675, loss = 0.71489477
Iteration 4676, loss = 0.71443054
Iteration 4677, loss = 0.71412049
Iteration 4678, loss = 0.71378817
Iteration 4679, loss = 0.71339742
Iteration 4680, loss = 0.71317827
Iteration 4681, loss = 0.71275090
Iteration 4682, loss = 0.71259359
Iteration 4683, loss = 0.71214882
Iteration 4684, loss = 0.71201799
Iteration 4685, loss = 0.71157677
Iteration 4686, loss = 0.71144032
Iteration 4687, loss = 0.71101794
Iteration 4688, loss = 0.71087572
Iteration 4689, loss = 0.71048833
Iteration 4690, loss = 0.71031385
Iteration 4691, loss = 0.70994870
Iteration 4692, loss = 0.70974547
Iteration 4693, loss = 0.70940596
Iteration 4694, loss = 0.70915501
Iteration 4695, loss = 0.70880738
Iteration 4696, loss = 0.70847030
Iteration 4697, loss = 0.70804649
Iteration 4698, loss = 0.70765672
Iteration 4699, loss = 0.70732446
Iteration 4700, loss = 0.70693416
Iteration 4701, loss = 0.70648666
Iteration 4702, loss = 0.70589470
Iteration 4703, loss = 0.70523459
Iteration 4704, loss = 0.70436896
Iteration 4705, loss = 0.70322224
Iteration 4706, loss = 0.70193419
Iteration 4707, loss = 0.69971305
Iteration 4708, loss = 0.69842109
Iteration 4709, loss = 0.69681209
Iteration 4710, loss = 0.69246096
Iteration 4711, loss = 0.66805569
Iteration 4712, loss = 0.81262504
Iteration 4713, loss = 0.86902464
Iteration 4714, loss = 0.77751875
Iteration 4715, loss = 0.87972616
Iteration 4716, loss = 0.74095332
Iteration 4717, loss = 0.87123484
Iteration 4718, loss = 0.72134564
Iteration 4719, loss = 0.86132852
Iteration 4720, loss = 0.71827035
Iteration 4721, loss = 0.84625531
Iteration 4722, loss = 0.72157294
Iteration 4723, loss = 0.82122218
Iteration 4724, loss = 0.72571997
Iteration 4725, loss = 0.78925281
Iteration 4726, loss = 0.73148494
Iteration 4727, loss = 0.75917203
Iteration 4728, loss = 0.74079621
Iteration 4729, loss = 0.73844020
Iteration 4730, loss = 0.75007678
Iteration 4731, loss = 0.72618813
Iteration 4732, loss = 0.75324271
Iteration 4733, loss = 0.71942522
Iteration 4734, loss = 0.74822920
Iteration 4735, loss = 0.71689049
Iteration 4736, loss = 0.73971012
Iteration 4737, loss = 0.71907086
Iteration 4738, loss = 0.73093332
Iteration 4739, loss = 0.72297589
Iteration 4740, loss = 0.72342853
Iteration 4741, loss = 0.72572541
Iteration 4742, loss = 0.71777912
Iteration 4743, loss = 0.72582383
Iteration 4744, loss = 0.71460146
Iteration 4745, loss = 0.72327024
Iteration 4746, loss = 0.71341745
Iteration 4747, loss = 0.71965440
Iteration 4748, loss = 0.71208772
Iteration 4749, loss = 0.70638994
Iteration 4750, loss = 0.79104855
Iteration 4751, loss = 0.75211141
Iteration 4752, loss = 0.77898518
Iteration 4753, loss = 0.75653015
Iteration 4754, loss = 0.75756017
Iteration 4755, loss = 0.75163884
Iteration 4756, loss = 0.73846050
Iteration 4757, loss = 0.74845386
Iteration 4758, loss = 0.72829493
Iteration 4759, loss = 0.74916087
Iteration 4760, loss = 0.72266334
Iteration 4761, loss = 0.74525014
Iteration 4762, loss = 0.71644955
Iteration 4763, loss = 0.74114430
Iteration 4764, loss = 0.71422073
Iteration 4765, loss = 0.73718244
Iteration 4766, loss = 0.71280845
Iteration 4767, loss = 0.73139149
Iteration 4768, loss = 0.71121750
Iteration 4769, loss = 0.72617351
Iteration 4770, loss = 0.71134340
Iteration 4771, loss = 0.72192373
Iteration 4772, loss = 0.71169841
Iteration 4773, loss = 0.71787908
Iteration 4774, loss = 0.71179686
Iteration 4775, loss = 0.71418443
Iteration 4776, loss = 0.71153025
Iteration 4777, loss = 0.71148917
Iteration 4778, loss = 0.71154715
Iteration 4779, loss = 0.70948786
Iteration 4780, loss = 0.71096293
Iteration 4781, loss = 0.70772898
Iteration 4782, loss = 0.71004352
Iteration 4783, loss = 0.70658906
Iteration 4784, loss = 0.70932016
Iteration 4785, loss = 0.70607639
Iteration 4786, loss = 0.70842866
Iteration 4787, loss = 0.70548468
Iteration 4788, loss = 0.70721528
Iteration 4789, loss = 0.70497840
Iteration 4790, loss = 0.70612428
Iteration 4791, loss = 0.70440026
Iteration 4792, loss = 0.70462782
Iteration 4793, loss = 0.70367112
Iteration 4794, loss = 0.70381273
Iteration 4795, loss = 0.70336809
Iteration 4796, loss = 0.70267567
Iteration 4797, loss = 0.70238897
Iteration 4798, loss = 0.70151994
Iteration 4799, loss = 0.70142268
Iteration 4800, loss = 0.69991150
Iteration 4801, loss = 0.69877394
Iteration 4802, loss = 0.69698715
Iteration 4803, loss = 0.69520487
Iteration 4804, loss = 0.69283349
Iteration 4805, loss = 0.68972498
Iteration 4806, loss = 0.65406292
Iteration 4807, loss = 0.77476547
Iteration 4808, loss = 0.84884247
Iteration 4809, loss = 0.75626310
Iteration 4810, loss = 0.85294908
Iteration 4811, loss = 0.72765461
Iteration 4812, loss = 0.83313327
Iteration 4813, loss = 0.71348231
Iteration 4814, loss = 0.81482288
Iteration 4815, loss = 0.71870223
Iteration 4816, loss = 0.79685136
Iteration 4817, loss = 0.73124829
Iteration 4818, loss = 0.77402714
Iteration 4819, loss = 0.74161327
Iteration 4820, loss = 0.74971755
Iteration 4821, loss = 0.74839110
Iteration 4822, loss = 0.73189719
Iteration 4823, loss = 0.75251623
Iteration 4824, loss = 0.72400511
Iteration 4825, loss = 0.75274583
Iteration 4826, loss = 0.72315723
Iteration 4827, loss = 0.74765534
Iteration 4828, loss = 0.72542342
Iteration 4829, loss = 0.73915930
Iteration 4830, loss = 0.72865160
Iteration 4831, loss = 0.73074840
Iteration 4832, loss = 0.73138377
Iteration 4833, loss = 0.72490558
Iteration 4834, loss = 0.73250909
Iteration 4835, loss = 0.72218669
Iteration 4836, loss = 0.73136685
Iteration 4837, loss = 0.72163606
Iteration 4838, loss = 0.72826926
Iteration 4839, loss = 0.72218422
Iteration 4840, loss = 0.72464827
Iteration 4841, loss = 0.72310894
Iteration 4842, loss = 0.72173128
Iteration 4843, loss = 0.72348905
Iteration 4844, loss = 0.71974902
Iteration 4845, loss = 0.72275084
Iteration 4846, loss = 0.71869140
Iteration 4847, loss = 0.72124746
Iteration 4848, loss = 0.71841930
Iteration 4849, loss = 0.71952857
Iteration 4850, loss = 0.71844148
Iteration 4851, loss = 0.71794318
Iteration 4852, loss = 0.71821655
Iteration 4853, loss = 0.71665486
Iteration 4854, loss = 0.71756052
Iteration 4855, loss = 0.71579442
Iteration 4856, loss = 0.71661353
Iteration 4857, loss = 0.71530310
Iteration 4858, loss = 0.71557557
Iteration 4859, loss = 0.71494859
Iteration 4860, loss = 0.71457807
Iteration 4861, loss = 0.71450850
Iteration 4862, loss = 0.71371322
Iteration 4863, loss = 0.71389258
Iteration 4864, loss = 0.71302917
Iteration 4865, loss = 0.71317571
Iteration 4866, loss = 0.71251527
Iteration 4867, loss = 0.71243445
Iteration 4868, loss = 0.71205748
Iteration 4869, loss = 0.71172339
Iteration 4870, loss = 0.71156604
Iteration 4871, loss = 0.71108205
Iteration 4872, loss = 0.71101405
Iteration 4873, loss = 0.71052906
Iteration 4874, loss = 0.71042983
Iteration 4875, loss = 0.71004448
Iteration 4876, loss = 0.70984711
Iteration 4877, loss = 0.70958608
Iteration 4878, loss = 0.70929642
Iteration 4879, loss = 0.70911987
Iteration 4880, loss = 0.70878685
Iteration 4881, loss = 0.70863411
Iteration 4882, loss = 0.70831739
Iteration 4883, loss = 0.70813721
Iteration 4884, loss = 0.70786976
Iteration 4885, loss = 0.70765235
Iteration 4886, loss = 0.70744459
Iteration 4887, loss = 0.70719750
Iteration 4888, loss = 0.70701557
Iteration 4889, loss = 0.70676482
Iteration 4890, loss = 0.70659149
Iteration 4891, loss = 0.70635898
Iteration 4892, loss = 0.70616858
Iteration 4893, loss = 0.70596428
Iteration 4894, loss = 0.70576384
Iteration 4895, loss = 0.70558207
Iteration 4896, loss = 0.70537562
Iteration 4897, loss = 0.70520608
Iteration 4898, loss = 0.70500788
Iteration 4899, loss = 0.70483738
Iteration 4900, loss = 0.70465464
Iteration 4901, loss = 0.70448312
Iteration 4902, loss = 0.70431421
Iteration 4903, loss = 0.70413715
Iteration 4904, loss = 0.70397420
Iteration 4905, loss = 0.70379868
Iteration 4906, loss = 0.70364097
Iteration 4907, loss = 0.70347800
Iteration 4908, loss = 0.70332259
Iteration 4909, loss = 0.70316543
Iteration 4910, loss = 0.70300941
Iteration 4911, loss = 0.70286092
Iteration 4912, loss = 0.70270284
Iteration 4913, loss = 0.70249983
Iteration 4914, loss = 0.70221826
Iteration 4915, loss = 0.70090167
Iteration 4916, loss = 0.70354488
Iteration 4917, loss = 0.70335640
Iteration 4918, loss = 0.68184786
Iteration 4919, loss = 0.73244658
Iteration 4920, loss = 0.71060660
Iteration 4921, loss = 0.72019901
Iteration 4922, loss = 0.71427389
Iteration 4923, loss = 0.71080046
Iteration 4924, loss = 0.71994221
Iteration 4925, loss = 0.70898157
Iteration 4926, loss = 0.72173221
Iteration 4927, loss = 0.71016421
Iteration 4928, loss = 0.71683731
Iteration 4929, loss = 0.71255104
Iteration 4930, loss = 0.71374463
Iteration 4931, loss = 0.71721166
Iteration 4932, loss = 0.71228394
Iteration 4933, loss = 0.71730372
Iteration 4934, loss = 0.71166033
Iteration 4935, loss = 0.71602073
Iteration 4936, loss = 0.71376509
Iteration 4937, loss = 0.71444161
Iteration 4938, loss = 0.71509630
Iteration 4939, loss = 0.71293227
Iteration 4940, loss = 0.71533168
Iteration 4941, loss = 0.71254033
Iteration 4942, loss = 0.71456304
Iteration 4943, loss = 0.71318424
Iteration 4944, loss = 0.71351711
Iteration 4945, loss = 0.71362443
Iteration 4946, loss = 0.71240551
Iteration 4947, loss = 0.71337011
Iteration 4948, loss = 0.71195607
Iteration 4949, loss = 0.71282905
Iteration 4950, loss = 0.71198867
Iteration 4951, loss = 0.71191198
Iteration 4952, loss = 0.71180621
Iteration 4953, loss = 0.71111372
Iteration 4954, loss = 0.71150713
Iteration 4955, loss = 0.71068281
Iteration 4956, loss = 0.71089712
Iteration 4957, loss = 0.71035807
Iteration 4958, loss = 0.71017950
Iteration 4959, loss = 0.71005313
Iteration 4960, loss = 0.70955526
Iteration 4961, loss = 0.70960593
Iteration 4962, loss = 0.70908216
Iteration 4963, loss = 0.70905226
Iteration 4964, loss = 0.70869785
Iteration 4965, loss = 0.70845495
Iteration 4966, loss = 0.70829917
Iteration 4967, loss = 0.70792927
Iteration 4968, loss = 0.70784524
Iteration 4969, loss = 0.70748044
Iteration 4970, loss = 0.70733426
Iteration 4971, loss = 0.70707456
Iteration 4972, loss = 0.70683273
Iteration 4973, loss = 0.70666935
Iteration 4974, loss = 0.70637649
Iteration 4975, loss = 0.70623140
Iteration 4976, loss = 0.70596083
Iteration 4977, loss = 0.70578031
Iteration 4978, loss = 0.70557236
Iteration 4979, loss = 0.70534611
Iteration 4980, loss = 0.70517683
Iteration 4981, loss = 0.70493654
Iteration 4982, loss = 0.70477311
Iteration 4983, loss = 0.70456186
Iteration 4984, loss = 0.70437919
Iteration 4985, loss = 0.70419837
Iteration 4986, loss = 0.70399548
Iteration 4987, loss = 0.70383304
Iteration 4988, loss = 0.70363712
Iteration 4989, loss = 0.70347526
Iteration 4990, loss = 0.70329798
Iteration 4991, loss = 0.70312591
Iteration 4992, loss = 0.70296759
Iteration 4993, loss = 0.70279567
Iteration 4994, loss = 0.70264746
Iteration 4995, loss = 0.70248319
Iteration 4996, loss = 0.70232735
Iteration 4997, loss = 0.70216779
Iteration 4998, loss = 0.70200858
Iteration 4999, loss = 0.70186643
Iteration 5000, loss = 0.70171770
