Iteration 1, loss = 0.74075436
Iteration 2, loss = 2.32613884
Iteration 3, loss = 0.91336849
Iteration 4, loss = 0.75747193
Iteration 5, loss = 0.75702729
Iteration 6, loss = 0.88119112
Iteration 7, loss = 0.93755065
Iteration 8, loss = 0.89435724
Iteration 9, loss = 0.80280555
Iteration 10, loss = 0.73017649
Iteration 11, loss = 0.72029002
Iteration 12, loss = 0.76016835
Iteration 13, loss = 0.79939386
Iteration 14, loss = 0.80331316
Iteration 15, loss = 0.77240331
Iteration 16, loss = 0.70726009
Iteration 17, loss = 0.69448946
Iteration 18, loss = 0.70275775
Iteration 19, loss = 0.65998507
Iteration 20, loss = 0.69329207
Iteration 21, loss = 0.81351804
Iteration 22, loss = 0.70453446
Iteration 23, loss = 0.73814022
Iteration 24, loss = 0.72595009
Iteration 25, loss = 0.69517511
Iteration 26, loss = 0.92617589
Iteration 27, loss = 0.70509805
Iteration 28, loss = 0.75310013
Iteration 29, loss = 0.76524783
Iteration 30, loss = 0.74406078
Iteration 31, loss = 0.73553203
Iteration 32, loss = 0.75614684
Iteration 33, loss = 0.77191073
Iteration 34, loss = 0.76072363
Iteration 35, loss = 0.74354431
Iteration 36, loss = 0.75073956
Iteration 37, loss = 0.74574078
Iteration 38, loss = 0.93922619
Iteration 39, loss = 0.75628644
Iteration 40, loss = 1.28678218
Iteration 41, loss = 0.87589296
Iteration 42, loss = 1.01103218
Iteration 43, loss = 0.72424094
Iteration 44, loss = 0.67665560
Iteration 45, loss = 0.86167373
Iteration 46, loss = 0.70993600
Iteration 47, loss = 0.79107749
Iteration 48, loss = 0.91850850
Iteration 49, loss = 0.77327099
Iteration 50, loss = 0.70658663
Iteration 51, loss = 0.78112714
Iteration 52, loss = 0.82128811
Iteration 53, loss = 0.79472333
Iteration 54, loss = 0.74218250
Iteration 55, loss = 0.72641122
Iteration 56, loss = 0.72770046
Iteration 57, loss = 0.77753817
Iteration 58, loss = 0.67659385
Iteration 59, loss = 0.68033656
Iteration 60, loss = 0.77776015
Iteration 61, loss = 0.73491063
Iteration 62, loss = 0.60455370
Iteration 63, loss = 0.68145101
Iteration 64, loss = 0.67620662
Iteration 65, loss = 0.59541324
Iteration 66, loss = 0.65792028
Iteration 67, loss = 0.47621748
Iteration 68, loss = 0.45201284
Iteration 69, loss = 0.42144511
Iteration 70, loss = 0.56692827
Iteration 71, loss = 0.43496262
Iteration 72, loss = 0.55374859
Iteration 73, loss = 0.41988421
Iteration 74, loss = 0.63838524
Iteration 75, loss = 0.67777091
Iteration 76, loss = 0.53326303
Iteration 77, loss = 0.42541545
Iteration 78, loss = 1.10780977
Iteration 79, loss = 0.91652137
Iteration 80, loss = 0.51013163
Iteration 81, loss = 0.74612578
Iteration 82, loss = 0.80371973
Iteration 83, loss = 0.69740620
Iteration 84, loss = 0.45856424
Iteration 85, loss = 0.88418846
Iteration 86, loss = 1.08869623
Iteration 87, loss = 0.99126165
Iteration 88, loss = 0.77044928
Iteration 89, loss = 1.05923645
Iteration 90, loss = 0.40676310
Iteration 91, loss = 0.93635273
Iteration 92, loss = 1.10603686
Iteration 93, loss = 0.76709666
Iteration 94, loss = 0.56468333
Iteration 95, loss = 0.50572468
Iteration 96, loss = 0.55519174
Iteration 97, loss = 0.57132270
Iteration 98, loss = 1.09482549
Iteration 99, loss = 0.89999837
Iteration 100, loss = 0.64590490
Iteration 101, loss = 0.68766861
Iteration 102, loss = 0.90387474
Iteration 103, loss = 0.75940576
Iteration 104, loss = 0.43663025
Iteration 105, loss = 0.50287831
Iteration 106, loss = 0.46190500
Iteration 107, loss = 0.45515669
Iteration 108, loss = 0.44110223
Iteration 109, loss = 0.36720592
Iteration 110, loss = 0.45252692
Iteration 111, loss = 0.35870445
Iteration 112, loss = 0.37870254
Iteration 113, loss = 0.35084098
Iteration 114, loss = 0.30007022
Iteration 115, loss = 0.28999783
Iteration 116, loss = 0.27465030
Iteration 117, loss = 0.29719412
Iteration 118, loss = 0.42042261
Iteration 119, loss = 1.01935589
Iteration 120, loss = 1.08170874
Iteration 121, loss = 0.76523807
Iteration 122, loss = 0.91186539
Iteration 123, loss = 1.07419131
Iteration 124, loss = 0.86286052
Iteration 125, loss = 0.83753421
Iteration 126, loss = 0.77486230
Iteration 127, loss = 0.79507854
Iteration 128, loss = 0.84037428
Iteration 129, loss = 0.81529768
Iteration 130, loss = 0.76897230
Iteration 131, loss = 0.78045111
Iteration 132, loss = 0.80721042
Iteration 133, loss = 0.78504828
Iteration 134, loss = 0.75352377
Iteration 135, loss = 0.76418081
Iteration 136, loss = 0.77975015
Iteration 137, loss = 0.76332334
Iteration 138, loss = 0.74510091
Iteration 139, loss = 0.75406157
Iteration 140, loss = 0.76127368
Iteration 141, loss = 0.74667204
Iteration 142, loss = 0.73314885
Iteration 143, loss = 0.72194695
Iteration 144, loss = 0.77937804
Iteration 145, loss = 0.77731794
Iteration 146, loss = 0.73734074
Iteration 147, loss = 0.76180833
Iteration 148, loss = 0.77905749
Iteration 149, loss = 0.75078089
Iteration 150, loss = 0.73962465
Iteration 151, loss = 0.75841301
Iteration 152, loss = 0.75161960
Iteration 153, loss = 0.72914259
Iteration 154, loss = 0.73372883
Iteration 155, loss = 0.74293776
Iteration 156, loss = 0.72984670
Iteration 157, loss = 0.72234793
Iteration 158, loss = 0.73241381
Iteration 159, loss = 0.73222254
Iteration 160, loss = 0.72201434
Iteration 161, loss = 0.72392766
Iteration 162, loss = 0.72931014
Iteration 163, loss = 0.72356569
Iteration 164, loss = 0.71961341
Iteration 165, loss = 0.72416919
Iteration 166, loss = 0.72381259
Iteration 167, loss = 0.71864093
Iteration 168, loss = 0.71960028
Iteration 169, loss = 0.72195577
Iteration 170, loss = 0.71874375
Iteration 171, loss = 0.71679702
Iteration 172, loss = 0.71875337
Iteration 173, loss = 0.71779348
Iteration 174, loss = 0.71485208
Iteration 175, loss = 0.71525831
Iteration 176, loss = 0.71588591
Iteration 177, loss = 0.71378369
Iteration 178, loss = 0.71280374
Iteration 179, loss = 0.71353720
Iteration 180, loss = 0.71257941
Iteration 181, loss = 0.71111827
Iteration 182, loss = 0.71134190
Iteration 183, loss = 0.71117400
Iteration 184, loss = 0.70978959
Iteration 185, loss = 0.70922852
Iteration 186, loss = 0.70913818
Iteration 187, loss = 0.70811445
Iteration 188, loss = 0.70708172
Iteration 189, loss = 0.70558898
Iteration 190, loss = 0.70018341
Iteration 191, loss = 0.68479073
Iteration 192, loss = 1.37531440
Iteration 193, loss = 0.85957395
Iteration 194, loss = 0.95867527
Iteration 195, loss = 0.37664650
Iteration 196, loss = 0.77374890
Iteration 197, loss = 0.72816844
Iteration 198, loss = 0.79730294
Iteration 199, loss = 0.83314690
Iteration 200, loss = 0.76873123
Iteration 201, loss = 0.75281336
Iteration 202, loss = 0.80083862
Iteration 203, loss = 0.78513683
Iteration 204, loss = 0.73646529
Iteration 205, loss = 0.75136890
Iteration 206, loss = 0.77002996
Iteration 207, loss = 0.73607264
Iteration 208, loss = 0.71812913
Iteration 209, loss = 0.73960201
Iteration 210, loss = 0.73449889
Iteration 211, loss = 0.70938235
Iteration 212, loss = 0.71509902
Iteration 213, loss = 0.72661155
Iteration 214, loss = 0.71220490
Iteration 215, loss = 0.70412807
Iteration 216, loss = 0.71544874
Iteration 217, loss = 0.71424353
Iteration 218, loss = 0.70261442
Iteration 219, loss = 0.70577513
Iteration 220, loss = 0.71178962
Iteration 221, loss = 0.70508950
Iteration 222, loss = 0.70178319
Iteration 223, loss = 0.70733058
Iteration 224, loss = 0.70602225
Iteration 225, loss = 0.70004650
Iteration 226, loss = 0.70137156
Iteration 227, loss = 0.70316449
Iteration 228, loss = 0.69882336
Iteration 229, loss = 0.69696863
Iteration 230, loss = 0.69911165
Iteration 231, loss = 0.69747171
Iteration 232, loss = 0.69433311
Iteration 233, loss = 0.69494700
Iteration 234, loss = 0.69490632
Iteration 235, loss = 0.69204637
Iteration 236, loss = 0.69059198
Iteration 237, loss = 0.68877441
Iteration 238, loss = 0.68443776
Iteration 239, loss = 0.68180219
Iteration 240, loss = 0.64339472
Iteration 241, loss = 0.91196106
Iteration 242, loss = 0.73720617
Iteration 243, loss = 0.77909338
Iteration 244, loss = 0.89438615
Iteration 245, loss = 0.82142218
Iteration 246, loss = 0.71964391
Iteration 247, loss = 0.78871042
Iteration 248, loss = 0.83392800
Iteration 249, loss = 0.75334043
Iteration 250, loss = 0.71552146
Iteration 251, loss = 0.77410889
Iteration 252, loss = 0.77205318
Iteration 253, loss = 0.70817135
Iteration 254, loss = 0.70870464
Iteration 255, loss = 0.74502874
Iteration 256, loss = 0.66490630
Iteration 257, loss = 0.72812086
Iteration 258, loss = 0.83956243
Iteration 259, loss = 0.81466279
Iteration 260, loss = 0.73416100
Iteration 261, loss = 0.76939601
Iteration 262, loss = 0.82286862
Iteration 263, loss = 0.77765302
Iteration 264, loss = 0.73219235
Iteration 265, loss = 0.76948393
Iteration 266, loss = 0.78369415
Iteration 267, loss = 0.73048513
Iteration 268, loss = 0.73418063
Iteration 269, loss = 0.75014852
Iteration 270, loss = 0.72621088
Iteration 271, loss = 0.72496959
Iteration 272, loss = 0.73907065
Iteration 273, loss = 0.72294589
Iteration 274, loss = 0.71869295
Iteration 275, loss = 0.73039303
Iteration 276, loss = 0.72082954
Iteration 277, loss = 0.71629591
Iteration 278, loss = 0.72623143
Iteration 279, loss = 0.72119311
Iteration 280, loss = 0.71661507
Iteration 281, loss = 0.72374038
Iteration 282, loss = 0.72091166
Iteration 283, loss = 0.71636316
Iteration 284, loss = 0.72110795
Iteration 285, loss = 0.71960642
Iteration 286, loss = 0.71556064
Iteration 287, loss = 0.71866678
Iteration 288, loss = 0.71805178
Iteration 289, loss = 0.71472496
Iteration 290, loss = 0.71670375
Iteration 291, loss = 0.71656191
Iteration 292, loss = 0.71389984
Iteration 293, loss = 0.71508262
Iteration 294, loss = 0.71511899
Iteration 295, loss = 0.71297537
Iteration 296, loss = 0.71358944
Iteration 297, loss = 0.71372487
Iteration 298, loss = 0.71217451
Iteration 299, loss = 0.71261321
Iteration 300, loss = 0.71285745
Iteration 301, loss = 0.71170899
Iteration 302, loss = 0.71191475
Iteration 303, loss = 0.71205283
Iteration 304, loss = 0.71109336
Iteration 305, loss = 0.71106898
Iteration 306, loss = 0.71102862
Iteration 307, loss = 0.71010245
Iteration 308, loss = 0.70970955
Iteration 309, loss = 0.70903768
Iteration 310, loss = 0.70684860
Iteration 311, loss = 0.71293609
Iteration 312, loss = 0.70427034
Iteration 313, loss = 0.71067566
Iteration 314, loss = 0.71358706
Iteration 315, loss = 0.71407110
Iteration 316, loss = 0.71279772
Iteration 317, loss = 0.70340769
Iteration 318, loss = 0.72811407
Iteration 319, loss = 0.71934663
Iteration 320, loss = 0.73250989
Iteration 321, loss = 0.73316776
Iteration 322, loss = 0.72275034
Iteration 323, loss = 0.73009631
Iteration 324, loss = 0.72857609
Iteration 325, loss = 0.71945080
Iteration 326, loss = 0.72391204
Iteration 327, loss = 0.72240374
Iteration 328, loss = 0.71581891
Iteration 329, loss = 0.71946922
Iteration 330, loss = 0.71876868
Iteration 331, loss = 0.71461271
Iteration 332, loss = 0.71793582
Iteration 333, loss = 0.71775965
Iteration 334, loss = 0.71503124
Iteration 335, loss = 0.71752830
Iteration 336, loss = 0.71707008
Iteration 337, loss = 0.71482890
Iteration 338, loss = 0.71637903
Iteration 339, loss = 0.71566328
Iteration 340, loss = 0.71395632
Iteration 341, loss = 0.71507879
Iteration 342, loss = 0.71442823
Iteration 343, loss = 0.71325719
Iteration 344, loss = 0.71410914
Iteration 345, loss = 0.71351346
Iteration 346, loss = 0.71267487
Iteration 347, loss = 0.71324057
Iteration 348, loss = 0.71264581
Iteration 349, loss = 0.71202277
Iteration 350, loss = 0.71235980
Iteration 351, loss = 0.71177344
Iteration 352, loss = 0.71130013
Iteration 353, loss = 0.71148967
Iteration 354, loss = 0.71099042
Iteration 355, loss = 0.71069758
Iteration 356, loss = 0.71083194
Iteration 357, loss = 0.71042879
Iteration 358, loss = 0.71022853
Iteration 359, loss = 0.71025032
Iteration 360, loss = 0.70985862
Iteration 361, loss = 0.70967306
Iteration 362, loss = 0.70959577
Iteration 363, loss = 0.70922195
Iteration 364, loss = 0.70903641
Iteration 365, loss = 0.70887860
Iteration 366, loss = 0.70851944
Iteration 367, loss = 0.70832919
Iteration 368, loss = 0.70813207
Iteration 369, loss = 0.70782361
Iteration 370, loss = 0.70765979
Iteration 371, loss = 0.70745788
Iteration 372, loss = 0.70719448
Iteration 373, loss = 0.70704144
Iteration 374, loss = 0.70683157
Iteration 375, loss = 0.70658413
Iteration 376, loss = 0.70640959
Iteration 377, loss = 0.70618585
Iteration 378, loss = 0.70596433
Iteration 379, loss = 0.70579900
Iteration 380, loss = 0.70558918
Iteration 381, loss = 0.70538249
Iteration 382, loss = 0.70518658
Iteration 383, loss = 0.70493003
Iteration 384, loss = 0.70466999
Iteration 385, loss = 0.70439392
Iteration 386, loss = 0.70390358
Iteration 387, loss = 0.71435009
Iteration 388, loss = 0.70351790
Iteration 389, loss = 0.71182634
Iteration 390, loss = 0.71168116
Iteration 391, loss = 0.70367619
Iteration 392, loss = 0.70866872
Iteration 393, loss = 0.70741480
Iteration 394, loss = 0.70115405
Iteration 395, loss = 0.70475786
Iteration 396, loss = 0.70398419
Iteration 397, loss = 0.69931879
Iteration 398, loss = 0.70195816
Iteration 399, loss = 0.70106103
Iteration 400, loss = 0.69688690
Iteration 401, loss = 0.69817207
Iteration 402, loss = 0.69653212
Iteration 403, loss = 0.69228561
Iteration 404, loss = 0.69355083
Iteration 405, loss = 0.66541314
Iteration 406, loss = 0.76755132
Iteration 407, loss = 0.72057223
Iteration 408, loss = 0.79162034
Iteration 409, loss = 0.77750993
Iteration 410, loss = 0.72377688
Iteration 411, loss = 0.76223553
Iteration 412, loss = 0.76521410
Iteration 413, loss = 0.71794841
Iteration 414, loss = 0.73438958
Iteration 415, loss = 0.74806744
Iteration 416, loss = 0.71361103
Iteration 417, loss = 0.71619593
Iteration 418, loss = 0.73522305
Iteration 419, loss = 0.71435712
Iteration 420, loss = 0.70978085
Iteration 421, loss = 0.72695983
Iteration 422, loss = 0.71636452
Iteration 423, loss = 0.70769451
Iteration 424, loss = 0.72010150
Iteration 425, loss = 0.71574109
Iteration 426, loss = 0.70572946
Iteration 427, loss = 0.71305807
Iteration 428, loss = 0.71257778
Iteration 429, loss = 0.70367902
Iteration 430, loss = 0.70740504
Iteration 431, loss = 0.70937981
Iteration 432, loss = 0.70272659
Iteration 433, loss = 0.70371981
Iteration 434, loss = 0.70492285
Iteration 435, loss = 0.69210418
Iteration 436, loss = 0.83316425
Iteration 437, loss = 0.74322728
Iteration 438, loss = 0.78278464
Iteration 439, loss = 0.73885621
Iteration 440, loss = 0.75214928
Iteration 441, loss = 0.78714103
Iteration 442, loss = 0.75160990
Iteration 443, loss = 0.73537000
Iteration 444, loss = 0.75891151
Iteration 445, loss = 0.73830869
Iteration 446, loss = 0.71248897
Iteration 447, loss = 0.72468485
Iteration 448, loss = 0.67960707
Iteration 449, loss = 0.87396409
Iteration 450, loss = 0.73789374
Iteration 451, loss = 0.79162958
Iteration 452, loss = 0.84873510
Iteration 453, loss = 0.74150694
Iteration 454, loss = 0.76811187
Iteration 455, loss = 0.81036414
Iteration 456, loss = 0.72985727
Iteration 457, loss = 0.74277362
Iteration 458, loss = 0.77872163
Iteration 459, loss = 0.72230784
Iteration 460, loss = 0.72886062
Iteration 461, loss = 0.75822928
Iteration 462, loss = 0.71853929
Iteration 463, loss = 0.71991657
Iteration 464, loss = 0.74248118
Iteration 465, loss = 0.71476349
Iteration 466, loss = 0.72437500
Iteration 467, loss = 0.74975799
Iteration 468, loss = 0.70629785
Iteration 469, loss = 0.82400853
Iteration 470, loss = 0.77110847
Iteration 471, loss = 0.73645963
Iteration 472, loss = 0.79252145
Iteration 473, loss = 0.76597060
Iteration 474, loss = 0.72033642
Iteration 475, loss = 0.75653887
Iteration 476, loss = 0.75546251
Iteration 477, loss = 0.71739082
Iteration 478, loss = 0.73805816
Iteration 479, loss = 0.75099300
Iteration 480, loss = 0.72304693
Iteration 481, loss = 0.72952155
Iteration 482, loss = 0.74531214
Iteration 483, loss = 0.72625009
Iteration 484, loss = 0.72307929
Iteration 485, loss = 0.73698194
Iteration 486, loss = 0.72605178
Iteration 487, loss = 0.71873123
Iteration 488, loss = 0.72953686
Iteration 489, loss = 0.72520919
Iteration 490, loss = 0.71735959
Iteration 491, loss = 0.72474290
Iteration 492, loss = 0.72443789
Iteration 493, loss = 0.71733560
Iteration 494, loss = 0.72133710
Iteration 495, loss = 0.72291566
Iteration 496, loss = 0.71724573
Iteration 497, loss = 0.71882375
Iteration 498, loss = 0.72115896
Iteration 499, loss = 0.71717013
Iteration 500, loss = 0.71724438
Iteration 501, loss = 0.71956657
Iteration 502, loss = 0.71698054
Iteration 503, loss = 0.71605107
Iteration 504, loss = 0.71981310
Iteration 505, loss = 0.71216497
Iteration 506, loss = 0.71744151
Iteration 507, loss = 0.72096724
Iteration 508, loss = 0.72129744
Iteration 509, loss = 0.71863536
Iteration 510, loss = 0.71830664
Iteration 511, loss = 0.71845172
Iteration 512, loss = 0.71719710
Iteration 513, loss = 0.71738936
Iteration 514, loss = 0.71843457
Iteration 515, loss = 0.71790242
Iteration 516, loss = 0.71751787
Iteration 517, loss = 0.71796740
Iteration 518, loss = 0.71746764
Iteration 519, loss = 0.71663708
Iteration 520, loss = 0.71487734
Iteration 521, loss = 0.72390680
Iteration 522, loss = 0.71898377
Iteration 523, loss = 0.72414573
Iteration 524, loss = 0.72429351
Iteration 525, loss = 0.71829297
Iteration 526, loss = 0.72042409
Iteration 527, loss = 0.72069563
Iteration 528, loss = 0.71694629
Iteration 529, loss = 0.71913677
Iteration 530, loss = 0.71979746
Iteration 531, loss = 0.71677110
Iteration 532, loss = 0.71787143
Iteration 533, loss = 0.71822399
Iteration 534, loss = 0.71539987
Iteration 535, loss = 0.71646344
Iteration 536, loss = 0.71726679
Iteration 537, loss = 0.71673147
Iteration 538, loss = 0.71704572
Iteration 539, loss = 0.71706773
Iteration 540, loss = 0.71590727
Iteration 541, loss = 0.71551092
Iteration 542, loss = 0.71524701
Iteration 543, loss = 0.71441735
Iteration 544, loss = 0.71431984
Iteration 545, loss = 0.71435676
Iteration 546, loss = 0.71390129
Iteration 547, loss = 0.71385505
Iteration 548, loss = 0.71378657
Iteration 549, loss = 0.71329442
Iteration 550, loss = 0.71311152
Iteration 551, loss = 0.71296602
Iteration 552, loss = 0.71257711
Iteration 553, loss = 0.71244892
Iteration 554, loss = 0.71233120
Iteration 555, loss = 0.71200592
Iteration 556, loss = 0.71184756
Iteration 557, loss = 0.71167888
Iteration 558, loss = 0.71136401
Iteration 559, loss = 0.71118410
Iteration 560, loss = 0.71100343
Iteration 561, loss = 0.71073450
Iteration 562, loss = 0.71057934
Iteration 563, loss = 0.71042147
Iteration 564, loss = 0.71019614
Iteration 565, loss = 0.71004193
Iteration 566, loss = 0.70986535
Iteration 567, loss = 0.70963494
Iteration 568, loss = 0.70946128
Iteration 569, loss = 0.70927800
Iteration 570, loss = 0.70907075
Iteration 571, loss = 0.70891338
Iteration 572, loss = 0.70874588
Iteration 573, loss = 0.70855947
Iteration 574, loss = 0.70840468
Iteration 575, loss = 0.70823592
Iteration 576, loss = 0.70805481
Iteration 577, loss = 0.70789836
Iteration 578, loss = 0.70773258
Iteration 579, loss = 0.70756332
Iteration 580, loss = 0.70741413
Iteration 581, loss = 0.70725672
Iteration 582, loss = 0.70709699
Iteration 583, loss = 0.70694940
Iteration 584, loss = 0.70679358
Iteration 585, loss = 0.70663815
Iteration 586, loss = 0.70649288
Iteration 587, loss = 0.70634294
Iteration 588, loss = 0.70619595
Iteration 589, loss = 0.70605623
Iteration 590, loss = 0.70591220
Iteration 591, loss = 0.70577030
Iteration 592, loss = 0.70563228
Iteration 593, loss = 0.70549064
Iteration 594, loss = 0.70535181
Iteration 595, loss = 0.70521635
Iteration 596, loss = 0.70507933
Iteration 597, loss = 0.70494556
Iteration 598, loss = 0.70481396
Iteration 599, loss = 0.70468111
Iteration 600, loss = 0.70455080
Iteration 601, loss = 0.70442166
Iteration 602, loss = 0.70429198
Iteration 603, loss = 0.70416471
Iteration 604, loss = 0.70403836
Iteration 605, loss = 0.70391202
Iteration 606, loss = 0.70378765
Iteration 607, loss = 0.70366361
Iteration 608, loss = 0.70353946
Iteration 609, loss = 0.70341616
Iteration 610, loss = 0.70329148
Iteration 611, loss = 0.70316205
Iteration 612, loss = 0.70298147
Iteration 613, loss = 0.70260082
Iteration 614, loss = 0.70213998
Iteration 615, loss = 0.70201420
Iteration 616, loss = 0.70164515
Iteration 617, loss = 0.70111818
Iteration 618, loss = 0.70024279
Iteration 619, loss = 0.69526169
Iteration 620, loss = 0.72717502
Iteration 621, loss = 0.69797083
Iteration 622, loss = 0.65420884
Iteration 623, loss = 0.71507984
Iteration 624, loss = 0.71873386
Iteration 625, loss = 0.72731128
Iteration 626, loss = 0.71420069
Iteration 627, loss = 0.73196660
Iteration 628, loss = 0.71997025
Iteration 629, loss = 0.70735043
Iteration 630, loss = 0.72078304
Iteration 631, loss = 0.71864202
Iteration 632, loss = 0.71431266
Iteration 633, loss = 0.71401944
Iteration 634, loss = 0.72951810
Iteration 635, loss = 0.73041190
Iteration 636, loss = 0.70671577
Iteration 637, loss = 0.71737733
Iteration 638, loss = 0.71978423
Iteration 639, loss = 0.71518671
Iteration 640, loss = 0.71678116
Iteration 641, loss = 0.71708438
Iteration 642, loss = 0.71121967
Iteration 643, loss = 0.71027809
Iteration 644, loss = 0.71295136
Iteration 645, loss = 0.71127759
Iteration 646, loss = 0.71079598
Iteration 647, loss = 0.71368012
Iteration 648, loss = 0.71344311
Iteration 649, loss = 0.71193684
Iteration 650, loss = 0.71318766
Iteration 651, loss = 0.71334190
Iteration 652, loss = 0.71174946
Iteration 653, loss = 0.71209526
Iteration 654, loss = 0.71266306
Iteration 655, loss = 0.71157614
Iteration 656, loss = 0.71144645
Iteration 657, loss = 0.71216219
Iteration 658, loss = 0.71166568
Iteration 659, loss = 0.71132242
Iteration 660, loss = 0.71187443
Iteration 661, loss = 0.71168307
Iteration 662, loss = 0.71117019
Iteration 663, loss = 0.71139241
Iteration 664, loss = 0.71134287
Iteration 665, loss = 0.71084298
Iteration 666, loss = 0.71084939
Iteration 667, loss = 0.71089390
Iteration 668, loss = 0.71050157
Iteration 669, loss = 0.71035434
Iteration 670, loss = 0.71038277
Iteration 671, loss = 0.71008219
Iteration 672, loss = 0.70985778
Iteration 673, loss = 0.70987013
Iteration 674, loss = 0.70969351
Iteration 675, loss = 0.70947419
Iteration 676, loss = 0.70943925
Iteration 677, loss = 0.70929527
Iteration 678, loss = 0.70904354
Iteration 679, loss = 0.70892617
Iteration 680, loss = 0.70879418
Iteration 681, loss = 0.70856831
Iteration 682, loss = 0.70843269
Iteration 683, loss = 0.70832605
Iteration 684, loss = 0.70813469
Iteration 685, loss = 0.70798012
Iteration 686, loss = 0.70786818
Iteration 687, loss = 0.70769575
Iteration 688, loss = 0.70753004
Iteration 689, loss = 0.70740889
Iteration 690, loss = 0.70725144
Iteration 691, loss = 0.70708286
Iteration 692, loss = 0.70695121
Iteration 693, loss = 0.70680290
Iteration 694, loss = 0.70663737
Iteration 695, loss = 0.70649970
Iteration 696, loss = 0.70635958
Iteration 697, loss = 0.70620241
Iteration 698, loss = 0.70606310
Iteration 699, loss = 0.70592799
Iteration 700, loss = 0.70577702
Iteration 701, loss = 0.70563388
Iteration 702, loss = 0.70549612
Iteration 703, loss = 0.70534416
Iteration 704, loss = 0.70518988
Iteration 705, loss = 0.70502697
Iteration 706, loss = 0.70477105
Iteration 707, loss = 0.68910212
Iteration 708, loss = 0.70376484
Iteration 709, loss = 0.70389490
Iteration 710, loss = 0.70305846
Iteration 711, loss = 0.69326614
Iteration 712, loss = 0.65307947
Iteration 713, loss = 1.59470671
Iteration 714, loss = 0.82345526
Iteration 715, loss = 1.20791653
Iteration 716, loss = 1.51855408
Iteration 717, loss = 1.06297680
Iteration 718, loss = 0.78377091
Iteration 719, loss = 1.20485222
Iteration 720, loss = 1.14602259
Iteration 721, loss = 0.75549923
Iteration 722, loss = 0.90211778
Iteration 723, loss = 1.08689983
Iteration 724, loss = 0.86698048
Iteration 725, loss = 0.73225072
Iteration 726, loss = 0.93888964
Iteration 727, loss = 0.91605509
Iteration 728, loss = 0.72545280
Iteration 729, loss = 0.80011378
Iteration 730, loss = 0.89213733
Iteration 731, loss = 0.77458535
Iteration 732, loss = 0.72299203
Iteration 733, loss = 0.82043483
Iteration 734, loss = 0.77915590
Iteration 735, loss = 0.85354816
Iteration 736, loss = 0.75871668
Iteration 737, loss = 0.75776991
Iteration 738, loss = 0.82139133
Iteration 739, loss = 0.73349485
Iteration 740, loss = 0.77781217
Iteration 741, loss = 0.79073815
Iteration 742, loss = 0.72649940
Iteration 743, loss = 0.76796506
Iteration 744, loss = 0.75639684
Iteration 745, loss = 0.71591665
Iteration 746, loss = 0.74993600
Iteration 747, loss = 0.72952580
Iteration 748, loss = 0.70363766
Iteration 749, loss = 0.75924119
Iteration 750, loss = 0.72901909
Iteration 751, loss = 0.70627252
Iteration 752, loss = 0.73684157
Iteration 753, loss = 0.73393831
Iteration 754, loss = 0.70343301
Iteration 755, loss = 0.71391316
Iteration 756, loss = 0.72731287
Iteration 757, loss = 0.70732895
Iteration 758, loss = 0.70058507
Iteration 759, loss = 0.71580336
Iteration 760, loss = 0.71014822
Iteration 761, loss = 0.69635578
Iteration 762, loss = 0.70370704
Iteration 763, loss = 0.70801432
Iteration 764, loss = 0.69664883
Iteration 765, loss = 0.69472451
Iteration 766, loss = 0.69860648
Iteration 767, loss = 0.69441429
Iteration 768, loss = 0.68510272
Iteration 769, loss = 0.68747920
Iteration 770, loss = 0.68704913
Iteration 771, loss = 0.68373424
Iteration 772, loss = 0.68042512
Iteration 773, loss = 0.64871809
Iteration 774, loss = 1.43400526
Iteration 775, loss = 0.78458824
Iteration 776, loss = 1.13666773
Iteration 777, loss = 1.36100033
Iteration 778, loss = 0.94758797
Iteration 779, loss = 0.83914772
Iteration 780, loss = 1.17003825
Iteration 781, loss = 1.05060183
Iteration 782, loss = 0.75574087
Iteration 783, loss = 0.94540568
Iteration 784, loss = 1.03144238
Iteration 785, loss = 0.80241398
Iteration 786, loss = 0.78758858
Iteration 787, loss = 0.94278315
Iteration 788, loss = 0.84210958
Iteration 789, loss = 0.72496518
Iteration 790, loss = 0.83944091
Iteration 791, loss = 0.84200717
Iteration 792, loss = 0.72309329
Iteration 793, loss = 0.76031303
Iteration 794, loss = 0.81418153
Iteration 795, loss = 0.73323569
Iteration 796, loss = 0.70190812
Iteration 797, loss = 1.48693923
Iteration 798, loss = 0.68926738
Iteration 799, loss = 0.76569042
Iteration 800, loss = 0.78719858
Iteration 801, loss = 0.72765289
Iteration 802, loss = 0.73865236
Iteration 803, loss = 0.77278555
Iteration 804, loss = 0.71272791
Iteration 805, loss = 0.52482916
Iteration 806, loss = 0.95633968
Iteration 807, loss = 0.85855034
Iteration 808, loss = 0.78168812
Iteration 809, loss = 0.93563416
Iteration 810, loss = 0.81048203
Iteration 811, loss = 0.77941820
Iteration 812, loss = 0.87373881
Iteration 813, loss = 0.76874581
Iteration 814, loss = 0.75665379
Iteration 815, loss = 0.81914090
Iteration 816, loss = 0.73776951
Iteration 817, loss = 0.73660055
Iteration 818, loss = 0.78098529
Iteration 819, loss = 0.72087512
Iteration 820, loss = 0.72338830
Iteration 821, loss = 0.75446194
Iteration 822, loss = 0.71118803
Iteration 823, loss = 0.71473688
Iteration 824, loss = 0.73678552
Iteration 825, loss = 0.70215340
Iteration 826, loss = 0.70495108
Iteration 827, loss = 0.70895914
Iteration 828, loss = 0.61972128
Iteration 829, loss = 0.76673672
Iteration 830, loss = 0.74634966
Iteration 831, loss = 0.74696975
Iteration 832, loss = 0.78100887
Iteration 833, loss = 0.75191870
Iteration 834, loss = 0.74404046
Iteration 835, loss = 0.76246769
Iteration 836, loss = 0.73641843
Iteration 837, loss = 0.72868147
Iteration 838, loss = 0.74191142
Iteration 839, loss = 0.72399016
Iteration 840, loss = 0.72110118
Iteration 841, loss = 0.73249081
Iteration 842, loss = 0.72093858
Iteration 843, loss = 0.72062341
Iteration 844, loss = 0.72914815
Iteration 845, loss = 0.72007771
Iteration 846, loss = 0.71973237
Iteration 847, loss = 0.72483292
Iteration 848, loss = 0.71717217
Iteration 849, loss = 0.71670624
Iteration 850, loss = 0.71941280
Iteration 851, loss = 0.69911079
Iteration 852, loss = 0.72081328
Iteration 853, loss = 0.72597460
Iteration 854, loss = 0.71827778
Iteration 855, loss = 0.72165339
Iteration 856, loss = 0.72302712
Iteration 857, loss = 0.71588770
Iteration 858, loss = 0.71838716
Iteration 859, loss = 0.71974681
Iteration 860, loss = 0.71571469
Iteration 861, loss = 0.71870027
Iteration 862, loss = 0.71978020
Iteration 863, loss = 0.71678668
Iteration 864, loss = 0.71871381
Iteration 865, loss = 0.71871957
Iteration 866, loss = 0.71617091
Iteration 867, loss = 0.71751404
Iteration 868, loss = 0.71739536
Iteration 869, loss = 0.71582756
Iteration 870, loss = 0.71705093
Iteration 871, loss = 0.71676382
Iteration 872, loss = 0.71555093
Iteration 873, loss = 0.71634603
Iteration 874, loss = 0.71579295
Iteration 875, loss = 0.71454476
Iteration 876, loss = 0.71446735
Iteration 877, loss = 0.71330065
Iteration 878, loss = 0.71228321
Iteration 879, loss = 0.71227524
Iteration 880, loss = 0.71117906
Iteration 881, loss = 0.70970812
Iteration 882, loss = 0.70995987
Iteration 883, loss = 0.70906093
Iteration 884, loss = 0.70732692
Iteration 885, loss = 0.70626501
Iteration 886, loss = 0.70391119
Iteration 887, loss = 0.70047305
Iteration 888, loss = 0.60791930
Iteration 889, loss = 0.74499392
Iteration 890, loss = 0.74047874
Iteration 891, loss = 0.71327527
Iteration 892, loss = 0.74444257
Iteration 893, loss = 0.73590107
Iteration 894, loss = 0.71068353
Iteration 895, loss = 0.72976427
Iteration 896, loss = 0.71966081
Iteration 897, loss = 0.69364952
Iteration 898, loss = 0.66314498
Iteration 899, loss = 0.91570797
Iteration 900, loss = 0.73338456
Iteration 901, loss = 0.88902889
Iteration 902, loss = 0.91198249
Iteration 903, loss = 0.74587185
Iteration 904, loss = 0.79674480
Iteration 905, loss = 0.87235640
Iteration 906, loss = 0.76236440
Iteration 907, loss = 0.74169652
Iteration 908, loss = 0.82378704
Iteration 909, loss = 0.77211967
Iteration 910, loss = 0.72101085
Iteration 911, loss = 0.78288404
Iteration 912, loss = 0.77406808
Iteration 913, loss = 0.71995374
Iteration 914, loss = 0.75317890
Iteration 915, loss = 0.76800726
Iteration 916, loss = 0.72473032
Iteration 917, loss = 0.73340975
Iteration 918, loss = 0.75650018
Iteration 919, loss = 0.72855590
Iteration 920, loss = 0.72181724
Iteration 921, loss = 0.74297650
Iteration 922, loss = 0.72899739
Iteration 923, loss = 0.71565777
Iteration 924, loss = 0.73071884
Iteration 925, loss = 0.72656408
Iteration 926, loss = 0.71123629
Iteration 927, loss = 0.71785377
Iteration 928, loss = 0.71785746
Iteration 929, loss = 0.70457970
Iteration 930, loss = 0.80755107
Iteration 931, loss = 0.73135570
Iteration 932, loss = 0.76506849
Iteration 933, loss = 0.75351279
Iteration 934, loss = 0.76255244
Iteration 935, loss = 0.78468221
Iteration 936, loss = 0.77070719
Iteration 937, loss = 0.76039363
Iteration 938, loss = 0.76937805
Iteration 939, loss = 0.75763683
Iteration 940, loss = 0.74166754
Iteration 941, loss = 0.74581636
Iteration 942, loss = 0.74197021
Iteration 943, loss = 0.72990707
Iteration 944, loss = 0.73254833
Iteration 945, loss = 0.73468272
Iteration 946, loss = 0.72733548
Iteration 947, loss = 0.72834427
Iteration 948, loss = 0.73220926
Iteration 949, loss = 0.72773945
Iteration 950, loss = 0.72672023
Iteration 951, loss = 0.73008925
Iteration 952, loss = 0.72767010
Iteration 953, loss = 0.72568548
Iteration 954, loss = 0.72813565
Iteration 955, loss = 0.72722607
Iteration 956, loss = 0.72506435
Iteration 957, loss = 0.72649372
Iteration 958, loss = 0.72641042
Iteration 959, loss = 0.72437077
Iteration 960, loss = 0.72478441
Iteration 961, loss = 0.72492807
Iteration 962, loss = 0.72314667
Iteration 963, loss = 0.72286888
Iteration 964, loss = 0.72311797
Iteration 965, loss = 0.72187869
Iteration 966, loss = 0.72141635
Iteration 967, loss = 0.72178144
Iteration 968, loss = 0.72107673
Iteration 969, loss = 0.72056697
Iteration 970, loss = 0.72086089
Iteration 971, loss = 0.72046643
Iteration 972, loss = 0.71991924
Iteration 973, loss = 0.72002538
Iteration 974, loss = 0.71976538
Iteration 975, loss = 0.71922289
Iteration 976, loss = 0.71918086
Iteration 977, loss = 0.71901599
Iteration 978, loss = 0.71853794
Iteration 979, loss = 0.71838177
Iteration 980, loss = 0.71823742
Iteration 981, loss = 0.71781107
Iteration 982, loss = 0.71757743
Iteration 983, loss = 0.71745763
Iteration 984, loss = 0.71715349
Iteration 985, loss = 0.71696294
Iteration 986, loss = 0.71690428
Iteration 987, loss = 0.71669436
Iteration 988, loss = 0.71649421
Iteration 989, loss = 0.71639736
Iteration 990, loss = 0.71620338
Iteration 991, loss = 0.71599311
Iteration 992, loss = 0.71587782
Iteration 993, loss = 0.71570633
Iteration 994, loss = 0.71547663
Iteration 995, loss = 0.71526053
Iteration 996, loss = 0.71491569
Iteration 997, loss = 0.71441126
Iteration 998, loss = 0.71403473
Iteration 999, loss = 0.71386383
Iteration 1000, loss = 0.71367799
Iteration 1001, loss = 0.71344820
Iteration 1002, loss = 0.71317595
Iteration 1003, loss = 0.71289096
Iteration 1004, loss = 0.71267067
Iteration 1005, loss = 0.71248938
Iteration 1006, loss = 0.71229099
Iteration 1007, loss = 0.71209380
Iteration 1008, loss = 0.71187632
Iteration 1009, loss = 0.71156737
Iteration 1010, loss = 0.71114323
Iteration 1011, loss = 0.71068486
Iteration 1012, loss = 0.71034131
Iteration 1013, loss = 0.71003265
Iteration 1014, loss = 0.70964604
Iteration 1015, loss = 0.70899367
Iteration 1016, loss = 0.70808505
Iteration 1017, loss = 0.70746782
Iteration 1018, loss = 0.70703319
Iteration 1019, loss = 0.70656348
Iteration 1020, loss = 0.70590953
Iteration 1021, loss = 0.70493315
Iteration 1022, loss = 0.70411184
Iteration 1023, loss = 0.70354430
Iteration 1024, loss = 0.70236834
Iteration 1025, loss = 0.70156742
Iteration 1026, loss = 0.70144561
Iteration 1027, loss = 0.70068853
Iteration 1028, loss = 0.70007120
Iteration 1029, loss = 0.69967993
Iteration 1030, loss = 0.69923426
Iteration 1031, loss = 0.69807829
Iteration 1032, loss = 0.69530288
Iteration 1033, loss = 0.69458559
Iteration 1034, loss = 0.69253560
Iteration 1035, loss = 0.69147137
Iteration 1036, loss = 0.68915736
Iteration 1037, loss = 0.68701893
Iteration 1038, loss = 0.67830051
Iteration 1039, loss = 0.63037695
Iteration 1040, loss = 0.97760461
Iteration 1041, loss = 0.75468402
Iteration 1042, loss = 0.87072758
Iteration 1043, loss = 0.98669561
Iteration 1044, loss = 0.83330998
Iteration 1045, loss = 0.76392750
Iteration 1046, loss = 0.88950480
Iteration 1047, loss = 0.85603488
Iteration 1048, loss = 0.73405649
Iteration 1049, loss = 0.78786684
Iteration 1050, loss = 0.83410731
Iteration 1051, loss = 0.74943023
Iteration 1052, loss = 0.73143712
Iteration 1053, loss = 0.79579696
Iteration 1054, loss = 0.76939573
Iteration 1055, loss = 0.72177129
Iteration 1056, loss = 0.76079966
Iteration 1057, loss = 0.77417195
Iteration 1058, loss = 0.73015057
Iteration 1059, loss = 0.73414930
Iteration 1060, loss = 0.76095491
Iteration 1061, loss = 0.73733830
Iteration 1062, loss = 0.71997884
Iteration 1063, loss = 0.74167476
Iteration 1064, loss = 0.73920756
Iteration 1065, loss = 0.71846016
Iteration 1066, loss = 0.72745068
Iteration 1067, loss = 0.73648541
Iteration 1068, loss = 0.72184236
Iteration 1069, loss = 0.71950083
Iteration 1070, loss = 0.73023183
Iteration 1071, loss = 0.72425452
Iteration 1072, loss = 0.71653378
Iteration 1073, loss = 0.72349670
Iteration 1074, loss = 0.72424768
Iteration 1075, loss = 0.71653563
Iteration 1076, loss = 0.71849261
Iteration 1077, loss = 0.72232558
Iteration 1078, loss = 0.71746625
Iteration 1079, loss = 0.71586903
Iteration 1080, loss = 0.71971512
Iteration 1081, loss = 0.71807434
Iteration 1082, loss = 0.71503495
Iteration 1083, loss = 0.71724563
Iteration 1084, loss = 0.71776387
Iteration 1085, loss = 0.71497321
Iteration 1086, loss = 0.71539122
Iteration 1087, loss = 0.71677169
Iteration 1088, loss = 0.71505781
Iteration 1089, loss = 0.71430367
Iteration 1090, loss = 0.71557780
Iteration 1091, loss = 0.71499697
Iteration 1092, loss = 0.71384199
Iteration 1093, loss = 0.71454846
Iteration 1094, loss = 0.71471108
Iteration 1095, loss = 0.71368597
Iteration 1096, loss = 0.71377823
Iteration 1097, loss = 0.71421454
Iteration 1098, loss = 0.71355586
Iteration 1099, loss = 0.71324026
Iteration 1100, loss = 0.71362467
Iteration 1101, loss = 0.71333911
Iteration 1102, loss = 0.71287005
Iteration 1103, loss = 0.71305182
Iteration 1104, loss = 0.71301161
Iteration 1105, loss = 0.71256785
Iteration 1106, loss = 0.71252928
Iteration 1107, loss = 0.71257416
Iteration 1108, loss = 0.71222497
Iteration 1109, loss = 0.71201185
Iteration 1110, loss = 0.71201010
Iteration 1111, loss = 0.71173964
Iteration 1112, loss = 0.71140975
Iteration 1113, loss = 0.71127372
Iteration 1114, loss = 0.71098868
Iteration 1115, loss = 0.71050882
Iteration 1116, loss = 0.71007263
Iteration 1117, loss = 0.70946231
Iteration 1118, loss = 0.70842789
Iteration 1119, loss = 0.70695256
Iteration 1120, loss = 0.70434975
Iteration 1121, loss = 0.69809802
Iteration 1122, loss = 0.60295889
Iteration 1123, loss = 0.73193816
Iteration 1124, loss = 0.73874449
Iteration 1125, loss = 0.72028729
Iteration 1126, loss = 0.73152067
Iteration 1127, loss = 0.74313391
Iteration 1128, loss = 0.72888015
Iteration 1129, loss = 0.72644143
Iteration 1130, loss = 0.73699020
Iteration 1131, loss = 0.72918006
Iteration 1132, loss = 0.72108602
Iteration 1133, loss = 0.72807940
Iteration 1134, loss = 0.72713540
Iteration 1135, loss = 0.71962545
Iteration 1136, loss = 0.72341000
Iteration 1137, loss = 0.72669041
Iteration 1138, loss = 0.72189910
Iteration 1139, loss = 0.72286817
Iteration 1140, loss = 0.72717002
Iteration 1141, loss = 0.72468436
Iteration 1142, loss = 0.72320171
Iteration 1143, loss = 0.72619907
Iteration 1144, loss = 0.72528206
Iteration 1145, loss = 0.72279580
Iteration 1146, loss = 0.72428060
Iteration 1147, loss = 0.72460611
Iteration 1148, loss = 0.72248220
Iteration 1149, loss = 0.72290313
Iteration 1150, loss = 0.72388353
Iteration 1151, loss = 0.72257346
Iteration 1152, loss = 0.72231964
Iteration 1153, loss = 0.72336577
Iteration 1154, loss = 0.72281245
Iteration 1155, loss = 0.72220761
Iteration 1156, loss = 0.72291176
Iteration 1157, loss = 0.72280062
Iteration 1158, loss = 0.72207968
Iteration 1159, loss = 0.72235154
Iteration 1160, loss = 0.72246499
Iteration 1161, loss = 0.72185331
Iteration 1162, loss = 0.72181784
Iteration 1163, loss = 0.72201169
Iteration 1164, loss = 0.72160203
Iteration 1165, loss = 0.72139920
Iteration 1166, loss = 0.72157081
Iteration 1167, loss = 0.72135284
Iteration 1168, loss = 0.72109041
Iteration 1169, loss = 0.72118050
Iteration 1170, loss = 0.72108624
Iteration 1171, loss = 0.72082439
Iteration 1172, loss = 0.72081798
Iteration 1173, loss = 0.72078138
Iteration 1174, loss = 0.72055366
Iteration 1175, loss = 0.72046979
Iteration 1176, loss = 0.72044499
Iteration 1177, loss = 0.72026309
Iteration 1178, loss = 0.72013445
Iteration 1179, loss = 0.72010033
Iteration 1180, loss = 0.71996475
Iteration 1181, loss = 0.71982222
Iteration 1182, loss = 0.71976987
Iteration 1183, loss = 0.71966669
Iteration 1184, loss = 0.71952529
Iteration 1185, loss = 0.71945149
Iteration 1186, loss = 0.71936556
Iteration 1187, loss = 0.71923420
Iteration 1188, loss = 0.71914413
Iteration 1189, loss = 0.71906492
Iteration 1190, loss = 0.71894600
Iteration 1191, loss = 0.71884529
Iteration 1192, loss = 0.71876517
Iteration 1193, loss = 0.71865697
Iteration 1194, loss = 0.71855121
Iteration 1195, loss = 0.71846693
Iteration 1196, loss = 0.71836639
Iteration 1197, loss = 0.71825911
Iteration 1198, loss = 0.71816881
Iteration 1199, loss = 0.71807107
Iteration 1200, loss = 0.71796201
Iteration 1201, loss = 0.71786248
Iteration 1202, loss = 0.71775958
Iteration 1203, loss = 0.71764380
Iteration 1204, loss = 0.71753364
Iteration 1205, loss = 0.71743129
Iteration 1206, loss = 0.71733130
Iteration 1207, loss = 0.71724263
Iteration 1208, loss = 0.71715912
Iteration 1209, loss = 0.71706400
Iteration 1210, loss = 0.71696161
Iteration 1211, loss = 0.71686093
Iteration 1212, loss = 0.71676043
Iteration 1213, loss = 0.71666393
Iteration 1214, loss = 0.71657448
Iteration 1215, loss = 0.71648426
Iteration 1216, loss = 0.71639033
Iteration 1217, loss = 0.71629677
Iteration 1218, loss = 0.71620267
Iteration 1219, loss = 0.71610812
Iteration 1220, loss = 0.71601740
Iteration 1221, loss = 0.71592943
Iteration 1222, loss = 0.71584080
Iteration 1223, loss = 0.71575233
Iteration 1224, loss = 0.71566397
Iteration 1225, loss = 0.71557455
Iteration 1226, loss = 0.71548609
Iteration 1227, loss = 0.71539980
Iteration 1228, loss = 0.71531414
Iteration 1229, loss = 0.71522907
Iteration 1230, loss = 0.71514495
Iteration 1231, loss = 0.71506070
Iteration 1232, loss = 0.71497647
Iteration 1233, loss = 0.71489326
Iteration 1234, loss = 0.71481065
Iteration 1235, loss = 0.71472838
Iteration 1236, loss = 0.71464693
Iteration 1237, loss = 0.71456593
Iteration 1238, loss = 0.71448504
Iteration 1239, loss = 0.71440472
Iteration 1240, loss = 0.71432494
Iteration 1241, loss = 0.71424542
Iteration 1242, loss = 0.71416641
Iteration 1243, loss = 0.71408791
Iteration 1244, loss = 0.71400961
Iteration 1245, loss = 0.71393163
Iteration 1246, loss = 0.71385404
Iteration 1247, loss = 0.71377664
Iteration 1248, loss = 0.71369949
Iteration 1249, loss = 0.71362268
Iteration 1250, loss = 0.71354606
Iteration 1251, loss = 0.71346958
Iteration 1252, loss = 0.71339331
Iteration 1253, loss = 0.71331710
Iteration 1254, loss = 0.71324087
Iteration 1255, loss = 0.71316464
Iteration 1256, loss = 0.71308829
Iteration 1257, loss = 0.71301171
Iteration 1258, loss = 0.71293483
Iteration 1259, loss = 0.71285750
Iteration 1260, loss = 0.71277947
Iteration 1261, loss = 0.71270056
Iteration 1262, loss = 0.71262043
Iteration 1263, loss = 0.71253866
Iteration 1264, loss = 0.71245470
Iteration 1265, loss = 0.71236785
Iteration 1266, loss = 0.71227711
Iteration 1267, loss = 0.71218128
Iteration 1268, loss = 0.71207879
Iteration 1269, loss = 0.71196747
Iteration 1270, loss = 0.71184359
Iteration 1271, loss = 0.71169734
Iteration 1272, loss = 0.71149769
Iteration 1273, loss = 0.71115012
Iteration 1274, loss = 0.71042501
Iteration 1275, loss = 0.70850949
Iteration 1276, loss = 0.70259057
Iteration 1277, loss = 0.72117448
Iteration 1278, loss = 0.68546119
Iteration 1279, loss = 0.72676014
Iteration 1280, loss = 0.73759706
Iteration 1281, loss = 0.74065034
Iteration 1282, loss = 0.73597971
Iteration 1283, loss = 0.72972888
Iteration 1284, loss = 0.72440485
Iteration 1285, loss = 0.71987809
Iteration 1286, loss = 0.71724235
Iteration 1287, loss = 0.71757022
Iteration 1288, loss = 0.71853768
Iteration 1289, loss = 0.71920874
Iteration 1290, loss = 0.72014672
Iteration 1291, loss = 0.72048194
Iteration 1292, loss = 0.71968027
Iteration 1293, loss = 0.71899913
Iteration 1294, loss = 0.71874139
Iteration 1295, loss = 0.71825239
Iteration 1296, loss = 0.71791133
Iteration 1297, loss = 0.71797054
Iteration 1298, loss = 0.71777336
Iteration 1299, loss = 0.71729679
Iteration 1300, loss = 0.71698764
Iteration 1301, loss = 0.71664363
Iteration 1302, loss = 0.71617745
Iteration 1303, loss = 0.71598887
Iteration 1304, loss = 0.71602867
Iteration 1305, loss = 0.71600714
Iteration 1306, loss = 0.71603001
Iteration 1307, loss = 0.71610031
Iteration 1308, loss = 0.71597348
Iteration 1309, loss = 0.71570177
Iteration 1310, loss = 0.71544301
Iteration 1311, loss = 0.71513246
Iteration 1312, loss = 0.71481759
Iteration 1313, loss = 0.71465053
Iteration 1314, loss = 0.71455190
Iteration 1315, loss = 0.71441254
Iteration 1316, loss = 0.71429039
Iteration 1317, loss = 0.71418633
Iteration 1318, loss = 0.71403973
Iteration 1319, loss = 0.71390202
Iteration 1320, loss = 0.71381072
Iteration 1321, loss = 0.71370487
Iteration 1322, loss = 0.71357297
Iteration 1323, loss = 0.71344079
Iteration 1324, loss = 0.71327827
Iteration 1325, loss = 0.71308161
Iteration 1326, loss = 0.71289925
Iteration 1327, loss = 0.71274182
Iteration 1328, loss = 0.71260243
Iteration 1329, loss = 0.71249348
Iteration 1330, loss = 0.71239705
Iteration 1331, loss = 0.71227936
Iteration 1332, loss = 0.71214831
Iteration 1333, loss = 0.71202238
Iteration 1334, loss = 0.71189640
Iteration 1335, loss = 0.71177060
Iteration 1336, loss = 0.71164965
Iteration 1337, loss = 0.71152298
Iteration 1338, loss = 0.71138867
Iteration 1339, loss = 0.71126103
Iteration 1340, loss = 0.71114319
Iteration 1341, loss = 0.71102956
Iteration 1342, loss = 0.71092051
Iteration 1343, loss = 0.71081222
Iteration 1344, loss = 0.71069709
Iteration 1345, loss = 0.71057687
Iteration 1346, loss = 0.71045489
Iteration 1347, loss = 0.71032822
Iteration 1348, loss = 0.71019576
Iteration 1349, loss = 0.71005724
Iteration 1350, loss = 0.70990779
Iteration 1351, loss = 0.70974825
Iteration 1352, loss = 0.70959547
Iteration 1353, loss = 0.70946930
Iteration 1354, loss = 0.70936677
Iteration 1355, loss = 0.70926667
Iteration 1356, loss = 0.70915251
Iteration 1357, loss = 0.70902198
Iteration 1358, loss = 0.70888425
Iteration 1359, loss = 0.70874792
Iteration 1360, loss = 0.70861189
Iteration 1361, loss = 0.70848021
Iteration 1362, loss = 0.70836763
Iteration 1363, loss = 0.70825767
Iteration 1364, loss = 0.70813873
Iteration 1365, loss = 0.70801539
Iteration 1366, loss = 0.70789753
Iteration 1367, loss = 0.70779126
Iteration 1368, loss = 0.70769255
Iteration 1369, loss = 0.70758855
Iteration 1370, loss = 0.70747532
Iteration 1371, loss = 0.70736109
Iteration 1372, loss = 0.70718937
Iteration 1373, loss = 0.70693042
Iteration 1374, loss = 0.70600713
Iteration 1375, loss = 0.70634141
Iteration 1376, loss = 0.70479608
Iteration 1377, loss = 0.70670879
Iteration 1378, loss = 0.70241555
Iteration 1379, loss = 0.65822242
Iteration 1380, loss = 0.80845719
Iteration 1381, loss = 0.72648699
Iteration 1382, loss = 0.76557938
Iteration 1383, loss = 0.81373924
Iteration 1384, loss = 0.75939494
Iteration 1385, loss = 0.72889519
Iteration 1386, loss = 0.77339141
Iteration 1387, loss = 0.76850223
Iteration 1388, loss = 0.72217798
Iteration 1389, loss = 0.73228032
Iteration 1390, loss = 0.75687500
Iteration 1391, loss = 0.73269720
Iteration 1392, loss = 0.71666871
Iteration 1393, loss = 0.73945816
Iteration 1394, loss = 0.74159440
Iteration 1395, loss = 0.72099268
Iteration 1396, loss = 0.72578280
Iteration 1397, loss = 0.73872997
Iteration 1398, loss = 0.72731370
Iteration 1399, loss = 0.71825454
Iteration 1400, loss = 0.72814382
Iteration 1401, loss = 0.72883969
Iteration 1402, loss = 0.71832118
Iteration 1403, loss = 0.72014560
Iteration 1404, loss = 0.72656479
Iteration 1405, loss = 0.72145893
Iteration 1406, loss = 0.71740524
Iteration 1407, loss = 0.72236952
Iteration 1408, loss = 0.72279235
Iteration 1409, loss = 0.71767950
Iteration 1410, loss = 0.71843900
Iteration 1411, loss = 0.72129982
Iteration 1412, loss = 0.71859420
Iteration 1413, loss = 0.71654809
Iteration 1414, loss = 0.71885142
Iteration 1415, loss = 0.71890421
Iteration 1416, loss = 0.71641983
Iteration 1417, loss = 0.71685172
Iteration 1418, loss = 0.71815804
Iteration 1419, loss = 0.71675716
Iteration 1420, loss = 0.71579704
Iteration 1421, loss = 0.71686549
Iteration 1422, loss = 0.71673439
Iteration 1423, loss = 0.71547291
Iteration 1424, loss = 0.71567122
Iteration 1425, loss = 0.71617847
Iteration 1426, loss = 0.71538270
Iteration 1427, loss = 0.71490520
Iteration 1428, loss = 0.71536369
Iteration 1429, loss = 0.71517727
Iteration 1430, loss = 0.71452234
Iteration 1431, loss = 0.71460531
Iteration 1432, loss = 0.71476098
Iteration 1433, loss = 0.71429510
Iteration 1434, loss = 0.71404578
Iteration 1435, loss = 0.71421031
Iteration 1436, loss = 0.71402131
Iteration 1437, loss = 0.71365394
Iteration 1438, loss = 0.71365512
Iteration 1439, loss = 0.71364314
Iteration 1440, loss = 0.71334223
Iteration 1441, loss = 0.71318356
Iteration 1442, loss = 0.71319969
Iteration 1443, loss = 0.71302599
Iteration 1444, loss = 0.71279829
Iteration 1445, loss = 0.71275240
Iteration 1446, loss = 0.71267297
Iteration 1447, loss = 0.71246509
Iteration 1448, loss = 0.71234593
Iteration 1449, loss = 0.71229427
Iteration 1450, loss = 0.71214271
Iteration 1451, loss = 0.71198340
Iteration 1452, loss = 0.71190975
Iteration 1453, loss = 0.71180406
Iteration 1454, loss = 0.71164410
Iteration 1455, loss = 0.71153593
Iteration 1456, loss = 0.71144962
Iteration 1457, loss = 0.71131347
Iteration 1458, loss = 0.71118519
Iteration 1459, loss = 0.71109645
Iteration 1460, loss = 0.71098555
Iteration 1461, loss = 0.71085493
Iteration 1462, loss = 0.71075308
Iteration 1463, loss = 0.71065500
Iteration 1464, loss = 0.71053276
Iteration 1465, loss = 0.71041963
Iteration 1466, loss = 0.71032274
Iteration 1467, loss = 0.71021189
Iteration 1468, loss = 0.71009571
Iteration 1469, loss = 0.70999480
Iteration 1470, loss = 0.70989254
Iteration 1471, loss = 0.70978014
Iteration 1472, loss = 0.70967524
Iteration 1473, loss = 0.70957647
Iteration 1474, loss = 0.70947001
Iteration 1475, loss = 0.70936347
Iteration 1476, loss = 0.70926428
Iteration 1477, loss = 0.70916263
Iteration 1478, loss = 0.70905719
Iteration 1479, loss = 0.70895661
Iteration 1480, loss = 0.70885784
Iteration 1481, loss = 0.70875540
Iteration 1482, loss = 0.70865448
Iteration 1483, loss = 0.70855701
Iteration 1484, loss = 0.70845783
Iteration 1485, loss = 0.70835788
Iteration 1486, loss = 0.70826084
Iteration 1487, loss = 0.70816408
Iteration 1488, loss = 0.70806585
Iteration 1489, loss = 0.70796910
Iteration 1490, loss = 0.70787376
Iteration 1491, loss = 0.70777747
Iteration 1492, loss = 0.70768144
Iteration 1493, loss = 0.70758695
Iteration 1494, loss = 0.70749229
Iteration 1495, loss = 0.70739704
Iteration 1496, loss = 0.70730209
Iteration 1497, loss = 0.70720444
Iteration 1498, loss = 0.70708245
Iteration 1499, loss = 0.70638630
Iteration 1500, loss = 0.70626293
Iteration 1501, loss = 0.70641378
Iteration 1502, loss = 0.70592593
Iteration 1503, loss = 0.70616773
Iteration 1504, loss = 0.70652265
Iteration 1505, loss = 0.70672994
Iteration 1506, loss = 0.70691073
Iteration 1507, loss = 0.70688052
Iteration 1508, loss = 0.70655348
Iteration 1509, loss = 0.70584855
Iteration 1510, loss = 0.70513421
Iteration 1511, loss = 0.70468725
Iteration 1512, loss = 0.70427894
Iteration 1513, loss = 0.70393923
Iteration 1514, loss = 0.70452297
Iteration 1515, loss = 0.70429859
Iteration 1516, loss = 0.70412255
Iteration 1517, loss = 0.70469734
Iteration 1518, loss = 0.70426435
Iteration 1519, loss = 0.70342206
Iteration 1520, loss = 0.70339346
Iteration 1521, loss = 0.70254768
Iteration 1522, loss = 0.70250058
Iteration 1523, loss = 0.70256273
Iteration 1524, loss = 0.70257967
Iteration 1525, loss = 0.70246129
Iteration 1526, loss = 0.70219974
Iteration 1527, loss = 0.70182932
Iteration 1528, loss = 0.70143325
Iteration 1529, loss = 0.70114042
Iteration 1530, loss = 0.70091699
Iteration 1531, loss = 0.70066193
Iteration 1532, loss = 0.70036626
Iteration 1533, loss = 0.69979959
Iteration 1534, loss = 0.69962055
Iteration 1535, loss = 0.69943386
Iteration 1536, loss = 0.69916065
Iteration 1537, loss = 0.69887037
Iteration 1538, loss = 0.69866656
Iteration 1539, loss = 0.69845036
Iteration 1540, loss = 0.69816089
Iteration 1541, loss = 0.69784223
Iteration 1542, loss = 0.69752834
Iteration 1543, loss = 0.69726525
Iteration 1544, loss = 0.69781234
Iteration 1545, loss = 0.69760431
Iteration 1546, loss = 0.69678651
Iteration 1547, loss = 0.69672065
Iteration 1548, loss = 0.69663710
Iteration 1549, loss = 0.69650103
Iteration 1550, loss = 0.69618190
Iteration 1551, loss = 0.69562321
Iteration 1552, loss = 0.69548616
Iteration 1553, loss = 0.69530374
Iteration 1554, loss = 0.69470804
Iteration 1555, loss = 0.69353855
Iteration 1556, loss = 0.69320905
Iteration 1557, loss = 0.69190580
Iteration 1558, loss = 0.69026166
Iteration 1559, loss = 0.68999529
Iteration 1560, loss = 0.68814277
Iteration 1561, loss = 0.68597393
Iteration 1562, loss = 0.68161439
Iteration 1563, loss = 0.67492234
Iteration 1564, loss = 0.66514330
Iteration 1565, loss = 0.64281529
Iteration 1566, loss = 0.56542292
Iteration 1567, loss = 1.01621485
Iteration 1568, loss = 0.75342706
Iteration 1569, loss = 0.80241538
Iteration 1570, loss = 0.99289412
Iteration 1571, loss = 0.86592764
Iteration 1572, loss = 0.75237110
Iteration 1573, loss = 0.90027641
Iteration 1574, loss = 0.89850870
Iteration 1575, loss = 0.75464205
Iteration 1576, loss = 0.79730927
Iteration 1577, loss = 0.86633864
Iteration 1578, loss = 0.77548149
Iteration 1579, loss = 0.74197405
Iteration 1580, loss = 0.81524165
Iteration 1581, loss = 0.78830991
Iteration 1582, loss = 0.72696063
Iteration 1583, loss = 0.76689669
Iteration 1584, loss = 0.78226471
Iteration 1585, loss = 0.71665731
Iteration 1586, loss = 0.74291887
Iteration 1587, loss = 0.75785194
Iteration 1588, loss = 0.73842049
Iteration 1589, loss = 0.74503470
Iteration 1590, loss = 0.76806005
Iteration 1591, loss = 0.75744962
Iteration 1592, loss = 0.73588774
Iteration 1593, loss = 0.73829351
Iteration 1594, loss = 0.73864855
Iteration 1595, loss = 0.71806042
Iteration 1596, loss = 0.70010780
Iteration 1597, loss = 0.78495166
Iteration 1598, loss = 0.65981439
Iteration 1599, loss = 0.79659837
Iteration 1600, loss = 0.79060867
Iteration 1601, loss = 0.73841385
Iteration 1602, loss = 0.75755048
Iteration 1603, loss = 0.78829421
Iteration 1604, loss = 0.75582011
Iteration 1605, loss = 0.72964579
Iteration 1606, loss = 0.75357038
Iteration 1607, loss = 0.75739252
Iteration 1608, loss = 0.72887364
Iteration 1609, loss = 0.72790502
Iteration 1610, loss = 0.74682024
Iteration 1611, loss = 0.73862259
Iteration 1612, loss = 0.72350797
Iteration 1613, loss = 0.73310974
Iteration 1614, loss = 0.74046943
Iteration 1615, loss = 0.72838975
Iteration 1616, loss = 0.72384740
Iteration 1617, loss = 0.73263387
Iteration 1618, loss = 0.74084017
Iteration 1619, loss = 0.72656221
Iteration 1620, loss = 0.74186057
Iteration 1621, loss = 0.74489632
Iteration 1622, loss = 0.73270527
Iteration 1623, loss = 0.73132191
Iteration 1624, loss = 0.73636339
Iteration 1625, loss = 0.73010929
Iteration 1626, loss = 0.72333580
Iteration 1627, loss = 0.72766072
Iteration 1628, loss = 0.73034563
Iteration 1629, loss = 0.72537273
Iteration 1630, loss = 0.72432658
Iteration 1631, loss = 0.72802580
Iteration 1632, loss = 0.72664532
Iteration 1633, loss = 0.72278917
Iteration 1634, loss = 0.72380678
Iteration 1635, loss = 0.72538222
Iteration 1636, loss = 0.72305117
Iteration 1637, loss = 0.72172628
Iteration 1638, loss = 0.72330195
Iteration 1639, loss = 0.72303503
Iteration 1640, loss = 0.72090564
Iteration 1641, loss = 0.72083161
Iteration 1642, loss = 0.72166293
Iteration 1643, loss = 0.72071990
Iteration 1644, loss = 0.71984089
Iteration 1645, loss = 0.72048938
Iteration 1646, loss = 0.72054179
Iteration 1647, loss = 0.71943835
Iteration 1648, loss = 0.71908919
Iteration 1649, loss = 0.71936255
Iteration 1650, loss = 0.71875466
Iteration 1651, loss = 0.71754291
Iteration 1652, loss = 0.71776881
Iteration 1653, loss = 0.71787724
Iteration 1654, loss = 0.71690085
Iteration 1655, loss = 0.71667487
Iteration 1656, loss = 0.71727238
Iteration 1657, loss = 0.71655922
Iteration 1658, loss = 0.71606231
Iteration 1659, loss = 0.71582786
Iteration 1660, loss = 0.71517409
Iteration 1661, loss = 0.71378079
Iteration 1662, loss = 0.71237652
Iteration 1663, loss = 0.71147413
Iteration 1664, loss = 0.71033327
Iteration 1665, loss = 0.70804630
Iteration 1666, loss = 0.70282378
Iteration 1667, loss = 0.66676989
Iteration 1668, loss = 0.96265050
Iteration 1669, loss = 0.79101711
Iteration 1670, loss = 0.74773684
Iteration 1671, loss = 0.88168723
Iteration 1672, loss = 0.91606046
Iteration 1673, loss = 0.80592180
Iteration 1674, loss = 0.74310527
Iteration 1675, loss = 0.81436967
Iteration 1676, loss = 0.85126424
Iteration 1677, loss = 0.78454618
Iteration 1678, loss = 0.72597772
Iteration 1679, loss = 0.76168549
Iteration 1680, loss = 0.79724544
Iteration 1681, loss = 0.76239760
Iteration 1682, loss = 0.72017811
Iteration 1683, loss = 0.73891253
Iteration 1684, loss = 0.76959839
Iteration 1685, loss = 0.75406625
Iteration 1686, loss = 0.72457018
Iteration 1687, loss = 0.73206971
Iteration 1688, loss = 0.75334274
Iteration 1689, loss = 0.74571902
Iteration 1690, loss = 0.72441102
Iteration 1691, loss = 0.72564740
Iteration 1692, loss = 0.73953393
Iteration 1693, loss = 0.73597856
Iteration 1694, loss = 0.72077284
Iteration 1695, loss = 0.71957624
Iteration 1696, loss = 0.72921467
Iteration 1697, loss = 0.72897352
Iteration 1698, loss = 0.71972060
Iteration 1699, loss = 0.71790515
Iteration 1700, loss = 0.72396583
Iteration 1701, loss = 0.72470184
Iteration 1702, loss = 0.71863380
Iteration 1703, loss = 0.71665058
Iteration 1704, loss = 0.72037807
Iteration 1705, loss = 0.72097490
Iteration 1706, loss = 0.71681647
Iteration 1707, loss = 0.71511097
Iteration 1708, loss = 0.71737347
Iteration 1709, loss = 0.71808716
Iteration 1710, loss = 0.71552869
Iteration 1711, loss = 0.71412091
Iteration 1712, loss = 0.71557475
Iteration 1713, loss = 0.71626650
Iteration 1714, loss = 0.71461095
Iteration 1715, loss = 0.71348135
Iteration 1716, loss = 0.71427971
Iteration 1717, loss = 0.71470087
Iteration 1718, loss = 0.71353629
Iteration 1719, loss = 0.71262009
Iteration 1720, loss = 0.71305947
Iteration 1721, loss = 0.71342565
Iteration 1722, loss = 0.71270922
Iteration 1723, loss = 0.71199229
Iteration 1724, loss = 0.71215898
Iteration 1725, loss = 0.71239568
Iteration 1726, loss = 0.71195857
Iteration 1727, loss = 0.71146201
Iteration 1728, loss = 0.71150768
Iteration 1729, loss = 0.71160563
Iteration 1730, loss = 0.71126477
Iteration 1731, loss = 0.71088127
Iteration 1732, loss = 0.71086566
Iteration 1733, loss = 0.71089692
Iteration 1734, loss = 0.71062099
Iteration 1735, loss = 0.71029266
Iteration 1736, loss = 0.71022366
Iteration 1737, loss = 0.71022329
Iteration 1738, loss = 0.71002525
Iteration 1739, loss = 0.70976639
Iteration 1740, loss = 0.70966364
Iteration 1741, loss = 0.70961737
Iteration 1742, loss = 0.70945529
Iteration 1743, loss = 0.70925221
Iteration 1744, loss = 0.70914292
Iteration 1745, loss = 0.70906640
Iteration 1746, loss = 0.70891306
Iteration 1747, loss = 0.70871945
Iteration 1748, loss = 0.70798190
Iteration 1749, loss = 0.70796843
Iteration 1750, loss = 0.70790456
Iteration 1751, loss = 0.70775413
Iteration 1752, loss = 0.70758679
Iteration 1753, loss = 0.70741152
Iteration 1754, loss = 0.70721769
Iteration 1755, loss = 0.70746611
Iteration 1756, loss = 0.70685275
Iteration 1757, loss = 0.70668587
Iteration 1758, loss = 0.70691513
Iteration 1759, loss = 0.70636286
Iteration 1760, loss = 0.70622057
Iteration 1761, loss = 0.70538880
Iteration 1762, loss = 0.70413352
Iteration 1763, loss = 0.70281152
Iteration 1764, loss = 0.70119828
Iteration 1765, loss = 0.69740850
Iteration 1766, loss = 0.68870330
Iteration 1767, loss = 0.62249773
Iteration 1768, loss = 0.94097627
Iteration 1769, loss = 0.75528522
Iteration 1770, loss = 0.77420780
Iteration 1771, loss = 0.90886764
Iteration 1772, loss = 0.86076986
Iteration 1773, loss = 0.73304353
Iteration 1774, loss = 0.77041392
Iteration 1775, loss = 0.84436941
Iteration 1776, loss = 0.78729245
Iteration 1777, loss = 0.71452276
Iteration 1778, loss = 0.76019058
Iteration 1779, loss = 0.79856985
Iteration 1780, loss = 0.74806597
Iteration 1781, loss = 0.71675450
Iteration 1782, loss = 0.75802565
Iteration 1783, loss = 0.76953333
Iteration 1784, loss = 0.72839606
Iteration 1785, loss = 0.71914737
Iteration 1786, loss = 0.74881938
Iteration 1787, loss = 0.74571228
Iteration 1788, loss = 0.71768440
Iteration 1789, loss = 0.72137983
Iteration 1790, loss = 0.73973210
Iteration 1791, loss = 0.73024894
Iteration 1792, loss = 0.71410506
Iteration 1793, loss = 0.72221269
Iteration 1794, loss = 0.73116018
Iteration 1795, loss = 0.72062298
Iteration 1796, loss = 0.71329356
Iteration 1797, loss = 0.72152587
Iteration 1798, loss = 0.72416869
Iteration 1799, loss = 0.71554460
Iteration 1800, loss = 0.71372718
Iteration 1801, loss = 0.71979780
Iteration 1802, loss = 0.71881713
Iteration 1803, loss = 0.71296220
Iteration 1804, loss = 0.71393504
Iteration 1805, loss = 0.71752509
Iteration 1806, loss = 0.71510526
Iteration 1807, loss = 0.71184293
Iteration 1808, loss = 0.71365394
Iteration 1809, loss = 0.71489192
Iteration 1810, loss = 0.71204652
Iteration 1811, loss = 0.71070404
Iteration 1812, loss = 0.71218789
Iteration 1813, loss = 0.71235605
Iteration 1814, loss = 0.70983321
Iteration 1815, loss = 0.70961549
Iteration 1816, loss = 0.71041007
Iteration 1817, loss = 0.70861915
Iteration 1818, loss = 0.70632512
Iteration 1819, loss = 0.70454810
Iteration 1820, loss = 0.68104268
Iteration 1821, loss = 0.88849893
Iteration 1822, loss = 0.75836374
Iteration 1823, loss = 0.73008580
Iteration 1824, loss = 0.82285784
Iteration 1825, loss = 0.84390505
Iteration 1826, loss = 0.76247573
Iteration 1827, loss = 0.71738906
Iteration 1828, loss = 0.76877371
Iteration 1829, loss = 0.79973119
Iteration 1830, loss = 0.75578901
Iteration 1831, loss = 0.71507959
Iteration 1832, loss = 0.74035004
Iteration 1833, loss = 0.77025666
Iteration 1834, loss = 0.74963267
Iteration 1835, loss = 0.71806194
Iteration 1836, loss = 0.72758158
Iteration 1837, loss = 0.75035535
Iteration 1838, loss = 0.74203175
Iteration 1839, loss = 0.71913039
Iteration 1840, loss = 0.72022203
Iteration 1841, loss = 0.73602322
Iteration 1842, loss = 0.73431962
Iteration 1843, loss = 0.71910730
Iteration 1844, loss = 0.71690862
Iteration 1845, loss = 0.72736388
Iteration 1846, loss = 0.72867496
Iteration 1847, loss = 0.71892855
Iteration 1848, loss = 0.71551099
Iteration 1849, loss = 0.72184032
Iteration 1850, loss = 0.72394402
Iteration 1851, loss = 0.71788366
Iteration 1852, loss = 0.71446712
Iteration 1853, loss = 0.71805943
Iteration 1854, loss = 0.72025316
Iteration 1855, loss = 0.71672840
Iteration 1856, loss = 0.71386289
Iteration 1857, loss = 0.71579689
Iteration 1858, loss = 0.71751030
Iteration 1859, loss = 0.71677185
Iteration 1860, loss = 0.70315125
Iteration 1861, loss = 0.71339713
Iteration 1862, loss = 0.71468601
Iteration 1863, loss = 0.71433570
Iteration 1864, loss = 0.71244691
Iteration 1865, loss = 0.71209743
Iteration 1866, loss = 0.71134354
Iteration 1867, loss = 0.71120623
Iteration 1868, loss = 0.70934240
Iteration 1869, loss = 0.70835185
Iteration 1870, loss = 0.70747671
Iteration 1871, loss = 0.70554428
Iteration 1872, loss = 0.70460341
Iteration 1873, loss = 0.69961065
Iteration 1874, loss = 0.64831225
Iteration 1875, loss = 0.92840740
Iteration 1876, loss = 0.80271611
Iteration 1877, loss = 0.75597993
Iteration 1878, loss = 0.84762042
Iteration 1879, loss = 0.88070561
Iteration 1880, loss = 0.79554132
Iteration 1881, loss = 0.72434560
Iteration 1882, loss = 0.76495800
Iteration 1883, loss = 0.81362351
Iteration 1884, loss = 0.78310108
Iteration 1885, loss = 0.73009106
Iteration 1886, loss = 0.74154690
Iteration 1887, loss = 0.78160230
Iteration 1888, loss = 0.77478151
Iteration 1889, loss = 0.73570044
Iteration 1890, loss = 0.72911732
Iteration 1891, loss = 0.75434533
Iteration 1892, loss = 0.75808468
Iteration 1893, loss = 0.73342560
Iteration 1894, loss = 0.72166253
Iteration 1895, loss = 0.73657748
Iteration 1896, loss = 0.74561869
Iteration 1897, loss = 0.73315477
Iteration 1898, loss = 0.72215859
Iteration 1899, loss = 0.72902502
Iteration 1900, loss = 0.73696843
Iteration 1901, loss = 0.73042649
Iteration 1902, loss = 0.72071224
Iteration 1903, loss = 0.72250955
Iteration 1904, loss = 0.72864960
Iteration 1905, loss = 0.72630120
Iteration 1906, loss = 0.71919411
Iteration 1907, loss = 0.71824055
Iteration 1908, loss = 0.72221497
Iteration 1909, loss = 0.72216293
Iteration 1910, loss = 0.71764246
Iteration 1911, loss = 0.71601957
Iteration 1912, loss = 0.71854125
Iteration 1913, loss = 0.71920801
Iteration 1914, loss = 0.71635957
Iteration 1915, loss = 0.71432912
Iteration 1916, loss = 0.71531004
Iteration 1917, loss = 0.71596730
Iteration 1918, loss = 0.71396849
Iteration 1919, loss = 0.71190746
Iteration 1920, loss = 0.71161616
Iteration 1921, loss = 0.71119599
Iteration 1922, loss = 0.70945506
Iteration 1923, loss = 0.70683034
Iteration 1924, loss = 0.70517703
Iteration 1925, loss = 0.70190800
Iteration 1926, loss = 0.69673063
Iteration 1927, loss = 0.69311776
Iteration 1928, loss = 0.64045127
Iteration 1929, loss = 1.03791530
Iteration 1930, loss = 0.87028604
Iteration 1931, loss = 0.75701493
Iteration 1932, loss = 0.84474030
Iteration 1933, loss = 0.95762281
Iteration 1934, loss = 0.93718111
Iteration 1935, loss = 0.81519916
Iteration 1936, loss = 0.74163866
Iteration 1937, loss = 0.79058900
Iteration 1938, loss = 0.84968871
Iteration 1939, loss = 0.82758839
Iteration 1940, loss = 0.75572845
Iteration 1941, loss = 0.72865092
Iteration 1942, loss = 0.77106191
Iteration 1943, loss = 0.80570979
Iteration 1944, loss = 0.78464785
Iteration 1945, loss = 0.74018933
Iteration 1946, loss = 0.73168543
Iteration 1947, loss = 0.75866215
Iteration 1948, loss = 0.77283554
Iteration 1949, loss = 0.75391115
Iteration 1950, loss = 0.72892085
Iteration 1951, loss = 0.72893006
Iteration 1952, loss = 0.74558364
Iteration 1953, loss = 0.74994019
Iteration 1954, loss = 0.73594204
Iteration 1955, loss = 0.72372860
Iteration 1956, loss = 0.72791787
Iteration 1957, loss = 0.73796684
Iteration 1958, loss = 0.73744884
Iteration 1959, loss = 0.72750838
Iteration 1960, loss = 0.72180694
Iteration 1961, loss = 0.72581467
Iteration 1962, loss = 0.73080732
Iteration 1963, loss = 0.72857498
Iteration 1964, loss = 0.72241741
Iteration 1965, loss = 0.72049049
Iteration 1966, loss = 0.72373430
Iteration 1967, loss = 0.72583958
Iteration 1968, loss = 0.72329324
Iteration 1969, loss = 0.71966177
Iteration 1970, loss = 0.71938886
Iteration 1971, loss = 0.72153836
Iteration 1972, loss = 0.72208920
Iteration 1973, loss = 0.72001529
Iteration 1974, loss = 0.71810306
Iteration 1975, loss = 0.71841072
Iteration 1976, loss = 0.71956218
Iteration 1977, loss = 0.71929161
Iteration 1978, loss = 0.71774309
Iteration 1979, loss = 0.71682811
Iteration 1980, loss = 0.71725341
Iteration 1981, loss = 0.71776511
Iteration 1982, loss = 0.71724523
Iteration 1983, loss = 0.71621524
Iteration 1984, loss = 0.71579927
Iteration 1985, loss = 0.71605552
Iteration 1986, loss = 0.71609655
Iteration 1987, loss = 0.71549755
Iteration 1988, loss = 0.71480097
Iteration 1989, loss = 0.71458720
Iteration 1990, loss = 0.71466212
Iteration 1991, loss = 0.71447001
Iteration 1992, loss = 0.71393287
Iteration 1993, loss = 0.71347647
Iteration 1994, loss = 0.71335745
Iteration 1995, loss = 0.71334531
Iteration 1996, loss = 0.71313620
Iteration 1997, loss = 0.71278313
Iteration 1998, loss = 0.71253914
Iteration 1999, loss = 0.71245228
Iteration 2000, loss = 0.71232958
Iteration 2001, loss = 0.71205086
Iteration 2002, loss = 0.71172657
Iteration 2003, loss = 0.71150592
Iteration 2004, loss = 0.71136553
Iteration 2005, loss = 0.71117502
Iteration 2006, loss = 0.71089541
Iteration 2007, loss = 0.71060887
Iteration 2008, loss = 0.71037210
Iteration 2009, loss = 0.71013449
Iteration 2010, loss = 0.70982094
Iteration 2011, loss = 0.70937789
Iteration 2012, loss = 0.70853689
Iteration 2013, loss = 0.70821479
Iteration 2014, loss = 0.70770905
Iteration 2015, loss = 0.70826050
Iteration 2016, loss = 0.70801923
Iteration 2017, loss = 0.70779226
Iteration 2018, loss = 0.70723020
Iteration 2019, loss = 0.70648712
Iteration 2020, loss = 0.70530092
Iteration 2021, loss = 0.70482538
Iteration 2022, loss = 0.70434985
Iteration 2023, loss = 0.70499868
Iteration 2024, loss = 0.70459167
Iteration 2025, loss = 0.70412791
Iteration 2026, loss = 0.70386902
Iteration 2027, loss = 0.70338344
Iteration 2028, loss = 0.70275802
Iteration 2029, loss = 0.70234283
Iteration 2030, loss = 0.70128851
Iteration 2031, loss = 0.69908607
Iteration 2032, loss = 0.69802147
Iteration 2033, loss = 0.69692215
Iteration 2034, loss = 0.69615065
Iteration 2035, loss = 0.69183331
Iteration 2036, loss = 0.67742216
Iteration 2037, loss = 0.91214438
Iteration 2038, loss = 0.60450598
Iteration 2039, loss = 0.79776313
Iteration 2040, loss = 0.76135664
Iteration 2041, loss = 0.76468401
Iteration 2042, loss = 0.80757637
Iteration 2043, loss = 0.83451632
Iteration 2044, loss = 0.81373223
Iteration 2045, loss = 0.76226062
Iteration 2046, loss = 0.72311018
Iteration 2047, loss = 0.72064452
Iteration 2048, loss = 0.73796846
Iteration 2049, loss = 0.74387089
Iteration 2050, loss = 0.72765604
Iteration 2051, loss = 0.70492908
Iteration 2052, loss = 0.69730199
Iteration 2053, loss = 0.70517215
Iteration 2054, loss = 0.71573176
Iteration 2055, loss = 0.70566380
Iteration 2056, loss = 0.67961135
Iteration 2057, loss = 0.55192806
Iteration 2058, loss = 1.04813495
Iteration 2059, loss = 0.81840354
Iteration 2060, loss = 0.76468309
Iteration 2061, loss = 0.92936873
Iteration 2062, loss = 1.03110281
Iteration 2063, loss = 0.95871147
Iteration 2064, loss = 0.80860705
Iteration 2065, loss = 0.77007617
Iteration 2066, loss = 0.85904518
Iteration 2067, loss = 0.90930603
Iteration 2068, loss = 0.85264972
Iteration 2069, loss = 0.75801592
Iteration 2070, loss = 0.74064983
Iteration 2071, loss = 0.79595181
Iteration 2072, loss = 0.82078645
Iteration 2073, loss = 0.77926089
Iteration 2074, loss = 0.72666700
Iteration 2075, loss = 0.72847225
Iteration 2076, loss = 0.76575243
Iteration 2077, loss = 0.77658090
Iteration 2078, loss = 0.74838469
Iteration 2079, loss = 0.72228703
Iteration 2080, loss = 0.73099315
Iteration 2081, loss = 0.75367916
Iteration 2082, loss = 0.75472851
Iteration 2083, loss = 0.73423833
Iteration 2084, loss = 0.72080262
Iteration 2085, loss = 0.72853491
Iteration 2086, loss = 0.73990297
Iteration 2087, loss = 0.73633152
Iteration 2088, loss = 0.72323509
Iteration 2089, loss = 0.71821430
Iteration 2090, loss = 0.72494096
Iteration 2091, loss = 0.73050541
Iteration 2092, loss = 0.72629932
Iteration 2093, loss = 0.71869410
Iteration 2094, loss = 0.71765019
Iteration 2095, loss = 0.72240223
Iteration 2096, loss = 0.72446734
Iteration 2097, loss = 0.72072579
Iteration 2098, loss = 0.71660465
Iteration 2099, loss = 0.71710677
Iteration 2100, loss = 0.72000673
Iteration 2101, loss = 0.72027091
Iteration 2102, loss = 0.71747653
Iteration 2103, loss = 0.71550559
Iteration 2104, loss = 0.71642687
Iteration 2105, loss = 0.71797376
Iteration 2106, loss = 0.71747449
Iteration 2107, loss = 0.71559223
Iteration 2108, loss = 0.71479945
Iteration 2109, loss = 0.71563576
Iteration 2110, loss = 0.71631055
Iteration 2111, loss = 0.71560556
Iteration 2112, loss = 0.71435883
Iteration 2113, loss = 0.71495909
Iteration 2114, loss = 0.71499570
Iteration 2115, loss = 0.71695168
Iteration 2116, loss = 0.71866798
Iteration 2117, loss = 0.71924134
Iteration 2118, loss = 0.71872141
Iteration 2119, loss = 0.71761952
Iteration 2120, loss = 0.71645318
Iteration 2121, loss = 0.71534665
Iteration 2122, loss = 0.71452758
Iteration 2123, loss = 0.71404650
Iteration 2124, loss = 0.71389121
Iteration 2125, loss = 0.71357306
Iteration 2126, loss = 0.71184273
Iteration 2127, loss = 0.71521313
Iteration 2128, loss = 0.71579505
Iteration 2129, loss = 0.71550101
Iteration 2130, loss = 0.71464369
Iteration 2131, loss = 0.71395270
Iteration 2132, loss = 0.71382896
Iteration 2133, loss = 0.71407431
Iteration 2134, loss = 0.71423608
Iteration 2135, loss = 0.71400862
Iteration 2136, loss = 0.71385204
Iteration 2137, loss = 0.71380013
Iteration 2138, loss = 0.71366371
Iteration 2139, loss = 0.71343341
Iteration 2140, loss = 0.71321996
Iteration 2141, loss = 0.71305906
Iteration 2142, loss = 0.71285469
Iteration 2143, loss = 0.71256814
Iteration 2144, loss = 0.71225862
Iteration 2145, loss = 0.71185670
Iteration 2146, loss = 0.71147209
Iteration 2147, loss = 0.71140973
Iteration 2148, loss = 0.71137530
Iteration 2149, loss = 0.71115528
Iteration 2150, loss = 0.71078811
Iteration 2151, loss = 0.71035707
Iteration 2152, loss = 0.70990931
Iteration 2153, loss = 0.70946962
Iteration 2154, loss = 0.70901858
Iteration 2155, loss = 0.70845606
Iteration 2156, loss = 0.70792173
Iteration 2157, loss = 0.70729728
Iteration 2158, loss = 0.70608021
Iteration 2159, loss = 0.70456898
Iteration 2160, loss = 0.70250378
Iteration 2161, loss = 0.69890287
Iteration 2162, loss = 0.69418220
Iteration 2163, loss = 0.68574532
Iteration 2164, loss = 0.63385270
Iteration 2165, loss = 1.18996329
Iteration 2166, loss = 0.77324947
Iteration 2167, loss = 0.93207319
Iteration 2168, loss = 1.12148979
Iteration 2169, loss = 0.91668735
Iteration 2170, loss = 0.73610682
Iteration 2171, loss = 0.90767936
Iteration 2172, loss = 0.96490572
Iteration 2173, loss = 0.79901095
Iteration 2174, loss = 0.73040622
Iteration 2175, loss = 0.85407158
Iteration 2176, loss = 0.86837636
Iteration 2177, loss = 0.75361116
Iteration 2178, loss = 0.73356358
Iteration 2179, loss = 0.81724240
Iteration 2180, loss = 0.81244064
Iteration 2181, loss = 0.73551406
Iteration 2182, loss = 0.73615005
Iteration 2183, loss = 0.78998288
Iteration 2184, loss = 0.77688630
Iteration 2185, loss = 0.72675034
Iteration 2186, loss = 0.73476350
Iteration 2187, loss = 0.76795499
Iteration 2188, loss = 0.75274748
Iteration 2189, loss = 0.72122263
Iteration 2190, loss = 0.73141367
Iteration 2191, loss = 0.75129283
Iteration 2192, loss = 0.73751863
Iteration 2193, loss = 0.71890955
Iteration 2194, loss = 0.72886906
Iteration 2195, loss = 0.74027994
Iteration 2196, loss = 0.72897186
Iteration 2197, loss = 0.71854256
Iteration 2198, loss = 0.72680865
Iteration 2199, loss = 0.73261896
Iteration 2200, loss = 0.72372626
Iteration 2201, loss = 0.71818107
Iteration 2202, loss = 0.72447480
Iteration 2203, loss = 0.72698533
Iteration 2204, loss = 0.72041896
Iteration 2205, loss = 0.71786515
Iteration 2206, loss = 0.72240153
Iteration 2207, loss = 0.72304168
Iteration 2208, loss = 0.71839995
Iteration 2209, loss = 0.71748840
Iteration 2210, loss = 0.72055563
Iteration 2211, loss = 0.72024584
Iteration 2212, loss = 0.71711729
Iteration 2213, loss = 0.71707769
Iteration 2214, loss = 0.71906184
Iteration 2215, loss = 0.71837960
Iteration 2216, loss = 0.71637716
Iteration 2217, loss = 0.71670960
Iteration 2218, loss = 0.71788217
Iteration 2219, loss = 0.71708306
Iteration 2220, loss = 0.71582490
Iteration 2221, loss = 0.71622443
Iteration 2222, loss = 0.71681962
Iteration 2223, loss = 0.71605942
Iteration 2224, loss = 0.71530526
Iteration 2225, loss = 0.71566790
Iteration 2226, loss = 0.71591747
Iteration 2227, loss = 0.71529467
Iteration 2228, loss = 0.71488259
Iteration 2229, loss = 0.71516825
Iteration 2230, loss = 0.71521057
Iteration 2231, loss = 0.71472154
Iteration 2232, loss = 0.71449555
Iteration 2233, loss = 0.71466940
Iteration 2234, loss = 0.71458070
Iteration 2235, loss = 0.71419915
Iteration 2236, loss = 0.71406658
Iteration 2237, loss = 0.71414158
Iteration 2238, loss = 0.71399044
Iteration 2239, loss = 0.71370232
Iteration 2240, loss = 0.71362030
Iteration 2241, loss = 0.71363084
Iteration 2242, loss = 0.71347079
Iteration 2243, loss = 0.71326438
Iteration 2244, loss = 0.71320525
Iteration 2245, loss = 0.71316379
Iteration 2246, loss = 0.71299890
Iteration 2247, loss = 0.71283621
Iteration 2248, loss = 0.71277623
Iteration 2249, loss = 0.71270524
Iteration 2250, loss = 0.71255717
Iteration 2251, loss = 0.71243250
Iteration 2252, loss = 0.71237017
Iteration 2253, loss = 0.71228248
Iteration 2254, loss = 0.71214941
Iteration 2255, loss = 0.71204490
Iteration 2256, loss = 0.71197529
Iteration 2257, loss = 0.71188030
Iteration 2258, loss = 0.71176357
Iteration 2259, loss = 0.71167312
Iteration 2260, loss = 0.71159832
Iteration 2261, loss = 0.71150097
Iteration 2262, loss = 0.71139508
Iteration 2263, loss = 0.71130999
Iteration 2264, loss = 0.71123048
Iteration 2265, loss = 0.71113496
Iteration 2266, loss = 0.71103856
Iteration 2267, loss = 0.71095610
Iteration 2268, loss = 0.71087294
Iteration 2269, loss = 0.71077946
Iteration 2270, loss = 0.71068920
Iteration 2271, loss = 0.71060790
Iteration 2272, loss = 0.71052351
Iteration 2273, loss = 0.71043312
Iteration 2274, loss = 0.71034692
Iteration 2275, loss = 0.71026574
Iteration 2276, loss = 0.71018122
Iteration 2277, loss = 0.71009403
Iteration 2278, loss = 0.71001085
Iteration 2279, loss = 0.70993006
Iteration 2280, loss = 0.70984648
Iteration 2281, loss = 0.70976220
Iteration 2282, loss = 0.70968102
Iteration 2283, loss = 0.70960062
Iteration 2284, loss = 0.70951834
Iteration 2285, loss = 0.70943657
Iteration 2286, loss = 0.70935706
Iteration 2287, loss = 0.70927753
Iteration 2288, loss = 0.70919685
Iteration 2289, loss = 0.70911703
Iteration 2290, loss = 0.70903865
Iteration 2291, loss = 0.70895998
Iteration 2292, loss = 0.70888082
Iteration 2293, loss = 0.70880249
Iteration 2294, loss = 0.70872470
Iteration 2295, loss = 0.70864565
Iteration 2296, loss = 0.70855856
Iteration 2297, loss = 0.70841069
Iteration 2298, loss = 0.70845230
Iteration 2299, loss = 0.70843963
Iteration 2300, loss = 0.70840113
Iteration 2301, loss = 0.70833220
Iteration 2302, loss = 0.70823193
Iteration 2303, loss = 0.70809585
Iteration 2304, loss = 0.70786686
Iteration 2305, loss = 0.67931915
Iteration 2306, loss = 0.73204931
Iteration 2307, loss = 0.72533640
Iteration 2308, loss = 0.74791578
Iteration 2309, loss = 0.75670549
Iteration 2310, loss = 0.74618312
Iteration 2311, loss = 0.75353314
Iteration 2312, loss = 0.74994283
Iteration 2313, loss = 0.73654552
Iteration 2314, loss = 0.73956889
Iteration 2315, loss = 0.73469565
Iteration 2316, loss = 0.72614722
Iteration 2317, loss = 0.73043286
Iteration 2318, loss = 0.72787081
Iteration 2319, loss = 0.72390191
Iteration 2320, loss = 0.72851870
Iteration 2321, loss = 0.72696005
Iteration 2322, loss = 0.72492495
Iteration 2323, loss = 0.72851658
Iteration 2324, loss = 0.72694568
Iteration 2325, loss = 0.72550245
Iteration 2326, loss = 0.72773773
Iteration 2327, loss = 0.72600441
Iteration 2328, loss = 0.72501344
Iteration 2329, loss = 0.72651538
Iteration 2330, loss = 0.72507089
Iteration 2331, loss = 0.72460241
Iteration 2332, loss = 0.72569810
Iteration 2333, loss = 0.72458653
Iteration 2334, loss = 0.72443620
Iteration 2335, loss = 0.72514737
Iteration 2336, loss = 0.72417489
Iteration 2337, loss = 0.72402765
Iteration 2338, loss = 0.72427981
Iteration 2339, loss = 0.72333266
Iteration 2340, loss = 0.72316796
Iteration 2341, loss = 0.72323320
Iteration 2342, loss = 0.72256038
Iteration 2343, loss = 0.72261248
Iteration 2344, loss = 0.72274078
Iteration 2345, loss = 0.72235167
Iteration 2346, loss = 0.72247904
Iteration 2347, loss = 0.72250908
Iteration 2348, loss = 0.72216511
Iteration 2349, loss = 0.72220774
Iteration 2350, loss = 0.72212018
Iteration 2351, loss = 0.72181374
Iteration 2352, loss = 0.72180278
Iteration 2353, loss = 0.72164860
Iteration 2354, loss = 0.72137142
Iteration 2355, loss = 0.72131529
Iteration 2356, loss = 0.72113438
Iteration 2357, loss = 0.72090667
Iteration 2358, loss = 0.72084264
Iteration 2359, loss = 0.72066939
Iteration 2360, loss = 0.72048120
Iteration 2361, loss = 0.72039017
Iteration 2362, loss = 0.72018958
Iteration 2363, loss = 0.71998106
Iteration 2364, loss = 0.71982776
Iteration 2365, loss = 0.71960213
Iteration 2366, loss = 0.71941701
Iteration 2367, loss = 0.71929208
Iteration 2368, loss = 0.71911690
Iteration 2369, loss = 0.71896334
Iteration 2370, loss = 0.71882322
Iteration 2371, loss = 0.71863443
Iteration 2372, loss = 0.71846651
Iteration 2373, loss = 0.71830220
Iteration 2374, loss = 0.71809751
Iteration 2375, loss = 0.71789006
Iteration 2376, loss = 0.71763853
Iteration 2377, loss = 0.71734160
Iteration 2378, loss = 0.71714765
Iteration 2379, loss = 0.71704492
Iteration 2380, loss = 0.71691791
Iteration 2381, loss = 0.71675740
Iteration 2382, loss = 0.71656998
Iteration 2383, loss = 0.71638488
Iteration 2384, loss = 0.71623536
Iteration 2385, loss = 0.71615762
Iteration 2386, loss = 0.71614332
Iteration 2387, loss = 0.71613405
Iteration 2388, loss = 0.71596400
Iteration 2389, loss = 0.71570805
Iteration 2390, loss = 0.71549421
Iteration 2391, loss = 0.71537774
Iteration 2392, loss = 0.71526976
Iteration 2393, loss = 0.71512416
Iteration 2394, loss = 0.71497064
Iteration 2395, loss = 0.71481550
Iteration 2396, loss = 0.71465799
Iteration 2397, loss = 0.71449277
Iteration 2398, loss = 0.71432182
Iteration 2399, loss = 0.71410688
Iteration 2400, loss = 0.71390765
Iteration 2401, loss = 0.71224198
Iteration 2402, loss = 0.71705156
Iteration 2403, loss = 0.72094638
Iteration 2404, loss = 0.72218462
Iteration 2405, loss = 0.72114656
Iteration 2406, loss = 0.71851840
Iteration 2407, loss = 0.71653000
Iteration 2408, loss = 0.71627732
Iteration 2409, loss = 0.71611324
Iteration 2410, loss = 0.71630220
Iteration 2411, loss = 0.71655666
Iteration 2412, loss = 0.71601379
Iteration 2413, loss = 0.71571622
Iteration 2414, loss = 0.71567625
Iteration 2415, loss = 0.71538145
Iteration 2416, loss = 0.71532280
Iteration 2417, loss = 0.71509336
Iteration 2418, loss = 0.71449064
Iteration 2419, loss = 0.71411710
Iteration 2420, loss = 0.71381360
Iteration 2421, loss = 0.71358941
Iteration 2422, loss = 0.71366931
Iteration 2423, loss = 0.71361011
Iteration 2424, loss = 0.71334122
Iteration 2425, loss = 0.71237657
Iteration 2426, loss = 0.70916324
Iteration 2427, loss = 0.71380048
Iteration 2428, loss = 0.71497449
Iteration 2429, loss = 0.71591845
Iteration 2430, loss = 0.71561429
Iteration 2431, loss = 0.71449699
Iteration 2432, loss = 0.71350142
Iteration 2433, loss = 0.71272475
Iteration 2434, loss = 0.71204428
Iteration 2435, loss = 0.71178684
Iteration 2436, loss = 0.71136035
Iteration 2437, loss = 0.71093730
Iteration 2438, loss = 0.71064679
Iteration 2439, loss = 0.71030029
Iteration 2440, loss = 0.71005117
Iteration 2441, loss = 0.70979837
Iteration 2442, loss = 0.70931890
Iteration 2443, loss = 0.70874733
Iteration 2444, loss = 0.70799956
Iteration 2445, loss = 0.70703240
Iteration 2446, loss = 0.70636493
Iteration 2447, loss = 0.70561538
Iteration 2448, loss = 0.70391801
Iteration 2449, loss = 0.70177724
Iteration 2450, loss = 0.69978938
Iteration 2451, loss = 0.69642178
Iteration 2452, loss = 0.69319830
Iteration 2453, loss = 0.68538815
Iteration 2454, loss = 0.63406945
Iteration 2455, loss = 0.97451391
Iteration 2456, loss = 0.73111047
Iteration 2457, loss = 0.96382455
Iteration 2458, loss = 0.91452661
Iteration 2459, loss = 0.73282551
Iteration 2460, loss = 0.89407872
Iteration 2461, loss = 0.86370874
Iteration 2462, loss = 0.72400591
Iteration 2463, loss = 0.83628566
Iteration 2464, loss = 0.82223096
Iteration 2465, loss = 0.71740004
Iteration 2466, loss = 0.79644618
Iteration 2467, loss = 0.79669734
Iteration 2468, loss = 0.71826050
Iteration 2469, loss = 0.77234580
Iteration 2470, loss = 0.77940078
Iteration 2471, loss = 0.71991834
Iteration 2472, loss = 0.75509636
Iteration 2473, loss = 0.76477064
Iteration 2474, loss = 0.71986637
Iteration 2475, loss = 0.74219659
Iteration 2476, loss = 0.75268034
Iteration 2477, loss = 0.71944441
Iteration 2478, loss = 0.73343033
Iteration 2479, loss = 0.74359377
Iteration 2480, loss = 0.71920380
Iteration 2481, loss = 0.72754410
Iteration 2482, loss = 0.73645378
Iteration 2483, loss = 0.71859529
Iteration 2484, loss = 0.72318977
Iteration 2485, loss = 0.73066114
Iteration 2486, loss = 0.71775239
Iteration 2487, loss = 0.72019063
Iteration 2488, loss = 0.72640639
Iteration 2489, loss = 0.71725801
Iteration 2490, loss = 0.71843292
Iteration 2491, loss = 0.72346153
Iteration 2492, loss = 0.71696144
Iteration 2493, loss = 0.71728702
Iteration 2494, loss = 0.72110529
Iteration 2495, loss = 0.71627400
Iteration 2496, loss = 0.71556712
Iteration 2497, loss = 0.71633339
Iteration 2498, loss = 0.70249248
Iteration 2499, loss = 0.75997574
Iteration 2500, loss = 0.71213324
Iteration 2501, loss = 0.76617842
Iteration 2502, loss = 0.77560396
Iteration 2503, loss = 0.72067591
Iteration 2504, loss = 0.71800390
Iteration 2505, loss = 0.70928065
Iteration 2506, loss = 0.71014586
Iteration 2507, loss = 0.72933237
Iteration 2508, loss = 0.72318849
Iteration 2509, loss = 0.71163955
Iteration 2510, loss = 0.72326108
Iteration 2511, loss = 0.71997200
Iteration 2512, loss = 0.70919433
Iteration 2513, loss = 0.71554271
Iteration 2514, loss = 0.71283393
Iteration 2515, loss = 0.70297035
Iteration 2516, loss = 0.70421683
Iteration 2517, loss = 0.69918262
Iteration 2518, loss = 0.55262529
Iteration 2519, loss = 0.90360572
Iteration 2520, loss = 0.74287749
Iteration 2521, loss = 0.86967802
Iteration 2522, loss = 0.93311082
Iteration 2523, loss = 0.79481317
Iteration 2524, loss = 0.77087209
Iteration 2525, loss = 0.86830451
Iteration 2526, loss = 0.82219721
Iteration 2527, loss = 0.73482178
Iteration 2528, loss = 0.78784302
Iteration 2529, loss = 0.81782633
Iteration 2530, loss = 0.75011469
Iteration 2531, loss = 0.74098684
Iteration 2532, loss = 0.79062155
Iteration 2533, loss = 0.76911164
Iteration 2534, loss = 0.72994215
Iteration 2535, loss = 0.75767393
Iteration 2536, loss = 0.77172777
Iteration 2537, loss = 0.73896948
Iteration 2538, loss = 0.73720495
Iteration 2539, loss = 0.76125929
Iteration 2540, loss = 0.74946040
Iteration 2541, loss = 0.73195919
Iteration 2542, loss = 0.74618162
Iteration 2543, loss = 0.75107143
Iteration 2544, loss = 0.73431505
Iteration 2545, loss = 0.73434105
Iteration 2546, loss = 0.74487225
Iteration 2547, loss = 0.73750266
Iteration 2548, loss = 0.72970234
Iteration 2549, loss = 0.73705857
Iteration 2550, loss = 0.73844717
Iteration 2551, loss = 0.73049024
Iteration 2552, loss = 0.73167352
Iteration 2553, loss = 0.73655506
Iteration 2554, loss = 0.73247763
Iteration 2555, loss = 0.72940035
Iteration 2556, loss = 0.73319933
Iteration 2557, loss = 0.73315992
Iteration 2558, loss = 0.72930333
Iteration 2559, loss = 0.73030882
Iteration 2560, loss = 0.73227106
Iteration 2561, loss = 0.72988700
Iteration 2562, loss = 0.72869142
Iteration 2563, loss = 0.73049531
Iteration 2564, loss = 0.72997105
Iteration 2565, loss = 0.72817280
Iteration 2566, loss = 0.72765767
Iteration 2567, loss = 0.73151455
Iteration 2568, loss = 0.72887249
Iteration 2569, loss = 0.73030413
Iteration 2570, loss = 0.73072321
Iteration 2571, loss = 0.72848990
Iteration 2572, loss = 0.72991440
Iteration 2573, loss = 0.72927478
Iteration 2574, loss = 0.72830402
Iteration 2575, loss = 0.72955841
Iteration 2576, loss = 0.72816248
Iteration 2577, loss = 0.72615669
Iteration 2578, loss = 0.71620564
Iteration 2579, loss = 0.75906149
Iteration 2580, loss = 0.73614405
Iteration 2581, loss = 0.74828362
Iteration 2582, loss = 0.75339393
Iteration 2583, loss = 0.73511000
Iteration 2584, loss = 0.74671305
Iteration 2585, loss = 0.74256987
Iteration 2586, loss = 0.73338591
Iteration 2587, loss = 0.74478507
Iteration 2588, loss = 0.73839922
Iteration 2589, loss = 0.73608332
Iteration 2590, loss = 0.74363198
Iteration 2591, loss = 0.73652017
Iteration 2592, loss = 0.73781601
Iteration 2593, loss = 0.74116370
Iteration 2594, loss = 0.73518153
Iteration 2595, loss = 0.73807378
Iteration 2596, loss = 0.73840684
Iteration 2597, loss = 0.73440881
Iteration 2598, loss = 0.73736525
Iteration 2599, loss = 0.73592062
Iteration 2600, loss = 0.73395130
Iteration 2601, loss = 0.73631806
Iteration 2602, loss = 0.73431207
Iteration 2603, loss = 0.73380017
Iteration 2604, loss = 0.73503875
Iteration 2605, loss = 0.73292640
Iteration 2606, loss = 0.73306930
Iteration 2607, loss = 0.73323734
Iteration 2608, loss = 0.73157185
Iteration 2609, loss = 0.73211758
Iteration 2610, loss = 0.73173331
Iteration 2611, loss = 0.73064709
Iteration 2612, loss = 0.73108860
Iteration 2613, loss = 0.73030246
Iteration 2614, loss = 0.72967170
Iteration 2615, loss = 0.72988107
Iteration 2616, loss = 0.72904964
Iteration 2617, loss = 0.72878928
Iteration 2618, loss = 0.72874952
Iteration 2619, loss = 0.72800618
Iteration 2620, loss = 0.72789396
Iteration 2621, loss = 0.72761336
Iteration 2622, loss = 0.72701287
Iteration 2623, loss = 0.72693105
Iteration 2624, loss = 0.72652552
Iteration 2625, loss = 0.72608099
Iteration 2626, loss = 0.72596678
Iteration 2627, loss = 0.72556658
Iteration 2628, loss = 0.72528829
Iteration 2629, loss = 0.72509617
Iteration 2630, loss = 0.72467827
Iteration 2631, loss = 0.72448274
Iteration 2632, loss = 0.72427630
Iteration 2633, loss = 0.72393529
Iteration 2634, loss = 0.72374852
Iteration 2635, loss = 0.72348599
Iteration 2636, loss = 0.72321582
Iteration 2637, loss = 0.72305418
Iteration 2638, loss = 0.72279352
Iteration 2639, loss = 0.72256962
Iteration 2640, loss = 0.72239658
Iteration 2641, loss = 0.72215856
Iteration 2642, loss = 0.72198158
Iteration 2643, loss = 0.72180203
Iteration 2644, loss = 0.72158335
Iteration 2645, loss = 0.72142098
Iteration 2646, loss = 0.72123989
Iteration 2647, loss = 0.72105584
Iteration 2648, loss = 0.72090747
Iteration 2649, loss = 0.72072953
Iteration 2650, loss = 0.72056596
Iteration 2651, loss = 0.72042072
Iteration 2652, loss = 0.72025410
Iteration 2653, loss = 0.72010573
Iteration 2654, loss = 0.71995753
Iteration 2655, loss = 0.71980080
Iteration 2656, loss = 0.71966426
Iteration 2657, loss = 0.71952100
Iteration 2658, loss = 0.71937664
Iteration 2659, loss = 0.71924407
Iteration 2660, loss = 0.71910365
Iteration 2661, loss = 0.71896933
Iteration 2662, loss = 0.71884014
Iteration 2663, loss = 0.71870434
Iteration 2664, loss = 0.71857489
Iteration 2665, loss = 0.71844490
Iteration 2666, loss = 0.71831331
Iteration 2667, loss = 0.71819062
Iteration 2668, loss = 0.71806911
Iteration 2669, loss = 0.71794974
Iteration 2670, loss = 0.71783299
Iteration 2671, loss = 0.71771293
Iteration 2672, loss = 0.71759701
Iteration 2673, loss = 0.71748585
Iteration 2674, loss = 0.71737583
Iteration 2675, loss = 0.71726942
Iteration 2676, loss = 0.71716278
Iteration 2677, loss = 0.71705593
Iteration 2678, loss = 0.71695200
Iteration 2679, loss = 0.71684861
Iteration 2680, loss = 0.71674674
Iteration 2681, loss = 0.71664612
Iteration 2682, loss = 0.71654471
Iteration 2683, loss = 0.71644462
Iteration 2684, loss = 0.71634555
Iteration 2685, loss = 0.71624692
Iteration 2686, loss = 0.71614979
Iteration 2687, loss = 0.71605305
Iteration 2688, loss = 0.71595712
Iteration 2689, loss = 0.71586263
Iteration 2690, loss = 0.71576860
Iteration 2691, loss = 0.71567550
Iteration 2692, loss = 0.71558323
Iteration 2693, loss = 0.71549138
Iteration 2694, loss = 0.71540054
Iteration 2695, loss = 0.71531020
Iteration 2696, loss = 0.71522013
Iteration 2697, loss = 0.71513053
Iteration 2698, loss = 0.71504100
Iteration 2699, loss = 0.71495163
Iteration 2700, loss = 0.71486219
Iteration 2701, loss = 0.71477181
Iteration 2702, loss = 0.71467939
Iteration 2703, loss = 0.71458040
Iteration 2704, loss = 0.71445056
Iteration 2705, loss = 0.71412276
Iteration 2706, loss = 0.71390353
Iteration 2707, loss = 0.71351441
Iteration 2708, loss = 0.71335052
Iteration 2709, loss = 0.71287330
Iteration 2710, loss = 0.71233331
Iteration 2711, loss = 0.71120879
Iteration 2712, loss = 0.70728981
Iteration 2713, loss = 0.80576711
Iteration 2714, loss = 0.77289419
Iteration 2715, loss = 0.79823061
Iteration 2716, loss = 0.73862852
Iteration 2717, loss = 0.79782448
Iteration 2718, loss = 0.71820665
Iteration 2719, loss = 0.78280542
Iteration 2720, loss = 0.72137206
Iteration 2721, loss = 0.75637652
Iteration 2722, loss = 0.73843115
Iteration 2723, loss = 0.73046911
Iteration 2724, loss = 0.75022717
Iteration 2725, loss = 0.71625906
Iteration 2726, loss = 0.74720137
Iteration 2727, loss = 0.71813810
Iteration 2728, loss = 0.73327617
Iteration 2729, loss = 0.72688400
Iteration 2730, loss = 0.71894553
Iteration 2731, loss = 0.73123759
Iteration 2732, loss = 0.71299798
Iteration 2733, loss = 0.72744896
Iteration 2734, loss = 0.71572966
Iteration 2735, loss = 0.71873850
Iteration 2736, loss = 0.71973195
Iteration 2737, loss = 0.71266563
Iteration 2738, loss = 0.72005786
Iteration 2739, loss = 0.71115250
Iteration 2740, loss = 0.71625364
Iteration 2741, loss = 0.71237094
Iteration 2742, loss = 0.71079562
Iteration 2743, loss = 0.71313380
Iteration 2744, loss = 0.70803505
Iteration 2745, loss = 0.71144868
Iteration 2746, loss = 0.70753895
Iteration 2747, loss = 0.70869030
Iteration 2748, loss = 0.70851815
Iteration 2749, loss = 0.70861733
Iteration 2750, loss = 0.71205487
Iteration 2751, loss = 0.70840390
Iteration 2752, loss = 0.70838829
Iteration 2753, loss = 0.70357293
Iteration 2754, loss = 0.69742502
Iteration 2755, loss = 0.68723169
Iteration 2756, loss = 0.85327955
Iteration 2757, loss = 0.56084299
Iteration 2758, loss = 1.48546885
Iteration 2759, loss = 0.86128173
Iteration 2760, loss = 1.13860500
Iteration 2761, loss = 1.31715802
Iteration 2762, loss = 0.81710554
Iteration 2763, loss = 1.00784977
Iteration 2764, loss = 1.17037456
Iteration 2765, loss = 0.79769834
Iteration 2766, loss = 0.88173790
Iteration 2767, loss = 1.05405166
Iteration 2768, loss = 0.79293689
Iteration 2769, loss = 0.81375561
Iteration 2770, loss = 0.97425345
Iteration 2771, loss = 0.79646864
Iteration 2772, loss = 0.77839201
Iteration 2773, loss = 0.91050243
Iteration 2774, loss = 0.78933155
Iteration 2775, loss = 0.75224006
Iteration 2776, loss = 0.85565535
Iteration 2777, loss = 0.77553632
Iteration 2778, loss = 0.73513773
Iteration 2779, loss = 0.81367817
Iteration 2780, loss = 0.76345955
Iteration 2781, loss = 0.71604469
Iteration 2782, loss = 0.92540639
Iteration 2783, loss = 0.80497239
Iteration 2784, loss = 0.74519726
Iteration 2785, loss = 0.85923291
Iteration 2786, loss = 0.83802789
Iteration 2787, loss = 0.73512494
Iteration 2788, loss = 0.78016990
Iteration 2789, loss = 0.82287666
Iteration 2790, loss = 0.75283246
Iteration 2791, loss = 0.73622605
Iteration 2792, loss = 0.79154046
Iteration 2793, loss = 0.77017519
Iteration 2794, loss = 0.72717307
Iteration 2795, loss = 0.75819644
Iteration 2796, loss = 0.77079573
Iteration 2797, loss = 0.73348668
Iteration 2798, loss = 0.73525965
Iteration 2799, loss = 0.75938793
Iteration 2800, loss = 0.74140252
Iteration 2801, loss = 0.72601904
Iteration 2802, loss = 0.74416852
Iteration 2803, loss = 0.74371202
Iteration 2804, loss = 0.72565092
Iteration 2805, loss = 0.73171692
Iteration 2806, loss = 0.74037320
Iteration 2807, loss = 0.72860397
Iteration 2808, loss = 0.72522733
Iteration 2809, loss = 0.73451566
Iteration 2810, loss = 0.73076705
Iteration 2811, loss = 0.72348893
Iteration 2812, loss = 0.72873168
Iteration 2813, loss = 0.73051825
Iteration 2814, loss = 0.72396766
Iteration 2815, loss = 0.72450500
Iteration 2816, loss = 0.72824343
Iteration 2817, loss = 0.72469799
Iteration 2818, loss = 0.72241781
Iteration 2819, loss = 0.72552999
Iteration 2820, loss = 0.72492852
Iteration 2821, loss = 0.72195071
Iteration 2822, loss = 0.72326394
Iteration 2823, loss = 0.72429909
Iteration 2824, loss = 0.72201893
Iteration 2825, loss = 0.72170780
Iteration 2826, loss = 0.72308158
Iteration 2827, loss = 0.72200928
Iteration 2828, loss = 0.72089608
Iteration 2829, loss = 0.72183377
Iteration 2830, loss = 0.72176197
Iteration 2831, loss = 0.72058609
Iteration 2832, loss = 0.72082723
Iteration 2833, loss = 0.72122202
Iteration 2834, loss = 0.72039456
Iteration 2835, loss = 0.72010402
Iteration 2836, loss = 0.72053530
Iteration 2837, loss = 0.72016373
Iteration 2838, loss = 0.71965140
Iteration 2839, loss = 0.71987809
Iteration 2840, loss = 0.71983191
Iteration 2841, loss = 0.71934054
Iteration 2842, loss = 0.71931719
Iteration 2843, loss = 0.71940990
Iteration 2844, loss = 0.71906753
Iteration 2845, loss = 0.71887280
Iteration 2846, loss = 0.71895675
Iteration 2847, loss = 0.71877503
Iteration 2848, loss = 0.71851714
Iteration 2849, loss = 0.71852184
Iteration 2850, loss = 0.71845053
Iteration 2851, loss = 0.71821258
Iteration 2852, loss = 0.71813124
Iteration 2853, loss = 0.71810219
Iteration 2854, loss = 0.71792020
Iteration 2855, loss = 0.71778306
Iteration 2856, loss = 0.71774871
Iteration 2857, loss = 0.71762471
Iteration 2858, loss = 0.71746991
Iteration 2859, loss = 0.71740726
Iteration 2860, loss = 0.71732045
Iteration 2861, loss = 0.71717438
Iteration 2862, loss = 0.71708325
Iteration 2863, loss = 0.71701213
Iteration 2864, loss = 0.71688777
Iteration 2865, loss = 0.71677909
Iteration 2866, loss = 0.71670646
Iteration 2867, loss = 0.71660221
Iteration 2868, loss = 0.71648777
Iteration 2869, loss = 0.71640607
Iteration 2870, loss = 0.71631569
Iteration 2871, loss = 0.71620526
Iteration 2872, loss = 0.71611475
Iteration 2873, loss = 0.71603058
Iteration 2874, loss = 0.71592782
Iteration 2875, loss = 0.71583146
Iteration 2876, loss = 0.71574737
Iteration 2877, loss = 0.71565179
Iteration 2878, loss = 0.71555332
Iteration 2879, loss = 0.71546492
Iteration 2880, loss = 0.71534796
Iteration 2881, loss = 0.71503033
Iteration 2882, loss = 0.71414963
Iteration 2883, loss = 0.70705008
Iteration 2884, loss = 0.71932817
Iteration 2885, loss = 0.71923612
Iteration 2886, loss = 0.71928701
Iteration 2887, loss = 0.72117352
Iteration 2888, loss = 0.71838000
Iteration 2889, loss = 0.71789902
Iteration 2890, loss = 0.71986525
Iteration 2891, loss = 0.71854946
Iteration 2892, loss = 0.71911305
Iteration 2893, loss = 0.72001313
Iteration 2894, loss = 0.71898821
Iteration 2895, loss = 0.71981979
Iteration 2896, loss = 0.72036212
Iteration 2897, loss = 0.71949039
Iteration 2898, loss = 0.72001875
Iteration 2899, loss = 0.71992144
Iteration 2900, loss = 0.71938732
Iteration 2901, loss = 0.71996885
Iteration 2902, loss = 0.71971079
Iteration 2903, loss = 0.71944536
Iteration 2904, loss = 0.71999749
Iteration 2905, loss = 0.71980098
Iteration 2906, loss = 0.71954908
Iteration 2907, loss = 0.71969032
Iteration 2908, loss = 0.71928778
Iteration 2909, loss = 0.71914954
Iteration 2910, loss = 0.71928347
Iteration 2911, loss = 0.71897198
Iteration 2912, loss = 0.71883904
Iteration 2913, loss = 0.71873091
Iteration 2914, loss = 0.71834373
Iteration 2915, loss = 0.71821933
Iteration 2916, loss = 0.71808236
Iteration 2917, loss = 0.71777551
Iteration 2918, loss = 0.71763670
Iteration 2919, loss = 0.71739563
Iteration 2920, loss = 0.71707152
Iteration 2921, loss = 0.71687967
Iteration 2922, loss = 0.71657064
Iteration 2923, loss = 0.71619718
Iteration 2924, loss = 0.71584846
Iteration 2925, loss = 0.71538949
Iteration 2926, loss = 0.71482783
Iteration 2927, loss = 0.71410854
Iteration 2928, loss = 0.71286038
Iteration 2929, loss = 0.71102755
Iteration 2930, loss = 0.70795247
Iteration 2931, loss = 0.70090350
Iteration 2932, loss = 0.76607178
Iteration 2933, loss = 0.72110985
Iteration 2934, loss = 0.77145141
Iteration 2935, loss = 0.74128259
Iteration 2936, loss = 0.73403536
Iteration 2937, loss = 0.76036614
Iteration 2938, loss = 0.72344380
Iteration 2939, loss = 0.73968782
Iteration 2940, loss = 0.73984446
Iteration 2941, loss = 0.71879014
Iteration 2942, loss = 0.73900965
Iteration 2943, loss = 0.72457950
Iteration 2944, loss = 0.72228632
Iteration 2945, loss = 0.73310506
Iteration 2946, loss = 0.71768148
Iteration 2947, loss = 0.72576584
Iteration 2948, loss = 0.72492115
Iteration 2949, loss = 0.71656900
Iteration 2950, loss = 0.72521984
Iteration 2951, loss = 0.71807656
Iteration 2952, loss = 0.71772255
Iteration 2953, loss = 0.72167708
Iteration 2954, loss = 0.71491236
Iteration 2955, loss = 0.71884074
Iteration 2956, loss = 0.71774722
Iteration 2957, loss = 0.71452970
Iteration 2958, loss = 0.71814705
Iteration 2959, loss = 0.71466593
Iteration 2960, loss = 0.71500538
Iteration 2961, loss = 0.71630648
Iteration 2962, loss = 0.71337038
Iteration 2963, loss = 0.71514043
Iteration 2964, loss = 0.71419358
Iteration 2965, loss = 0.71314618
Iteration 2966, loss = 0.71471375
Iteration 2967, loss = 0.71310788
Iteration 2968, loss = 0.71346010
Iteration 2969, loss = 0.71366083
Iteration 2970, loss = 0.71235935
Iteration 2971, loss = 0.71317886
Iteration 2972, loss = 0.71258705
Iteration 2973, loss = 0.71224340
Iteration 2974, loss = 0.71270556
Iteration 2975, loss = 0.71184656
Iteration 2976, loss = 0.71207602
Iteration 2977, loss = 0.71202058
Iteration 2978, loss = 0.71151584
Iteration 2979, loss = 0.71183105
Iteration 2980, loss = 0.71140305
Iteration 2981, loss = 0.71128463
Iteration 2982, loss = 0.71139255
Iteration 2983, loss = 0.71099213
Iteration 2984, loss = 0.71109870
Iteration 2985, loss = 0.71094950
Iteration 2986, loss = 0.71072861
Iteration 2987, loss = 0.71081022
Iteration 2988, loss = 0.71054641
Iteration 2989, loss = 0.71049284
Iteration 2990, loss = 0.71044392
Iteration 2991, loss = 0.71022005
Iteration 2992, loss = 0.71021301
Iteration 2993, loss = 0.71003293
Iteration 2994, loss = 0.70988713
Iteration 2995, loss = 0.70986013
Iteration 2996, loss = 0.70969664
Iteration 2997, loss = 0.70962883
Iteration 2998, loss = 0.70950897
Iteration 2999, loss = 0.70936582
Iteration 3000, loss = 0.70932121
Iteration 3001, loss = 0.70918518
Iteration 3002, loss = 0.70908610
Iteration 3003, loss = 0.70900494
Iteration 3004, loss = 0.70887851
Iteration 3005, loss = 0.70880889
Iteration 3006, loss = 0.70869963
Iteration 3007, loss = 0.70859130
Iteration 3008, loss = 0.70850973
Iteration 3009, loss = 0.70838263
Iteration 3010, loss = 0.70826971
Iteration 3011, loss = 0.70813422
Iteration 3012, loss = 0.70798474
Iteration 3013, loss = 0.70787843
Iteration 3014, loss = 0.70776044
Iteration 3015, loss = 0.70763471
Iteration 3016, loss = 0.70748816
Iteration 3017, loss = 0.70729893
Iteration 3018, loss = 0.70701876
Iteration 3019, loss = 0.70644365
Iteration 3020, loss = 0.70628843
Iteration 3021, loss = 0.70620942
Iteration 3022, loss = 0.70577508
Iteration 3023, loss = 0.70538496
Iteration 3024, loss = 0.70465359
Iteration 3025, loss = 0.70444843
Iteration 3026, loss = 0.70413197
Iteration 3027, loss = 0.70318821
Iteration 3028, loss = 0.70220035
Iteration 3029, loss = 0.70123492
Iteration 3030, loss = 0.69970553
Iteration 3031, loss = 0.69659429
Iteration 3032, loss = 0.55080087
Iteration 3033, loss = 0.77995460
Iteration 3034, loss = 0.73187823
Iteration 3035, loss = 0.83707689
Iteration 3036, loss = 0.76376523
Iteration 3037, loss = 0.73913559
Iteration 3038, loss = 0.80904239
Iteration 3039, loss = 0.74574830
Iteration 3040, loss = 0.73534109
Iteration 3041, loss = 0.78265466
Iteration 3042, loss = 0.73202192
Iteration 3043, loss = 0.73243865
Iteration 3044, loss = 0.76434981
Iteration 3045, loss = 0.72565594
Iteration 3046, loss = 0.73224446
Iteration 3047, loss = 0.75284752
Iteration 3048, loss = 0.72351465
Iteration 3049, loss = 0.73263730
Iteration 3050, loss = 0.74484401
Iteration 3051, loss = 0.72298028
Iteration 3052, loss = 0.73226407
Iteration 3053, loss = 0.73857512
Iteration 3054, loss = 0.72258731
Iteration 3055, loss = 0.73109030
Iteration 3056, loss = 0.73341908
Iteration 3057, loss = 0.72196959
Iteration 3058, loss = 0.72923028
Iteration 3059, loss = 0.72929457
Iteration 3060, loss = 0.72160965
Iteration 3061, loss = 0.72775711
Iteration 3062, loss = 0.72670175
Iteration 3063, loss = 0.72178803
Iteration 3064, loss = 0.72669335
Iteration 3065, loss = 0.72501058
Iteration 3066, loss = 0.72197493
Iteration 3067, loss = 0.72562345
Iteration 3068, loss = 0.72364930
Iteration 3069, loss = 0.72186662
Iteration 3070, loss = 0.72445618
Iteration 3071, loss = 0.72252576
Iteration 3072, loss = 0.72164126
Iteration 3073, loss = 0.72341342
Iteration 3074, loss = 0.72170446
Iteration 3075, loss = 0.72137527
Iteration 3076, loss = 0.72250394
Iteration 3077, loss = 0.72106707
Iteration 3078, loss = 0.72107030
Iteration 3079, loss = 0.72172183
Iteration 3080, loss = 0.72057200
Iteration 3081, loss = 0.72073859
Iteration 3082, loss = 0.72104923
Iteration 3083, loss = 0.72016104
Iteration 3084, loss = 0.72038312
Iteration 3085, loss = 0.72045289
Iteration 3086, loss = 0.71978001
Iteration 3087, loss = 0.71998801
Iteration 3088, loss = 0.71990361
Iteration 3089, loss = 0.71940751
Iteration 3090, loss = 0.71957444
Iteration 3091, loss = 0.71940452
Iteration 3092, loss = 0.71904796
Iteration 3093, loss = 0.71916288
Iteration 3094, loss = 0.71895374
Iteration 3095, loss = 0.71870279
Iteration 3096, loss = 0.71876500
Iteration 3097, loss = 0.71854579
Iteration 3098, loss = 0.71836742
Iteration 3099, loss = 0.71837907
Iteration 3100, loss = 0.71816402
Iteration 3101, loss = 0.71802909
Iteration 3102, loss = 0.71799494
Iteration 3103, loss = 0.71779188
Iteration 3104, loss = 0.71768194
Iteration 3105, loss = 0.71761367
Iteration 3106, loss = 0.71742873
Iteration 3107, loss = 0.71733337
Iteration 3108, loss = 0.71724246
Iteration 3109, loss = 0.71707631
Iteration 3110, loss = 0.71698544
Iteration 3111, loss = 0.71687658
Iteration 3112, loss = 0.71672210
Iteration 3113, loss = 0.71662242
Iteration 3114, loss = 0.71648713
Iteration 3115, loss = 0.71630705
Iteration 3116, loss = 0.71608862
Iteration 3117, loss = 0.71554919
Iteration 3118, loss = 0.71496226
Iteration 3119, loss = 0.71487362
Iteration 3120, loss = 0.71443393
Iteration 3121, loss = 0.71362897
Iteration 3122, loss = 0.71203608
Iteration 3123, loss = 0.71108611
Iteration 3124, loss = 0.71004591
Iteration 3125, loss = 0.70834316
Iteration 3126, loss = 0.70663901
Iteration 3127, loss = 0.70306065
Iteration 3128, loss = 0.69660074
Iteration 3129, loss = 0.94285676
Iteration 3130, loss = 0.86463733
Iteration 3131, loss = 0.89853228
Iteration 3132, loss = 0.77266973
Iteration 3133, loss = 0.88054139
Iteration 3134, loss = 0.88922806
Iteration 3135, loss = 0.76649016
Iteration 3136, loss = 0.82270953
Iteration 3137, loss = 0.82764558
Iteration 3138, loss = 0.73588287
Iteration 3139, loss = 0.77891692
Iteration 3140, loss = 0.79082965
Iteration 3141, loss = 0.72848124
Iteration 3142, loss = 0.76324243
Iteration 3143, loss = 0.77606668
Iteration 3144, loss = 0.73223150
Iteration 3145, loss = 0.75832770
Iteration 3146, loss = 0.76702338
Iteration 3147, loss = 0.73317184
Iteration 3148, loss = 0.74979215
Iteration 3149, loss = 0.75366947
Iteration 3150, loss = 0.72736510
Iteration 3151, loss = 0.73921567
Iteration 3152, loss = 0.74152101
Iteration 3153, loss = 0.72294897
Iteration 3154, loss = 0.73283295
Iteration 3155, loss = 0.73521544
Iteration 3156, loss = 0.72258001
Iteration 3157, loss = 0.73050196
Iteration 3158, loss = 0.73200888
Iteration 3159, loss = 0.72269092
Iteration 3160, loss = 0.72822224
Iteration 3161, loss = 0.72849484
Iteration 3162, loss = 0.72088810
Iteration 3163, loss = 0.72137155
Iteration 3164, loss = 0.72122078
Iteration 3165, loss = 0.72440680
Iteration 3166, loss = 0.72488130
Iteration 3167, loss = 0.72320372
Iteration 3168, loss = 0.72479138
Iteration 3169, loss = 0.72262908
Iteration 3170, loss = 0.72308750
Iteration 3171, loss = 0.72375084
Iteration 3172, loss = 0.72282087
Iteration 3173, loss = 0.72422651
Iteration 3174, loss = 0.72364970
Iteration 3175, loss = 0.72390926
Iteration 3176, loss = 0.72447952
Iteration 3177, loss = 0.72385310
Iteration 3178, loss = 0.72457348
Iteration 3179, loss = 0.72425128
Iteration 3180, loss = 0.72409742
Iteration 3181, loss = 0.72439783
Iteration 3182, loss = 0.72387467
Iteration 3183, loss = 0.72416345
Iteration 3184, loss = 0.72404095
Iteration 3185, loss = 0.72386839
Iteration 3186, loss = 0.72407376
Iteration 3187, loss = 0.72370805
Iteration 3188, loss = 0.72373609
Iteration 3189, loss = 0.72360633
Iteration 3190, loss = 0.72336787
Iteration 3191, loss = 0.72343719
Iteration 3192, loss = 0.72318560
Iteration 3193, loss = 0.72312765
Iteration 3194, loss = 0.72302291
Iteration 3195, loss = 0.72278897
Iteration 3196, loss = 0.72274723
Iteration 3197, loss = 0.72251926
Iteration 3198, loss = 0.72237784
Iteration 3199, loss = 0.72224618
Iteration 3200, loss = 0.72202179
Iteration 3201, loss = 0.72192636
Iteration 3202, loss = 0.72173722
Iteration 3203, loss = 0.72158422
Iteration 3204, loss = 0.72145267
Iteration 3205, loss = 0.72125102
Iteration 3206, loss = 0.72112204
Iteration 3207, loss = 0.72094280
Iteration 3208, loss = 0.72077525
Iteration 3209, loss = 0.72063127
Iteration 3210, loss = 0.72044174
Iteration 3211, loss = 0.72028648
Iteration 3212, loss = 0.72005046
Iteration 3213, loss = 0.71943243
Iteration 3214, loss = 0.71914588
Iteration 3215, loss = 0.71912093
Iteration 3216, loss = 0.71901377
Iteration 3217, loss = 0.71870879
Iteration 3218, loss = 0.71833551
Iteration 3219, loss = 0.71815621
Iteration 3220, loss = 0.71821157
Iteration 3221, loss = 0.71769258
Iteration 3222, loss = 0.71757598
Iteration 3223, loss = 0.71744673
Iteration 3224, loss = 0.71721873
Iteration 3225, loss = 0.71695484
Iteration 3226, loss = 0.71683232
Iteration 3227, loss = 0.71676796
Iteration 3228, loss = 0.71657752
Iteration 3229, loss = 0.71632533
Iteration 3230, loss = 0.71615687
Iteration 3231, loss = 0.71589549
Iteration 3232, loss = 0.71568983
Iteration 3233, loss = 0.71510804
Iteration 3234, loss = 0.71533779
Iteration 3235, loss = 0.71516296
Iteration 3236, loss = 0.71459781
Iteration 3237, loss = 0.71372631
Iteration 3238, loss = 0.71392612
Iteration 3239, loss = 0.71371110
Iteration 3240, loss = 0.71418248
Iteration 3241, loss = 0.71381882
Iteration 3242, loss = 0.71349362
Iteration 3243, loss = 0.71351437
Iteration 3244, loss = 0.71310456
Iteration 3245, loss = 0.71211554
Iteration 3246, loss = 0.71128133
Iteration 3247, loss = 0.70965139
Iteration 3248, loss = 0.70789559
Iteration 3249, loss = 0.70220726
Iteration 3250, loss = 0.60476332
Iteration 3251, loss = 0.89612022
Iteration 3252, loss = 0.74450234
Iteration 3253, loss = 0.94230786
Iteration 3254, loss = 0.84632136
Iteration 3255, loss = 0.76274514
Iteration 3256, loss = 0.89331743
Iteration 3257, loss = 0.79086602
Iteration 3258, loss = 0.75537499
Iteration 3259, loss = 0.84176680
Iteration 3260, loss = 0.75444269
Iteration 3261, loss = 0.75339850
Iteration 3262, loss = 0.80986673
Iteration 3263, loss = 0.74092510
Iteration 3264, loss = 0.75813171
Iteration 3265, loss = 0.78869298
Iteration 3266, loss = 0.73349767
Iteration 3267, loss = 0.75539579
Iteration 3268, loss = 0.76945983
Iteration 3269, loss = 0.73058490
Iteration 3270, loss = 0.75343002
Iteration 3271, loss = 0.75622583
Iteration 3272, loss = 0.72961025
Iteration 3273, loss = 0.74962448
Iteration 3274, loss = 0.74553500
Iteration 3275, loss = 0.72882313
Iteration 3276, loss = 0.74517799
Iteration 3277, loss = 0.73817493
Iteration 3278, loss = 0.72924089
Iteration 3279, loss = 0.74175896
Iteration 3280, loss = 0.73393549
Iteration 3281, loss = 0.73007419
Iteration 3282, loss = 0.73860265
Iteration 3283, loss = 0.73095837
Iteration 3284, loss = 0.73011416
Iteration 3285, loss = 0.73529718
Iteration 3286, loss = 0.72876816
Iteration 3287, loss = 0.72977899
Iteration 3288, loss = 0.73260201
Iteration 3289, loss = 0.72760354
Iteration 3290, loss = 0.72949615
Iteration 3291, loss = 0.73059791
Iteration 3292, loss = 0.72698608
Iteration 3293, loss = 0.72897959
Iteration 3294, loss = 0.72889597
Iteration 3295, loss = 0.72645733
Iteration 3296, loss = 0.72820638
Iteration 3297, loss = 0.72749240
Iteration 3298, loss = 0.72603869
Iteration 3299, loss = 0.72741969
Iteration 3300, loss = 0.72645158
Iteration 3301, loss = 0.72570081
Iteration 3302, loss = 0.72663445
Iteration 3303, loss = 0.72560123
Iteration 3304, loss = 0.72526930
Iteration 3305, loss = 0.72576505
Iteration 3306, loss = 0.72479607
Iteration 3307, loss = 0.72470683
Iteration 3308, loss = 0.72487615
Iteration 3309, loss = 0.72407743
Iteration 3310, loss = 0.72412640
Iteration 3311, loss = 0.72407530
Iteration 3312, loss = 0.72344540
Iteration 3313, loss = 0.72350177
Iteration 3314, loss = 0.72328348
Iteration 3315, loss = 0.72279725
Iteration 3316, loss = 0.72281576
Iteration 3317, loss = 0.72250712
Iteration 3318, loss = 0.72216371
Iteration 3319, loss = 0.72219727
Iteration 3320, loss = 0.72193763
Iteration 3321, loss = 0.72171968
Iteration 3322, loss = 0.72166885
Iteration 3323, loss = 0.72135945
Iteration 3324, loss = 0.72115859
Iteration 3325, loss = 0.72102120
Iteration 3326, loss = 0.72069359
Iteration 3327, loss = 0.72050599
Iteration 3328, loss = 0.72034019
Iteration 3329, loss = 0.72007709
Iteration 3330, loss = 0.71994463
Iteration 3331, loss = 0.71979341
Iteration 3332, loss = 0.71958857
Iteration 3333, loss = 0.71946681
Iteration 3334, loss = 0.71929273
Iteration 3335, loss = 0.71909487
Iteration 3336, loss = 0.71895236
Iteration 3337, loss = 0.71876385
Iteration 3338, loss = 0.71858129
Iteration 3339, loss = 0.71842512
Iteration 3340, loss = 0.71822086
Iteration 3341, loss = 0.71803464
Iteration 3342, loss = 0.71786941
Iteration 3343, loss = 0.71767975
Iteration 3344, loss = 0.71751331
Iteration 3345, loss = 0.71735090
Iteration 3346, loss = 0.71717197
Iteration 3347, loss = 0.71701313
Iteration 3348, loss = 0.71685121
Iteration 3349, loss = 0.71668373
Iteration 3350, loss = 0.71653290
Iteration 3351, loss = 0.71637359
Iteration 3352, loss = 0.71621157
Iteration 3353, loss = 0.71605876
Iteration 3354, loss = 0.71589468
Iteration 3355, loss = 0.71572614
Iteration 3356, loss = 0.71554952
Iteration 3357, loss = 0.71532714
Iteration 3358, loss = 0.71498019
Iteration 3359, loss = 0.71435027
Iteration 3360, loss = 0.71396134
Iteration 3361, loss = 0.71353647
Iteration 3362, loss = 0.71224739
Iteration 3363, loss = 0.71072448
Iteration 3364, loss = 0.70953805
Iteration 3365, loss = 0.70752162
Iteration 3366, loss = 0.70552164
Iteration 3367, loss = 0.69871966
Iteration 3368, loss = 0.62860975
Iteration 3369, loss = 0.83855850
Iteration 3370, loss = 0.74297755
Iteration 3371, loss = 0.83775665
Iteration 3372, loss = 0.85016269
Iteration 3373, loss = 0.75172478
Iteration 3374, loss = 0.77611105
Iteration 3375, loss = 0.81507782
Iteration 3376, loss = 0.74896805
Iteration 3377, loss = 0.73748145
Iteration 3378, loss = 0.78685381
Iteration 3379, loss = 0.76096593
Iteration 3380, loss = 0.73371281
Iteration 3381, loss = 0.76953385
Iteration 3382, loss = 0.76645538
Iteration 3383, loss = 0.73466481
Iteration 3384, loss = 0.75176969
Iteration 3385, loss = 0.76252400
Iteration 3386, loss = 0.73773068
Iteration 3387, loss = 0.73967342
Iteration 3388, loss = 0.75410350
Iteration 3389, loss = 0.73965989
Iteration 3390, loss = 0.73383531
Iteration 3391, loss = 0.74701203
Iteration 3392, loss = 0.74185328
Iteration 3393, loss = 0.73297040
Iteration 3394, loss = 0.74122834
Iteration 3395, loss = 0.74137003
Iteration 3396, loss = 0.73286203
Iteration 3397, loss = 0.73655499
Iteration 3398, loss = 0.73976624
Iteration 3399, loss = 0.73338529
Iteration 3400, loss = 0.73330812
Iteration 3401, loss = 0.73711743
Iteration 3402, loss = 0.73358348
Iteration 3403, loss = 0.73176922
Iteration 3404, loss = 0.73474769
Iteration 3405, loss = 0.73243824
Iteration 3406, loss = 0.73128183
Iteration 3407, loss = 0.73287276
Iteration 3408, loss = 0.73117762
Iteration 3409, loss = 0.73135763
Iteration 3410, loss = 0.73198676
Iteration 3411, loss = 0.73049627
Iteration 3412, loss = 0.73104027
Iteration 3413, loss = 0.73055749
Iteration 3414, loss = 0.72960637
Iteration 3415, loss = 0.73016103
Iteration 3416, loss = 0.72937052
Iteration 3417, loss = 0.72906504
Iteration 3418, loss = 0.72936236
Iteration 3419, loss = 0.72862023
Iteration 3420, loss = 0.72866965
Iteration 3421, loss = 0.72852530
Iteration 3422, loss = 0.72789264
Iteration 3423, loss = 0.72802353
Iteration 3424, loss = 0.72761719
Iteration 3425, loss = 0.72731239
Iteration 3426, loss = 0.72734945
Iteration 3427, loss = 0.72691207
Iteration 3428, loss = 0.72675925
Iteration 3429, loss = 0.72663574
Iteration 3430, loss = 0.72625527
Iteration 3431, loss = 0.72618221
Iteration 3432, loss = 0.72593715
Iteration 3433, loss = 0.72566419
Iteration 3434, loss = 0.72557809
Iteration 3435, loss = 0.72529730
Iteration 3436, loss = 0.72511570
Iteration 3437, loss = 0.72496821
Iteration 3438, loss = 0.72468964
Iteration 3439, loss = 0.72454605
Iteration 3440, loss = 0.72434384
Iteration 3441, loss = 0.72411492
Iteration 3442, loss = 0.72397852
Iteration 3443, loss = 0.72375541
Iteration 3444, loss = 0.72357041
Iteration 3445, loss = 0.72340907
Iteration 3446, loss = 0.72318644
Iteration 3447, loss = 0.72302103
Iteration 3448, loss = 0.72283268
Iteration 3449, loss = 0.72262765
Iteration 3450, loss = 0.72246315
Iteration 3451, loss = 0.72226191
Iteration 3452, loss = 0.72207422
Iteration 3453, loss = 0.72189769
Iteration 3454, loss = 0.72169445
Iteration 3455, loss = 0.72151393
Iteration 3456, loss = 0.72132438
Iteration 3457, loss = 0.72112554
Iteration 3458, loss = 0.72094238
Iteration 3459, loss = 0.72074312
Iteration 3460, loss = 0.72054709
Iteration 3461, loss = 0.72035494
Iteration 3462, loss = 0.72014820
Iteration 3463, loss = 0.71994501
Iteration 3464, loss = 0.71972784
Iteration 3465, loss = 0.71949375
Iteration 3466, loss = 0.71926569
Iteration 3467, loss = 0.71902076
Iteration 3468, loss = 0.71871237
Iteration 3469, loss = 0.71840409
Iteration 3470, loss = 0.71812033
Iteration 3471, loss = 0.71774449
Iteration 3472, loss = 0.71715545
Iteration 3473, loss = 0.71573061
Iteration 3474, loss = 0.71254521
Iteration 3475, loss = 0.61851120
Iteration 3476, loss = 0.75686805
Iteration 3477, loss = 0.74597489
Iteration 3478, loss = 0.73663167
Iteration 3479, loss = 0.76067349
Iteration 3480, loss = 0.73636646
Iteration 3481, loss = 0.74034368
Iteration 3482, loss = 0.74570572
Iteration 3483, loss = 0.72628716
Iteration 3484, loss = 0.73843759
Iteration 3485, loss = 0.73532971
Iteration 3486, loss = 0.72828543
Iteration 3487, loss = 0.74025664
Iteration 3488, loss = 0.73192135
Iteration 3489, loss = 0.73158749
Iteration 3490, loss = 0.73673181
Iteration 3491, loss = 0.72878750
Iteration 3492, loss = 0.73320230
Iteration 3493, loss = 0.73334152
Iteration 3494, loss = 0.72884731
Iteration 3495, loss = 0.73357195
Iteration 3496, loss = 0.73069834
Iteration 3497, loss = 0.72965194
Iteration 3498, loss = 0.73238451
Iteration 3499, loss = 0.72891334
Iteration 3500, loss = 0.73007603
Iteration 3501, loss = 0.73062405
Iteration 3502, loss = 0.72829644
Iteration 3503, loss = 0.73015487
Iteration 3504, loss = 0.72923548
Iteration 3505, loss = 0.72836678
Iteration 3506, loss = 0.72964137
Iteration 3507, loss = 0.72817924
Iteration 3508, loss = 0.72838718
Iteration 3509, loss = 0.72875939
Iteration 3510, loss = 0.72756945
Iteration 3511, loss = 0.72815208
Iteration 3512, loss = 0.72774039
Iteration 3513, loss = 0.72709392
Iteration 3514, loss = 0.72754881
Iteration 3515, loss = 0.72686749
Iteration 3516, loss = 0.72678923
Iteration 3517, loss = 0.72695159
Iteration 3518, loss = 0.72635934
Iteration 3519, loss = 0.72649835
Iteration 3520, loss = 0.72628121
Iteration 3521, loss = 0.72586851
Iteration 3522, loss = 0.72596751
Iteration 3523, loss = 0.72559007
Iteration 3524, loss = 0.72541865
Iteration 3525, loss = 0.72539697
Iteration 3526, loss = 0.72503501
Iteration 3527, loss = 0.72498618
Iteration 3528, loss = 0.72481920
Iteration 3529, loss = 0.72454629
Iteration 3530, loss = 0.72450405
Iteration 3531, loss = 0.72426077
Iteration 3532, loss = 0.72408921
Iteration 3533, loss = 0.72399287
Iteration 3534, loss = 0.72374358
Iteration 3535, loss = 0.72362622
Iteration 3536, loss = 0.72346647
Iteration 3537, loss = 0.72325656
Iteration 3538, loss = 0.72314940
Iteration 3539, loss = 0.72295748
Iteration 3540, loss = 0.72279365
Iteration 3541, loss = 0.72266496
Iteration 3542, loss = 0.72247014
Iteration 3543, loss = 0.72233282
Iteration 3544, loss = 0.72217921
Iteration 3545, loss = 0.72200439
Iteration 3546, loss = 0.72187457
Iteration 3547, loss = 0.72170803
Iteration 3548, loss = 0.72155361
Iteration 3549, loss = 0.72141393
Iteration 3550, loss = 0.72124604
Iteration 3551, loss = 0.72110386
Iteration 3552, loss = 0.72095465
Iteration 3553, loss = 0.72079763
Iteration 3554, loss = 0.72066048
Iteration 3555, loss = 0.72050777
Iteration 3556, loss = 0.72036172
Iteration 3557, loss = 0.72022191
Iteration 3558, loss = 0.72007060
Iteration 3559, loss = 0.71993098
Iteration 3560, loss = 0.71978776
Iteration 3561, loss = 0.71964201
Iteration 3562, loss = 0.71950492
Iteration 3563, loss = 0.71936135
Iteration 3564, loss = 0.71922189
Iteration 3565, loss = 0.71908515
Iteration 3566, loss = 0.71894423
Iteration 3567, loss = 0.71880897
Iteration 3568, loss = 0.71867203
Iteration 3569, loss = 0.71853482
Iteration 3570, loss = 0.71840150
Iteration 3571, loss = 0.71826566
Iteration 3572, loss = 0.71813238
Iteration 3573, loss = 0.71800030
Iteration 3574, loss = 0.71786704
Iteration 3575, loss = 0.71773671
Iteration 3576, loss = 0.71760580
Iteration 3577, loss = 0.71747549
Iteration 3578, loss = 0.71734708
Iteration 3579, loss = 0.71721792
Iteration 3580, loss = 0.71709044
Iteration 3581, loss = 0.71696363
Iteration 3582, loss = 0.71683684
Iteration 3583, loss = 0.71671171
Iteration 3584, loss = 0.71658659
Iteration 3585, loss = 0.71646225
Iteration 3586, loss = 0.71633896
Iteration 3587, loss = 0.71621568
Iteration 3588, loss = 0.71609345
Iteration 3589, loss = 0.71597142
Iteration 3590, loss = 0.71584845
Iteration 3591, loss = 0.71571183
Iteration 3592, loss = 0.71479109
Iteration 3593, loss = 0.71808160
Iteration 3594, loss = 0.72153466
Iteration 3595, loss = 0.72517352
Iteration 3596, loss = 0.72737255
Iteration 3597, loss = 0.72634823
Iteration 3598, loss = 0.72438769
Iteration 3599, loss = 0.72159180
Iteration 3600, loss = 0.71904650
Iteration 3601, loss = 0.71791122
Iteration 3602, loss = 0.71719852
Iteration 3603, loss = 0.71731988
Iteration 3604, loss = 0.71774100
Iteration 3605, loss = 0.72394991
Iteration 3606, loss = 0.72438943
Iteration 3607, loss = 0.72683737
Iteration 3608, loss = 0.73020364
Iteration 3609, loss = 0.73368573
Iteration 3610, loss = 0.72889611
Iteration 3611, loss = 0.72673085
Iteration 3612, loss = 0.72303159
Iteration 3613, loss = 0.71900439
Iteration 3614, loss = 0.71971110
Iteration 3615, loss = 0.71864595
Iteration 3616, loss = 0.71952564
Iteration 3617, loss = 0.72072697
Iteration 3618, loss = 0.71949824
Iteration 3619, loss = 0.71982604
Iteration 3620, loss = 0.71871997
Iteration 3621, loss = 0.71767035
Iteration 3622, loss = 0.71789867
Iteration 3623, loss = 0.71697832
Iteration 3624, loss = 0.71714205
Iteration 3625, loss = 0.71708264
Iteration 3626, loss = 0.71640201
Iteration 3627, loss = 0.71651249
Iteration 3628, loss = 0.71586756
Iteration 3629, loss = 0.71553994
Iteration 3630, loss = 0.71551246
Iteration 3631, loss = 0.71503886
Iteration 3632, loss = 0.71514065
Iteration 3633, loss = 0.71498516
Iteration 3634, loss = 0.71476254
Iteration 3635, loss = 0.71480011
Iteration 3636, loss = 0.71444589
Iteration 3637, loss = 0.71429887
Iteration 3638, loss = 0.71411062
Iteration 3639, loss = 0.71378715
Iteration 3640, loss = 0.71372019
Iteration 3641, loss = 0.71350597
Iteration 3642, loss = 0.71338867
Iteration 3643, loss = 0.71334766
Iteration 3644, loss = 0.71316915
Iteration 3645, loss = 0.71310863
Iteration 3646, loss = 0.71295692
Iteration 3647, loss = 0.71277874
Iteration 3648, loss = 0.71267044
Iteration 3649, loss = 0.71247867
Iteration 3650, loss = 0.71236320
Iteration 3651, loss = 0.71224954
Iteration 3652, loss = 0.71211076
Iteration 3653, loss = 0.71203204
Iteration 3654, loss = 0.71190241
Iteration 3655, loss = 0.71178961
Iteration 3656, loss = 0.71168469
Iteration 3657, loss = 0.71154584
Iteration 3658, loss = 0.71144283
Iteration 3659, loss = 0.71132076
Iteration 3660, loss = 0.71120240
Iteration 3661, loss = 0.71110287
Iteration 3662, loss = 0.71098265
Iteration 3663, loss = 0.71088209
Iteration 3664, loss = 0.71077641
Iteration 3665, loss = 0.71066529
Iteration 3666, loss = 0.71056782
Iteration 3667, loss = 0.71045687
Iteration 3668, loss = 0.71035345
Iteration 3669, loss = 0.71025089
Iteration 3670, loss = 0.71014246
Iteration 3671, loss = 0.71004450
Iteration 3672, loss = 0.70994147
Iteration 3673, loss = 0.70984202
Iteration 3674, loss = 0.70974614
Iteration 3675, loss = 0.70964523
Iteration 3676, loss = 0.70954944
Iteration 3677, loss = 0.70945077
Iteration 3678, loss = 0.70935219
Iteration 3679, loss = 0.70925718
Iteration 3680, loss = 0.70915989
Iteration 3681, loss = 0.70906651
Iteration 3682, loss = 0.70897330
Iteration 3683, loss = 0.70887970
Iteration 3684, loss = 0.70878844
Iteration 3685, loss = 0.70869533
Iteration 3686, loss = 0.70860369
Iteration 3687, loss = 0.70851265
Iteration 3688, loss = 0.70842138
Iteration 3689, loss = 0.70833233
Iteration 3690, loss = 0.70824302
Iteration 3691, loss = 0.70815476
Iteration 3692, loss = 0.70806734
Iteration 3693, loss = 0.70797958
Iteration 3694, loss = 0.70789306
Iteration 3695, loss = 0.70780653
Iteration 3696, loss = 0.70772060
Iteration 3697, loss = 0.70763561
Iteration 3698, loss = 0.70755070
Iteration 3699, loss = 0.70746680
Iteration 3700, loss = 0.70738322
Iteration 3701, loss = 0.70730007
Iteration 3702, loss = 0.70721769
Iteration 3703, loss = 0.70713548
Iteration 3704, loss = 0.70705400
Iteration 3705, loss = 0.70697296
Iteration 3706, loss = 0.70689230
Iteration 3707, loss = 0.70681230
Iteration 3708, loss = 0.70673258
Iteration 3709, loss = 0.70665342
Iteration 3710, loss = 0.70657469
Iteration 3711, loss = 0.70649630
Iteration 3712, loss = 0.70641845
Iteration 3713, loss = 0.70634088
Iteration 3714, loss = 0.70626370
Iteration 3715, loss = 0.70618684
Iteration 3716, loss = 0.70611014
Iteration 3717, loss = 0.70603360
Iteration 3718, loss = 0.70595684
Iteration 3719, loss = 0.70587943
Iteration 3720, loss = 0.70580025
Iteration 3721, loss = 0.70571647
Iteration 3722, loss = 0.70562237
Iteration 3723, loss = 0.70551729
Iteration 3724, loss = 0.70542595
Iteration 3725, loss = 0.70534675
Iteration 3726, loss = 0.70520573
Iteration 3727, loss = 0.70511847
Iteration 3728, loss = 0.70504043
Iteration 3729, loss = 0.70496270
Iteration 3730, loss = 0.70492108
Iteration 3731, loss = 0.70478745
Iteration 3732, loss = 0.70456818
Iteration 3733, loss = 0.70429731
Iteration 3734, loss = 0.70399546
Iteration 3735, loss = 0.70372920
Iteration 3736, loss = 0.70322490
Iteration 3737, loss = 0.70215486
Iteration 3738, loss = 0.69399238
Iteration 3739, loss = 0.71688195
Iteration 3740, loss = 0.70635645
Iteration 3741, loss = 0.72038693
Iteration 3742, loss = 0.71521215
Iteration 3743, loss = 0.70944107
Iteration 3744, loss = 0.71752954
Iteration 3745, loss = 0.70898090
Iteration 3746, loss = 0.70844868
Iteration 3747, loss = 0.71270560
Iteration 3748, loss = 0.70563463
Iteration 3749, loss = 0.70866615
Iteration 3750, loss = 0.70977913
Iteration 3751, loss = 0.70537412
Iteration 3752, loss = 0.70915453
Iteration 3753, loss = 0.70781321
Iteration 3754, loss = 0.70555735
Iteration 3755, loss = 0.70837187
Iteration 3756, loss = 0.70608439
Iteration 3757, loss = 0.70575037
Iteration 3758, loss = 0.70736460
Iteration 3759, loss = 0.70510764
Iteration 3760, loss = 0.70565334
Iteration 3761, loss = 0.70594507
Iteration 3762, loss = 0.70428307
Iteration 3763, loss = 0.70525556
Iteration 3764, loss = 0.70489096
Iteration 3765, loss = 0.70408478
Iteration 3766, loss = 0.70497323
Iteration 3767, loss = 0.70424464
Iteration 3768, loss = 0.70397222
Iteration 3769, loss = 0.70441453
Iteration 3770, loss = 0.70363688
Iteration 3771, loss = 0.70373235
Iteration 3772, loss = 0.70381755
Iteration 3773, loss = 0.70323394
Iteration 3774, loss = 0.70347929
Iteration 3775, loss = 0.70331729
Iteration 3776, loss = 0.70296009
Iteration 3777, loss = 0.70313679
Iteration 3778, loss = 0.70282261
Iteration 3779, loss = 0.70267311
Iteration 3780, loss = 0.70278200
Iteration 3781, loss = 0.70251140
Iteration 3782, loss = 0.70250964
Iteration 3783, loss = 0.70248958
Iteration 3784, loss = 0.70225166
Iteration 3785, loss = 0.70227869
Iteration 3786, loss = 0.70218187
Iteration 3787, loss = 0.70204097
Iteration 3788, loss = 0.70206820
Iteration 3789, loss = 0.70193097
Iteration 3790, loss = 0.70184315
Iteration 3791, loss = 0.70181904
Iteration 3792, loss = 0.70167036
Iteration 3793, loss = 0.70160899
Iteration 3794, loss = 0.70152781
Iteration 3795, loss = 0.70137035
Iteration 3796, loss = 0.70127888
Iteration 3797, loss = 0.70113097
Iteration 3798, loss = 0.70098616
Iteration 3799, loss = 0.70091613
Iteration 3800, loss = 0.70080680
Iteration 3801, loss = 0.70071350
Iteration 3802, loss = 0.70061616
Iteration 3803, loss = 0.70045272
Iteration 3804, loss = 0.70028228
Iteration 3805, loss = 0.70005178
Iteration 3806, loss = 0.69980516
Iteration 3807, loss = 0.69971569
Iteration 3808, loss = 0.69967265
Iteration 3809, loss = 0.69959129
Iteration 3810, loss = 0.69946674
Iteration 3811, loss = 0.69930305
Iteration 3812, loss = 0.69916105
Iteration 3813, loss = 0.69904398
Iteration 3814, loss = 0.69892690
Iteration 3815, loss = 0.69879851
Iteration 3816, loss = 0.69862370
Iteration 3817, loss = 0.69841913
Iteration 3818, loss = 0.69822636
Iteration 3819, loss = 0.69806232
Iteration 3820, loss = 0.69794653
Iteration 3821, loss = 0.69786066
Iteration 3822, loss = 0.69777812
Iteration 3823, loss = 0.69770099
Iteration 3824, loss = 0.69761279
Iteration 3825, loss = 0.69750649
Iteration 3826, loss = 0.69740022
Iteration 3827, loss = 0.69728673
Iteration 3828, loss = 0.69714441
Iteration 3829, loss = 0.69695072
Iteration 3830, loss = 0.69669977
Iteration 3831, loss = 0.69643733
Iteration 3832, loss = 0.69620373
Iteration 3833, loss = 0.69600309
Iteration 3834, loss = 0.69581190
Iteration 3835, loss = 0.69549196
Iteration 3836, loss = 0.69483364
Iteration 3837, loss = 0.69397618
Iteration 3838, loss = 0.69314371
Iteration 3839, loss = 0.69125791
Iteration 3840, loss = 0.68970452
Iteration 3841, loss = 0.68715775
Iteration 3842, loss = 0.68369964
Iteration 3843, loss = 0.67820542
Iteration 3844, loss = 0.60265160
Iteration 3845, loss = 0.81823468
Iteration 3846, loss = 0.75978114
Iteration 3847, loss = 0.88994490
Iteration 3848, loss = 0.74510329
Iteration 3849, loss = 0.80906136
Iteration 3850, loss = 0.82114237
Iteration 3851, loss = 0.72023813
Iteration 3852, loss = 0.80533842
Iteration 3853, loss = 0.75082156
Iteration 3854, loss = 0.72896832
Iteration 3855, loss = 0.78232044
Iteration 3856, loss = 0.71804949
Iteration 3857, loss = 0.74825749
Iteration 3858, loss = 0.75629279
Iteration 3859, loss = 0.71600405
Iteration 3860, loss = 0.75527341
Iteration 3861, loss = 0.73304174
Iteration 3862, loss = 0.72445456
Iteration 3863, loss = 0.74794321
Iteration 3864, loss = 0.71964713
Iteration 3865, loss = 0.73180098
Iteration 3866, loss = 0.73497331
Iteration 3867, loss = 0.71703662
Iteration 3868, loss = 0.73359820
Iteration 3869, loss = 0.72368108
Iteration 3870, loss = 0.71973463
Iteration 3871, loss = 0.72978757
Iteration 3872, loss = 0.71739628
Iteration 3873, loss = 0.72264429
Iteration 3874, loss = 0.72389000
Iteration 3875, loss = 0.71627719
Iteration 3876, loss = 0.72357546
Iteration 3877, loss = 0.71926067
Iteration 3878, loss = 0.71786638
Iteration 3879, loss = 0.72219677
Iteration 3880, loss = 0.71684553
Iteration 3881, loss = 0.71925475
Iteration 3882, loss = 0.71950576
Iteration 3883, loss = 0.71617705
Iteration 3884, loss = 0.71917896
Iteration 3885, loss = 0.71697490
Iteration 3886, loss = 0.71638129
Iteration 3887, loss = 0.71800174
Iteration 3888, loss = 0.71556330
Iteration 3889, loss = 0.71667244
Iteration 3890, loss = 0.71659606
Iteration 3891, loss = 0.71524262
Iteration 3892, loss = 0.71654731
Iteration 3893, loss = 0.71548848
Iteration 3894, loss = 0.71534446
Iteration 3895, loss = 0.71592612
Iteration 3896, loss = 0.71481154
Iteration 3897, loss = 0.71529485
Iteration 3898, loss = 0.71507886
Iteration 3899, loss = 0.71447560
Iteration 3900, loss = 0.71494880
Iteration 3901, loss = 0.71435433
Iteration 3902, loss = 0.71429641
Iteration 3903, loss = 0.71442735
Iteration 3904, loss = 0.71389563
Iteration 3905, loss = 0.71408966
Iteration 3906, loss = 0.71388972
Iteration 3907, loss = 0.71362523
Iteration 3908, loss = 0.71376909
Iteration 3909, loss = 0.71343420
Iteration 3910, loss = 0.71339510
Iteration 3911, loss = 0.71335879
Iteration 3912, loss = 0.71308010
Iteration 3913, loss = 0.71311796
Iteration 3914, loss = 0.71294121
Iteration 3915, loss = 0.71279404
Iteration 3916, loss = 0.71278709
Iteration 3917, loss = 0.71257672
Iteration 3918, loss = 0.71252398
Iteration 3919, loss = 0.71243297
Iteration 3920, loss = 0.71226768
Iteration 3921, loss = 0.71223331
Iteration 3922, loss = 0.71208863
Iteration 3923, loss = 0.71198521
Iteration 3924, loss = 0.71191915
Iteration 3925, loss = 0.71177267
Iteration 3926, loss = 0.71170426
Iteration 3927, loss = 0.71160023
Iteration 3928, loss = 0.71148230
Iteration 3929, loss = 0.71141365
Iteration 3930, loss = 0.71129274
Iteration 3931, loss = 0.71120257
Iteration 3932, loss = 0.71111545
Iteration 3933, loss = 0.71100070
Iteration 3934, loss = 0.71092131
Iteration 3935, loss = 0.71081849
Iteration 3936, loss = 0.71071920
Iteration 3937, loss = 0.71063513
Iteration 3938, loss = 0.71052835
Iteration 3939, loss = 0.71043845
Iteration 3940, loss = 0.71033913
Iteration 3941, loss = 0.71021137
Iteration 3942, loss = 0.70987725
Iteration 3943, loss = 0.70951687
Iteration 3944, loss = 0.70971928
Iteration 3945, loss = 0.70927249
Iteration 3946, loss = 0.70888210
Iteration 3947, loss = 0.70831921
Iteration 3948, loss = 0.70925314
Iteration 3949, loss = 0.70805689
Iteration 3950, loss = 0.70803781
Iteration 3951, loss = 0.70802819
Iteration 3952, loss = 0.70770943
Iteration 3953, loss = 0.70737027
Iteration 3954, loss = 0.70733785
Iteration 3955, loss = 0.70655526
Iteration 3956, loss = 0.70741254
Iteration 3957, loss = 0.70738402
Iteration 3958, loss = 0.70660280
Iteration 3959, loss = 0.69173368
Iteration 3960, loss = 0.86406010
Iteration 3961, loss = 0.72849970
Iteration 3962, loss = 0.88742994
Iteration 3963, loss = 0.72777226
Iteration 3964, loss = 0.77702276
Iteration 3965, loss = 0.73606941
Iteration 3966, loss = 0.72865059
Iteration 3967, loss = 0.75471942
Iteration 3968, loss = 0.74574104
Iteration 3969, loss = 0.73016146
Iteration 3970, loss = 0.73870384
Iteration 3971, loss = 0.71934511
Iteration 3972, loss = 0.72004721
Iteration 3973, loss = 0.72486266
Iteration 3974, loss = 0.71404262
Iteration 3975, loss = 0.72348286
Iteration 3976, loss = 0.72183082
Iteration 3977, loss = 0.71625293
Iteration 3978, loss = 0.72302640
Iteration 3979, loss = 0.71694459
Iteration 3980, loss = 0.71600359
Iteration 3981, loss = 0.71841017
Iteration 3982, loss = 0.71319213
Iteration 3983, loss = 0.71626474
Iteration 3984, loss = 0.71565690
Iteration 3985, loss = 0.71276354
Iteration 3986, loss = 0.71546273
Iteration 3987, loss = 0.71254827
Iteration 3988, loss = 0.71196584
Iteration 3989, loss = 0.71321162
Iteration 3990, loss = 0.71084430
Iteration 3991, loss = 0.71215496
Iteration 3992, loss = 0.71199551
Iteration 3993, loss = 0.71067785
Iteration 3994, loss = 0.71189600
Iteration 3995, loss = 0.71070972
Iteration 3996, loss = 0.71032310
Iteration 3997, loss = 0.71065277
Iteration 3998, loss = 0.70939985
Iteration 3999, loss = 0.70973185
Iteration 4000, loss = 0.70952456
Iteration 4001, loss = 0.70882915
Iteration 4002, loss = 0.70928410
Iteration 4003, loss = 0.70882294
Iteration 4004, loss = 0.70874573
Iteration 4005, loss = 0.70895793
Iteration 4006, loss = 0.70839439
Iteration 4007, loss = 0.70848490
Iteration 4008, loss = 0.70834334
Iteration 4009, loss = 0.70797555
Iteration 4010, loss = 0.70808416
Iteration 4011, loss = 0.70777502
Iteration 4012, loss = 0.70766264
Iteration 4013, loss = 0.70771690
Iteration 4014, loss = 0.70746686
Iteration 4015, loss = 0.70749552
Iteration 4016, loss = 0.70739609
Iteration 4017, loss = 0.70721142
Iteration 4018, loss = 0.70722670
Iteration 4019, loss = 0.70704173
Iteration 4020, loss = 0.70693575
Iteration 4021, loss = 0.70687874
Iteration 4022, loss = 0.70670082
Iteration 4023, loss = 0.70666222
Iteration 4024, loss = 0.70656627
Iteration 4025, loss = 0.70644483
Iteration 4026, loss = 0.70640604
Iteration 4027, loss = 0.70628242
Iteration 4028, loss = 0.70620429
Iteration 4029, loss = 0.70613546
Iteration 4030, loss = 0.70601178
Iteration 4031, loss = 0.70594495
Iteration 4032, loss = 0.70584760
Iteration 4033, loss = 0.70574965
Iteration 4034, loss = 0.70568563
Iteration 4035, loss = 0.70558456
Iteration 4036, loss = 0.70550894
Iteration 4037, loss = 0.70543493
Iteration 4038, loss = 0.70534288
Iteration 4039, loss = 0.70527572
Iteration 4040, loss = 0.70519076
Iteration 4041, loss = 0.70510824
Iteration 4042, loss = 0.70503774
Iteration 4043, loss = 0.70495183
Iteration 4044, loss = 0.70487867
Iteration 4045, loss = 0.70480297
Iteration 4046, loss = 0.70472206
Iteration 4047, loss = 0.70465267
Iteration 4048, loss = 0.70457534
Iteration 4049, loss = 0.70450136
Iteration 4050, loss = 0.70443083
Iteration 4051, loss = 0.70435431
Iteration 4052, loss = 0.70428442
Iteration 4053, loss = 0.70421219
Iteration 4054, loss = 0.70413875
Iteration 4055, loss = 0.70406958
Iteration 4056, loss = 0.70399679
Iteration 4057, loss = 0.70392684
Iteration 4058, loss = 0.70385782
Iteration 4059, loss = 0.70378690
Iteration 4060, loss = 0.70371927
Iteration 4061, loss = 0.70365044
Iteration 4062, loss = 0.70358223
Iteration 4063, loss = 0.70351575
Iteration 4064, loss = 0.70344782
Iteration 4065, loss = 0.70338161
Iteration 4066, loss = 0.70331551
Iteration 4067, loss = 0.70324916
Iteration 4068, loss = 0.70318436
Iteration 4069, loss = 0.70311899
Iteration 4070, loss = 0.70305446
Iteration 4071, loss = 0.70299072
Iteration 4072, loss = 0.70292675
Iteration 4073, loss = 0.70286388
Iteration 4074, loss = 0.70280105
Iteration 4075, loss = 0.70273852
Iteration 4076, loss = 0.70267679
Iteration 4077, loss = 0.70261497
Iteration 4078, loss = 0.70255384
Iteration 4079, loss = 0.70249305
Iteration 4080, loss = 0.70243245
Iteration 4081, loss = 0.70237256
Iteration 4082, loss = 0.70231282
Iteration 4083, loss = 0.70225354
Iteration 4084, loss = 0.70219474
Iteration 4085, loss = 0.70213612
Iteration 4086, loss = 0.70207805
Iteration 4087, loss = 0.70202027
Iteration 4088, loss = 0.70196282
Iteration 4089, loss = 0.70190583
Iteration 4090, loss = 0.70184909
Iteration 4091, loss = 0.70179279
Iteration 4092, loss = 0.70173684
Iteration 4093, loss = 0.70168119
Iteration 4094, loss = 0.70162598
Iteration 4095, loss = 0.70157106
Iteration 4096, loss = 0.70151650
Iteration 4097, loss = 0.70146232
Iteration 4098, loss = 0.70140844
Iteration 4099, loss = 0.70135494
Iteration 4100, loss = 0.70130176
Iteration 4101, loss = 0.70124891
Iteration 4102, loss = 0.70119642
Iteration 4103, loss = 0.70114423
Iteration 4104, loss = 0.70109239
Iteration 4105, loss = 0.70104088
Iteration 4106, loss = 0.70098968
Iteration 4107, loss = 0.70093882
Iteration 4108, loss = 0.70088827
Iteration 4109, loss = 0.70083805
Iteration 4110, loss = 0.70078815
Iteration 4111, loss = 0.70073855
Iteration 4112, loss = 0.70068928
Iteration 4113, loss = 0.70064031
Iteration 4114, loss = 0.70059165
Iteration 4115, loss = 0.70054330
Iteration 4116, loss = 0.70049526
Iteration 4117, loss = 0.70044752
Iteration 4118, loss = 0.70040007
Iteration 4119, loss = 0.70035293
Iteration 4120, loss = 0.70030609
Iteration 4121, loss = 0.70025954
Iteration 4122, loss = 0.70021328
Iteration 4123, loss = 0.70016732
Iteration 4124, loss = 0.70012164
Iteration 4125, loss = 0.70007626
Iteration 4126, loss = 0.70003115
Iteration 4127, loss = 0.69998634
Iteration 4128, loss = 0.69994180
Iteration 4129, loss = 0.69989754
Iteration 4130, loss = 0.69985357
Iteration 4131, loss = 0.69980987
Iteration 4132, loss = 0.69976644
Iteration 4133, loss = 0.69972329
Iteration 4134, loss = 0.69968041
Iteration 4135, loss = 0.69963780
Iteration 4136, loss = 0.69959545
Iteration 4137, loss = 0.69955338
Iteration 4138, loss = 0.69951156
Iteration 4139, loss = 0.69947001
Iteration 4140, loss = 0.69942872
Iteration 4141, loss = 0.69938769
Iteration 4142, loss = 0.69934692
Iteration 4143, loss = 0.69930641
Iteration 4144, loss = 0.69926614
Iteration 4145, loss = 0.69922613
Iteration 4146, loss = 0.69918638
Iteration 4147, loss = 0.69914687
Iteration 4148, loss = 0.69910761
Iteration 4149, loss = 0.69906859
Iteration 4150, loss = 0.69902982
Iteration 4151, loss = 0.69899130
Iteration 4152, loss = 0.69895301
Iteration 4153, loss = 0.69891497
Iteration 4154, loss = 0.69887716
Iteration 4155, loss = 0.69883959
Iteration 4156, loss = 0.69880226
Iteration 4157, loss = 0.69876516
Iteration 4158, loss = 0.69872829
Iteration 4159, loss = 0.69869166
Iteration 4160, loss = 0.69865525
Iteration 4161, loss = 0.69861907
Iteration 4162, loss = 0.69858312
Iteration 4163, loss = 0.69854740
Iteration 4164, loss = 0.69851190
Iteration 4165, loss = 0.69847662
Iteration 4166, loss = 0.69844156
Iteration 4167, loss = 0.69840672
Iteration 4168, loss = 0.69837210
Iteration 4169, loss = 0.69833770
Iteration 4170, loss = 0.69830351
Iteration 4171, loss = 0.69826954
Iteration 4172, loss = 0.69823577
Iteration 4173, loss = 0.69820223
Iteration 4174, loss = 0.69816889
Iteration 4175, loss = 0.69813575
Iteration 4176, loss = 0.69810283
Iteration 4177, loss = 0.69807011
Iteration 4178, loss = 0.69803760
Iteration 4179, loss = 0.69800529
Iteration 4180, loss = 0.69797319
Iteration 4181, loss = 0.69794128
Iteration 4182, loss = 0.69790957
Iteration 4183, loss = 0.69787806
Iteration 4184, loss = 0.69784675
Iteration 4185, loss = 0.69781564
Iteration 4186, loss = 0.69778472
Iteration 4187, loss = 0.69775399
Iteration 4188, loss = 0.69772345
Iteration 4189, loss = 0.69769311
Iteration 4190, loss = 0.69766296
Iteration 4191, loss = 0.69763299
Iteration 4192, loss = 0.69760321
Iteration 4193, loss = 0.69757362
Iteration 4194, loss = 0.69754421
Iteration 4195, loss = 0.69751498
Iteration 4196, loss = 0.69748594
Iteration 4197, loss = 0.69745708
Iteration 4198, loss = 0.69742840
Iteration 4199, loss = 0.69739989
Iteration 4200, loss = 0.69737157
Iteration 4201, loss = 0.69734342
Iteration 4202, loss = 0.69731545
Iteration 4203, loss = 0.69728765
Iteration 4204, loss = 0.69726002
Iteration 4205, loss = 0.69723257
Iteration 4206, loss = 0.69720528
Iteration 4207, loss = 0.69717817
Iteration 4208, loss = 0.69715123
Iteration 4209, loss = 0.69712445
Iteration 4210, loss = 0.69709784
Iteration 4211, loss = 0.69707139
Iteration 4212, loss = 0.69704511
Iteration 4213, loss = 0.69701899
Iteration 4214, loss = 0.69699303
Iteration 4215, loss = 0.69696724
Iteration 4216, loss = 0.69694160
Iteration 4217, loss = 0.69691613
Iteration 4218, loss = 0.69689081
Iteration 4219, loss = 0.69686564
Iteration 4220, loss = 0.69684063
Iteration 4221, loss = 0.69681578
Iteration 4222, loss = 0.69679108
Iteration 4223, loss = 0.69676653
Iteration 4224, loss = 0.69674214
Iteration 4225, loss = 0.69671789
Iteration 4226, loss = 0.69669380
Iteration 4227, loss = 0.69666985
Iteration 4228, loss = 0.69664605
Iteration 4229, loss = 0.69662239
Iteration 4230, loss = 0.69659888
Iteration 4231, loss = 0.69657551
Iteration 4232, loss = 0.69655229
Iteration 4233, loss = 0.69652921
Iteration 4234, loss = 0.69650627
Iteration 4235, loss = 0.69648347
Iteration 4236, loss = 0.69646081
Iteration 4237, loss = 0.69643828
Iteration 4238, loss = 0.69641590
Iteration 4239, loss = 0.69639365
Iteration 4240, loss = 0.69637153
Iteration 4241, loss = 0.69634955
Iteration 4242, loss = 0.69632770
Iteration 4243, loss = 0.69630598
Iteration 4244, loss = 0.69628439
Iteration 4245, loss = 0.69626293
Iteration 4246, loss = 0.69624160
Iteration 4247, loss = 0.69622039
Iteration 4248, loss = 0.69619931
Iteration 4249, loss = 0.69617834
Iteration 4250, loss = 0.69615749
Iteration 4251, loss = 0.69613675
Iteration 4252, loss = 0.69611609
Iteration 4253, loss = 0.69609545
Iteration 4254, loss = 0.69607465
Iteration 4255, loss = 0.69605264
Iteration 4256, loss = 0.69601490
Iteration 4257, loss = 0.69578354
Iteration 4258, loss = 0.69626417
Iteration 4259, loss = 0.69224695
Iteration 4260, loss = 0.69763411
Iteration 4261, loss = 0.69784881
Iteration 4262, loss = 0.69770551
Iteration 4263, loss = 0.69674126
Iteration 4264, loss = 0.69430377
Iteration 4265, loss = 0.68652497
Iteration 4266, loss = 0.69675347
Iteration 4267, loss = 0.79003505
Iteration 4268, loss = 0.74941667
Iteration 4269, loss = 0.73730641
Iteration 4270, loss = 0.77793569
Iteration 4271, loss = 0.70569504
Iteration 4272, loss = 0.74695933
Iteration 4273, loss = 0.72913614
Iteration 4274, loss = 0.70817196
Iteration 4275, loss = 0.73369197
Iteration 4276, loss = 0.70546129
Iteration 4277, loss = 0.71280306
Iteration 4278, loss = 0.72262703
Iteration 4279, loss = 0.69935116
Iteration 4280, loss = 0.71105706
Iteration 4281, loss = 0.70227232
Iteration 4282, loss = 0.71161345
Iteration 4283, loss = 0.71630173
Iteration 4284, loss = 0.72431571
Iteration 4285, loss = 0.74275296
Iteration 4286, loss = 0.71965083
Iteration 4287, loss = 0.79698495
Iteration 4288, loss = 0.72593245
Iteration 4289, loss = 0.72743987
Iteration 4290, loss = 0.76633020
Iteration 4291, loss = 0.70631067
Iteration 4292, loss = 0.72826471
Iteration 4293, loss = 0.74561892
Iteration 4294, loss = 0.70300707
Iteration 4295, loss = 0.72817662
Iteration 4296, loss = 0.72586088
Iteration 4297, loss = 0.69964775
Iteration 4298, loss = 0.72517690
Iteration 4299, loss = 0.71576350
Iteration 4300, loss = 0.70194229
Iteration 4301, loss = 0.71950290
Iteration 4302, loss = 0.70577717
Iteration 4303, loss = 0.70067805
Iteration 4304, loss = 0.71278544
Iteration 4305, loss = 0.70023215
Iteration 4306, loss = 0.70155252
Iteration 4307, loss = 0.70708148
Iteration 4308, loss = 0.69654045
Iteration 4309, loss = 0.70046070
Iteration 4310, loss = 0.70304640
Iteration 4311, loss = 0.69397615
Iteration 4312, loss = 0.69838045
Iteration 4313, loss = 0.69623266
Iteration 4314, loss = 0.68888978
Iteration 4315, loss = 0.68046336
Iteration 4316, loss = 0.91606364
Iteration 4317, loss = 0.71015836
Iteration 4318, loss = 0.91962862
Iteration 4319, loss = 0.80814054
Iteration 4320, loss = 0.76346806
Iteration 4321, loss = 0.87631106
Iteration 4322, loss = 0.73042710
Iteration 4323, loss = 0.77812066
Iteration 4324, loss = 0.78825986
Iteration 4325, loss = 0.58783153
Iteration 4326, loss = 1.09913574
Iteration 4327, loss = 1.04170844
Iteration 4328, loss = 0.71165537
Iteration 4329, loss = 0.99433920
Iteration 4330, loss = 0.95920230
Iteration 4331, loss = 0.71346216
Iteration 4332, loss = 0.91670841
Iteration 4333, loss = 0.90018507
Iteration 4334, loss = 0.70483094
Iteration 4335, loss = 0.85114191
Iteration 4336, loss = 0.83625877
Iteration 4337, loss = 0.69639737
Iteration 4338, loss = 0.80519952
Iteration 4339, loss = 0.78705291
Iteration 4340, loss = 0.68790266
Iteration 4341, loss = 1.46548556
Iteration 4342, loss = 0.73765067
Iteration 4343, loss = 0.87560863
Iteration 4344, loss = 0.81561761
Iteration 4345, loss = 0.79387446
Iteration 4346, loss = 0.86373445
Iteration 4347, loss = 0.66475069
Iteration 4348, loss = 0.86527557
Iteration 4349, loss = 0.83231545
Iteration 4350, loss = 0.87815740
Iteration 4351, loss = 0.89152587
Iteration 4352, loss = 0.85261740
Iteration 4353, loss = 0.87046524
Iteration 4354, loss = 0.86144816
Iteration 4355, loss = 0.81882427
Iteration 4356, loss = 0.82318519
Iteration 4357, loss = 0.80991039
Iteration 4358, loss = 0.77827194
Iteration 4359, loss = 0.78490344
Iteration 4360, loss = 0.77716868
Iteration 4361, loss = 0.76005436
Iteration 4362, loss = 0.77033745
Iteration 4363, loss = 0.76777905
Iteration 4364, loss = 0.75901668
Iteration 4365, loss = 0.76876676
Iteration 4366, loss = 0.76692923
Iteration 4367, loss = 0.76098702
Iteration 4368, loss = 0.76701927
Iteration 4369, loss = 0.76245800
Iteration 4370, loss = 0.75660981
Iteration 4371, loss = 0.75964296
Iteration 4372, loss = 0.75496745
Iteration 4373, loss = 0.75071889
Iteration 4374, loss = 0.75289030
Iteration 4375, loss = 0.74974892
Iteration 4376, loss = 0.74807680
Iteration 4377, loss = 0.75059720
Iteration 4378, loss = 0.74860872
Iteration 4379, loss = 0.74799857
Iteration 4380, loss = 0.74982308
Iteration 4381, loss = 0.74808232
Iteration 4382, loss = 0.74764985
Iteration 4383, loss = 0.74855010
Iteration 4384, loss = 0.74677335
Iteration 4385, loss = 0.74624064
Iteration 4386, loss = 0.74648215
Iteration 4387, loss = 0.74499770
Iteration 4388, loss = 0.74478941
Iteration 4389, loss = 0.74492306
Iteration 4390, loss = 0.74380655
Iteration 4391, loss = 0.74373995
Iteration 4392, loss = 0.74375037
Iteration 4393, loss = 0.74293981
Iteration 4394, loss = 0.74298834
Iteration 4395, loss = 0.74296234
Iteration 4396, loss = 0.74241564
Iteration 4397, loss = 0.74253395
Iteration 4398, loss = 0.74248086
Iteration 4399, loss = 0.74208738
Iteration 4400, loss = 0.74215298
Iteration 4401, loss = 0.74198637
Iteration 4402, loss = 0.74162549
Iteration 4403, loss = 0.74161713
Iteration 4404, loss = 0.74141591
Iteration 4405, loss = 0.74114198
Iteration 4406, loss = 0.74111994
Iteration 4407, loss = 0.74092042
Iteration 4408, loss = 0.74070106
Iteration 4409, loss = 0.74064655
Iteration 4410, loss = 0.74044293
Iteration 4411, loss = 0.74025923
Iteration 4412, loss = 0.74018776
Iteration 4413, loss = 0.74000674
Iteration 4414, loss = 0.73986957
Iteration 4415, loss = 0.73980084
Iteration 4416, loss = 0.73964401
Iteration 4417, loss = 0.73952642
Iteration 4418, loss = 0.73943814
Iteration 4419, loss = 0.73928359
Iteration 4420, loss = 0.73917007
Iteration 4421, loss = 0.73907020
Iteration 4422, loss = 0.73892671
Iteration 4423, loss = 0.73881926
Iteration 4424, loss = 0.73871146
Iteration 4425, loss = 0.73857420
Iteration 4426, loss = 0.73846652
Iteration 4427, loss = 0.73835321
Iteration 4428, loss = 0.73822427
Iteration 4429, loss = 0.73812036
Iteration 4430, loss = 0.73800911
Iteration 4431, loss = 0.73789039
Iteration 4432, loss = 0.73778930
Iteration 4433, loss = 0.73767852
Iteration 4434, loss = 0.73756425
Iteration 4435, loss = 0.73746167
Iteration 4436, loss = 0.73735043
Iteration 4437, loss = 0.73723984
Iteration 4438, loss = 0.73713752
Iteration 4439, loss = 0.73702840
Iteration 4440, loss = 0.73692173
Iteration 4441, loss = 0.73681983
Iteration 4442, loss = 0.73671240
Iteration 4443, loss = 0.73660793
Iteration 4444, loss = 0.73650594
Iteration 4445, loss = 0.73640014
Iteration 4446, loss = 0.73629758
Iteration 4447, loss = 0.73619618
Iteration 4448, loss = 0.73609239
Iteration 4449, loss = 0.73599150
Iteration 4450, loss = 0.73589077
Iteration 4451, loss = 0.73578866
Iteration 4452, loss = 0.73568900
Iteration 4453, loss = 0.73558912
Iteration 4454, loss = 0.73548882
Iteration 4455, loss = 0.73539054
Iteration 4456, loss = 0.73529192
Iteration 4457, loss = 0.73519338
Iteration 4458, loss = 0.73509631
Iteration 4459, loss = 0.73499879
Iteration 4460, loss = 0.73490163
Iteration 4461, loss = 0.73480549
Iteration 4462, loss = 0.73470904
Iteration 4463, loss = 0.73461315
Iteration 4464, loss = 0.73451802
Iteration 4465, loss = 0.73442274
Iteration 4466, loss = 0.73432811
Iteration 4467, loss = 0.73423400
Iteration 4468, loss = 0.73413989
Iteration 4469, loss = 0.73404642
Iteration 4470, loss = 0.73395335
Iteration 4471, loss = 0.73386042
Iteration 4472, loss = 0.73376810
Iteration 4473, loss = 0.73367610
Iteration 4474, loss = 0.73358434
Iteration 4475, loss = 0.73349312
Iteration 4476, loss = 0.73340216
Iteration 4477, loss = 0.73331149
Iteration 4478, loss = 0.73322130
Iteration 4479, loss = 0.73313135
Iteration 4480, loss = 0.73304175
Iteration 4481, loss = 0.73295257
Iteration 4482, loss = 0.73286365
Iteration 4483, loss = 0.73277509
Iteration 4484, loss = 0.73268691
Iteration 4485, loss = 0.73259899
Iteration 4486, loss = 0.73251145
Iteration 4487, loss = 0.73242424
Iteration 4488, loss = 0.73233731
Iteration 4489, loss = 0.73225075
Iteration 4490, loss = 0.73216451
Iteration 4491, loss = 0.73207857
Iteration 4492, loss = 0.73199298
Iteration 4493, loss = 0.73190769
Iteration 4494, loss = 0.73182270
Iteration 4495, loss = 0.73173805
Iteration 4496, loss = 0.73165370
Iteration 4497, loss = 0.73156965
Iteration 4498, loss = 0.73148592
Iteration 4499, loss = 0.73140248
Iteration 4500, loss = 0.73131935
Iteration 4501, loss = 0.73123653
Iteration 4502, loss = 0.73115399
Iteration 4503, loss = 0.73107176
Iteration 4504, loss = 0.73098982
Iteration 4505, loss = 0.73090817
Iteration 4506, loss = 0.73082682
Iteration 4507, loss = 0.73074576
Iteration 4508, loss = 0.73066498
Iteration 4509, loss = 0.73058449
Iteration 4510, loss = 0.73050428
Iteration 4511, loss = 0.73042435
Iteration 4512, loss = 0.73034471
Iteration 4513, loss = 0.73026535
Iteration 4514, loss = 0.73018626
Iteration 4515, loss = 0.73010745
Iteration 4516, loss = 0.73002891
Iteration 4517, loss = 0.72995065
Iteration 4518, loss = 0.72987265
Iteration 4519, loss = 0.72979493
Iteration 4520, loss = 0.72971747
Iteration 4521, loss = 0.72964028
Iteration 4522, loss = 0.72956335
Iteration 4523, loss = 0.72948668
Iteration 4524, loss = 0.72941028
Iteration 4525, loss = 0.72933413
Iteration 4526, loss = 0.72925824
Iteration 4527, loss = 0.72918261
Iteration 4528, loss = 0.72910724
Iteration 4529, loss = 0.72903211
Iteration 4530, loss = 0.72895724
Iteration 4531, loss = 0.72888262
Iteration 4532, loss = 0.72880825
Iteration 4533, loss = 0.72873413
Iteration 4534, loss = 0.72866025
Iteration 4535, loss = 0.72858662
Iteration 4536, loss = 0.72851323
Iteration 4537, loss = 0.72844008
Iteration 4538, loss = 0.72836717
Iteration 4539, loss = 0.72829450
Iteration 4540, loss = 0.72822207
Iteration 4541, loss = 0.72814988
Iteration 4542, loss = 0.72807792
Iteration 4543, loss = 0.72800619
Iteration 4544, loss = 0.72793470
Iteration 4545, loss = 0.72786344
Iteration 4546, loss = 0.72779241
Iteration 4547, loss = 0.72772160
Iteration 4548, loss = 0.72765103
Iteration 4549, loss = 0.72758068
Iteration 4550, loss = 0.72751055
Iteration 4551, loss = 0.72744065
Iteration 4552, loss = 0.72737097
Iteration 4553, loss = 0.72730152
Iteration 4554, loss = 0.72723228
Iteration 4555, loss = 0.72716326
Iteration 4556, loss = 0.72709446
Iteration 4557, loss = 0.72702588
Iteration 4558, loss = 0.72695751
Iteration 4559, loss = 0.72688935
Iteration 4560, loss = 0.72682141
Iteration 4561, loss = 0.72675368
Iteration 4562, loss = 0.72668616
Iteration 4563, loss = 0.72661885
Iteration 4564, loss = 0.72655175
Iteration 4565, loss = 0.72648486
Iteration 4566, loss = 0.72641817
Iteration 4567, loss = 0.72635169
Iteration 4568, loss = 0.72628541
Iteration 4569, loss = 0.72621933
Iteration 4570, loss = 0.72615346
Iteration 4571, loss = 0.72608779
Iteration 4572, loss = 0.72602232
Iteration 4573, loss = 0.72595705
Iteration 4574, loss = 0.72589197
Iteration 4575, loss = 0.72582709
Iteration 4576, loss = 0.72576241
Iteration 4577, loss = 0.72569793
Iteration 4578, loss = 0.72563363
Iteration 4579, loss = 0.72556953
Iteration 4580, loss = 0.72550563
Iteration 4581, loss = 0.72544191
Iteration 4582, loss = 0.72537838
Iteration 4583, loss = 0.72531505
Iteration 4584, loss = 0.72525190
Iteration 4585, loss = 0.72518894
Iteration 4586, loss = 0.72512616
Iteration 4587, loss = 0.72506357
Iteration 4588, loss = 0.72500116
Iteration 4589, loss = 0.72493894
Iteration 4590, loss = 0.72487690
Iteration 4591, loss = 0.72481504
Iteration 4592, loss = 0.72475336
Iteration 4593, loss = 0.72469186
Iteration 4594, loss = 0.72463053
Iteration 4595, loss = 0.72456938
Iteration 4596, loss = 0.72450840
Iteration 4597, loss = 0.72444758
Iteration 4598, loss = 0.72438691
Iteration 4599, loss = 0.72432636
Iteration 4600, loss = 0.72426578
Iteration 4601, loss = 0.72420442
Iteration 4602, loss = 0.72412733
Iteration 4603, loss = 0.72328954
Iteration 4604, loss = 0.72065420
Iteration 4605, loss = 0.72580993
Iteration 4606, loss = 0.72598997
Iteration 4607, loss = 0.72628672
Iteration 4608, loss = 0.72492983
Iteration 4609, loss = 0.72421636
Iteration 4610, loss = 0.71326007
Iteration 4611, loss = 0.75893661
Iteration 4612, loss = 0.73069064
Iteration 4613, loss = 0.74014581
Iteration 4614, loss = 0.74784271
Iteration 4615, loss = 0.72501382
Iteration 4616, loss = 0.73892859
Iteration 4617, loss = 0.73656845
Iteration 4618, loss = 0.72495791
Iteration 4619, loss = 0.73870957
Iteration 4620, loss = 0.73086069
Iteration 4621, loss = 0.72691961
Iteration 4622, loss = 0.73519686
Iteration 4623, loss = 0.72589076
Iteration 4624, loss = 0.72758178
Iteration 4625, loss = 0.73134145
Iteration 4626, loss = 0.72421352
Iteration 4627, loss = 0.72825444
Iteration 4628, loss = 0.72801580
Iteration 4629, loss = 0.72368457
Iteration 4630, loss = 0.72773980
Iteration 4631, loss = 0.72554388
Iteration 4632, loss = 0.72409025
Iteration 4633, loss = 0.72690340
Iteration 4634, loss = 0.72404669
Iteration 4635, loss = 0.72430106
Iteration 4636, loss = 0.72546616
Iteration 4637, loss = 0.72311610
Iteration 4638, loss = 0.72431800
Iteration 4639, loss = 0.72433128
Iteration 4640, loss = 0.72295303
Iteration 4641, loss = 0.72419457
Iteration 4642, loss = 0.72343801
Iteration 4643, loss = 0.72288225
Iteration 4644, loss = 0.72369581
Iteration 4645, loss = 0.72274705
Iteration 4646, loss = 0.72282260
Iteration 4647, loss = 0.72316347
Iteration 4648, loss = 0.72239906
Iteration 4649, loss = 0.72275248
Iteration 4650, loss = 0.72267620
Iteration 4651, loss = 0.72219905
Iteration 4652, loss = 0.72254376
Iteration 4653, loss = 0.72223955
Iteration 4654, loss = 0.72205573
Iteration 4655, loss = 0.72227033
Iteration 4656, loss = 0.72192481
Iteration 4657, loss = 0.72193284
Iteration 4658, loss = 0.72197512
Iteration 4659, loss = 0.72169179
Iteration 4660, loss = 0.72177442
Iteration 4661, loss = 0.72168875
Iteration 4662, loss = 0.72151514
Iteration 4663, loss = 0.72158889
Iteration 4664, loss = 0.72143980
Iteration 4665, loss = 0.72135893
Iteration 4666, loss = 0.72137724
Iteration 4667, loss = 0.72122254
Iteration 4668, loss = 0.72119903
Iteration 4669, loss = 0.72116189
Iteration 4670, loss = 0.72103902
Iteration 4671, loss = 0.72103378
Iteration 4672, loss = 0.72095765
Iteration 4673, loss = 0.72087249
Iteration 4674, loss = 0.72085601
Iteration 4675, loss = 0.72076439
Iteration 4676, loss = 0.72070949
Iteration 4677, loss = 0.72067293
Iteration 4678, loss = 0.72058647
Iteration 4679, loss = 0.72054758
Iteration 4680, loss = 0.72049276
Iteration 4681, loss = 0.72041977
Iteration 4682, loss = 0.72038261
Iteration 4683, loss = 0.72031731
Iteration 4684, loss = 0.72025803
Iteration 4685, loss = 0.72021505
Iteration 4686, loss = 0.72014819
Iteration 4687, loss = 0.72009824
Iteration 4688, loss = 0.72004801
Iteration 4689, loss = 0.71998545
Iteration 4690, loss = 0.71993915
Iteration 4691, loss = 0.71988373
Iteration 4692, loss = 0.71982696
Iteration 4693, loss = 0.71977982
Iteration 4694, loss = 0.71972254
Iteration 4695, loss = 0.71967056
Iteration 4696, loss = 0.71962102
Iteration 4697, loss = 0.71956495
Iteration 4698, loss = 0.71951569
Iteration 4699, loss = 0.71946403
Iteration 4700, loss = 0.71941045
Iteration 4701, loss = 0.71936177
Iteration 4702, loss = 0.71930917
Iteration 4703, loss = 0.71925800
Iteration 4704, loss = 0.71920882
Iteration 4705, loss = 0.71915661
Iteration 4706, loss = 0.71910714
Iteration 4707, loss = 0.71905733
Iteration 4708, loss = 0.71900630
Iteration 4709, loss = 0.71895761
Iteration 4710, loss = 0.71890755
Iteration 4711, loss = 0.71885783
Iteration 4712, loss = 0.71880933
Iteration 4713, loss = 0.71875956
Iteration 4714, loss = 0.71871090
Iteration 4715, loss = 0.71866241
Iteration 4716, loss = 0.71861333
Iteration 4717, loss = 0.71856536
Iteration 4718, loss = 0.71851698
Iteration 4719, loss = 0.71846872
Iteration 4720, loss = 0.71842114
Iteration 4721, loss = 0.71837310
Iteration 4722, loss = 0.71832556
Iteration 4723, loss = 0.71827824
Iteration 4724, loss = 0.71823071
Iteration 4725, loss = 0.71818374
Iteration 4726, loss = 0.71813672
Iteration 4727, loss = 0.71808978
Iteration 4728, loss = 0.71804323
Iteration 4729, loss = 0.71799657
Iteration 4730, loss = 0.71795018
Iteration 4731, loss = 0.71790400
Iteration 4732, loss = 0.71785778
Iteration 4733, loss = 0.71781188
Iteration 4734, loss = 0.71776604
Iteration 4735, loss = 0.71772031
Iteration 4736, loss = 0.71767482
Iteration 4737, loss = 0.71762936
Iteration 4738, loss = 0.71758408
Iteration 4739, loss = 0.71753897
Iteration 4740, loss = 0.71749392
Iteration 4741, loss = 0.71744908
Iteration 4742, loss = 0.71740433
Iteration 4743, loss = 0.71735970
Iteration 4744, loss = 0.71731524
Iteration 4745, loss = 0.71727087
Iteration 4746, loss = 0.71722665
Iteration 4747, loss = 0.71718256
Iteration 4748, loss = 0.71713857
Iteration 4749, loss = 0.71709473
Iteration 4750, loss = 0.71705101
Iteration 4751, loss = 0.71700739
Iteration 4752, loss = 0.71696393
Iteration 4753, loss = 0.71692056
Iteration 4754, loss = 0.71687732
Iteration 4755, loss = 0.71683420
Iteration 4756, loss = 0.71679119
Iteration 4757, loss = 0.71674830
Iteration 4758, loss = 0.71670553
Iteration 4759, loss = 0.71666287
Iteration 4760, loss = 0.71662033
Iteration 4761, loss = 0.71657789
Iteration 4762, loss = 0.71653557
Iteration 4763, loss = 0.71649336
Iteration 4764, loss = 0.71645126
Iteration 4765, loss = 0.71640927
Iteration 4766, loss = 0.71636738
Iteration 4767, loss = 0.71632561
Iteration 4768, loss = 0.71628393
Iteration 4769, loss = 0.71624236
Iteration 4770, loss = 0.71620090
Iteration 4771, loss = 0.71615954
Iteration 4772, loss = 0.71611828
Iteration 4773, loss = 0.71607712
Iteration 4774, loss = 0.71603605
Iteration 4775, loss = 0.71599509
Iteration 4776, loss = 0.71595422
Iteration 4777, loss = 0.71591345
Iteration 4778, loss = 0.71587278
Iteration 4779, loss = 0.71583219
Iteration 4780, loss = 0.71579170
Iteration 4781, loss = 0.71575131
Iteration 4782, loss = 0.71571100
Iteration 4783, loss = 0.71567078
Iteration 4784, loss = 0.71563065
Iteration 4785, loss = 0.71559060
Iteration 4786, loss = 0.71555064
Iteration 4787, loss = 0.71551076
Iteration 4788, loss = 0.71547097
Iteration 4789, loss = 0.71543126
Iteration 4790, loss = 0.71539163
Iteration 4791, loss = 0.71535207
Iteration 4792, loss = 0.71531260
Iteration 4793, loss = 0.71527319
Iteration 4794, loss = 0.71523387
Iteration 4795, loss = 0.71519462
Iteration 4796, loss = 0.71515543
Iteration 4797, loss = 0.71511632
Iteration 4798, loss = 0.71507728
Iteration 4799, loss = 0.71503830
Iteration 4800, loss = 0.71499940
Iteration 4801, loss = 0.71496055
Iteration 4802, loss = 0.71492177
Iteration 4803, loss = 0.71488305
Iteration 4804, loss = 0.71484439
Iteration 4805, loss = 0.71480579
Iteration 4806, loss = 0.71476725
Iteration 4807, loss = 0.71472876
Iteration 4808, loss = 0.71469033
Iteration 4809, loss = 0.71465195
Iteration 4810, loss = 0.71461362
Iteration 4811, loss = 0.71457534
Iteration 4812, loss = 0.71453711
Iteration 4813, loss = 0.71449893
Iteration 4814, loss = 0.71446080
Iteration 4815, loss = 0.71442271
Iteration 4816, loss = 0.71438466
Iteration 4817, loss = 0.71434666
Iteration 4818, loss = 0.71430869
Iteration 4819, loss = 0.71427076
Iteration 4820, loss = 0.71423287
Iteration 4821, loss = 0.71419502
Iteration 4822, loss = 0.71415719
Iteration 4823, loss = 0.71411939
Iteration 4824, loss = 0.71408163
Iteration 4825, loss = 0.71404388
Iteration 4826, loss = 0.71400616
Iteration 4827, loss = 0.71396845
Iteration 4828, loss = 0.71393076
Iteration 4829, loss = 0.71389308
Iteration 4830, loss = 0.71385540
Iteration 4831, loss = 0.71381773
Iteration 4832, loss = 0.71378005
Iteration 4833, loss = 0.71374236
Iteration 4834, loss = 0.71370465
Iteration 4835, loss = 0.71366692
Iteration 4836, loss = 0.71362916
Iteration 4837, loss = 0.71359136
Iteration 4838, loss = 0.71355350
Iteration 4839, loss = 0.71351558
Iteration 4840, loss = 0.71347759
Iteration 4841, loss = 0.71343951
Iteration 4842, loss = 0.71340133
Iteration 4843, loss = 0.71336303
Iteration 4844, loss = 0.71332460
Iteration 4845, loss = 0.71328601
Iteration 4846, loss = 0.71324724
Iteration 4847, loss = 0.71320827
Iteration 4848, loss = 0.71316908
Iteration 4849, loss = 0.71312963
Iteration 4850, loss = 0.71308992
Iteration 4851, loss = 0.71304989
Iteration 4852, loss = 0.71300953
Iteration 4853, loss = 0.71296881
Iteration 4854, loss = 0.71292771
Iteration 4855, loss = 0.71288618
Iteration 4856, loss = 0.71284420
Iteration 4857, loss = 0.71280173
Iteration 4858, loss = 0.71275871
Iteration 4859, loss = 0.71271496
Iteration 4860, loss = 0.71266969
Iteration 4861, loss = 0.71260960
Iteration 4862, loss = 0.71405284
Iteration 4863, loss = 0.71692791
Iteration 4864, loss = 0.72102649
Iteration 4865, loss = 0.72495304
Iteration 4866, loss = 0.72710226
Iteration 4867, loss = 0.72415321
Iteration 4868, loss = 0.72171367
Iteration 4869, loss = 0.71860669
Iteration 4870, loss = 0.71638662
Iteration 4871, loss = 0.71665109
Iteration 4872, loss = 0.71633476
Iteration 4873, loss = 0.71724798
Iteration 4874, loss = 0.71779921
Iteration 4875, loss = 0.71747211
Iteration 4876, loss = 0.71771038
Iteration 4877, loss = 0.71701028
Iteration 4878, loss = 0.71667447
Iteration 4879, loss = 0.71650870
Iteration 4880, loss = 0.71600995
Iteration 4881, loss = 0.71615633
Iteration 4882, loss = 0.71592972
Iteration 4883, loss = 0.71575299
Iteration 4884, loss = 0.71571502
Iteration 4885, loss = 0.71530235
Iteration 4886, loss = 0.71521341
Iteration 4887, loss = 0.71501690
Iteration 4888, loss = 0.71485800
Iteration 4889, loss = 0.71492189
Iteration 4890, loss = 0.71477264
Iteration 4891, loss = 0.71474070
Iteration 4892, loss = 0.71459785
Iteration 4893, loss = 0.71433945
Iteration 4894, loss = 0.71419323
Iteration 4895, loss = 0.71394679
Iteration 4896, loss = 0.71382043
Iteration 4897, loss = 0.71373920
Iteration 4898, loss = 0.71361573
Iteration 4899, loss = 0.71356093
Iteration 4900, loss = 0.71340359
Iteration 4901, loss = 0.71323595
Iteration 4902, loss = 0.71306359
Iteration 4903, loss = 0.71284636
Iteration 4904, loss = 0.71269688
Iteration 4905, loss = 0.71253777
Iteration 4906, loss = 0.71240379
Iteration 4907, loss = 0.71230013
Iteration 4908, loss = 0.71217246
Iteration 4909, loss = 0.71207145
Iteration 4910, loss = 0.71193956
Iteration 4911, loss = 0.71178742
Iteration 4912, loss = 0.71165341
Iteration 4913, loss = 0.71152238
Iteration 4914, loss = 0.71142517
Iteration 4915, loss = 0.71132339
Iteration 4916, loss = 0.71119899
Iteration 4917, loss = 0.71105586
Iteration 4918, loss = 0.71087066
Iteration 4919, loss = 0.71067020
Iteration 4920, loss = 0.71046308
Iteration 4921, loss = 0.71026686
Iteration 4922, loss = 0.71010056
Iteration 4923, loss = 0.70994341
Iteration 4924, loss = 0.70979976
Iteration 4925, loss = 0.70966680
Iteration 4926, loss = 0.70954149
Iteration 4927, loss = 0.70943237
Iteration 4928, loss = 0.70932940
Iteration 4929, loss = 0.70922428
Iteration 4930, loss = 0.70909975
Iteration 4931, loss = 0.70895374
Iteration 4932, loss = 0.70879521
Iteration 4933, loss = 0.70858989
Iteration 4934, loss = 0.70828769
Iteration 4935, loss = 0.70792000
Iteration 4936, loss = 0.70767473
Iteration 4937, loss = 0.70755570
Iteration 4938, loss = 0.70740751
Iteration 4939, loss = 0.70717752
Iteration 4940, loss = 0.70686113
Iteration 4941, loss = 0.70637942
Iteration 4942, loss = 0.70560299
Iteration 4943, loss = 0.70459301
Iteration 4944, loss = 0.70408466
Iteration 4945, loss = 0.70363051
Iteration 4946, loss = 0.70306822
Iteration 4947, loss = 0.70253237
Iteration 4948, loss = 0.70133927
Iteration 4949, loss = 0.70034759
Iteration 4950, loss = 0.69936155
Iteration 4951, loss = 0.69791326
Iteration 4952, loss = 0.69454968
Iteration 4953, loss = 0.69067560
Iteration 4954, loss = 0.68190547
Iteration 4955, loss = 0.85374628
Iteration 4956, loss = 0.99395090
Iteration 4957, loss = 0.91308499
Iteration 4958, loss = 0.77437176
Iteration 4959, loss = 0.98822161
Iteration 4960, loss = 0.84665665
Iteration 4961, loss = 0.81808315
Iteration 4962, loss = 0.93454617
Iteration 4963, loss = 0.78424843
Iteration 4964, loss = 0.82189820
Iteration 4965, loss = 0.86089403
Iteration 4966, loss = 0.74170955
Iteration 4967, loss = 0.80716383
Iteration 4968, loss = 0.79564950
Iteration 4969, loss = 0.72584555
Iteration 4970, loss = 0.79012105
Iteration 4971, loss = 0.75393183
Iteration 4972, loss = 0.72971630
Iteration 4973, loss = 0.77568967
Iteration 4974, loss = 0.73343600
Iteration 4975, loss = 0.73965598
Iteration 4976, loss = 0.76248526
Iteration 4977, loss = 0.72690950
Iteration 4978, loss = 0.74635842
Iteration 4979, loss = 0.74884129
Iteration 4980, loss = 0.72578760
Iteration 4981, loss = 0.74583450
Iteration 4982, loss = 0.73594530
Iteration 4983, loss = 0.72607615
Iteration 4984, loss = 0.74045733
Iteration 4985, loss = 0.72664720
Iteration 4986, loss = 0.72679260
Iteration 4987, loss = 0.73381909
Iteration 4988, loss = 0.72185986
Iteration 4989, loss = 0.72718498
Iteration 4990, loss = 0.72791670
Iteration 4991, loss = 0.72037505
Iteration 4992, loss = 0.72661734
Iteration 4993, loss = 0.72351662
Iteration 4994, loss = 0.72055765
Iteration 4995, loss = 0.72527973
Iteration 4996, loss = 0.72106595
Iteration 4997, loss = 0.72144752
Iteration 4998, loss = 0.72372547
Iteration 4999, loss = 0.72005983
Iteration 5000, loss = 0.72192649
