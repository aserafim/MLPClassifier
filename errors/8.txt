Iteration 1, loss = 0.70848806
Iteration 2, loss = 2.03908142
Iteration 3, loss = 0.98870048
Iteration 4, loss = 0.80255299
Iteration 5, loss = 0.89288205
Iteration 6, loss = 1.03569081
Iteration 7, loss = 1.03400113
Iteration 8, loss = 0.88049331
Iteration 9, loss = 0.75411917
Iteration 10, loss = 0.73953524
Iteration 11, loss = 1.13476686
Iteration 12, loss = 0.72555029
Iteration 13, loss = 0.77640817
Iteration 14, loss = 0.76069452
Iteration 15, loss = 0.77784428
Iteration 16, loss = 0.81994454
Iteration 17, loss = 0.88288148
Iteration 18, loss = 0.76630431
Iteration 19, loss = 0.83058907
Iteration 20, loss = 0.78599840
Iteration 21, loss = 0.74024021
Iteration 22, loss = 0.77012865
Iteration 23, loss = 0.79342753
Iteration 24, loss = 0.68541296
Iteration 25, loss = 0.82257565
Iteration 26, loss = 0.64112048
Iteration 27, loss = 0.89752214
Iteration 28, loss = 0.76474412
Iteration 29, loss = 0.78555504
Iteration 30, loss = 0.81105166
Iteration 31, loss = 0.80259141
Iteration 32, loss = 0.80652544
Iteration 33, loss = 0.81834767
Iteration 34, loss = 0.80271552
Iteration 35, loss = 0.79900889
Iteration 36, loss = 0.80069423
Iteration 37, loss = 0.78406260
Iteration 38, loss = 0.77884813
Iteration 39, loss = 0.77714326
Iteration 40, loss = 0.76296450
Iteration 41, loss = 1.48500439
Iteration 42, loss = 0.78133065
Iteration 43, loss = 0.78590405
Iteration 44, loss = 1.01837966
Iteration 45, loss = 0.89539926
Iteration 46, loss = 0.79414274
Iteration 47, loss = 0.93651735
Iteration 48, loss = 0.82421593
Iteration 49, loss = 0.84010840
Iteration 50, loss = 0.87662286
Iteration 51, loss = 0.77894860
Iteration 52, loss = 0.81866375
Iteration 53, loss = 1.27575993
Iteration 54, loss = 0.81807815
Iteration 55, loss = 1.00113588
Iteration 56, loss = 1.21122508
Iteration 57, loss = 0.95453639
Iteration 58, loss = 0.78496325
Iteration 59, loss = 1.02022123
Iteration 60, loss = 1.01677944
Iteration 61, loss = 0.79124522
Iteration 62, loss = 0.82642104
Iteration 63, loss = 0.96091284
Iteration 64, loss = 0.85958912
Iteration 65, loss = 0.74799272
Iteration 66, loss = 0.85099320
Iteration 67, loss = 0.87900521
Iteration 68, loss = 0.76925178
Iteration 69, loss = 0.76788402
Iteration 70, loss = 0.84402042
Iteration 71, loss = 0.80229744
Iteration 72, loss = 0.74245576
Iteration 73, loss = 0.78987195
Iteration 74, loss = 0.80542099
Iteration 75, loss = 0.74568142
Iteration 76, loss = 0.77532573
Iteration 77, loss = 0.75757817
Iteration 78, loss = 0.72453952
Iteration 79, loss = 1.20524561
Iteration 80, loss = 0.76677680
Iteration 81, loss = 0.88991503
Iteration 82, loss = 0.85503822
Iteration 83, loss = 0.77443870
Iteration 84, loss = 0.80868249
Iteration 85, loss = 0.80517918
Iteration 86, loss = 0.75176114
Iteration 87, loss = 0.78982109
Iteration 88, loss = 0.76898257
Iteration 89, loss = 0.73145697
Iteration 90, loss = 0.93058491
Iteration 91, loss = 0.75660645
Iteration 92, loss = 0.98732470
Iteration 93, loss = 1.01514814
Iteration 94, loss = 0.82838631
Iteration 95, loss = 0.78177289
Iteration 96, loss = 0.91967723
Iteration 97, loss = 0.91548252
Iteration 98, loss = 0.82873332
Iteration 99, loss = 0.79148443
Iteration 100, loss = 0.75358120
Iteration 101, loss = 0.80927083
Iteration 102, loss = 0.79692914
Iteration 103, loss = 0.76375613
Iteration 104, loss = 0.80674165
Iteration 105, loss = 0.78078891
Iteration 106, loss = 0.75345114
Iteration 107, loss = 0.78219745
Iteration 108, loss = 0.72789372
Iteration 109, loss = 0.76922190
Iteration 110, loss = 0.76309772
Iteration 111, loss = 0.78340610
Iteration 112, loss = 0.78208471
Iteration 113, loss = 0.76873953
Iteration 114, loss = 0.77499730
Iteration 115, loss = 0.76922019
Iteration 116, loss = 0.75603826
Iteration 117, loss = 0.76028837
Iteration 118, loss = 0.75846167
Iteration 119, loss = 0.75097332
Iteration 120, loss = 0.75626780
Iteration 121, loss = 0.75670812
Iteration 122, loss = 0.75148165
Iteration 123, loss = 0.75435629
Iteration 124, loss = 0.75350493
Iteration 125, loss = 0.74808556
Iteration 126, loss = 0.75007331
Iteration 127, loss = 0.74822970
Iteration 128, loss = 0.74420106
Iteration 129, loss = 0.74426128
Iteration 130, loss = 0.74117134
Iteration 131, loss = 0.97051231
Iteration 132, loss = 0.90579380
Iteration 133, loss = 0.72781739
Iteration 134, loss = 0.77033499
Iteration 135, loss = 0.81478445
Iteration 136, loss = 0.78190798
Iteration 137, loss = 0.78537348
Iteration 138, loss = 0.79946331
Iteration 139, loss = 0.76254747
Iteration 140, loss = 0.77160396
Iteration 141, loss = 0.77227154
Iteration 142, loss = 0.74835276
Iteration 143, loss = 0.76346898
Iteration 144, loss = 0.75856736
Iteration 145, loss = 0.74742995
Iteration 146, loss = 0.76130263
Iteration 147, loss = 0.75248607
Iteration 148, loss = 0.74923590
Iteration 149, loss = 0.75763942
Iteration 150, loss = 0.74757401
Iteration 151, loss = 0.74893494
Iteration 152, loss = 0.75160619
Iteration 153, loss = 0.74304027
Iteration 154, loss = 0.74619493
Iteration 155, loss = 0.74415205
Iteration 156, loss = 0.73849193
Iteration 157, loss = 0.74064505
Iteration 158, loss = 0.72189386
Iteration 159, loss = 0.75661022
Iteration 160, loss = 0.74708615
Iteration 161, loss = 0.75252419
Iteration 162, loss = 0.75573691
Iteration 163, loss = 0.74654149
Iteration 164, loss = 0.75051682
Iteration 165, loss = 0.74924406
Iteration 166, loss = 0.74292661
Iteration 167, loss = 0.74703745
Iteration 168, loss = 0.74464435
Iteration 169, loss = 0.74178246
Iteration 170, loss = 0.74523650
Iteration 171, loss = 0.74219611
Iteration 172, loss = 0.74110954
Iteration 173, loss = 0.74284816
Iteration 174, loss = 0.73946744
Iteration 175, loss = 0.73919006
Iteration 176, loss = 0.73929251
Iteration 177, loss = 0.73527408
Iteration 178, loss = 0.73233836
Iteration 179, loss = 0.72176692
Iteration 180, loss = 0.92645100
Iteration 181, loss = 0.84338366
Iteration 182, loss = 0.77304613
Iteration 183, loss = 0.77992893
Iteration 184, loss = 0.80122758
Iteration 185, loss = 0.76760470
Iteration 186, loss = 0.80516191
Iteration 187, loss = 0.80519602
Iteration 188, loss = 0.83540083
Iteration 189, loss = 0.77705212
Iteration 190, loss = 0.80109482
Iteration 191, loss = 0.80223391
Iteration 192, loss = 0.76805834
Iteration 193, loss = 0.79968626
Iteration 194, loss = 0.78507505
Iteration 195, loss = 0.77450450
Iteration 196, loss = 0.79728141
Iteration 197, loss = 0.77582938
Iteration 198, loss = 0.77965111
Iteration 199, loss = 0.78710405
Iteration 200, loss = 0.76846389
Iteration 201, loss = 0.77846941
Iteration 202, loss = 0.77483162
Iteration 203, loss = 0.76560575
Iteration 204, loss = 0.77576782
Iteration 205, loss = 0.76799102
Iteration 206, loss = 0.76799847
Iteration 207, loss = 0.77339369
Iteration 208, loss = 0.76551132
Iteration 209, loss = 0.76922948
Iteration 210, loss = 0.76819140
Iteration 211, loss = 0.76296622
Iteration 212, loss = 0.76653333
Iteration 213, loss = 0.76234248
Iteration 214, loss = 0.76126365
Iteration 215, loss = 0.76298141
Iteration 216, loss = 0.75906533
Iteration 217, loss = 0.76054510
Iteration 218, loss = 0.75983682
Iteration 219, loss = 0.75760313
Iteration 220, loss = 0.75897016
Iteration 221, loss = 0.75658271
Iteration 222, loss = 0.75586178
Iteration 223, loss = 0.75572206
Iteration 224, loss = 0.75335036
Iteration 225, loss = 0.75357951
Iteration 226, loss = 0.75244671
Iteration 227, loss = 0.75128296
Iteration 228, loss = 0.75142169
Iteration 229, loss = 0.74987509
Iteration 230, loss = 0.74949140
Iteration 231, loss = 0.74883763
Iteration 232, loss = 0.74753231
Iteration 233, loss = 0.74727167
Iteration 234, loss = 0.74606636
Iteration 235, loss = 0.74520294
Iteration 236, loss = 0.74451139
Iteration 237, loss = 0.74321567
Iteration 238, loss = 0.74242104
Iteration 239, loss = 0.74099881
Iteration 240, loss = 0.73930305
Iteration 241, loss = 0.73676239
Iteration 242, loss = 0.73348926
Iteration 243, loss = 0.72759585
Iteration 244, loss = 0.61810275
Iteration 245, loss = 0.77366595
Iteration 246, loss = 0.82834381
Iteration 247, loss = 0.83058625
Iteration 248, loss = 0.77167787
Iteration 249, loss = 0.84223061
Iteration 250, loss = 0.76292887
Iteration 251, loss = 0.81056882
Iteration 252, loss = 0.78323717
Iteration 253, loss = 0.76691353
Iteration 254, loss = 0.79424107
Iteration 255, loss = 0.74616804
Iteration 256, loss = 0.78183588
Iteration 257, loss = 0.75353665
Iteration 258, loss = 0.75995008
Iteration 259, loss = 0.76264675
Iteration 260, loss = 0.77293623
Iteration 261, loss = 0.75724566
Iteration 262, loss = 0.78104337
Iteration 263, loss = 0.75773200
Iteration 264, loss = 0.76022535
Iteration 265, loss = 0.76410404
Iteration 266, loss = 0.75170787
Iteration 267, loss = 0.75772070
Iteration 268, loss = 0.75039656
Iteration 269, loss = 0.75924986
Iteration 270, loss = 0.75495073
Iteration 271, loss = 0.76146768
Iteration 272, loss = 0.75715698
Iteration 273, loss = 0.76016488
Iteration 274, loss = 0.75593398
Iteration 275, loss = 0.75703343
Iteration 276, loss = 0.75440495
Iteration 277, loss = 0.75473082
Iteration 278, loss = 0.75446395
Iteration 279, loss = 0.75463858
Iteration 280, loss = 0.75500306
Iteration 281, loss = 0.75410178
Iteration 282, loss = 0.75433050
Iteration 283, loss = 0.75269633
Iteration 284, loss = 0.75294435
Iteration 285, loss = 0.75130241
Iteration 286, loss = 0.75182142
Iteration 287, loss = 0.75044902
Iteration 288, loss = 0.75094256
Iteration 289, loss = 0.74956463
Iteration 290, loss = 0.74978207
Iteration 291, loss = 0.74847776
Iteration 292, loss = 0.74853063
Iteration 293, loss = 0.74736265
Iteration 294, loss = 0.74724501
Iteration 295, loss = 0.74619882
Iteration 296, loss = 0.74596248
Iteration 297, loss = 0.74505376
Iteration 298, loss = 0.74474206
Iteration 299, loss = 0.74397394
Iteration 300, loss = 0.74362087
Iteration 301, loss = 0.74293257
Iteration 302, loss = 0.74248888
Iteration 303, loss = 0.74181196
Iteration 304, loss = 0.74129037
Iteration 305, loss = 0.74064438
Iteration 306, loss = 0.74011018
Iteration 307, loss = 0.73952412
Iteration 308, loss = 0.73900192
Iteration 309, loss = 0.73845627
Iteration 310, loss = 0.73793738
Iteration 311, loss = 0.73741613
Iteration 312, loss = 0.73689583
Iteration 313, loss = 0.73638083
Iteration 314, loss = 0.73586294
Iteration 315, loss = 0.73537578
Iteration 316, loss = 0.73489442
Iteration 317, loss = 0.73444269
Iteration 318, loss = 0.73397942
Iteration 319, loss = 0.73353302
Iteration 320, loss = 0.73307439
Iteration 321, loss = 0.73263669
Iteration 322, loss = 0.73219324
Iteration 323, loss = 0.73176991
Iteration 324, loss = 0.73134353
Iteration 325, loss = 0.73093410
Iteration 326, loss = 0.73052112
Iteration 327, loss = 0.73011748
Iteration 328, loss = 0.72970789
Iteration 329, loss = 0.72930160
Iteration 330, loss = 0.72888756
Iteration 331, loss = 0.72846865
Iteration 332, loss = 0.72803701
Iteration 333, loss = 0.72760343
Iteration 334, loss = 0.72718232
Iteration 335, loss = 0.72675723
Iteration 336, loss = 0.72630732
Iteration 337, loss = 0.72583328
Iteration 338, loss = 0.72535251
Iteration 339, loss = 0.72480934
Iteration 340, loss = 0.72389027
Iteration 341, loss = 0.72307378
Iteration 342, loss = 0.72062904
Iteration 343, loss = 0.70613494
Iteration 344, loss = 0.80285161
Iteration 345, loss = 0.81898393
Iteration 346, loss = 0.78279206
Iteration 347, loss = 0.80619224
Iteration 348, loss = 0.76314991
Iteration 349, loss = 0.78839017
Iteration 350, loss = 0.75649278
Iteration 351, loss = 0.77946168
Iteration 352, loss = 0.75716070
Iteration 353, loss = 0.76927749
Iteration 354, loss = 0.75262564
Iteration 355, loss = 0.75756205
Iteration 356, loss = 0.75063438
Iteration 357, loss = 0.74873670
Iteration 358, loss = 0.74676850
Iteration 359, loss = 0.74030898
Iteration 360, loss = 0.74228725
Iteration 361, loss = 0.73005148
Iteration 362, loss = 0.66656064
Iteration 363, loss = 0.90587054
Iteration 364, loss = 0.77257115
Iteration 365, loss = 0.92058132
Iteration 366, loss = 0.77262444
Iteration 367, loss = 0.88724737
Iteration 368, loss = 0.78803473
Iteration 369, loss = 0.82134408
Iteration 370, loss = 0.80030752
Iteration 371, loss = 0.76401337
Iteration 372, loss = 0.80673025
Iteration 373, loss = 0.74175715
Iteration 374, loss = 0.80526915
Iteration 375, loss = 0.74930663
Iteration 376, loss = 0.79214863
Iteration 377, loss = 0.76427935
Iteration 378, loss = 0.77049252
Iteration 379, loss = 0.77278450
Iteration 380, loss = 0.75134138
Iteration 381, loss = 0.77219943
Iteration 382, loss = 0.74213637
Iteration 383, loss = 0.76605249
Iteration 384, loss = 0.74357105
Iteration 385, loss = 0.75785798
Iteration 386, loss = 0.74893211
Iteration 387, loss = 0.74936719
Iteration 388, loss = 0.75225833
Iteration 389, loss = 0.74302532
Iteration 390, loss = 0.75178356
Iteration 391, loss = 0.73963603
Iteration 392, loss = 0.74856688
Iteration 393, loss = 0.73920977
Iteration 394, loss = 0.74445893
Iteration 395, loss = 0.74024960
Iteration 396, loss = 0.74045891
Iteration 397, loss = 0.74084304
Iteration 398, loss = 0.73730180
Iteration 399, loss = 0.74015779
Iteration 400, loss = 0.73498479
Iteration 401, loss = 0.73818356
Iteration 402, loss = 0.73388475
Iteration 403, loss = 0.73597982
Iteration 404, loss = 0.73329068
Iteration 405, loss = 0.73344120
Iteration 406, loss = 0.73213547
Iteration 407, loss = 0.73074728
Iteration 408, loss = 0.72911853
Iteration 409, loss = 0.71399764
Iteration 410, loss = 0.79926469
Iteration 411, loss = 0.94131791
Iteration 412, loss = 0.77450834
Iteration 413, loss = 0.85453117
Iteration 414, loss = 0.78262086
Iteration 415, loss = 0.81996728
Iteration 416, loss = 0.74898082
Iteration 417, loss = 0.78391847
Iteration 418, loss = 0.73765484
Iteration 419, loss = 0.77684444
Iteration 420, loss = 0.74544874
Iteration 421, loss = 0.77548428
Iteration 422, loss = 0.74161635
Iteration 423, loss = 0.74744968
Iteration 424, loss = 0.79094734
Iteration 425, loss = 0.74669843
Iteration 426, loss = 0.74832963
Iteration 427, loss = 0.91437603
Iteration 428, loss = 0.99307519
Iteration 429, loss = 0.78144885
Iteration 430, loss = 0.99332023
Iteration 431, loss = 0.77137719
Iteration 432, loss = 0.93540883
Iteration 433, loss = 0.74935554
Iteration 434, loss = 0.88730713
Iteration 435, loss = 0.74041066
Iteration 436, loss = 0.85709053
Iteration 437, loss = 0.74105038
Iteration 438, loss = 0.79938682
Iteration 439, loss = 0.95753504
Iteration 440, loss = 0.77130341
Iteration 441, loss = 0.93877635
Iteration 442, loss = 0.77771001
Iteration 443, loss = 0.89637450
Iteration 444, loss = 0.78834615
Iteration 445, loss = 0.84363673
Iteration 446, loss = 0.80145468
Iteration 447, loss = 0.80075726
Iteration 448, loss = 0.81600598
Iteration 449, loss = 0.77488202
Iteration 450, loss = 0.82185433
Iteration 451, loss = 0.76222533
Iteration 452, loss = 0.81443793
Iteration 453, loss = 0.75760001
Iteration 454, loss = 0.80029222
Iteration 455, loss = 0.75982205
Iteration 456, loss = 0.78481931
Iteration 457, loss = 0.76517545
Iteration 458, loss = 0.77062046
Iteration 459, loss = 0.77151043
Iteration 460, loss = 0.76387138
Iteration 461, loss = 0.77293446
Iteration 462, loss = 0.75656421
Iteration 463, loss = 0.77042244
Iteration 464, loss = 0.74846598
Iteration 465, loss = 0.76268448
Iteration 466, loss = 0.74505291
Iteration 467, loss = 0.75477079
Iteration 468, loss = 0.74139760
Iteration 469, loss = 0.71952906
Iteration 470, loss = 0.91235081
Iteration 471, loss = 0.81393658
Iteration 472, loss = 0.95222445
Iteration 473, loss = 0.78659620
Iteration 474, loss = 0.90802259
Iteration 475, loss = 0.82170938
Iteration 476, loss = 0.82451814
Iteration 477, loss = 0.84918935
Iteration 478, loss = 0.76530471
Iteration 479, loss = 0.84289584
Iteration 480, loss = 0.76347562
Iteration 481, loss = 0.81375451
Iteration 482, loss = 0.78947199
Iteration 483, loss = 0.77888354
Iteration 484, loss = 0.80467185
Iteration 485, loss = 0.75897493
Iteration 486, loss = 0.79763152
Iteration 487, loss = 0.75943561
Iteration 488, loss = 0.77792890
Iteration 489, loss = 0.76899675
Iteration 490, loss = 0.75951741
Iteration 491, loss = 0.77403808
Iteration 492, loss = 0.75091270
Iteration 493, loss = 0.76971546
Iteration 494, loss = 0.75146591
Iteration 495, loss = 0.75949303
Iteration 496, loss = 0.75517673
Iteration 497, loss = 0.75002293
Iteration 498, loss = 0.75671699
Iteration 499, loss = 0.74528845
Iteration 500, loss = 0.75413323
Iteration 501, loss = 0.74489489
Iteration 502, loss = 0.74897415
Iteration 503, loss = 0.74615345
Iteration 504, loss = 0.74398477
Iteration 505, loss = 0.74644069
Iteration 506, loss = 0.74090518
Iteration 507, loss = 0.74484775
Iteration 508, loss = 0.73983593
Iteration 509, loss = 0.74193753
Iteration 510, loss = 0.73967698
Iteration 511, loss = 0.73891085
Iteration 512, loss = 0.73926226
Iteration 513, loss = 0.73656366
Iteration 514, loss = 0.73800146
Iteration 515, loss = 0.73519575
Iteration 516, loss = 0.73619338
Iteration 517, loss = 0.73439647
Iteration 518, loss = 0.73415761
Iteration 519, loss = 0.73369246
Iteration 520, loss = 0.73247062
Iteration 521, loss = 0.73272527
Iteration 522, loss = 0.73106318
Iteration 523, loss = 0.73127767
Iteration 524, loss = 0.72984192
Iteration 525, loss = 0.72957941
Iteration 526, loss = 0.72876028
Iteration 527, loss = 0.72805674
Iteration 528, loss = 0.72762125
Iteration 529, loss = 0.72633145
Iteration 530, loss = 0.72555633
Iteration 531, loss = 0.72416875
Iteration 532, loss = 0.72375746
Iteration 533, loss = 0.72258557
Iteration 534, loss = 0.72173221
Iteration 535, loss = 0.72050393
Iteration 536, loss = 0.71862013
Iteration 537, loss = 0.71696048
Iteration 538, loss = 0.71474172
Iteration 539, loss = 0.71221266
Iteration 540, loss = 0.70687806
Iteration 541, loss = 0.66461769
Iteration 542, loss = 0.92847184
Iteration 543, loss = 0.79284733
Iteration 544, loss = 0.86963928
Iteration 545, loss = 0.86279551
Iteration 546, loss = 0.77419986
Iteration 547, loss = 0.86405386
Iteration 548, loss = 0.74370154
Iteration 549, loss = 0.82441629
Iteration 550, loss = 0.77199127
Iteration 551, loss = 0.77600125
Iteration 552, loss = 0.80117871
Iteration 553, loss = 0.74752783
Iteration 554, loss = 0.80365285
Iteration 555, loss = 0.75082722
Iteration 556, loss = 0.78470415
Iteration 557, loss = 0.76822610
Iteration 558, loss = 0.76066933
Iteration 559, loss = 0.77750932
Iteration 560, loss = 0.74637786
Iteration 561, loss = 0.77257924
Iteration 562, loss = 0.74672303
Iteration 563, loss = 0.76067508
Iteration 564, loss = 0.75462731
Iteration 565, loss = 0.75000602
Iteration 566, loss = 0.75979132
Iteration 567, loss = 0.74508143
Iteration 568, loss = 0.75838689
Iteration 569, loss = 0.74611570
Iteration 570, loss = 0.75271474
Iteration 571, loss = 0.74922988
Iteration 572, loss = 0.74661493
Iteration 573, loss = 0.75275396
Iteration 574, loss = 0.75403080
Iteration 575, loss = 0.76381668
Iteration 576, loss = 0.75809077
Iteration 577, loss = 0.76063318
Iteration 578, loss = 0.84632459
Iteration 579, loss = 0.79295204
Iteration 580, loss = 0.76417857
Iteration 581, loss = 0.82929189
Iteration 582, loss = 0.79227389
Iteration 583, loss = 0.82590460
Iteration 584, loss = 0.80362066
Iteration 585, loss = 0.79566550
Iteration 586, loss = 0.79446536
Iteration 587, loss = 0.76972497
Iteration 588, loss = 0.78510140
Iteration 589, loss = 0.76158731
Iteration 590, loss = 0.78122787
Iteration 591, loss = 0.76395362
Iteration 592, loss = 0.77778216
Iteration 593, loss = 0.76783045
Iteration 594, loss = 0.77270520
Iteration 595, loss = 0.76935714
Iteration 596, loss = 0.76680727
Iteration 597, loss = 0.76860415
Iteration 598, loss = 0.76233819
Iteration 599, loss = 0.76738890
Iteration 600, loss = 0.76032064
Iteration 601, loss = 0.76583730
Iteration 602, loss = 0.75934755
Iteration 603, loss = 0.76316964
Iteration 604, loss = 0.75825654
Iteration 605, loss = 0.75982602
Iteration 606, loss = 0.75713263
Iteration 607, loss = 0.75683477
Iteration 608, loss = 0.75627567
Iteration 609, loss = 0.75477471
Iteration 610, loss = 0.75565493
Iteration 611, loss = 0.75349601
Iteration 612, loss = 0.75473701
Iteration 613, loss = 0.75228298
Iteration 614, loss = 0.75309738
Iteration 615, loss = 0.75089303
Iteration 616, loss = 0.75001774
Iteration 617, loss = 0.74896901
Iteration 618, loss = 0.74922494
Iteration 619, loss = 0.74974604
Iteration 620, loss = 0.74915066
Iteration 621, loss = 0.74806552
Iteration 622, loss = 0.74717875
Iteration 623, loss = 0.74605705
Iteration 624, loss = 0.74565333
Iteration 625, loss = 0.74490205
Iteration 626, loss = 0.74437486
Iteration 627, loss = 0.74356938
Iteration 628, loss = 0.74283307
Iteration 629, loss = 0.74223562
Iteration 630, loss = 0.74136740
Iteration 631, loss = 0.74099445
Iteration 632, loss = 0.74031341
Iteration 633, loss = 0.73933495
Iteration 634, loss = 0.73892746
Iteration 635, loss = 0.73826111
Iteration 636, loss = 0.73776402
Iteration 637, loss = 0.73676808
Iteration 638, loss = 0.73592287
Iteration 639, loss = 0.73478935
Iteration 640, loss = 0.73397193
Iteration 641, loss = 0.73317403
Iteration 642, loss = 0.73158889
Iteration 643, loss = 0.72686288
Iteration 644, loss = 0.61673300
Iteration 645, loss = 0.74365763
Iteration 646, loss = 0.80792214
Iteration 647, loss = 0.74848159
Iteration 648, loss = 0.79722973
Iteration 649, loss = 0.74919909
Iteration 650, loss = 0.77846438
Iteration 651, loss = 0.74954908
Iteration 652, loss = 0.76558829
Iteration 653, loss = 0.75522440
Iteration 654, loss = 0.75901027
Iteration 655, loss = 0.76129256
Iteration 656, loss = 0.71502864
Iteration 657, loss = 0.85428504
Iteration 658, loss = 0.81609503
Iteration 659, loss = 0.85322177
Iteration 660, loss = 0.79914415
Iteration 661, loss = 0.84044409
Iteration 662, loss = 0.78387200
Iteration 663, loss = 0.83147091
Iteration 664, loss = 0.78185368
Iteration 665, loss = 0.82855945
Iteration 666, loss = 0.78579684
Iteration 667, loss = 0.82399844
Iteration 668, loss = 0.78424592
Iteration 669, loss = 0.79732893
Iteration 670, loss = 0.79368249
Iteration 671, loss = 0.79975570
Iteration 672, loss = 0.79418128
Iteration 673, loss = 0.79428160
Iteration 674, loss = 0.78809167
Iteration 675, loss = 0.77417478
Iteration 676, loss = 0.87571331
Iteration 677, loss = 0.86443477
Iteration 678, loss = 0.85626695
Iteration 679, loss = 0.85884527
Iteration 680, loss = 0.83247793
Iteration 681, loss = 0.84621915
Iteration 682, loss = 0.82069107
Iteration 683, loss = 0.84006324
Iteration 684, loss = 0.81574137
Iteration 685, loss = 0.83194238
Iteration 686, loss = 0.80843668
Iteration 687, loss = 0.82186641
Iteration 688, loss = 0.80249926
Iteration 689, loss = 0.81434171
Iteration 690, loss = 0.79882859
Iteration 691, loss = 0.80774893
Iteration 692, loss = 0.79472009
Iteration 693, loss = 0.80122433
Iteration 694, loss = 0.79082319
Iteration 695, loss = 0.79564249
Iteration 696, loss = 0.78741389
Iteration 697, loss = 0.79062862
Iteration 698, loss = 0.78387490
Iteration 699, loss = 0.78596715
Iteration 700, loss = 0.78086711
Iteration 701, loss = 0.78251945
Iteration 702, loss = 0.77845022
Iteration 703, loss = 0.77921447
Iteration 704, loss = 0.77561876
Iteration 705, loss = 0.77592887
Iteration 706, loss = 0.77304293
Iteration 707, loss = 0.77322184
Iteration 708, loss = 0.77080161
Iteration 709, loss = 0.77070302
Iteration 710, loss = 0.76849763
Iteration 711, loss = 0.76823209
Iteration 712, loss = 0.76625126
Iteration 713, loss = 0.76590712
Iteration 714, loss = 0.76416166
Iteration 715, loss = 0.76383052
Iteration 716, loss = 0.76226428
Iteration 717, loss = 0.76189425
Iteration 718, loss = 0.76044172
Iteration 719, loss = 0.75975768
Iteration 720, loss = 0.77089242
Iteration 721, loss = 0.76730377
Iteration 722, loss = 0.77170633
Iteration 723, loss = 0.76302597
Iteration 724, loss = 0.77090931
Iteration 725, loss = 0.75906483
Iteration 726, loss = 0.76779478
Iteration 727, loss = 0.75534398
Iteration 728, loss = 0.76449337
Iteration 729, loss = 0.75385840
Iteration 730, loss = 0.76223732
Iteration 731, loss = 0.75341978
Iteration 732, loss = 0.75960264
Iteration 733, loss = 0.75240657
Iteration 734, loss = 0.75639577
Iteration 735, loss = 0.75126378
Iteration 736, loss = 0.75365495
Iteration 737, loss = 0.75049670
Iteration 738, loss = 0.75150080
Iteration 739, loss = 0.74969048
Iteration 740, loss = 0.74940178
Iteration 741, loss = 0.74845199
Iteration 742, loss = 0.74732649
Iteration 743, loss = 0.74687372
Iteration 744, loss = 0.74546149
Iteration 745, loss = 0.74579372
Iteration 746, loss = 0.74399815
Iteration 747, loss = 0.74421284
Iteration 748, loss = 0.74226277
Iteration 749, loss = 0.74259885
Iteration 750, loss = 0.74068442
Iteration 751, loss = 0.74086816
Iteration 752, loss = 0.73897364
Iteration 753, loss = 0.73900551
Iteration 754, loss = 0.73766395
Iteration 755, loss = 0.73673311
Iteration 756, loss = 0.73431716
Iteration 757, loss = 0.72959557
Iteration 758, loss = 0.67741056
Iteration 759, loss = 0.78075183
Iteration 760, loss = 0.77257515
Iteration 761, loss = 0.75040744
Iteration 762, loss = 0.81132389
Iteration 763, loss = 0.78224698
Iteration 764, loss = 0.81667859
Iteration 765, loss = 0.79052682
Iteration 766, loss = 0.79710485
Iteration 767, loss = 0.78123064
Iteration 768, loss = 0.77893151
Iteration 769, loss = 0.78029858
Iteration 770, loss = 0.77604295
Iteration 771, loss = 0.78856113
Iteration 772, loss = 0.77907823
Iteration 773, loss = 0.79102555
Iteration 774, loss = 0.77621810
Iteration 775, loss = 0.76283329
Iteration 776, loss = 0.78585925
Iteration 777, loss = 0.79416019
Iteration 778, loss = 0.75457398
Iteration 779, loss = 0.93114241
Iteration 780, loss = 0.86894427
Iteration 781, loss = 0.99401998
Iteration 782, loss = 0.81668572
Iteration 783, loss = 0.93940254
Iteration 784, loss = 0.88208771
Iteration 785, loss = 0.84094125
Iteration 786, loss = 0.91708398
Iteration 787, loss = 0.78635114
Iteration 788, loss = 0.83176378
Iteration 789, loss = 0.88773535
Iteration 790, loss = 0.83450257
Iteration 791, loss = 0.85270188
Iteration 792, loss = 0.86198903
Iteration 793, loss = 0.82257897
Iteration 794, loss = 0.85659698
Iteration 795, loss = 0.84003475
Iteration 796, loss = 0.83390206
Iteration 797, loss = 0.85658369
Iteration 798, loss = 0.83129098
Iteration 799, loss = 0.84191648
Iteration 800, loss = 0.84164178
Iteration 801, loss = 0.82608161
Iteration 802, loss = 0.84140750
Iteration 803, loss = 0.83133495
Iteration 804, loss = 0.83108300
Iteration 805, loss = 0.83800699
Iteration 806, loss = 0.82618635
Iteration 807, loss = 0.83220339
Iteration 808, loss = 0.82939671
Iteration 809, loss = 0.82408362
Iteration 810, loss = 0.82982878
Iteration 811, loss = 0.82335605
Iteration 812, loss = 0.82415866
Iteration 813, loss = 0.82474394
Iteration 814, loss = 0.81914014
Iteration 815, loss = 0.82161414
Iteration 816, loss = 0.81835843
Iteration 817, loss = 0.81658002
Iteration 818, loss = 0.81790431
Iteration 819, loss = 0.81413543
Iteration 820, loss = 0.81467045
Iteration 821, loss = 0.81331661
Iteration 822, loss = 0.81073512
Iteration 823, loss = 0.81118017
Iteration 824, loss = 0.80856247
Iteration 825, loss = 0.80776766
Iteration 826, loss = 0.80712517
Iteration 827, loss = 0.80482361
Iteration 828, loss = 0.80460989
Iteration 829, loss = 0.80276848
Iteration 830, loss = 0.80124717
Iteration 831, loss = 0.80060182
Iteration 832, loss = 0.79819966
Iteration 833, loss = 0.75922572
Iteration 834, loss = 0.81651271
Iteration 835, loss = 0.81245605
Iteration 836, loss = 0.83288738
Iteration 837, loss = 0.81451315
Iteration 838, loss = 0.82651921
Iteration 839, loss = 0.81613092
Iteration 840, loss = 0.81408445
Iteration 841, loss = 0.82042041
Iteration 842, loss = 0.81163335
Iteration 843, loss = 0.82315461
Iteration 844, loss = 0.81724819
Iteration 845, loss = 0.82142662
Iteration 846, loss = 0.82264051
Iteration 847, loss = 0.81896063
Iteration 848, loss = 0.82466178
Iteration 849, loss = 0.81954516
Iteration 850, loss = 0.82317758
Iteration 851, loss = 0.82122428
Iteration 852, loss = 0.82022447
Iteration 853, loss = 0.82200852
Iteration 854, loss = 0.81885460
Iteration 855, loss = 0.82152091
Iteration 856, loss = 0.81933813
Iteration 857, loss = 0.81984635
Iteration 858, loss = 0.81951671
Iteration 859, loss = 0.81760501
Iteration 860, loss = 0.81827678
Iteration 861, loss = 0.81591427
Iteration 862, loss = 0.81621114
Iteration 863, loss = 0.81489641
Iteration 864, loss = 0.81402372
Iteration 865, loss = 0.81373822
Iteration 866, loss = 0.81208826
Iteration 867, loss = 0.81201213
Iteration 868, loss = 0.81046637
Iteration 869, loss = 0.80985488
Iteration 870, loss = 0.80883560
Iteration 871, loss = 0.80758266
Iteration 872, loss = 0.80695028
Iteration 873, loss = 0.80551404
Iteration 874, loss = 0.80489060
Iteration 875, loss = 0.80369459
Iteration 876, loss = 0.80279056
Iteration 877, loss = 0.80189059
Iteration 878, loss = 0.80071425
Iteration 879, loss = 0.79992215
Iteration 880, loss = 0.79869912
Iteration 881, loss = 0.79783232
Iteration 882, loss = 0.79676437
Iteration 883, loss = 0.79577077
Iteration 884, loss = 0.79487051
Iteration 885, loss = 0.79379715
Iteration 886, loss = 0.79293925
Iteration 887, loss = 0.79187810
Iteration 888, loss = 0.79096748
Iteration 889, loss = 0.78999100
Iteration 890, loss = 0.78900949
Iteration 891, loss = 0.78742447
Iteration 892, loss = 0.78915397
Iteration 893, loss = 0.79063782
Iteration 894, loss = 0.79048296
Iteration 895, loss = 0.78782660
Iteration 896, loss = 0.78547924
Iteration 897, loss = 0.78391884
Iteration 898, loss = 0.78296309
Iteration 899, loss = 0.78250916
Iteration 900, loss = 0.78169045
Iteration 901, loss = 0.78070963
Iteration 902, loss = 0.77972056
Iteration 903, loss = 0.77894029
Iteration 904, loss = 0.77799191
Iteration 905, loss = 0.77691523
Iteration 906, loss = 0.77593843
Iteration 907, loss = 0.77505929
Iteration 908, loss = 0.77430772
Iteration 909, loss = 0.77315623
Iteration 910, loss = 0.77237708
Iteration 911, loss = 0.77267708
Iteration 912, loss = 0.77305809
Iteration 913, loss = 0.77209869
Iteration 914, loss = 0.76966827
Iteration 915, loss = 0.76748263
Iteration 916, loss = 0.76568528
Iteration 917, loss = 0.76511461
Iteration 918, loss = 0.76433686
Iteration 919, loss = 0.76298049
Iteration 920, loss = 0.75695589
Iteration 921, loss = 0.71391891
Iteration 922, loss = 0.85839061
Iteration 923, loss = 0.82412528
Iteration 924, loss = 0.88971745
Iteration 925, loss = 0.79372172
Iteration 926, loss = 0.88102133
Iteration 927, loss = 0.78440901
Iteration 928, loss = 0.84512112
Iteration 929, loss = 0.78887545
Iteration 930, loss = 0.80738147
Iteration 931, loss = 0.80153530
Iteration 932, loss = 0.78501216
Iteration 933, loss = 0.81260286
Iteration 934, loss = 0.77538190
Iteration 935, loss = 0.81071149
Iteration 936, loss = 0.77306272
Iteration 937, loss = 0.79969410
Iteration 938, loss = 0.77578043
Iteration 939, loss = 0.78608825
Iteration 940, loss = 0.77900265
Iteration 941, loss = 0.77464765
Iteration 942, loss = 0.78124988
Iteration 943, loss = 0.76790689
Iteration 944, loss = 0.78031294
Iteration 945, loss = 0.76539236
Iteration 946, loss = 0.77657816
Iteration 947, loss = 0.76535597
Iteration 948, loss = 0.77219518
Iteration 949, loss = 0.76826369
Iteration 950, loss = 0.76880949
Iteration 951, loss = 0.76724512
Iteration 952, loss = 0.76263721
Iteration 953, loss = 0.76637477
Iteration 954, loss = 0.76069101
Iteration 955, loss = 0.76421526
Iteration 956, loss = 0.75906295
Iteration 957, loss = 0.76171203
Iteration 958, loss = 0.75716781
Iteration 959, loss = 0.75629686
Iteration 960, loss = 0.75182845
Iteration 961, loss = 0.65856621
Iteration 962, loss = 0.78751746
Iteration 963, loss = 0.78890358
Iteration 964, loss = 0.81396075
Iteration 965, loss = 0.76838047
Iteration 966, loss = 0.81245660
Iteration 967, loss = 0.77446754
Iteration 968, loss = 0.79260090
Iteration 969, loss = 0.79167369
Iteration 970, loss = 0.77726265
Iteration 971, loss = 0.80161193
Iteration 972, loss = 0.77780445
Iteration 973, loss = 0.79837435
Iteration 974, loss = 0.78768793
Iteration 975, loss = 0.78871869
Iteration 976, loss = 0.79543258
Iteration 977, loss = 0.78305996
Iteration 978, loss = 0.79616539
Iteration 979, loss = 0.78518612
Iteration 980, loss = 0.79218798
Iteration 981, loss = 0.79077062
Iteration 982, loss = 0.78803776
Iteration 983, loss = 0.79371104
Iteration 984, loss = 0.78642332
Iteration 985, loss = 0.79214694
Iteration 986, loss = 0.78739854
Iteration 987, loss = 0.78871209
Iteration 988, loss = 0.78914521
Iteration 989, loss = 0.78630767
Iteration 990, loss = 0.78941437
Iteration 991, loss = 0.78553190
Iteration 992, loss = 0.78764972
Iteration 993, loss = 0.78564065
Iteration 994, loss = 0.78524496
Iteration 995, loss = 0.78562627
Iteration 996, loss = 0.78347782
Iteration 997, loss = 0.78469949
Iteration 998, loss = 0.78251235
Iteration 999, loss = 0.78297906
Iteration 1000, loss = 0.78195022
