Iteration 1, loss = 0.70246415
Iteration 2, loss = 1.09907035
Iteration 3, loss = 7.79225347
Iteration 4, loss = 4.12968459
Iteration 5, loss = 5.88148632
Iteration 6, loss = 3.92608912
Iteration 7, loss = 0.79563334
Iteration 8, loss = 2.52699726
Iteration 9, loss = 1.01075388
Iteration 10, loss = 3.46104327
Iteration 11, loss = 0.85275356
Iteration 12, loss = 0.84419149
Iteration 13, loss = 0.94563623
Iteration 14, loss = 0.96906675
Iteration 15, loss = 0.86625366
Iteration 16, loss = 1.33157632
Iteration 17, loss = 1.49257294
Iteration 18, loss = 1.10606914
Iteration 19, loss = 1.61143712
Iteration 20, loss = 1.12701036
Iteration 21, loss = 1.66175777
Iteration 22, loss = 1.37718795
Iteration 23, loss = 1.83789161
Iteration 24, loss = 1.15544701
Iteration 25, loss = 1.11518382
Iteration 26, loss = 1.07475212
Iteration 27, loss = 1.24256457
Iteration 28, loss = 0.93464100
Iteration 29, loss = 0.90912556
Iteration 30, loss = 0.92677574
Iteration 31, loss = 0.90172656
Iteration 32, loss = 1.25689692
Iteration 33, loss = 1.00826508
Iteration 34, loss = 1.11469620
Iteration 35, loss = 0.91509620
Iteration 36, loss = 1.08870919
Iteration 37, loss = 1.00362721
Iteration 38, loss = 1.07847378
Iteration 39, loss = 1.00470839
Iteration 40, loss = 1.06242122
Iteration 41, loss = 0.88431638
Iteration 42, loss = 0.87193905
Iteration 43, loss = 0.86389174
Iteration 44, loss = 0.95001935
Iteration 45, loss = 0.86475608
Iteration 46, loss = 1.09227648
Iteration 47, loss = 1.51488925
Iteration 48, loss = 1.01941284
Iteration 49, loss = 1.55557672
Iteration 50, loss = 0.86899943
Iteration 51, loss = 1.29567447
Iteration 52, loss = 1.17482051
Iteration 53, loss = 1.22939323
Iteration 54, loss = 1.02642689
Iteration 55, loss = 2.02432285
Iteration 56, loss = 0.87373145
Iteration 57, loss = 0.93392023
Iteration 58, loss = 0.98587031
Iteration 59, loss = 1.30194092
Iteration 60, loss = 0.99007195
Iteration 61, loss = 1.07157789
Iteration 62, loss = 1.04217844
Iteration 63, loss = 1.13256216
Iteration 64, loss = 1.02847316
Iteration 65, loss = 1.13903307
Iteration 66, loss = 1.04043077
Iteration 67, loss = 1.11604063
Iteration 68, loss = 1.05034720
Iteration 69, loss = 1.07742211
Iteration 70, loss = 1.02719346
Iteration 71, loss = 0.95964447
Iteration 72, loss = 1.85706569
Iteration 73, loss = 1.11040102
Iteration 74, loss = 1.67017509
Iteration 75, loss = 1.03810557
Iteration 76, loss = 1.68015414
Iteration 77, loss = 1.13496454
Iteration 78, loss = 1.54562543
Iteration 79, loss = 1.01321498
Iteration 80, loss = 1.31520121
Iteration 81, loss = 0.95611057
Iteration 82, loss = 1.20345919
Iteration 83, loss = 0.95698767
Iteration 84, loss = 1.14364404
Iteration 85, loss = 0.93292548
Iteration 86, loss = 1.07390100
Iteration 87, loss = 0.92487922
Iteration 88, loss = 1.04004592
Iteration 89, loss = 0.92220405
Iteration 90, loss = 1.01385858
Iteration 91, loss = 1.03095424
Iteration 92, loss = 0.95086004
Iteration 93, loss = 0.97309905
Iteration 94, loss = 1.42656907
Iteration 95, loss = 1.15034277
Iteration 96, loss = 0.98787280
Iteration 97, loss = 1.16036962
Iteration 98, loss = 0.95787792
Iteration 99, loss = 1.12529593
Iteration 100, loss = 0.96964193
Iteration 101, loss = 1.03361678
Iteration 102, loss = 0.99090977
Iteration 103, loss = 1.05410508
Iteration 104, loss = 1.03820352
Iteration 105, loss = 1.16070025
Iteration 106, loss = 1.01249594
Iteration 107, loss = 1.11149163
Iteration 108, loss = 1.01002148
Iteration 109, loss = 1.07382441
Iteration 110, loss = 1.15219766
Iteration 111, loss = 0.99205566
Iteration 112, loss = 1.14478777
Iteration 113, loss = 0.95957276
Iteration 114, loss = 1.00632307
Iteration 115, loss = 0.97193025
Iteration 116, loss = 1.00161475
Iteration 117, loss = 0.96259055
Iteration 118, loss = 0.98703932
Iteration 119, loss = 1.19018033
Iteration 120, loss = 1.46138976
Iteration 121, loss = 0.95290154
Iteration 122, loss = 1.13270068
Iteration 123, loss = 0.97645091
Iteration 124, loss = 1.06874962
Iteration 125, loss = 1.01297027
Iteration 126, loss = 1.28749474
Iteration 127, loss = 1.01838387
Iteration 128, loss = 1.21050910
Iteration 129, loss = 0.96083883
Iteration 130, loss = 0.97345433
Iteration 131, loss = 0.96247651
Iteration 132, loss = 1.18772215
Iteration 133, loss = 0.94067003
Iteration 134, loss = 1.13953156
Iteration 135, loss = 0.93402063
Iteration 136, loss = 1.09251151
Iteration 137, loss = 0.93064140
Iteration 138, loss = 1.00918950
Iteration 139, loss = 0.94289093
Iteration 140, loss = 0.93644242
Iteration 141, loss = 0.94475347
Iteration 142, loss = 0.93696496
Iteration 143, loss = 0.89999205
Iteration 144, loss = 0.93512191
Iteration 145, loss = 0.93261581
Iteration 146, loss = 0.92852527
Iteration 147, loss = 0.92264231
Iteration 148, loss = 0.89628211
Iteration 149, loss = 0.93631474
Iteration 150, loss = 1.03394354
Iteration 151, loss = 0.99075288
Iteration 152, loss = 1.07209540
Iteration 153, loss = 0.96355959
Iteration 154, loss = 1.05913063
Iteration 155, loss = 0.94284217
Iteration 156, loss = 1.02371805
Iteration 157, loss = 0.93986390
Iteration 158, loss = 1.00943813
Iteration 159, loss = 0.94921252
Iteration 160, loss = 0.99342689
Iteration 161, loss = 0.94871237
Iteration 162, loss = 1.15368689
Iteration 163, loss = 1.18890341
Iteration 164, loss = 0.99129413
Iteration 165, loss = 1.00085926
Iteration 166, loss = 1.01785871
Iteration 167, loss = 1.00093976
Iteration 168, loss = 0.99866963
Iteration 169, loss = 0.97344353
Iteration 170, loss = 0.97225353
Iteration 171, loss = 0.95121656
Iteration 172, loss = 0.96944616
Iteration 173, loss = 0.95477650
Iteration 174, loss = 0.96744450
Iteration 175, loss = 0.94697282
Iteration 176, loss = 1.09849930
Iteration 177, loss = 1.10168726
Iteration 178, loss = 1.04293887
Iteration 179, loss = 1.11309086
Iteration 180, loss = 1.00496511
Iteration 181, loss = 1.11786764
Iteration 182, loss = 0.98084845
Iteration 183, loss = 1.11579356
Iteration 184, loss = 0.96299498
Iteration 185, loss = 1.10325452
Iteration 186, loss = 0.94730544
Iteration 187, loss = 1.06453411
Iteration 188, loss = 1.03725158
Iteration 189, loss = 0.96110179
Iteration 190, loss = 0.97502859
Iteration 191, loss = 0.94968350
Iteration 192, loss = 1.05743037
Iteration 193, loss = 0.99656318
Iteration 194, loss = 0.96682438
Iteration 195, loss = 1.02819806
Iteration 196, loss = 0.93478272
Iteration 197, loss = 0.99512700
Iteration 198, loss = 0.95986935
Iteration 199, loss = 0.94290608
Iteration 200, loss = 0.98298936
Iteration 201, loss = 0.92786682
Iteration 202, loss = 0.96095228
Iteration 203, loss = 0.94394302
Iteration 204, loss = 0.92525935
Iteration 205, loss = 0.95038215
Iteration 206, loss = 0.91600645
Iteration 207, loss = 0.92927964
Iteration 208, loss = 0.92629433
Iteration 209, loss = 0.90795116
Iteration 210, loss = 0.92489631
Iteration 211, loss = 0.90677872
Iteration 212, loss = 0.90076824
Iteration 213, loss = 0.91425410
Iteration 214, loss = 1.03498046
Iteration 215, loss = 1.07135925
Iteration 216, loss = 0.89496024
Iteration 217, loss = 0.99600116
Iteration 218, loss = 0.99873132
Iteration 219, loss = 0.88432493
Iteration 220, loss = 0.98213152
Iteration 221, loss = 0.93322756
Iteration 222, loss = 0.88630816
Iteration 223, loss = 0.88068879
Iteration 224, loss = 0.88388211
Iteration 225, loss = 0.88518757
Iteration 226, loss = 0.87787892
Iteration 227, loss = 0.87219322
Iteration 228, loss = 0.87115030
Iteration 229, loss = 0.87017971
Iteration 230, loss = 0.86786668
Iteration 231, loss = 0.86483564
Iteration 232, loss = 0.86142700
Iteration 233, loss = 0.83703853
Iteration 234, loss = 0.86689214
Iteration 235, loss = 0.85209931
Iteration 236, loss = 1.28659692
Iteration 237, loss = 1.84050336
Iteration 238, loss = 1.11214558
Iteration 239, loss = 2.10393247
Iteration 240, loss = 1.54380275
Iteration 241, loss = 2.18176346
Iteration 242, loss = 2.04986992
Iteration 243, loss = 1.54892481
Iteration 244, loss = 1.60699613
Iteration 245, loss = 1.20321377
Iteration 246, loss = 0.97570904
Iteration 247, loss = 0.92290230
Iteration 248, loss = 0.95421991
Iteration 249, loss = 0.99519272
Iteration 250, loss = 0.90335822
Iteration 251, loss = 0.91247895
Iteration 252, loss = 1.13859361
Iteration 253, loss = 0.90304767
Iteration 254, loss = 1.10072563
Iteration 255, loss = 0.89517577
Iteration 256, loss = 1.04550405
Iteration 257, loss = 0.90278283
Iteration 258, loss = 0.98739111
Iteration 259, loss = 0.92456001
Iteration 260, loss = 0.93269686
Iteration 261, loss = 0.93339328
Iteration 262, loss = 0.88718602
Iteration 263, loss = 0.91090838
Iteration 264, loss = 0.90771181
Iteration 265, loss = 0.91565702
Iteration 266, loss = 0.91602135
Iteration 267, loss = 0.91864083
Iteration 268, loss = 1.13153731
Iteration 269, loss = 0.95823436
Iteration 270, loss = 0.98969944
Iteration 271, loss = 0.97026932
Iteration 272, loss = 0.95565335
Iteration 273, loss = 0.93509786
Iteration 274, loss = 1.35548358
Iteration 275, loss = 1.09696610
Iteration 276, loss = 1.20785902
Iteration 277, loss = 1.09040878
Iteration 278, loss = 1.10694088
Iteration 279, loss = 1.11257837
Iteration 280, loss = 1.03028325
Iteration 281, loss = 1.12936703
Iteration 282, loss = 0.90999584
Iteration 283, loss = 0.93178542
Iteration 284, loss = 0.97913919
Iteration 285, loss = 0.95970737
Iteration 286, loss = 0.97275785
Iteration 287, loss = 0.96607122
Iteration 288, loss = 0.94199572
Iteration 289, loss = 0.94030858
Iteration 290, loss = 0.97480856
Iteration 291, loss = 1.18766722
Iteration 292, loss = 0.95955421
Iteration 293, loss = 1.14358211
Iteration 294, loss = 1.01341890
Iteration 295, loss = 1.04893174
Iteration 296, loss = 1.11959595
Iteration 297, loss = 0.96617024
Iteration 298, loss = 1.09447358
Iteration 299, loss = 0.94485047
Iteration 300, loss = 1.02043179
Iteration 301, loss = 0.96064318
Iteration 302, loss = 0.96863453
Iteration 303, loss = 0.98839385
Iteration 304, loss = 0.94246482
Iteration 305, loss = 0.99226648
Iteration 306, loss = 0.94623320
Iteration 307, loss = 0.95575923
Iteration 308, loss = 0.94957958
Iteration 309, loss = 0.93908912
Iteration 310, loss = 0.95127719
Iteration 311, loss = 0.93213419
Iteration 312, loss = 0.94016645
Iteration 313, loss = 0.92784223
Iteration 314, loss = 0.90837739
Iteration 315, loss = 1.06782549
Iteration 316, loss = 1.09396907
Iteration 317, loss = 0.99866174
Iteration 318, loss = 1.39661006
Iteration 319, loss = 0.94642895
Iteration 320, loss = 1.52418364
Iteration 321, loss = 0.93886551
Iteration 322, loss = 1.41335736
Iteration 323, loss = 0.92557019
Iteration 324, loss = 1.42886090
Iteration 325, loss = 1.09068529
Iteration 326, loss = 1.18474920
Iteration 327, loss = 1.19550965
Iteration 328, loss = 1.01206868
Iteration 329, loss = 1.27015220
Iteration 330, loss = 0.94827616
Iteration 331, loss = 1.25147243
Iteration 332, loss = 1.03592584
Iteration 333, loss = 0.96612797
Iteration 334, loss = 1.08570867
Iteration 335, loss = 0.96144091
Iteration 336, loss = 1.01788981
Iteration 337, loss = 0.99953244
Iteration 338, loss = 0.98251504
Iteration 339, loss = 1.15535782
Iteration 340, loss = 0.93883166
Iteration 341, loss = 1.04670391
Iteration 342, loss = 0.94638689
Iteration 343, loss = 0.98215667
Iteration 344, loss = 0.98148645
Iteration 345, loss = 0.89852395
Iteration 346, loss = 0.96314531
Iteration 347, loss = 0.94088467
Iteration 348, loss = 0.96715059
Iteration 349, loss = 0.92097890
Iteration 350, loss = 1.05042252
Iteration 351, loss = 1.17012982
Iteration 352, loss = 0.97074037
Iteration 353, loss = 1.04354670
Iteration 354, loss = 0.95849669
Iteration 355, loss = 1.02208675
Iteration 356, loss = 0.98919838
Iteration 357, loss = 1.00324298
Iteration 358, loss = 1.01483124
Iteration 359, loss = 0.97965164
Iteration 360, loss = 1.00615262
Iteration 361, loss = 0.97693303
Iteration 362, loss = 0.97351251
Iteration 363, loss = 0.97826391
Iteration 364, loss = 0.95232535
Iteration 365, loss = 0.96724257
Iteration 366, loss = 0.95558157
Iteration 367, loss = 0.95092500
Iteration 368, loss = 0.95540222
Iteration 369, loss = 0.94746340
Iteration 370, loss = 1.26589130
Iteration 371, loss = 0.99194314
Iteration 372, loss = 1.19581797
Iteration 373, loss = 1.18847259
Iteration 374, loss = 1.05561729
Iteration 375, loss = 1.29389286
Iteration 376, loss = 0.99584170
Iteration 377, loss = 1.29737606
Iteration 378, loss = 0.99103380
Iteration 379, loss = 1.19464126
Iteration 380, loss = 0.98598721
Iteration 381, loss = 1.16578832
Iteration 382, loss = 1.07084030
Iteration 383, loss = 1.04222674
Iteration 384, loss = 1.13797961
Iteration 385, loss = 0.98123027
Iteration 386, loss = 1.14883626
Iteration 387, loss = 0.97584080
Iteration 388, loss = 1.09847108
Iteration 389, loss = 1.01026375
Iteration 390, loss = 1.02407189
Iteration 391, loss = 1.05318718
Iteration 392, loss = 0.97849453
Iteration 393, loss = 1.05805140
Iteration 394, loss = 0.97691441
Iteration 395, loss = 1.02054625
Iteration 396, loss = 1.00143977
Iteration 397, loss = 0.97907273
Iteration 398, loss = 1.01526818
Iteration 399, loss = 0.96495222
Iteration 400, loss = 0.99792502
Iteration 401, loss = 0.97539701
Iteration 402, loss = 0.96886606
Iteration 403, loss = 0.98482671
Iteration 404, loss = 0.95491359
Iteration 405, loss = 0.97476723
Iteration 406, loss = 0.94016319
Iteration 407, loss = 1.02066011
Iteration 408, loss = 1.32608593
Iteration 409, loss = 1.02273002
Iteration 410, loss = 1.09597206
Iteration 411, loss = 1.20209538
Iteration 412, loss = 0.97465109
Iteration 413, loss = 1.14808529
Iteration 414, loss = 1.03705291
Iteration 415, loss = 0.97635587
Iteration 416, loss = 1.17167794
Iteration 417, loss = 1.00483574
Iteration 418, loss = 0.98911218
Iteration 419, loss = 1.07797969
Iteration 420, loss = 0.93949691
Iteration 421, loss = 1.15926730
Iteration 422, loss = 1.08655392
Iteration 423, loss = 0.95162415
Iteration 424, loss = 1.11658755
Iteration 425, loss = 0.97353691
Iteration 426, loss = 0.97824778
Iteration 427, loss = 1.03716535
Iteration 428, loss = 1.04759796
Iteration 429, loss = 0.97349368
Iteration 430, loss = 0.96436481
Iteration 431, loss = 1.01939782
Iteration 432, loss = 0.93419677
Iteration 433, loss = 0.97612797
Iteration 434, loss = 0.93497956
Iteration 435, loss = 0.96814638
Iteration 436, loss = 0.97439027
Iteration 437, loss = 0.94332454
Iteration 438, loss = 0.96580995
Iteration 439, loss = 1.00790137
Iteration 440, loss = 1.25173303
Iteration 441, loss = 0.97354687
Iteration 442, loss = 1.20231880
Iteration 443, loss = 1.05690100
Iteration 444, loss = 1.08430549
Iteration 445, loss = 1.18433476
Iteration 446, loss = 1.00985169
Iteration 447, loss = 1.02596268
Iteration 448, loss = 1.11871880
Iteration 449, loss = 0.96451667
Iteration 450, loss = 0.99850928
Iteration 451, loss = 1.04836984
Iteration 452, loss = 0.91154039
Iteration 453, loss = 1.27552842
Iteration 454, loss = 1.65629163
Iteration 455, loss = 1.06649954
Iteration 456, loss = 1.92112971
Iteration 457, loss = 1.12148452
Iteration 458, loss = 2.17478030
Iteration 459, loss = 1.54698366
Iteration 460, loss = 2.08719269
Iteration 461, loss = 2.06140746
Iteration 462, loss = 1.28960013
Iteration 463, loss = 1.64525445
Iteration 464, loss = 1.15492473
Iteration 465, loss = 1.30454136
Iteration 466, loss = 1.24216071
Iteration 467, loss = 1.09562855
Iteration 468, loss = 1.37296912
Iteration 469, loss = 1.02070928
Iteration 470, loss = 1.46109364
Iteration 471, loss = 1.00312122
Iteration 472, loss = 1.51883300
Iteration 473, loss = 1.02087346
Iteration 474, loss = 1.58952491
Iteration 475, loss = 1.08151060
Iteration 476, loss = 1.66880337
Iteration 477, loss = 1.25076535
Iteration 478, loss = 1.66168326
Iteration 479, loss = 1.45016457
Iteration 480, loss = 1.45847826
Iteration 481, loss = 1.45856825
Iteration 482, loss = 1.25417844
Iteration 483, loss = 1.30813071
Iteration 484, loss = 1.19165547
Iteration 485, loss = 1.16341256
Iteration 486, loss = 1.72014132
Iteration 487, loss = 1.16110030
Iteration 488, loss = 1.62966412
Iteration 489, loss = 1.52468464
Iteration 490, loss = 1.22167616
Iteration 491, loss = 1.45363365
Iteration 492, loss = 1.00567448
Iteration 493, loss = 1.30543890
Iteration 494, loss = 0.94090895
Iteration 495, loss = 1.20686670
Iteration 496, loss = 0.92601668
Iteration 497, loss = 1.14687231
Iteration 498, loss = 0.92452711
Iteration 499, loss = 1.10317767
Iteration 500, loss = 0.92283234
Iteration 501, loss = 1.06222030
Iteration 502, loss = 0.91935195
Iteration 503, loss = 1.02204353
Iteration 504, loss = 0.91687898
Iteration 505, loss = 0.98467926
Iteration 506, loss = 0.91833232
Iteration 507, loss = 0.95167361
Iteration 508, loss = 0.90364780
Iteration 509, loss = 1.00267215
Iteration 510, loss = 0.99840049
Iteration 511, loss = 0.94943671
Iteration 512, loss = 0.99850430
Iteration 513, loss = 0.95755727
Iteration 514, loss = 1.01515528
Iteration 515, loss = 0.95142201
Iteration 516, loss = 1.00212260
Iteration 517, loss = 0.93719109
Iteration 518, loss = 0.97763275
Iteration 519, loss = 0.93029528
Iteration 520, loss = 0.95842087
Iteration 521, loss = 0.93558018
Iteration 522, loss = 0.94695913
Iteration 523, loss = 0.94411578
Iteration 524, loss = 0.92995947
Iteration 525, loss = 0.95659446
Iteration 526, loss = 0.97294832
Iteration 527, loss = 0.93860986
Iteration 528, loss = 0.98578130
Iteration 529, loss = 1.02211584
Iteration 530, loss = 0.96367895
Iteration 531, loss = 0.99218656
Iteration 532, loss = 0.99114667
Iteration 533, loss = 0.94284478
Iteration 534, loss = 0.97478947
Iteration 535, loss = 0.95188051
Iteration 536, loss = 0.94100230
Iteration 537, loss = 0.96796199
Iteration 538, loss = 0.94102887
Iteration 539, loss = 0.94783833
Iteration 540, loss = 0.95257852
Iteration 541, loss = 0.96140155
Iteration 542, loss = 0.94749479
Iteration 543, loss = 0.93820470
Iteration 544, loss = 0.94187369
Iteration 545, loss = 0.94273238
Iteration 546, loss = 0.93350379
Iteration 547, loss = 0.93124994
Iteration 548, loss = 0.93169593
Iteration 549, loss = 0.94274980
Iteration 550, loss = 0.92550713
Iteration 551, loss = 0.92893033
Iteration 552, loss = 0.92814103
Iteration 553, loss = 0.92617871
Iteration 554, loss = 0.92270895
Iteration 555, loss = 0.91905364
Iteration 556, loss = 0.89226405
Iteration 557, loss = 0.93084320
Iteration 558, loss = 0.96500805
Iteration 559, loss = 0.88243013
Iteration 560, loss = 0.94497561
Iteration 561, loss = 0.93813531
Iteration 562, loss = 0.94333366
Iteration 563, loss = 0.93419100
Iteration 564, loss = 0.93310286
Iteration 565, loss = 0.93826667
Iteration 566, loss = 0.93422089
Iteration 567, loss = 0.93007434
Iteration 568, loss = 0.99955073
Iteration 569, loss = 1.16794060
Iteration 570, loss = 0.95074651
Iteration 571, loss = 1.07120583
Iteration 572, loss = 0.95332974
Iteration 573, loss = 0.97407777
Iteration 574, loss = 1.01272556
Iteration 575, loss = 0.98890753
Iteration 576, loss = 0.95783485
Iteration 577, loss = 0.98433527
Iteration 578, loss = 0.98306675
Iteration 579, loss = 0.95555269
Iteration 580, loss = 0.96946857
Iteration 581, loss = 0.97814307
Iteration 582, loss = 0.96477737
Iteration 583, loss = 0.97160798
Iteration 584, loss = 0.98548269
Iteration 585, loss = 0.98059048
Iteration 586, loss = 0.94982545
Iteration 587, loss = 0.95333602
Iteration 588, loss = 0.96659901
Iteration 589, loss = 0.89361466
Iteration 590, loss = 0.95544641
Iteration 591, loss = 1.08228217
Iteration 592, loss = 1.10063416
Iteration 593, loss = 0.97939709
Iteration 594, loss = 1.03051830
Iteration 595, loss = 1.05038318
Iteration 596, loss = 1.17406350
Iteration 597, loss = 1.13767481
Iteration 598, loss = 0.98385732
Iteration 599, loss = 1.18520052
Iteration 600, loss = 1.04628751
Iteration 601, loss = 1.00366017
Iteration 602, loss = 1.12762680
Iteration 603, loss = 0.98748301
Iteration 604, loss = 1.00366484
Iteration 605, loss = 1.07451953
Iteration 606, loss = 0.96744370
Iteration 607, loss = 1.00249457
Iteration 608, loss = 1.03744809
Iteration 609, loss = 0.95556771
Iteration 610, loss = 0.98665235
Iteration 611, loss = 1.00343345
Iteration 612, loss = 0.94468841
Iteration 613, loss = 0.97100608
Iteration 614, loss = 0.98180763
Iteration 615, loss = 0.93794326
Iteration 616, loss = 0.95486787
Iteration 617, loss = 0.96105107
Iteration 618, loss = 0.92491158
Iteration 619, loss = 0.91744673
Iteration 620, loss = 0.99470934
Iteration 621, loss = 0.98762173
Iteration 622, loss = 0.93605050
Iteration 623, loss = 0.98000136
Iteration 624, loss = 0.95271762
Iteration 625, loss = 0.92361756
Iteration 626, loss = 0.96017020
Iteration 627, loss = 0.93630973
Iteration 628, loss = 0.92060043
Iteration 629, loss = 0.94572014
Iteration 630, loss = 0.92389330
Iteration 631, loss = 0.91429880
Iteration 632, loss = 0.93199727
Iteration 633, loss = 0.91446373
Iteration 634, loss = 0.90742991
Iteration 635, loss = 0.91900800
Iteration 636, loss = 0.90547780
Iteration 637, loss = 0.90075996
Iteration 638, loss = 0.90951385
Iteration 639, loss = 0.89948582
Iteration 640, loss = 0.89490775
Iteration 641, loss = 0.90033680
Iteration 642, loss = 0.89227578
Iteration 643, loss = 0.88735356
Iteration 644, loss = 0.88490605
Iteration 645, loss = 0.88209283
Iteration 646, loss = 0.88527017
Iteration 647, loss = 0.86101502
Iteration 648, loss = 0.98453688
Iteration 649, loss = 1.04489063
Iteration 650, loss = 0.91046804
Iteration 651, loss = 0.98099483
Iteration 652, loss = 0.98992271
Iteration 653, loss = 0.88834119
Iteration 654, loss = 0.94657424
Iteration 655, loss = 0.95416785
Iteration 656, loss = 0.88518350
Iteration 657, loss = 0.92971818
Iteration 658, loss = 0.93948902
Iteration 659, loss = 0.88552604
Iteration 660, loss = 0.91213897
Iteration 661, loss = 0.92518717
Iteration 662, loss = 0.88324637
Iteration 663, loss = 0.89531606
Iteration 664, loss = 0.92296635
Iteration 665, loss = 0.90952335
Iteration 666, loss = 0.88159083
Iteration 667, loss = 0.89830842
Iteration 668, loss = 0.89727334
Iteration 669, loss = 0.86709483
Iteration 670, loss = 0.87942221
Iteration 671, loss = 0.89230430
Iteration 672, loss = 0.88185052
Iteration 673, loss = 0.86801753
Iteration 674, loss = 1.01346670
Iteration 675, loss = 1.11582569
Iteration 676, loss = 0.87270216
Iteration 677, loss = 1.11762624
Iteration 678, loss = 0.88131145
Iteration 679, loss = 1.13034095
Iteration 680, loss = 1.39054290
Iteration 681, loss = 0.90557792
Iteration 682, loss = 1.53985099
Iteration 683, loss = 0.92610202
Iteration 684, loss = 1.63013200
Iteration 685, loss = 0.96733926
Iteration 686, loss = 2.02489754
Iteration 687, loss = 1.28835949
Iteration 688, loss = 1.87714334
Iteration 689, loss = 1.86352767
Iteration 690, loss = 1.11258473
Iteration 691, loss = 1.55562866
Iteration 692, loss = 0.93281927
Iteration 693, loss = 1.33147148
Iteration 694, loss = 0.91623194
Iteration 695, loss = 1.18014688
Iteration 696, loss = 0.93885482
Iteration 697, loss = 1.04874973
Iteration 698, loss = 0.98843907
Iteration 699, loss = 0.95005267
Iteration 700, loss = 1.03641878
Iteration 701, loss = 0.90041971
Iteration 702, loss = 1.04394642
Iteration 703, loss = 0.88953138
Iteration 704, loss = 1.00428975
Iteration 705, loss = 0.90397990
Iteration 706, loss = 0.95028748
Iteration 707, loss = 0.92851849
Iteration 708, loss = 0.90530487
Iteration 709, loss = 0.94470785
Iteration 710, loss = 0.88209938
Iteration 711, loss = 0.93938233
Iteration 712, loss = 0.88057231
Iteration 713, loss = 0.91473916
Iteration 714, loss = 0.89381929
Iteration 715, loss = 0.88989825
Iteration 716, loss = 0.91691376
Iteration 717, loss = 0.86082214
Iteration 718, loss = 0.91362229
Iteration 719, loss = 0.89250779
Iteration 720, loss = 0.90198676
Iteration 721, loss = 0.90120185
Iteration 722, loss = 0.88945166
Iteration 723, loss = 0.90535738
Iteration 724, loss = 0.89002820
Iteration 725, loss = 0.90000842
Iteration 726, loss = 0.89470559
Iteration 727, loss = 0.89086450
Iteration 728, loss = 0.88860850
Iteration 729, loss = 0.88578311
Iteration 730, loss = 0.93962822
Iteration 731, loss = 1.18459694
Iteration 732, loss = 0.91435364
Iteration 733, loss = 1.06216239
Iteration 734, loss = 0.90794271
Iteration 735, loss = 1.04678155
Iteration 736, loss = 0.95331903
Iteration 737, loss = 0.93210949
Iteration 738, loss = 1.01678317
Iteration 739, loss = 0.89283596
Iteration 740, loss = 0.99091092
Iteration 741, loss = 0.92070417
Iteration 742, loss = 0.91962270
Iteration 743, loss = 0.96050213
Iteration 744, loss = 0.88414964
Iteration 745, loss = 0.93874530
Iteration 746, loss = 0.89850200
Iteration 747, loss = 0.88715727
Iteration 748, loss = 0.91733673
Iteration 749, loss = 0.86949626
Iteration 750, loss = 0.89701804
Iteration 751, loss = 0.88285242
Iteration 752, loss = 0.86261053
Iteration 753, loss = 0.88483936
Iteration 754, loss = 0.85407729
Iteration 755, loss = 0.85977847
Iteration 756, loss = 0.85077790
Iteration 757, loss = 1.05578029
Iteration 758, loss = 1.25017212
Iteration 759, loss = 0.88526904
Iteration 760, loss = 1.28636290
Iteration 761, loss = 0.88029314
Iteration 762, loss = 1.06541981
Iteration 763, loss = 1.01153250
Iteration 764, loss = 0.85985003
Iteration 765, loss = 0.94885386
Iteration 766, loss = 0.90038903
Iteration 767, loss = 0.87222916
Iteration 768, loss = 0.92249409
Iteration 769, loss = 0.86111733
Iteration 770, loss = 0.87564100
Iteration 771, loss = 0.89824317
Iteration 772, loss = 0.85296478
Iteration 773, loss = 0.87864679
Iteration 774, loss = 0.87429281
Iteration 775, loss = 0.84486360
Iteration 776, loss = 0.86683322
Iteration 777, loss = 0.82103096
Iteration 778, loss = 0.98052162
Iteration 779, loss = 0.97814648
Iteration 780, loss = 0.87069654
Iteration 781, loss = 1.00305644
Iteration 782, loss = 0.86835852
Iteration 783, loss = 0.90389768
Iteration 784, loss = 0.93562613
Iteration 785, loss = 0.84450783
Iteration 786, loss = 0.92292440
Iteration 787, loss = 0.87640267
Iteration 788, loss = 0.85236749
Iteration 789, loss = 0.90297883
Iteration 790, loss = 0.83713507
Iteration 791, loss = 0.84805633
Iteration 792, loss = 1.32345406
Iteration 793, loss = 1.06381472
Iteration 794, loss = 1.02973481
Iteration 795, loss = 1.08056164
Iteration 796, loss = 0.88317121
Iteration 797, loss = 0.87347435
Iteration 798, loss = 0.88505595
Iteration 799, loss = 0.86164454
Iteration 800, loss = 0.84988683
Iteration 801, loss = 0.85433694
Iteration 802, loss = 0.84169276
Iteration 803, loss = 0.85271629
Iteration 804, loss = 0.84911376
Iteration 805, loss = 0.86197875
Iteration 806, loss = 0.86565292
Iteration 807, loss = 0.85862599
Iteration 808, loss = 0.85938870
Iteration 809, loss = 0.85391596
Iteration 810, loss = 0.85113130
Iteration 811, loss = 0.85577884
Iteration 812, loss = 0.85264417
Iteration 813, loss = 0.84943847
Iteration 814, loss = 0.85745740
Iteration 815, loss = 0.87298353
Iteration 816, loss = 0.84277714
Iteration 817, loss = 0.89369883
Iteration 818, loss = 0.88345414
Iteration 819, loss = 0.87814350
Iteration 820, loss = 0.86607513
Iteration 821, loss = 0.86005437
Iteration 822, loss = 0.86445752
Iteration 823, loss = 0.86356651
Iteration 824, loss = 0.86584494
Iteration 825, loss = 0.87008975
Iteration 826, loss = 0.86753509
Iteration 827, loss = 0.86665824
Iteration 828, loss = 0.86528433
Iteration 829, loss = 0.86092673
Iteration 830, loss = 0.85989196
Iteration 831, loss = 0.84776142
Iteration 832, loss = 0.93128402
Iteration 833, loss = 1.01604859
Iteration 834, loss = 0.87717088
Iteration 835, loss = 1.00492738
Iteration 836, loss = 0.89857097
Iteration 837, loss = 0.90668272
Iteration 838, loss = 0.94569565
Iteration 839, loss = 0.85664927
Iteration 840, loss = 0.93035688
Iteration 841, loss = 0.88406916
Iteration 842, loss = 0.87179409
Iteration 843, loss = 0.91224176
Iteration 844, loss = 0.85243730
Iteration 845, loss = 0.88185399
Iteration 846, loss = 0.87421521
Iteration 847, loss = 0.84546941
Iteration 848, loss = 0.87700730
Iteration 849, loss = 0.84832583
Iteration 850, loss = 0.84893739
Iteration 851, loss = 0.86093406
Iteration 852, loss = 0.83428456
Iteration 853, loss = 0.84721065
Iteration 854, loss = 0.84148090
Iteration 855, loss = 0.82495021
Iteration 856, loss = 0.83074155
Iteration 857, loss = 0.82602502
Iteration 858, loss = 0.82337707
Iteration 859, loss = 0.81657426
Iteration 860, loss = 0.78689914
Iteration 861, loss = 0.89024098
Iteration 862, loss = 1.08905779
Iteration 863, loss = 0.91154322
Iteration 864, loss = 0.84355669
Iteration 865, loss = 0.90596960
Iteration 866, loss = 0.91298170
Iteration 867, loss = 0.82978651
Iteration 868, loss = 0.84010268
Iteration 869, loss = 0.95630973
Iteration 870, loss = 0.94174616
Iteration 871, loss = 0.83602799
Iteration 872, loss = 0.89912701
Iteration 873, loss = 0.93085299
Iteration 874, loss = 0.83724755
Iteration 875, loss = 0.84508768
Iteration 876, loss = 0.99506671
Iteration 877, loss = 0.94163792
Iteration 878, loss = 0.83025823
Iteration 879, loss = 0.95009175
Iteration 880, loss = 0.97721527
Iteration 881, loss = 0.85227739
Iteration 882, loss = 0.87129901
Iteration 883, loss = 0.93660027
Iteration 884, loss = 0.84394916
Iteration 885, loss = 0.83927921
Iteration 886, loss = 0.90284833
Iteration 887, loss = 0.85160577
Iteration 888, loss = 0.82715404
Iteration 889, loss = 0.87506772
Iteration 890, loss = 0.85340486
Iteration 891, loss = 0.81656010
Iteration 892, loss = 0.84531439
Iteration 893, loss = 0.84839105
Iteration 894, loss = 0.77429604
Iteration 895, loss = 0.90979948
Iteration 896, loss = 1.29846745
Iteration 897, loss = 0.97913805
Iteration 898, loss = 0.86925267
Iteration 899, loss = 1.05325671
Iteration 900, loss = 1.09589979
Iteration 901, loss = 1.10515821
Iteration 902, loss = 0.90833380
Iteration 903, loss = 0.88847615
Iteration 904, loss = 1.05325012
Iteration 905, loss = 0.95008567
Iteration 906, loss = 0.85156080
Iteration 907, loss = 0.94408617
Iteration 908, loss = 0.95107769
Iteration 909, loss = 0.84451409
Iteration 910, loss = 0.86779935
Iteration 911, loss = 0.93488276
Iteration 912, loss = 0.87531428
Iteration 913, loss = 0.82249447
Iteration 914, loss = 0.95157037
Iteration 915, loss = 1.05567816
Iteration 916, loss = 0.86245440
Iteration 917, loss = 0.93149903
Iteration 918, loss = 0.98231429
Iteration 919, loss = 0.84348904
Iteration 920, loss = 0.97230103
Iteration 921, loss = 0.87698789
Iteration 922, loss = 0.89677808
Iteration 923, loss = 1.16355261
Iteration 924, loss = 0.85436963
Iteration 925, loss = 0.99094349
Iteration 926, loss = 1.01873288
Iteration 927, loss = 0.83665310
Iteration 928, loss = 1.00751585
Iteration 929, loss = 0.92279146
Iteration 930, loss = 0.84616138
Iteration 931, loss = 0.97528401
Iteration 932, loss = 0.87513556
Iteration 933, loss = 0.85206589
Iteration 934, loss = 0.93832297
Iteration 935, loss = 0.85356451
Iteration 936, loss = 0.85065865
Iteration 937, loss = 0.90828333
Iteration 938, loss = 0.84278462
Iteration 939, loss = 0.84358804
Iteration 940, loss = 0.88431996
Iteration 941, loss = 0.83661328
Iteration 942, loss = 0.83534681
Iteration 943, loss = 0.86575562
Iteration 944, loss = 0.83184111
Iteration 945, loss = 0.82658665
Iteration 946, loss = 0.85021357
Iteration 947, loss = 0.82788528
Iteration 948, loss = 0.81985949
Iteration 949, loss = 0.83798969
Iteration 950, loss = 0.82406757
Iteration 951, loss = 0.81366222
Iteration 952, loss = 0.82653460
Iteration 953, loss = 0.81937749
Iteration 954, loss = 0.80888517
Iteration 955, loss = 0.80018825
Iteration 956, loss = 0.85390186
Iteration 957, loss = 0.91225820
Iteration 958, loss = 0.85863763
Iteration 959, loss = 0.88088808
Iteration 960, loss = 0.89728212
Iteration 961, loss = 0.83311685
Iteration 962, loss = 0.83480724
Iteration 963, loss = 0.84937768
Iteration 964, loss = 0.81198411
Iteration 965, loss = 0.81646207
Iteration 966, loss = 0.80684000
Iteration 967, loss = 0.91166559
Iteration 968, loss = 1.60148356
Iteration 969, loss = 0.86716045
Iteration 970, loss = 1.49291056
Iteration 971, loss = 0.93613968
Iteration 972, loss = 1.04993780
Iteration 973, loss = 1.23957152
Iteration 974, loss = 0.83332682
Iteration 975, loss = 1.18796295
Iteration 976, loss = 0.95302977
Iteration 977, loss = 0.87176988
Iteration 978, loss = 1.12325759
Iteration 979, loss = 0.86689838
Iteration 980, loss = 0.91297920
Iteration 981, loss = 1.03726775
Iteration 982, loss = 0.83521935
Iteration 983, loss = 0.90831460
Iteration 984, loss = 0.87269132
Iteration 985, loss = 0.85651835
Iteration 986, loss = 0.97179027
Iteration 987, loss = 0.84171657
Iteration 988, loss = 0.85304739
Iteration 989, loss = 0.92479494
Iteration 990, loss = 0.82761930
Iteration 991, loss = 0.84431737
Iteration 992, loss = 0.89362450
Iteration 993, loss = 0.81843871
Iteration 994, loss = 0.88176707
Iteration 995, loss = 1.03602295
Iteration 996, loss = 0.83936237
Iteration 997, loss = 0.90412456
Iteration 998, loss = 0.97408516
Iteration 999, loss = 0.82252371
Iteration 1000, loss = 0.88267253
Iteration 1001, loss = 0.92868582
Iteration 1002, loss = 0.82184781
Iteration 1003, loss = 0.86721711
Iteration 1004, loss = 0.90846611
Iteration 1005, loss = 0.82790385
Iteration 1006, loss = 0.84798168
Iteration 1007, loss = 0.88679674
Iteration 1008, loss = 0.82915648
Iteration 1009, loss = 0.82967283
Iteration 1010, loss = 0.86731198
Iteration 1011, loss = 0.83288384
Iteration 1012, loss = 0.81915480
Iteration 1013, loss = 0.86480145
Iteration 1014, loss = 0.82796577
Iteration 1015, loss = 0.83156936
Iteration 1016, loss = 0.93589722
Iteration 1017, loss = 0.86218062
Iteration 1018, loss = 0.82446262
Iteration 1019, loss = 0.91747192
Iteration 1020, loss = 0.74918931
Iteration 1021, loss = 1.09281999
Iteration 1022, loss = 1.06920520
Iteration 1023, loss = 0.85188698
Iteration 1024, loss = 1.31251855
Iteration 1025, loss = 0.88026652
Iteration 1026, loss = 1.02561263
Iteration 1027, loss = 1.06695935
Iteration 1028, loss = 0.87154416
Iteration 1029, loss = 1.11096489
Iteration 1030, loss = 1.12421080
Iteration 1031, loss = 0.84902785
Iteration 1032, loss = 0.95033806
Iteration 1033, loss = 1.09109290
Iteration 1034, loss = 0.88684092
Iteration 1035, loss = 0.90317778
Iteration 1036, loss = 1.04225248
Iteration 1037, loss = 0.91004769
Iteration 1038, loss = 0.86164657
Iteration 1039, loss = 0.97204211
Iteration 1040, loss = 0.92793214
Iteration 1041, loss = 0.84178219
Iteration 1042, loss = 0.89115145
Iteration 1043, loss = 0.88248600
Iteration 1044, loss = 0.85699747
Iteration 1045, loss = 0.86872081
Iteration 1046, loss = 0.87515726
Iteration 1047, loss = 0.85438493
Iteration 1048, loss = 0.85248230
Iteration 1049, loss = 0.86699962
Iteration 1050, loss = 0.85891090
Iteration 1051, loss = 0.83605056
Iteration 1052, loss = 0.88041679
Iteration 1053, loss = 1.03439460
Iteration 1054, loss = 0.89309655
Iteration 1055, loss = 0.89518977
Iteration 1056, loss = 0.98679957
Iteration 1057, loss = 0.87053389
Iteration 1058, loss = 0.87974738
Iteration 1059, loss = 0.94238168
Iteration 1060, loss = 0.85848087
Iteration 1061, loss = 0.86638247
Iteration 1062, loss = 0.91394231
Iteration 1063, loss = 0.85471910
Iteration 1064, loss = 0.85170438
Iteration 1065, loss = 0.88988244
Iteration 1066, loss = 0.84936517
Iteration 1067, loss = 0.83325103
Iteration 1068, loss = 0.84773596
Iteration 1069, loss = 0.83625468
Iteration 1070, loss = 0.83202865
Iteration 1071, loss = 0.86063294
Iteration 1072, loss = 0.85778822
Iteration 1073, loss = 0.82885330
Iteration 1074, loss = 0.84266644
Iteration 1075, loss = 0.84695089
Iteration 1076, loss = 0.82370890
Iteration 1077, loss = 0.82888136
Iteration 1078, loss = 0.83754523
Iteration 1079, loss = 0.82174443
Iteration 1080, loss = 0.82022743
Iteration 1081, loss = 0.81629869
Iteration 1082, loss = 0.82701371
Iteration 1083, loss = 0.83190736
Iteration 1084, loss = 0.81622893
Iteration 1085, loss = 0.82123344
Iteration 1086, loss = 0.82324333
Iteration 1087, loss = 0.80957058
Iteration 1088, loss = 0.81250397
Iteration 1089, loss = 0.81650374
Iteration 1090, loss = 0.80711645
Iteration 1091, loss = 0.80716956
Iteration 1092, loss = 0.81010138
Iteration 1093, loss = 0.80296953
Iteration 1094, loss = 0.80148243
Iteration 1095, loss = 0.80401231
Iteration 1096, loss = 0.79906942
Iteration 1097, loss = 0.79684615
Iteration 1098, loss = 0.79892331
Iteration 1099, loss = 0.79577304
Iteration 1100, loss = 0.79309388
Iteration 1101, loss = 0.79417916
Iteration 1102, loss = 0.79200564
Iteration 1103, loss = 0.78933013
Iteration 1104, loss = 0.78971753
Iteration 1105, loss = 0.78878105
Iteration 1106, loss = 0.78606897
Iteration 1107, loss = 0.78590722
Iteration 1108, loss = 0.78641779
Iteration 1109, loss = 0.78509032
Iteration 1110, loss = 0.78365472
Iteration 1111, loss = 0.78181679
Iteration 1112, loss = 0.77954773
Iteration 1113, loss = 0.77897353
Iteration 1114, loss = 0.77868449
Iteration 1115, loss = 0.77514322
Iteration 1116, loss = 0.80840152
Iteration 1117, loss = 0.81585901
Iteration 1118, loss = 0.77920559
Iteration 1119, loss = 0.79316833
Iteration 1120, loss = 0.79821553
Iteration 1121, loss = 0.76281889
Iteration 1122, loss = 0.63219544
Iteration 1123, loss = 0.81440028
Iteration 1124, loss = 0.86856550
Iteration 1125, loss = 0.78618825
Iteration 1126, loss = 0.82063740
Iteration 1127, loss = 0.84078715
Iteration 1128, loss = 0.77454096
Iteration 1129, loss = 0.80385004
Iteration 1130, loss = 0.81880073
Iteration 1131, loss = 0.77133786
Iteration 1132, loss = 0.78993659
Iteration 1133, loss = 0.80373333
Iteration 1134, loss = 0.76832858
Iteration 1135, loss = 0.77906604
Iteration 1136, loss = 0.79081088
Iteration 1137, loss = 0.76271429
Iteration 1138, loss = 0.76476833
Iteration 1139, loss = 0.77575514
Iteration 1140, loss = 0.75701461
Iteration 1141, loss = 0.75493473
Iteration 1142, loss = 0.77075296
Iteration 1143, loss = 0.76216677
Iteration 1144, loss = 0.74636584
Iteration 1145, loss = 0.75248745
Iteration 1146, loss = 0.68960867
Iteration 1147, loss = 0.78971448
Iteration 1148, loss = 1.00940773
Iteration 1149, loss = 1.11158572
Iteration 1150, loss = 0.85026644
Iteration 1151, loss = 0.92358995
Iteration 1152, loss = 0.96451933
Iteration 1153, loss = 0.78620015
Iteration 1154, loss = 0.92756952
Iteration 1155, loss = 0.85192757
Iteration 1156, loss = 0.78304200
Iteration 1157, loss = 0.80431759
Iteration 1158, loss = 0.99621448
Iteration 1159, loss = 0.86076144
Iteration 1160, loss = 0.91520821
Iteration 1161, loss = 1.14288277
Iteration 1162, loss = 0.81975810
Iteration 1163, loss = 1.14349565
Iteration 1164, loss = 0.81543318
Iteration 1165, loss = 0.96436309
Iteration 1166, loss = 0.81983653
Iteration 1167, loss = 0.90886837
Iteration 1168, loss = 0.84981902
Iteration 1169, loss = 0.84132247
Iteration 1170, loss = 0.88242879
Iteration 1171, loss = 0.81662859
Iteration 1172, loss = 0.88210522
Iteration 1173, loss = 0.82466550
Iteration 1174, loss = 0.84659644
Iteration 1175, loss = 0.84499812
Iteration 1176, loss = 0.80787814
Iteration 1177, loss = 0.90044340
Iteration 1178, loss = 0.83745003
Iteration 1179, loss = 0.87244268
Iteration 1180, loss = 0.86227057
Iteration 1181, loss = 0.82616045
Iteration 1182, loss = 0.86291461
Iteration 1183, loss = 0.82173135
Iteration 1184, loss = 0.85208052
Iteration 1185, loss = 0.83457200
Iteration 1186, loss = 0.83389160
Iteration 1187, loss = 0.84322540
Iteration 1188, loss = 0.82051487
Iteration 1189, loss = 0.83825959
Iteration 1190, loss = 0.88693688
Iteration 1191, loss = 1.02645421
Iteration 1192, loss = 0.99018666
Iteration 1193, loss = 1.55597731
Iteration 1194, loss = 1.23923134
Iteration 1195, loss = 1.38340593
Iteration 1196, loss = 1.33674940
Iteration 1197, loss = 1.12207998
Iteration 1198, loss = 1.24121711
Iteration 1199, loss = 1.01431504
Iteration 1200, loss = 1.12143353
Iteration 1201, loss = 0.99181997
Iteration 1202, loss = 1.02621055
Iteration 1203, loss = 0.99548282
Iteration 1204, loss = 0.94941416
Iteration 1205, loss = 1.01323130
Iteration 1206, loss = 0.90519021
Iteration 1207, loss = 1.02510660
Iteration 1208, loss = 0.87336001
Iteration 1209, loss = 1.02460982
Iteration 1210, loss = 0.85092848
Iteration 1211, loss = 1.01064799
Iteration 1212, loss = 0.83436432
Iteration 1213, loss = 0.98770949
Iteration 1214, loss = 0.82263762
Iteration 1215, loss = 0.95413597
Iteration 1216, loss = 0.79202219
Iteration 1217, loss = 0.83653189
Iteration 1218, loss = 0.83683496
Iteration 1219, loss = 0.83874150
Iteration 1220, loss = 0.83282364
Iteration 1221, loss = 0.82252438
Iteration 1222, loss = 0.82243886
Iteration 1223, loss = 0.81457437
Iteration 1224, loss = 0.76435703
Iteration 1225, loss = 0.87259212
Iteration 1226, loss = 0.89735298
Iteration 1227, loss = 0.82408017
Iteration 1228, loss = 0.87106837
Iteration 1229, loss = 0.88455838
Iteration 1230, loss = 0.88531446
Iteration 1231, loss = 0.87489766
Iteration 1232, loss = 0.88571364
Iteration 1233, loss = 0.86372407
Iteration 1234, loss = 0.88147178
Iteration 1235, loss = 0.86576317
Iteration 1236, loss = 0.88384965
Iteration 1237, loss = 0.87631715
Iteration 1238, loss = 0.88222536
Iteration 1239, loss = 0.87987178
Iteration 1240, loss = 0.87503863
Iteration 1241, loss = 0.87900119
Iteration 1242, loss = 0.87127404
Iteration 1243, loss = 0.87820612
Iteration 1244, loss = 0.87017774
Iteration 1245, loss = 0.86669656
Iteration 1246, loss = 0.90964167
Iteration 1247, loss = 0.90022346
Iteration 1248, loss = 0.88934877
Iteration 1249, loss = 0.90949690
Iteration 1250, loss = 0.87320113
Iteration 1251, loss = 0.90095958
Iteration 1252, loss = 0.86991249
Iteration 1253, loss = 0.87108312
Iteration 1254, loss = 0.86689558
Iteration 1255, loss = 0.88839598
Iteration 1256, loss = 0.89389412
Iteration 1257, loss = 0.85625729
Iteration 1258, loss = 0.91552485
Iteration 1259, loss = 0.97009210
Iteration 1260, loss = 0.88250430
Iteration 1261, loss = 0.97153785
Iteration 1262, loss = 0.89579207
Iteration 1263, loss = 0.84560255
Iteration 1264, loss = 0.94203892
Iteration 1265, loss = 0.98406111
Iteration 1266, loss = 0.91602317
Iteration 1267, loss = 0.99172640
Iteration 1268, loss = 0.89417766
Iteration 1269, loss = 0.95003408
Iteration 1270, loss = 0.91237700
Iteration 1271, loss = 0.91465859
Iteration 1272, loss = 0.94023036
Iteration 1273, loss = 0.89614483
Iteration 1274, loss = 0.93724593
Iteration 1275, loss = 0.89777386
Iteration 1276, loss = 0.91300569
Iteration 1277, loss = 0.91080235
Iteration 1278, loss = 0.89325500
Iteration 1279, loss = 0.91490989
Iteration 1280, loss = 0.88887783
Iteration 1281, loss = 0.90305472
Iteration 1282, loss = 0.89428004
Iteration 1283, loss = 0.88771987
Iteration 1284, loss = 0.89704455
Iteration 1285, loss = 0.88085115
Iteration 1286, loss = 0.88981616
Iteration 1287, loss = 0.88111079
Iteration 1288, loss = 0.87834950
Iteration 1289, loss = 0.88159614
Iteration 1290, loss = 0.87157808
Iteration 1291, loss = 0.87646589
Iteration 1292, loss = 0.86945685
Iteration 1293, loss = 0.86870796
Iteration 1294, loss = 0.89371641
Iteration 1295, loss = 0.87230957
Iteration 1296, loss = 0.88008028
Iteration 1297, loss = 0.87153333
Iteration 1298, loss = 0.85946037
Iteration 1299, loss = 0.87065293
Iteration 1300, loss = 0.85635890
Iteration 1301, loss = 0.86273493
Iteration 1302, loss = 0.85684000
Iteration 1303, loss = 0.85003619
Iteration 1304, loss = 0.85473532
Iteration 1305, loss = 0.84490200
Iteration 1306, loss = 0.84812814
Iteration 1307, loss = 0.84458846
Iteration 1308, loss = 0.83990913
Iteration 1309, loss = 0.84187858
Iteration 1310, loss = 0.83521252
Iteration 1311, loss = 0.83508736
Iteration 1312, loss = 0.83270849
Iteration 1313, loss = 0.83559415
Iteration 1314, loss = 0.83849731
Iteration 1315, loss = 0.82849559
Iteration 1316, loss = 0.83057675
Iteration 1317, loss = 0.82755622
Iteration 1318, loss = 0.82268067
Iteration 1319, loss = 0.82588746
Iteration 1320, loss = 0.82109187
Iteration 1321, loss = 0.81912103
Iteration 1322, loss = 0.81978816
Iteration 1323, loss = 0.81499218
Iteration 1324, loss = 0.81502344
Iteration 1325, loss = 0.81387727
Iteration 1326, loss = 0.81018085
Iteration 1327, loss = 0.81041922
Iteration 1328, loss = 0.80736077
Iteration 1329, loss = 0.80535210
Iteration 1330, loss = 0.80515668
Iteration 1331, loss = 0.80326996
Iteration 1332, loss = 0.80070818
Iteration 1333, loss = 0.79833960
Iteration 1334, loss = 0.79581293
Iteration 1335, loss = 0.79306645
Iteration 1336, loss = 0.78928379
Iteration 1337, loss = 0.80700897
Iteration 1338, loss = 0.95788388
Iteration 1339, loss = 1.09477186
Iteration 1340, loss = 0.85614792
Iteration 1341, loss = 0.83486908
Iteration 1342, loss = 0.99521622
Iteration 1343, loss = 0.80822300
Iteration 1344, loss = 0.90634303
Iteration 1345, loss = 1.32419737
Iteration 1346, loss = 0.82763422
Iteration 1347, loss = 1.13028042
Iteration 1348, loss = 1.04583994
Iteration 1349, loss = 0.82553138
Iteration 1350, loss = 1.12007597
Iteration 1351, loss = 0.87069838
Iteration 1352, loss = 0.85930195
Iteration 1353, loss = 1.03626131
Iteration 1354, loss = 0.82313629
Iteration 1355, loss = 0.89044777
Iteration 1356, loss = 0.97467412
Iteration 1357, loss = 0.81395652
Iteration 1358, loss = 0.88531421
Iteration 1359, loss = 0.92062730
Iteration 1360, loss = 0.80382104
Iteration 1361, loss = 0.86420035
Iteration 1362, loss = 0.88901795
Iteration 1363, loss = 0.80427400
Iteration 1364, loss = 0.84615705
Iteration 1365, loss = 0.86861319
Iteration 1366, loss = 0.80371683
Iteration 1367, loss = 0.82648959
Iteration 1368, loss = 0.84978517
Iteration 1369, loss = 0.80164253
Iteration 1370, loss = 0.80937007
Iteration 1371, loss = 0.83251169
Iteration 1372, loss = 0.79782546
Iteration 1373, loss = 0.79082890
Iteration 1374, loss = 0.88320664
Iteration 1375, loss = 1.08344293
Iteration 1376, loss = 0.86994922
Iteration 1377, loss = 0.93428287
Iteration 1378, loss = 1.02098155
Iteration 1379, loss = 0.82861503
Iteration 1380, loss = 0.93769829
Iteration 1381, loss = 0.98508663
Iteration 1382, loss = 0.81811404
Iteration 1383, loss = 0.95955572
Iteration 1384, loss = 0.91122740
Iteration 1385, loss = 0.83570740
Iteration 1386, loss = 0.95383507
Iteration 1387, loss = 0.88034866
Iteration 1388, loss = 0.85559822
Iteration 1389, loss = 0.93426374
Iteration 1390, loss = 0.86281616
Iteration 1391, loss = 0.85661896
Iteration 1392, loss = 0.90807290
Iteration 1393, loss = 0.85401530
Iteration 1394, loss = 0.85903665
Iteration 1395, loss = 0.89758864
Iteration 1396, loss = 0.85863281
Iteration 1397, loss = 0.88559595
Iteration 1398, loss = 1.04960250
Iteration 1399, loss = 0.91382573
Iteration 1400, loss = 0.93327801
Iteration 1401, loss = 1.03217175
Iteration 1402, loss = 0.89780434
Iteration 1403, loss = 0.94874789
Iteration 1404, loss = 0.96639576
Iteration 1405, loss = 0.87289791
Iteration 1406, loss = 0.93880735
Iteration 1407, loss = 0.92010440
Iteration 1408, loss = 0.88233994
Iteration 1409, loss = 0.94057865
Iteration 1410, loss = 0.90251788
Iteration 1411, loss = 0.89318313
Iteration 1412, loss = 0.92742518
Iteration 1413, loss = 0.88803534
Iteration 1414, loss = 0.89337276
Iteration 1415, loss = 0.89741304
Iteration 1416, loss = 0.88480067
Iteration 1417, loss = 0.88781445
Iteration 1418, loss = 0.89846985
Iteration 1419, loss = 0.89336101
Iteration 1420, loss = 0.90535545
Iteration 1421, loss = 0.91181301
Iteration 1422, loss = 0.89326457
Iteration 1423, loss = 0.87681598
Iteration 1424, loss = 0.88050349
Iteration 1425, loss = 0.89152066
Iteration 1426, loss = 0.88801822
Iteration 1427, loss = 0.87094595
Iteration 1428, loss = 0.87187931
Iteration 1429, loss = 0.90721162
Iteration 1430, loss = 0.92493171
Iteration 1431, loss = 0.89117796
Iteration 1432, loss = 0.85920211
Iteration 1433, loss = 0.86582147
Iteration 1434, loss = 0.88862011
Iteration 1435, loss = 0.88546656
Iteration 1436, loss = 0.85951841
Iteration 1437, loss = 0.84657730
Iteration 1438, loss = 0.84871851
Iteration 1439, loss = 0.84338803
Iteration 1440, loss = 0.84969512
Iteration 1441, loss = 0.84969909
Iteration 1442, loss = 0.74966905
Iteration 1443, loss = 1.02755484
Iteration 1444, loss = 1.55499486
Iteration 1445, loss = 0.95204968
Iteration 1446, loss = 1.02893639
Iteration 1447, loss = 1.41399491
Iteration 1448, loss = 0.92093276
Iteration 1449, loss = 0.97955966
Iteration 1450, loss = 1.28463372
Iteration 1451, loss = 0.91316823
Iteration 1452, loss = 0.92414560
Iteration 1453, loss = 1.18279548
Iteration 1454, loss = 0.94224315
Iteration 1455, loss = 0.86987633
Iteration 1456, loss = 1.06368792
Iteration 1457, loss = 0.99623345
Iteration 1458, loss = 0.85270600
Iteration 1459, loss = 0.93608894
Iteration 1460, loss = 1.02113767
Iteration 1461, loss = 0.89432162
Iteration 1462, loss = 0.85331005
Iteration 1463, loss = 0.91068476
Iteration 1464, loss = 0.91395403
Iteration 1465, loss = 0.85378513
Iteration 1466, loss = 0.84143696
Iteration 1467, loss = 0.88343073
Iteration 1468, loss = 0.86560823
Iteration 1469, loss = 0.89392552
Iteration 1470, loss = 0.90006911
Iteration 1471, loss = 0.88399364
Iteration 1472, loss = 0.87168502
Iteration 1473, loss = 0.87406127
Iteration 1474, loss = 0.88286474
Iteration 1475, loss = 0.87512290
Iteration 1476, loss = 0.86612834
Iteration 1477, loss = 0.86830236
Iteration 1478, loss = 0.87026169
Iteration 1479, loss = 0.84210630
Iteration 1480, loss = 0.92857940
Iteration 1481, loss = 0.99630833
Iteration 1482, loss = 0.89888526
Iteration 1483, loss = 0.88980853
Iteration 1484, loss = 0.95434992
Iteration 1485, loss = 0.90660204
Iteration 1486, loss = 0.87044108
Iteration 1487, loss = 0.91778574
Iteration 1488, loss = 0.91366466
Iteration 1489, loss = 0.86734039
Iteration 1490, loss = 0.88362460
Iteration 1491, loss = 0.90449799
Iteration 1492, loss = 0.87142950
Iteration 1493, loss = 0.86051783
Iteration 1494, loss = 0.88310573
Iteration 1495, loss = 0.87459720
Iteration 1496, loss = 0.85291535
Iteration 1497, loss = 0.86196056
Iteration 1498, loss = 0.86971866
Iteration 1499, loss = 0.85236811
Iteration 1500, loss = 0.84541064
Iteration 1501, loss = 0.85232632
Iteration 1502, loss = 0.84914794
Iteration 1503, loss = 0.83875273
Iteration 1504, loss = 0.83550533
Iteration 1505, loss = 0.83595334
Iteration 1506, loss = 0.87721232
Iteration 1507, loss = 1.09926769
Iteration 1508, loss = 1.01478740
Iteration 1509, loss = 0.88330681
Iteration 1510, loss = 1.05227099
Iteration 1511, loss = 0.98655849
Iteration 1512, loss = 0.84920800
Iteration 1513, loss = 0.94523644
Iteration 1514, loss = 1.01263893
Iteration 1515, loss = 0.87062472
Iteration 1516, loss = 0.89314103
Iteration 1517, loss = 0.98057869
Iteration 1518, loss = 0.87700991
Iteration 1519, loss = 0.87537612
Iteration 1520, loss = 0.94605168
Iteration 1521, loss = 0.87832880
Iteration 1522, loss = 0.85373012
Iteration 1523, loss = 0.90793733
Iteration 1524, loss = 0.87518273
Iteration 1525, loss = 0.84071897
Iteration 1526, loss = 0.88071020
Iteration 1527, loss = 0.87837742
Iteration 1528, loss = 0.84133750
Iteration 1529, loss = 0.85777065
Iteration 1530, loss = 0.86922924
Iteration 1531, loss = 0.83876367
Iteration 1532, loss = 0.83660683
Iteration 1533, loss = 0.85276623
Iteration 1534, loss = 0.83675142
Iteration 1535, loss = 0.80013204
Iteration 1536, loss = 0.84555480
Iteration 1537, loss = 0.86453054
Iteration 1538, loss = 0.87627807
Iteration 1539, loss = 0.84980516
Iteration 1540, loss = 0.85298395
Iteration 1541, loss = 0.85801595
Iteration 1542, loss = 0.84241332
Iteration 1543, loss = 0.84884082
Iteration 1544, loss = 0.85529303
Iteration 1545, loss = 0.85054266
Iteration 1546, loss = 0.85305384
Iteration 1547, loss = 0.87655262
Iteration 1548, loss = 0.86542129
Iteration 1549, loss = 0.84813498
Iteration 1550, loss = 0.85914812
Iteration 1551, loss = 0.86492746
Iteration 1552, loss = 0.84939782
Iteration 1553, loss = 0.84598608
Iteration 1554, loss = 0.85542535
Iteration 1555, loss = 0.85070031
Iteration 1556, loss = 0.83934082
Iteration 1557, loss = 0.84678186
Iteration 1558, loss = 0.88209520
Iteration 1559, loss = 0.93583173
Iteration 1560, loss = 0.85377251
Iteration 1561, loss = 0.86542785
Iteration 1562, loss = 0.84747004
Iteration 1563, loss = 0.89138134
Iteration 1564, loss = 0.98906103
Iteration 1565, loss = 0.86064723
Iteration 1566, loss = 0.78861653
Iteration 1567, loss = 0.86210405
Iteration 1568, loss = 0.90250986
Iteration 1569, loss = 0.96218437
Iteration 1570, loss = 1.01357859
Iteration 1571, loss = 0.91174866
Iteration 1572, loss = 0.97042547
Iteration 1573, loss = 1.00642596
Iteration 1574, loss = 0.90659771
Iteration 1575, loss = 0.95328509
Iteration 1576, loss = 0.93802048
Iteration 1577, loss = 0.88283605
Iteration 1578, loss = 0.93200814
Iteration 1579, loss = 0.91568870
Iteration 1580, loss = 0.90104603
Iteration 1581, loss = 0.93786117
Iteration 1582, loss = 0.93475417
Iteration 1583, loss = 0.90511750
Iteration 1584, loss = 0.90479366
Iteration 1585, loss = 0.92194310
Iteration 1586, loss = 0.89790574
Iteration 1587, loss = 0.89504086
Iteration 1588, loss = 0.90899425
Iteration 1589, loss = 0.89449645
Iteration 1590, loss = 0.89234969
Iteration 1591, loss = 0.90387447
Iteration 1592, loss = 0.89321350
Iteration 1593, loss = 0.88767169
Iteration 1594, loss = 0.89383977
Iteration 1595, loss = 0.88516823
Iteration 1596, loss = 0.87863384
Iteration 1597, loss = 0.88295617
Iteration 1598, loss = 0.87751573
Iteration 1599, loss = 0.87100092
Iteration 1600, loss = 0.86915419
Iteration 1601, loss = 0.85861080
Iteration 1602, loss = 0.89377781
Iteration 1603, loss = 0.95534270
Iteration 1604, loss = 0.89150838
Iteration 1605, loss = 0.88466025
Iteration 1606, loss = 0.91892957
Iteration 1607, loss = 0.87072209
Iteration 1608, loss = 0.90969645
Iteration 1609, loss = 1.04799031
Iteration 1610, loss = 0.95763402
Iteration 1611, loss = 0.90665759
Iteration 1612, loss = 1.00818342
Iteration 1613, loss = 0.90892025
Iteration 1614, loss = 0.87991532
Iteration 1615, loss = 0.96203640
Iteration 1616, loss = 0.89619343
Iteration 1617, loss = 0.88961042
Iteration 1618, loss = 0.90528338
Iteration 1619, loss = 0.89196208
Iteration 1620, loss = 0.88630131
Iteration 1621, loss = 0.94669294
Iteration 1622, loss = 0.94311147
Iteration 1623, loss = 0.89758551
Iteration 1624, loss = 0.94718872
Iteration 1625, loss = 0.90497868
Iteration 1626, loss = 0.91135110
Iteration 1627, loss = 0.93339399
Iteration 1628, loss = 0.89378129
Iteration 1629, loss = 0.91724765
Iteration 1630, loss = 0.90830977
Iteration 1631, loss = 0.89082382
Iteration 1632, loss = 0.91166256
Iteration 1633, loss = 0.88934566
Iteration 1634, loss = 0.88895807
Iteration 1635, loss = 0.89002104
Iteration 1636, loss = 0.88663000
Iteration 1637, loss = 0.87615338
Iteration 1638, loss = 0.91154309
Iteration 1639, loss = 0.95639125
Iteration 1640, loss = 0.89913814
Iteration 1641, loss = 0.93011591
Iteration 1642, loss = 0.91715883
Iteration 1643, loss = 0.88258388
Iteration 1644, loss = 0.90497560
Iteration 1645, loss = 1.07729689
Iteration 1646, loss = 1.26195677
Iteration 1647, loss = 0.91682362
Iteration 1648, loss = 0.98334280
Iteration 1649, loss = 1.15850246
Iteration 1650, loss = 0.90127816
Iteration 1651, loss = 0.96406047
Iteration 1652, loss = 1.07744225
Iteration 1653, loss = 0.88671247
Iteration 1654, loss = 0.94430481
Iteration 1655, loss = 1.03405184
Iteration 1656, loss = 0.89261854
Iteration 1657, loss = 0.89636256
Iteration 1658, loss = 0.97098218
Iteration 1659, loss = 0.88365057
Iteration 1660, loss = 0.87931494
Iteration 1661, loss = 0.93786566
Iteration 1662, loss = 0.87917412
Iteration 1663, loss = 0.86505565
Iteration 1664, loss = 0.91038324
Iteration 1665, loss = 0.87450017
Iteration 1666, loss = 0.85419414
Iteration 1667, loss = 0.88813205
Iteration 1668, loss = 0.86882852
Iteration 1669, loss = 0.84552318
Iteration 1670, loss = 0.86887593
Iteration 1671, loss = 0.86337226
Iteration 1672, loss = 0.84171793
Iteration 1673, loss = 0.85331761
Iteration 1674, loss = 0.85867195
Iteration 1675, loss = 0.83968729
Iteration 1676, loss = 0.83874868
Iteration 1677, loss = 0.84245172
Iteration 1678, loss = 0.83135709
Iteration 1679, loss = 0.82875915
Iteration 1680, loss = 0.82950165
Iteration 1681, loss = 0.78827904
Iteration 1682, loss = 0.92691766
Iteration 1683, loss = 1.14571642
Iteration 1684, loss = 0.87071395
Iteration 1685, loss = 1.13265664
Iteration 1686, loss = 0.84231790
Iteration 1687, loss = 1.02046835
Iteration 1688, loss = 0.88327137
Iteration 1689, loss = 0.90398959
Iteration 1690, loss = 0.93397162
Iteration 1691, loss = 0.80592485
Iteration 1692, loss = 0.83677283
Iteration 1693, loss = 1.00435981
Iteration 1694, loss = 0.84474768
Iteration 1695, loss = 0.92265647
Iteration 1696, loss = 0.87734262
Iteration 1697, loss = 0.90002366
Iteration 1698, loss = 0.86389329
Iteration 1699, loss = 0.93345267
Iteration 1700, loss = 0.86922521
Iteration 1701, loss = 0.90366257
Iteration 1702, loss = 0.86295874
Iteration 1703, loss = 0.86165189
Iteration 1704, loss = 1.14734853
Iteration 1705, loss = 0.87650565
Iteration 1706, loss = 1.13503716
Iteration 1707, loss = 0.88962404
Iteration 1708, loss = 1.07707122
Iteration 1709, loss = 0.90468372
Iteration 1710, loss = 1.00175652
Iteration 1711, loss = 0.94115857
Iteration 1712, loss = 0.93854900
Iteration 1713, loss = 0.97736942
Iteration 1714, loss = 0.90513656
Iteration 1715, loss = 0.99141388
Iteration 1716, loss = 0.90185674
Iteration 1717, loss = 0.97343095
Iteration 1718, loss = 0.91867431
Iteration 1719, loss = 0.94013522
Iteration 1720, loss = 0.93847502
Iteration 1721, loss = 0.91402564
Iteration 1722, loss = 0.94688933
Iteration 1723, loss = 0.90373477
Iteration 1724, loss = 0.93637491
Iteration 1725, loss = 0.90477361
Iteration 1726, loss = 0.91462672
Iteration 1727, loss = 0.89007629
Iteration 1728, loss = 0.96788335
Iteration 1729, loss = 1.74665668
Iteration 1730, loss = 1.13430402
Iteration 1731, loss = 1.89184552
Iteration 1732, loss = 1.54634596
Iteration 1733, loss = 1.75238922
Iteration 1734, loss = 1.69677534
Iteration 1735, loss = 1.36676866
Iteration 1736, loss = 1.48464512
Iteration 1737, loss = 1.12210824
Iteration 1738, loss = 1.29493483
Iteration 1739, loss = 1.02982697
Iteration 1740, loss = 1.17077999
Iteration 1741, loss = 1.02350819
Iteration 1742, loss = 1.09895756
Iteration 1743, loss = 1.04298338
Iteration 1744, loss = 1.04725257
Iteration 1745, loss = 1.05825627
Iteration 1746, loss = 1.00383796
Iteration 1747, loss = 1.06070409
Iteration 1748, loss = 0.97128860
Iteration 1749, loss = 1.06071651
Iteration 1750, loss = 0.95382685
Iteration 1751, loss = 1.04237949
Iteration 1752, loss = 0.96417507
Iteration 1753, loss = 1.02218921
Iteration 1754, loss = 0.96611654
Iteration 1755, loss = 0.99214231
Iteration 1756, loss = 0.96933925
Iteration 1757, loss = 0.97061586
Iteration 1758, loss = 0.97716573
Iteration 1759, loss = 0.96018716
Iteration 1760, loss = 0.98051694
Iteration 1761, loss = 0.95168735
Iteration 1762, loss = 0.96259749
Iteration 1763, loss = 0.96770789
Iteration 1764, loss = 0.95961191
Iteration 1765, loss = 0.97004736
Iteration 1766, loss = 0.95940576
Iteration 1767, loss = 0.96566161
Iteration 1768, loss = 0.95687734
Iteration 1769, loss = 0.95029061
Iteration 1770, loss = 1.03829150
Iteration 1771, loss = 1.13108137
Iteration 1772, loss = 1.01067374
Iteration 1773, loss = 1.13347041
Iteration 1774, loss = 0.97975042
Iteration 1775, loss = 1.15459568
Iteration 1776, loss = 0.98425375
Iteration 1777, loss = 1.13798363
Iteration 1778, loss = 0.98686641
Iteration 1779, loss = 1.05287375
Iteration 1780, loss = 1.03788329
Iteration 1781, loss = 0.99194151
Iteration 1782, loss = 1.04073523
Iteration 1783, loss = 0.97149626
Iteration 1784, loss = 1.03559224
Iteration 1785, loss = 0.96275091
Iteration 1786, loss = 1.02358470
Iteration 1787, loss = 0.95830385
Iteration 1788, loss = 1.00254919
Iteration 1789, loss = 0.95577229
Iteration 1790, loss = 0.97526590
Iteration 1791, loss = 0.93382855
Iteration 1792, loss = 0.98315927
Iteration 1793, loss = 1.00172788
Iteration 1794, loss = 0.97836744
Iteration 1795, loss = 0.98093582
Iteration 1796, loss = 0.95535880
Iteration 1797, loss = 0.96643829
Iteration 1798, loss = 0.95113504
Iteration 1799, loss = 0.96265209
Iteration 1800, loss = 0.94793369
Iteration 1801, loss = 0.95103523
Iteration 1802, loss = 0.92602443
Iteration 1803, loss = 0.98927643
Iteration 1804, loss = 0.98668957
Iteration 1805, loss = 0.97623111
Iteration 1806, loss = 0.97018865
Iteration 1807, loss = 0.96008079
Iteration 1808, loss = 0.95674050
Iteration 1809, loss = 0.95183091
Iteration 1810, loss = 0.95217311
Iteration 1811, loss = 0.94822813
Iteration 1812, loss = 0.94829133
Iteration 1813, loss = 0.94267885
Iteration 1814, loss = 0.94209491
Iteration 1815, loss = 0.93620806
Iteration 1816, loss = 0.93624767
Iteration 1817, loss = 0.93056515
Iteration 1818, loss = 0.93077249
Iteration 1819, loss = 0.91993397
Iteration 1820, loss = 0.92073961
Iteration 1821, loss = 0.91982534
Iteration 1822, loss = 0.91820043
Iteration 1823, loss = 0.91764685
Iteration 1824, loss = 0.91293851
Iteration 1825, loss = 0.91104356
Iteration 1826, loss = 0.90874073
Iteration 1827, loss = 0.90540806
Iteration 1828, loss = 0.90323636
Iteration 1829, loss = 0.90037503
Iteration 1830, loss = 0.89762287
Iteration 1831, loss = 0.89470545
Iteration 1832, loss = 0.90637885
Iteration 1833, loss = 1.03770090
Iteration 1834, loss = 0.94769099
Iteration 1835, loss = 0.92893214
Iteration 1836, loss = 0.87959354
Iteration 1837, loss = 1.15620379
Iteration 1838, loss = 1.12073366
Iteration 1839, loss = 0.95780773
Iteration 1840, loss = 1.39723112
Iteration 1841, loss = 1.05633353
Iteration 1842, loss = 1.53376846
Iteration 1843, loss = 1.29787887
Iteration 1844, loss = 1.28553609
Iteration 1845, loss = 1.35523503
Iteration 1846, loss = 1.06156699
Iteration 1847, loss = 1.26652547
Iteration 1848, loss = 0.97196886
Iteration 1849, loss = 1.19449351
Iteration 1850, loss = 0.95707129
Iteration 1851, loss = 1.14423684
Iteration 1852, loss = 0.94798680
Iteration 1853, loss = 1.09614602
Iteration 1854, loss = 0.94075270
Iteration 1855, loss = 1.06340643
Iteration 1856, loss = 0.93939339
Iteration 1857, loss = 1.03705015
Iteration 1858, loss = 0.93873837
Iteration 1859, loss = 1.01443147
Iteration 1860, loss = 0.93631811
Iteration 1861, loss = 0.99338734
Iteration 1862, loss = 0.93474408
Iteration 1863, loss = 0.97596451
Iteration 1864, loss = 0.93204603
Iteration 1865, loss = 0.95820206
Iteration 1866, loss = 0.92889693
Iteration 1867, loss = 0.94295985
Iteration 1868, loss = 0.87568870
Iteration 1869, loss = 1.10413675
Iteration 1870, loss = 0.94899031
Iteration 1871, loss = 1.06319952
Iteration 1872, loss = 0.93590824
Iteration 1873, loss = 1.02870033
Iteration 1874, loss = 0.94042071
Iteration 1875, loss = 1.01078781
Iteration 1876, loss = 0.94505334
Iteration 1877, loss = 0.99215795
Iteration 1878, loss = 0.94790011
Iteration 1879, loss = 0.97618431
Iteration 1880, loss = 0.94936416
Iteration 1881, loss = 0.96317926
Iteration 1882, loss = 0.95078835
Iteration 1883, loss = 0.95358519
Iteration 1884, loss = 0.95131471
Iteration 1885, loss = 0.94384290
Iteration 1886, loss = 0.94777371
Iteration 1887, loss = 0.93444604
Iteration 1888, loss = 0.93809295
Iteration 1889, loss = 0.96291653
Iteration 1890, loss = 0.95073390
Iteration 1891, loss = 0.95193128
Iteration 1892, loss = 0.90875608
Iteration 1893, loss = 0.95633876
Iteration 1894, loss = 0.97278612
Iteration 1895, loss = 0.96355536
Iteration 1896, loss = 0.96970211
Iteration 1897, loss = 0.96011320
Iteration 1898, loss = 0.95735638
Iteration 1899, loss = 0.94801063
Iteration 1900, loss = 0.94329942
Iteration 1901, loss = 0.93817379
Iteration 1902, loss = 0.93080327
Iteration 1903, loss = 0.95308293
Iteration 1904, loss = 0.93419264
Iteration 1905, loss = 0.95706803
Iteration 1906, loss = 0.94930451
Iteration 1907, loss = 0.93883941
Iteration 1908, loss = 0.95048318
Iteration 1909, loss = 0.93222916
Iteration 1910, loss = 0.94146495
Iteration 1911, loss = 0.92081177
Iteration 1912, loss = 0.93289112
Iteration 1913, loss = 0.91641268
Iteration 1914, loss = 0.92837662
Iteration 1915, loss = 0.91114709
Iteration 1916, loss = 0.91338979
Iteration 1917, loss = 0.89049848
Iteration 1918, loss = 1.37524507
Iteration 1919, loss = 1.74197345
Iteration 1920, loss = 1.42827140
Iteration 1921, loss = 1.42481934
Iteration 1922, loss = 1.63068947
Iteration 1923, loss = 1.05697573
Iteration 1924, loss = 1.47211966
Iteration 1925, loss = 0.98620690
Iteration 1926, loss = 1.34828809
Iteration 1927, loss = 1.06314528
Iteration 1928, loss = 1.23359166
Iteration 1929, loss = 1.15746120
Iteration 1930, loss = 1.11029975
Iteration 1931, loss = 1.17710874
Iteration 1932, loss = 1.02310544
Iteration 1933, loss = 1.14465006
Iteration 1934, loss = 0.97185979
Iteration 1935, loss = 1.09683891
Iteration 1936, loss = 0.94050755
Iteration 1937, loss = 1.05153724
Iteration 1938, loss = 0.92168813
Iteration 1939, loss = 1.01767693
Iteration 1940, loss = 0.91454599
Iteration 1941, loss = 0.99611066
Iteration 1942, loss = 0.91318637
Iteration 1943, loss = 0.97984247
Iteration 1944, loss = 0.91149878
Iteration 1945, loss = 0.96415970
Iteration 1946, loss = 0.90713300
Iteration 1947, loss = 0.94876197
Iteration 1948, loss = 0.90178071
Iteration 1949, loss = 0.93534427
Iteration 1950, loss = 0.89741886
Iteration 1951, loss = 0.92465141
Iteration 1952, loss = 0.89394971
Iteration 1953, loss = 0.91531369
Iteration 1954, loss = 0.89034390
Iteration 1955, loss = 0.90710579
Iteration 1956, loss = 0.88697539
Iteration 1957, loss = 0.89965722
Iteration 1958, loss = 0.88356582
Iteration 1959, loss = 0.89292947
Iteration 1960, loss = 0.88025963
Iteration 1961, loss = 0.88690578
Iteration 1962, loss = 0.87711259
Iteration 1963, loss = 0.88160254
Iteration 1964, loss = 0.87404818
Iteration 1965, loss = 0.91006217
Iteration 1966, loss = 0.95033131
Iteration 1967, loss = 0.88691010
Iteration 1968, loss = 0.94565180
Iteration 1969, loss = 0.87891245
Iteration 1970, loss = 0.92219200
Iteration 1971, loss = 0.86408201
Iteration 1972, loss = 0.89885865
Iteration 1973, loss = 0.85697914
Iteration 1974, loss = 0.91005731
Iteration 1975, loss = 0.87164179
Iteration 1976, loss = 0.89812050
Iteration 1977, loss = 0.86330169
Iteration 1978, loss = 0.88476491
Iteration 1979, loss = 0.85946145
Iteration 1980, loss = 0.87853967
Iteration 1981, loss = 0.85938687
Iteration 1982, loss = 0.87372336
Iteration 1983, loss = 0.85821383
Iteration 1984, loss = 0.86812131
Iteration 1985, loss = 0.85579019
Iteration 1986, loss = 0.86242742
Iteration 1987, loss = 0.85336834
Iteration 1988, loss = 0.85795351
Iteration 1989, loss = 0.85161039
Iteration 1990, loss = 0.85248009
Iteration 1991, loss = 0.84960176
Iteration 1992, loss = 0.84902324
Iteration 1993, loss = 0.84823003
Iteration 1994, loss = 0.84533598
Iteration 1995, loss = 0.84567865
Iteration 1996, loss = 0.84174354
Iteration 1997, loss = 0.84254064
Iteration 1998, loss = 0.83885241
Iteration 1999, loss = 0.83923210
Iteration 2000, loss = 0.83564210
Iteration 2001, loss = 0.83482198
Iteration 2002, loss = 0.83195263
Iteration 2003, loss = 0.82969131
Iteration 2004, loss = 0.82744040
Iteration 2005, loss = 0.82402127
Iteration 2006, loss = 0.82172024
Iteration 2007, loss = 0.81942046
Iteration 2008, loss = 0.77319227
Iteration 2009, loss = 0.85686058
Iteration 2010, loss = 0.95719094
Iteration 2011, loss = 0.86851451
Iteration 2012, loss = 0.90093640
Iteration 2013, loss = 0.87086681
Iteration 2014, loss = 0.84552448
Iteration 2015, loss = 0.85118757
Iteration 2016, loss = 0.85212470
Iteration 2017, loss = 0.85790237
Iteration 2018, loss = 0.85684738
Iteration 2019, loss = 0.85803789
Iteration 2020, loss = 0.85749615
Iteration 2021, loss = 0.85902662
Iteration 2022, loss = 0.85825723
Iteration 2023, loss = 0.85818544
Iteration 2024, loss = 0.85749204
Iteration 2025, loss = 0.85624312
Iteration 2026, loss = 0.85538631
Iteration 2027, loss = 0.85481498
Iteration 2028, loss = 0.86112477
Iteration 2029, loss = 0.85802965
Iteration 2030, loss = 0.86006773
Iteration 2031, loss = 0.85393338
Iteration 2032, loss = 0.85164895
Iteration 2033, loss = 0.84685176
Iteration 2034, loss = 0.83292324
Iteration 2035, loss = 0.90299547
Iteration 2036, loss = 0.94449765
Iteration 2037, loss = 0.91612291
Iteration 2038, loss = 0.90436652
Iteration 2039, loss = 0.90237555
Iteration 2040, loss = 0.87800120
Iteration 2041, loss = 0.90158709
Iteration 2042, loss = 0.86973831
Iteration 2043, loss = 0.89842491
Iteration 2044, loss = 0.85996670
Iteration 2045, loss = 0.88749088
Iteration 2046, loss = 0.84983869
Iteration 2047, loss = 0.87654438
Iteration 2048, loss = 0.84553035
Iteration 2049, loss = 0.87015226
Iteration 2050, loss = 0.84425216
Iteration 2051, loss = 0.86297583
Iteration 2052, loss = 0.84061182
Iteration 2053, loss = 0.85399843
Iteration 2054, loss = 0.83654386
Iteration 2055, loss = 0.84691032
Iteration 2056, loss = 0.83455448
Iteration 2057, loss = 0.84175731
Iteration 2058, loss = 0.83220902
Iteration 2059, loss = 0.83590157
Iteration 2060, loss = 0.82859202
Iteration 2061, loss = 0.83030310
Iteration 2062, loss = 0.81395012
Iteration 2063, loss = 0.84044973
Iteration 2064, loss = 0.85845048
Iteration 2065, loss = 0.86797601
Iteration 2066, loss = 0.85702760
Iteration 2067, loss = 0.84506778
Iteration 2068, loss = 0.83275491
Iteration 2069, loss = 0.83296596
Iteration 2070, loss = 0.83356344
Iteration 2071, loss = 0.83903985
Iteration 2072, loss = 0.83856884
Iteration 2073, loss = 0.83983664
Iteration 2074, loss = 0.83656116
Iteration 2075, loss = 0.83613830
Iteration 2076, loss = 0.83257504
Iteration 2077, loss = 0.83194752
Iteration 2078, loss = 0.82900950
Iteration 2079, loss = 0.82868967
Iteration 2080, loss = 0.82664087
Iteration 2081, loss = 0.82628601
Iteration 2082, loss = 0.82317428
Iteration 2083, loss = 0.82264781
Iteration 2084, loss = 0.82053454
Iteration 2085, loss = 0.81822970
Iteration 2086, loss = 0.84191704
Iteration 2087, loss = 0.83551913
Iteration 2088, loss = 0.84366242
Iteration 2089, loss = 0.82916299
Iteration 2090, loss = 0.83561164
Iteration 2091, loss = 0.81840947
Iteration 2092, loss = 0.83159419
Iteration 2093, loss = 0.81273367
Iteration 2094, loss = 0.82383801
Iteration 2095, loss = 0.80080755
Iteration 2096, loss = 0.74703827
Iteration 2097, loss = 1.00416611
Iteration 2098, loss = 0.85433176
Iteration 2099, loss = 1.00299332
Iteration 2100, loss = 0.86231316
Iteration 2101, loss = 0.93028396
Iteration 2102, loss = 0.87286846
Iteration 2103, loss = 0.93054218
Iteration 2104, loss = 0.87377297
Iteration 2105, loss = 0.86168635
Iteration 2106, loss = 0.87887665
Iteration 2107, loss = 0.87457195
Iteration 2108, loss = 0.79885241
Iteration 2109, loss = 0.95904515
Iteration 2110, loss = 0.92006901
Iteration 2111, loss = 0.94982238
Iteration 2112, loss = 0.93418506
Iteration 2113, loss = 0.93669986
Iteration 2114, loss = 0.93940013
Iteration 2115, loss = 0.92944884
Iteration 2116, loss = 0.95092085
Iteration 2117, loss = 0.93647416
Iteration 2118, loss = 0.96384981
Iteration 2119, loss = 0.94019974
Iteration 2120, loss = 0.96330734
Iteration 2121, loss = 0.93799397
Iteration 2122, loss = 0.95989514
Iteration 2123, loss = 0.94034392
Iteration 2124, loss = 0.95886536
Iteration 2125, loss = 0.94359668
Iteration 2126, loss = 0.95443330
Iteration 2127, loss = 0.94291086
Iteration 2128, loss = 0.94784551
Iteration 2129, loss = 0.94206899
Iteration 2130, loss = 0.94297818
Iteration 2131, loss = 0.94120121
Iteration 2132, loss = 0.93790636
Iteration 2133, loss = 0.93794557
Iteration 2134, loss = 0.93197117
Iteration 2135, loss = 0.93336592
Iteration 2136, loss = 0.92672260
Iteration 2137, loss = 0.93142531
Iteration 2138, loss = 0.92285197
Iteration 2139, loss = 0.92260317
Iteration 2140, loss = 0.90974752
Iteration 2141, loss = 0.92404194
Iteration 2142, loss = 0.92408765
Iteration 2143, loss = 0.92116663
Iteration 2144, loss = 0.91675146
Iteration 2145, loss = 0.91405566
Iteration 2146, loss = 0.91277033
Iteration 2147, loss = 0.91246553
Iteration 2148, loss = 0.91248367
Iteration 2149, loss = 0.91171919
Iteration 2150, loss = 0.91082596
Iteration 2151, loss = 0.90896759
Iteration 2152, loss = 0.90747446
Iteration 2153, loss = 0.90568205
Iteration 2154, loss = 0.90431551
Iteration 2155, loss = 0.90301501
Iteration 2156, loss = 0.90176217
Iteration 2157, loss = 0.90048966
Iteration 2158, loss = 0.89881057
Iteration 2159, loss = 0.89712174
Iteration 2160, loss = 0.89506936
Iteration 2161, loss = 0.89313833
Iteration 2162, loss = 0.89108784
Iteration 2163, loss = 0.88910160
Iteration 2164, loss = 0.88705586
Iteration 2165, loss = 0.88493689
Iteration 2166, loss = 0.88274015
Iteration 2167, loss = 0.88030625
Iteration 2168, loss = 0.87793754
Iteration 2169, loss = 0.87486527
Iteration 2170, loss = 0.87205724
Iteration 2171, loss = 0.86849281
Iteration 2172, loss = 0.86359724
Iteration 2173, loss = 0.90306175
Iteration 2174, loss = 0.92182395
Iteration 2175, loss = 0.87727561
Iteration 2176, loss = 0.91313067
Iteration 2177, loss = 0.86137130
Iteration 2178, loss = 0.89302472
Iteration 2179, loss = 0.86313882
Iteration 2180, loss = 0.85577113
Iteration 2181, loss = 0.89215504
Iteration 2182, loss = 1.05401243
Iteration 2183, loss = 0.87321459
Iteration 2184, loss = 1.00843306
Iteration 2185, loss = 0.87326390
Iteration 2186, loss = 0.94868399
Iteration 2187, loss = 0.89063258
Iteration 2188, loss = 0.86715758
Iteration 2189, loss = 0.87321515
Iteration 2190, loss = 0.86420365
Iteration 2191, loss = 0.86745585
Iteration 2192, loss = 0.86047477
Iteration 2193, loss = 0.85824996
Iteration 2194, loss = 0.85964501
Iteration 2195, loss = 0.85569552
Iteration 2196, loss = 0.85898562
Iteration 2197, loss = 0.85478996
Iteration 2198, loss = 0.85372303
Iteration 2199, loss = 0.85289570
Iteration 2200, loss = 0.84908319
Iteration 2201, loss = 0.84969229
Iteration 2202, loss = 0.84642480
Iteration 2203, loss = 0.84597141
Iteration 2204, loss = 0.84514624
Iteration 2205, loss = 0.84280364
Iteration 2206, loss = 0.84272377
Iteration 2207, loss = 0.84008126
Iteration 2208, loss = 0.83922535
Iteration 2209, loss = 0.83793134
Iteration 2210, loss = 0.83592495
Iteration 2211, loss = 0.83533388
Iteration 2212, loss = 0.83338883
Iteration 2213, loss = 0.83257637
Iteration 2214, loss = 0.83137100
Iteration 2215, loss = 0.82975764
Iteration 2216, loss = 0.82885511
Iteration 2217, loss = 0.82706355
Iteration 2218, loss = 0.82585542
Iteration 2219, loss = 0.82452748
Iteration 2220, loss = 0.82318480
Iteration 2221, loss = 0.82213531
Iteration 2222, loss = 0.82018980
Iteration 2223, loss = 0.81884607
Iteration 2224, loss = 0.81697541
Iteration 2225, loss = 0.81418471
Iteration 2226, loss = 0.85345566
Iteration 2227, loss = 0.99727093
Iteration 2228, loss = 0.84554884
Iteration 2229, loss = 0.92751497
Iteration 2230, loss = 0.88224564
Iteration 2231, loss = 0.84444141
Iteration 2232, loss = 0.90359585
Iteration 2233, loss = 0.81248743
Iteration 2234, loss = 0.89552886
Iteration 2235, loss = 0.82436442
Iteration 2236, loss = 0.85446489
Iteration 2237, loss = 0.84621008
Iteration 2238, loss = 0.81552395
Iteration 2239, loss = 0.85379906
Iteration 2240, loss = 0.80518637
Iteration 2241, loss = 0.83864432
Iteration 2242, loss = 0.81534550
Iteration 2243, loss = 0.81351716
Iteration 2244, loss = 0.82475251
Iteration 2245, loss = 0.79890311
Iteration 2246, loss = 0.82073312
Iteration 2247, loss = 0.80007122
Iteration 2248, loss = 0.80655833
Iteration 2249, loss = 0.80567528
Iteration 2250, loss = 0.79101523
Iteration 2251, loss = 0.79587822
Iteration 2252, loss = 0.79676928
Iteration 2253, loss = 0.79789891
Iteration 2254, loss = 0.79192936
Iteration 2255, loss = 0.79473123
Iteration 2256, loss = 0.78854720
Iteration 2257, loss = 0.78910772
Iteration 2258, loss = 0.78750807
Iteration 2259, loss = 0.78386247
Iteration 2260, loss = 0.78628263
Iteration 2261, loss = 0.78162014
Iteration 2262, loss = 0.78129620
Iteration 2263, loss = 0.77869063
Iteration 2264, loss = 0.77511537
Iteration 2265, loss = 0.77414071
Iteration 2266, loss = 0.76796465
Iteration 2267, loss = 0.76261577
Iteration 2268, loss = 0.78218081
Iteration 2269, loss = 0.74018325
Iteration 2270, loss = 1.05798068
Iteration 2271, loss = 0.91034659
Iteration 2272, loss = 0.99211553
Iteration 2273, loss = 1.22777156
Iteration 2274, loss = 0.88380219
Iteration 2275, loss = 1.14076551
Iteration 2276, loss = 0.84779664
Iteration 2277, loss = 1.09470780
Iteration 2278, loss = 0.86199320
Iteration 2279, loss = 1.09127398
Iteration 2280, loss = 0.88640680
Iteration 2281, loss = 1.08301505
Iteration 2282, loss = 0.89354488
Iteration 2283, loss = 1.06254629
Iteration 2284, loss = 0.90089013
Iteration 2285, loss = 1.02820754
Iteration 2286, loss = 0.91196502
Iteration 2287, loss = 0.99645153
Iteration 2288, loss = 0.91984921
Iteration 2289, loss = 0.97024733
Iteration 2290, loss = 0.91811598
Iteration 2291, loss = 0.94451040
Iteration 2292, loss = 0.90993422
Iteration 2293, loss = 0.92338232
Iteration 2294, loss = 0.89944445
Iteration 2295, loss = 0.90678657
Iteration 2296, loss = 0.88854594
Iteration 2297, loss = 0.89422994
Iteration 2298, loss = 0.86700159
Iteration 2299, loss = 0.89666293
Iteration 2300, loss = 0.86050327
Iteration 2301, loss = 0.87460764
Iteration 2302, loss = 0.85458176
Iteration 2303, loss = 0.86778197
Iteration 2304, loss = 0.85588916
Iteration 2305, loss = 0.85964535
Iteration 2306, loss = 0.85062115
Iteration 2307, loss = 0.85218499
Iteration 2308, loss = 0.84752410
Iteration 2309, loss = 0.84508423
Iteration 2310, loss = 0.83966083
Iteration 2311, loss = 0.82096449
Iteration 2312, loss = 0.85844349
Iteration 2313, loss = 0.88239384
Iteration 2314, loss = 0.85286480
Iteration 2315, loss = 0.88832845
Iteration 2316, loss = 0.88385872
Iteration 2317, loss = 0.89480757
Iteration 2318, loss = 0.86926720
Iteration 2319, loss = 0.86398284
Iteration 2320, loss = 0.92636663
Iteration 2321, loss = 1.06391813
Iteration 2322, loss = 0.92068510
Iteration 2323, loss = 1.07041976
Iteration 2324, loss = 0.92611404
Iteration 2325, loss = 1.01964716
Iteration 2326, loss = 0.90516326
Iteration 2327, loss = 0.98689634
Iteration 2328, loss = 0.91142708
Iteration 2329, loss = 1.03757850
Iteration 2330, loss = 0.90615052
Iteration 2331, loss = 1.01322769
Iteration 2332, loss = 0.84604903
Iteration 2333, loss = 1.06632685
Iteration 2334, loss = 0.93988435
Iteration 2335, loss = 1.05542714
Iteration 2336, loss = 0.93077486
Iteration 2337, loss = 1.01848371
Iteration 2338, loss = 0.91539180
Iteration 2339, loss = 0.99399255
Iteration 2340, loss = 0.91655255
Iteration 2341, loss = 0.98370575
Iteration 2342, loss = 0.91799405
Iteration 2343, loss = 0.88168118
Iteration 2344, loss = 1.10956242
Iteration 2345, loss = 0.98569338
Iteration 2346, loss = 1.09873342
Iteration 2347, loss = 0.96271084
Iteration 2348, loss = 1.05914703
Iteration 2349, loss = 0.94195913
Iteration 2350, loss = 1.02998675
Iteration 2351, loss = 0.93964523
Iteration 2352, loss = 1.01216776
Iteration 2353, loss = 0.97404610
Iteration 2354, loss = 1.06069629
Iteration 2355, loss = 1.03682523
Iteration 2356, loss = 1.10755433
Iteration 2357, loss = 1.04259513
Iteration 2358, loss = 1.06220054
Iteration 2359, loss = 0.99551973
Iteration 2360, loss = 1.01816561
Iteration 2361, loss = 0.97986861
Iteration 2362, loss = 1.01361396
Iteration 2363, loss = 0.99176072
Iteration 2364, loss = 1.02038640
Iteration 2365, loss = 0.99949014
Iteration 2366, loss = 1.01705005
Iteration 2367, loss = 0.99482227
Iteration 2368, loss = 1.00457622
Iteration 2369, loss = 0.98351191
Iteration 2370, loss = 0.99052422
Iteration 2371, loss = 0.97371134
Iteration 2372, loss = 0.97193323
Iteration 2373, loss = 1.05658287
Iteration 2374, loss = 1.04872022
Iteration 2375, loss = 1.01891201
Iteration 2376, loss = 1.07089868
Iteration 2377, loss = 0.98937561
Iteration 2378, loss = 1.06562912
Iteration 2379, loss = 0.97154620
Iteration 2380, loss = 1.03966087
Iteration 2381, loss = 0.96682611
Iteration 2382, loss = 1.00645546
Iteration 2383, loss = 0.97108795
Iteration 2384, loss = 0.96696532
Iteration 2385, loss = 0.97171859
Iteration 2386, loss = 0.95541984
Iteration 2387, loss = 0.96740107
Iteration 2388, loss = 0.94712822
Iteration 2389, loss = 0.95377278
Iteration 2390, loss = 0.94589808
Iteration 2391, loss = 0.94174211
Iteration 2392, loss = 0.94490865
Iteration 2393, loss = 0.93344681
Iteration 2394, loss = 0.93870722
Iteration 2395, loss = 0.92956429
Iteration 2396, loss = 0.93026156
Iteration 2397, loss = 0.92783036
Iteration 2398, loss = 0.92216894
Iteration 2399, loss = 0.92347577
Iteration 2400, loss = 0.91629709
Iteration 2401, loss = 0.91721325
Iteration 2402, loss = 0.91306186
Iteration 2403, loss = 0.91051808
Iteration 2404, loss = 0.90932207
Iteration 2405, loss = 0.90433450
Iteration 2406, loss = 0.90402556
Iteration 2407, loss = 0.89971164
Iteration 2408, loss = 0.89819213
Iteration 2409, loss = 0.89564941
Iteration 2410, loss = 0.89229495
Iteration 2411, loss = 0.89108939
Iteration 2412, loss = 0.88715254
Iteration 2413, loss = 0.88457108
Iteration 2414, loss = 0.88026005
Iteration 2415, loss = 0.87718442
Iteration 2416, loss = 0.87336794
Iteration 2417, loss = 0.86887710
Iteration 2418, loss = 0.86338080
Iteration 2419, loss = 0.82843715
Iteration 2420, loss = 1.07916486
Iteration 2421, loss = 1.07971705
Iteration 2422, loss = 1.07655035
Iteration 2423, loss = 1.01509412
Iteration 2424, loss = 1.03490889
Iteration 2425, loss = 0.95038893
Iteration 2426, loss = 1.00721425
Iteration 2427, loss = 0.91510942
Iteration 2428, loss = 0.98713653
Iteration 2429, loss = 0.89972172
Iteration 2430, loss = 0.96870526
Iteration 2431, loss = 0.88930977
Iteration 2432, loss = 0.94943755
Iteration 2433, loss = 0.88185963
Iteration 2434, loss = 0.93361843
Iteration 2435, loss = 0.87771476
Iteration 2436, loss = 0.92070415
Iteration 2437, loss = 0.87415403
Iteration 2438, loss = 0.90862985
Iteration 2439, loss = 0.86994038
Iteration 2440, loss = 0.89786083
Iteration 2441, loss = 0.86676819
Iteration 2442, loss = 0.88975071
Iteration 2443, loss = 0.86463761
Iteration 2444, loss = 0.88293968
Iteration 2445, loss = 0.86030906
Iteration 2446, loss = 0.87119200
Iteration 2447, loss = 0.86151671
Iteration 2448, loss = 0.86842169
Iteration 2449, loss = 0.85884128
Iteration 2450, loss = 0.86210304
Iteration 2451, loss = 0.85417869
Iteration 2452, loss = 0.85678842
Iteration 2453, loss = 0.85146960
Iteration 2454, loss = 0.85342099
Iteration 2455, loss = 0.84902176
Iteration 2456, loss = 0.84963244
Iteration 2457, loss = 0.84588946
Iteration 2458, loss = 0.84575722
Iteration 2459, loss = 0.84281610
Iteration 2460, loss = 0.84242684
Iteration 2461, loss = 0.84013164
Iteration 2462, loss = 0.83920795
Iteration 2463, loss = 0.83703268
Iteration 2464, loss = 0.83581317
Iteration 2465, loss = 0.83411282
Iteration 2466, loss = 0.83298059
Iteration 2467, loss = 0.83157731
Iteration 2468, loss = 0.83025616
Iteration 2469, loss = 0.82881641
Iteration 2470, loss = 0.82732657
Iteration 2471, loss = 0.82602171
Iteration 2472, loss = 0.82463172
Iteration 2473, loss = 0.82345826
Iteration 2474, loss = 0.82203614
Iteration 2475, loss = 0.82085946
Iteration 2476, loss = 0.81945141
Iteration 2477, loss = 0.81833093
Iteration 2478, loss = 0.81695760
Iteration 2479, loss = 0.81584388
Iteration 2480, loss = 0.81446517
Iteration 2481, loss = 0.81324486
Iteration 2482, loss = 0.81065387
Iteration 2483, loss = 0.81101263
Iteration 2484, loss = 0.81188517
Iteration 2485, loss = 0.81129253
Iteration 2486, loss = 0.80518786
Iteration 2487, loss = 0.76941280
Iteration 2488, loss = 0.85281091
Iteration 2489, loss = 0.82746422
Iteration 2490, loss = 0.85640948
Iteration 2491, loss = 0.82076959
Iteration 2492, loss = 0.84182583
Iteration 2493, loss = 0.81956720
Iteration 2494, loss = 0.84401395
Iteration 2495, loss = 0.82716382
Iteration 2496, loss = 0.84611732
Iteration 2497, loss = 0.83180274
Iteration 2498, loss = 0.84671444
Iteration 2499, loss = 0.83313226
Iteration 2500, loss = 0.82967885
Iteration 2501, loss = 0.84959511
Iteration 2502, loss = 0.86588035
Iteration 2503, loss = 0.87867312
Iteration 2504, loss = 0.87717266
Iteration 2505, loss = 0.87028075
Iteration 2506, loss = 0.86265654
Iteration 2507, loss = 0.86098921
Iteration 2508, loss = 0.86436071
Iteration 2509, loss = 0.86980602
Iteration 2510, loss = 0.87460376
Iteration 2511, loss = 0.87751806
Iteration 2512, loss = 0.87684651
Iteration 2513, loss = 0.88028002
Iteration 2514, loss = 0.88484054
Iteration 2515, loss = 0.87803707
Iteration 2516, loss = 0.93364664
Iteration 2517, loss = 0.91525373
Iteration 2518, loss = 0.92784819
Iteration 2519, loss = 0.90107219
Iteration 2520, loss = 0.91349871
Iteration 2521, loss = 0.89629716
Iteration 2522, loss = 0.91334554
Iteration 2523, loss = 0.89667349
Iteration 2524, loss = 0.90601883
Iteration 2525, loss = 0.88917263
Iteration 2526, loss = 0.89849483
Iteration 2527, loss = 0.88610833
Iteration 2528, loss = 0.89343224
Iteration 2529, loss = 0.88241475
Iteration 2530, loss = 0.88760132
Iteration 2531, loss = 0.87891953
Iteration 2532, loss = 0.88393086
Iteration 2533, loss = 0.87706876
Iteration 2534, loss = 0.87973491
Iteration 2535, loss = 0.87264311
Iteration 2536, loss = 0.87411434
Iteration 2537, loss = 0.86919168
Iteration 2538, loss = 0.87096559
Iteration 2539, loss = 0.86685268
Iteration 2540, loss = 0.86727161
Iteration 2541, loss = 0.86362559
Iteration 2542, loss = 0.86340877
Iteration 2543, loss = 0.86014830
Iteration 2544, loss = 0.85944875
Iteration 2545, loss = 0.84990076
Iteration 2546, loss = 0.86417052
Iteration 2547, loss = 0.86874206
Iteration 2548, loss = 0.86322867
Iteration 2549, loss = 0.85829513
Iteration 2550, loss = 0.85734929
Iteration 2551, loss = 0.86110456
Iteration 2552, loss = 0.86188428
Iteration 2553, loss = 0.86158530
Iteration 2554, loss = 0.85971127
Iteration 2555, loss = 0.85931976
Iteration 2556, loss = 0.85869489
Iteration 2557, loss = 0.85930590
Iteration 2558, loss = 0.85884485
Iteration 2559, loss = 0.85808317
Iteration 2560, loss = 0.85638067
Iteration 2561, loss = 0.85489730
Iteration 2562, loss = 0.87098950
Iteration 2563, loss = 1.11422593
Iteration 2564, loss = 1.17695996
Iteration 2565, loss = 0.96394413
Iteration 2566, loss = 1.14093031
Iteration 2567, loss = 1.00926813
Iteration 2568, loss = 1.03690352
Iteration 2569, loss = 1.01506877
Iteration 2570, loss = 0.96633490
Iteration 2571, loss = 1.02012711
Iteration 2572, loss = 0.93352482
Iteration 2573, loss = 1.01027427
Iteration 2574, loss = 0.90785599
Iteration 2575, loss = 0.98597703
Iteration 2576, loss = 0.88990871
Iteration 2577, loss = 0.96340596
Iteration 2578, loss = 0.88272199
Iteration 2579, loss = 0.94870365
Iteration 2580, loss = 0.87745885
Iteration 2581, loss = 0.93149911
Iteration 2582, loss = 0.91804232
Iteration 2583, loss = 0.97383399
Iteration 2584, loss = 0.93008534
Iteration 2585, loss = 0.98630698
Iteration 2586, loss = 0.91828538
Iteration 2587, loss = 0.94576173
Iteration 2588, loss = 0.89146894
Iteration 2589, loss = 0.92586715
Iteration 2590, loss = 0.89376143
Iteration 2591, loss = 0.93245098
Iteration 2592, loss = 0.89918429
Iteration 2593, loss = 0.92204781
Iteration 2594, loss = 0.89483227
Iteration 2595, loss = 0.90866927
Iteration 2596, loss = 0.88470618
Iteration 2597, loss = 0.89681493
Iteration 2598, loss = 0.87950130
Iteration 2599, loss = 0.89095359
Iteration 2600, loss = 0.87663277
Iteration 2601, loss = 0.88451588
Iteration 2602, loss = 0.87238952
Iteration 2603, loss = 0.87859973
Iteration 2604, loss = 0.86807271
Iteration 2605, loss = 0.87160745
Iteration 2606, loss = 0.86161858
Iteration 2607, loss = 0.86379131
Iteration 2608, loss = 0.85581353
Iteration 2609, loss = 0.85832236
Iteration 2610, loss = 0.85219380
Iteration 2611, loss = 0.85388030
Iteration 2612, loss = 0.84799101
Iteration 2613, loss = 0.84808228
Iteration 2614, loss = 0.84198746
Iteration 2615, loss = 0.84134020
Iteration 2616, loss = 0.83656068
Iteration 2617, loss = 0.83621056
Iteration 2618, loss = 0.83183090
Iteration 2619, loss = 0.83065014
Iteration 2620, loss = 0.82644337
Iteration 2621, loss = 0.82423396
Iteration 2622, loss = 0.82185114
Iteration 2623, loss = 0.82555723
Iteration 2624, loss = 0.82511588
Iteration 2625, loss = 0.82760190
Iteration 2626, loss = 0.81804765
Iteration 2627, loss = 0.91877151
Iteration 2628, loss = 0.88978346
Iteration 2629, loss = 0.89021079
Iteration 2630, loss = 0.87257174
Iteration 2631, loss = 0.86646600
Iteration 2632, loss = 0.86431708
Iteration 2633, loss = 0.85222060
Iteration 2634, loss = 0.85868907
Iteration 2635, loss = 0.83889134
Iteration 2636, loss = 0.85054821
Iteration 2637, loss = 0.82558075
Iteration 2638, loss = 0.84321133
Iteration 2639, loss = 0.81764290
Iteration 2640, loss = 0.83777418
Iteration 2641, loss = 0.81042061
Iteration 2642, loss = 0.83086419
Iteration 2643, loss = 0.80447626
Iteration 2644, loss = 0.82663129
Iteration 2645, loss = 0.80274610
Iteration 2646, loss = 0.82026078
Iteration 2647, loss = 0.79608364
Iteration 2648, loss = 0.81062125
Iteration 2649, loss = 0.79169310
Iteration 2650, loss = 0.80576125
Iteration 2651, loss = 0.78969743
Iteration 2652, loss = 0.80008760
Iteration 2653, loss = 0.78746020
Iteration 2654, loss = 0.79507443
Iteration 2655, loss = 0.78475416
Iteration 2656, loss = 0.78888934
Iteration 2657, loss = 0.78240586
Iteration 2658, loss = 0.78452961
Iteration 2659, loss = 0.77845509
Iteration 2660, loss = 0.77854482
Iteration 2661, loss = 0.77514192
Iteration 2662, loss = 0.77448976
Iteration 2663, loss = 0.77228923
Iteration 2664, loss = 0.77023759
Iteration 2665, loss = 0.76892144
Iteration 2666, loss = 0.76550638
Iteration 2667, loss = 0.76549885
Iteration 2668, loss = 0.75987845
Iteration 2669, loss = 0.74849371
Iteration 2670, loss = 0.72620496
Iteration 2671, loss = 0.50195227
Iteration 2672, loss = 1.02025427
Iteration 2673, loss = 1.74414433
Iteration 2674, loss = 1.27191267
Iteration 2675, loss = 1.53541111
Iteration 2676, loss = 1.49801806
Iteration 2677, loss = 1.06670393
Iteration 2678, loss = 1.32100901
Iteration 2679, loss = 0.87030445
Iteration 2680, loss = 1.13417246
Iteration 2681, loss = 0.82747760
Iteration 2682, loss = 1.01056816
Iteration 2683, loss = 0.83082031
Iteration 2684, loss = 0.92272047
Iteration 2685, loss = 0.84845635
Iteration 2686, loss = 0.85769296
Iteration 2687, loss = 0.86656889
Iteration 2688, loss = 0.81364326
Iteration 2689, loss = 0.87778696
Iteration 2690, loss = 0.78872643
Iteration 2691, loss = 0.87824706
Iteration 2692, loss = 0.77790823
Iteration 2693, loss = 0.86705942
Iteration 2694, loss = 0.77588273
Iteration 2695, loss = 0.84636504
Iteration 2696, loss = 0.77970696
Iteration 2697, loss = 0.82182626
Iteration 2698, loss = 0.78710626
Iteration 2699, loss = 0.79927545
Iteration 2700, loss = 0.79461098
Iteration 2701, loss = 0.78263632
Iteration 2702, loss = 0.79863301
Iteration 2703, loss = 0.77290885
Iteration 2704, loss = 0.80017195
Iteration 2705, loss = 0.76999351
Iteration 2706, loss = 0.78995800
Iteration 2707, loss = 0.77138850
Iteration 2708, loss = 0.78011301
Iteration 2709, loss = 0.77385290
Iteration 2710, loss = 0.77211681
Iteration 2711, loss = 0.77540104
Iteration 2712, loss = 0.76685565
Iteration 2713, loss = 0.77489805
Iteration 2714, loss = 0.76435642
Iteration 2715, loss = 0.77284223
Iteration 2716, loss = 0.76317368
Iteration 2717, loss = 0.77220627
Iteration 2718, loss = 0.77632173
Iteration 2719, loss = 0.77482993
Iteration 2720, loss = 0.78547616
Iteration 2721, loss = 0.76906749
Iteration 2722, loss = 0.77203670
Iteration 2723, loss = 0.75981560
Iteration 2724, loss = 0.76312493
Iteration 2725, loss = 0.89506144
Iteration 2726, loss = 1.51607134
Iteration 2727, loss = 0.98274333
Iteration 2728, loss = 1.45002567
Iteration 2729, loss = 1.27760635
Iteration 2730, loss = 1.05552805
Iteration 2731, loss = 1.23875273
Iteration 2732, loss = 0.84246311
Iteration 2733, loss = 1.13404732
Iteration 2734, loss = 0.78956184
Iteration 2735, loss = 1.05442739
Iteration 2736, loss = 0.77313135
Iteration 2737, loss = 0.99594661
Iteration 2738, loss = 0.76887965
Iteration 2739, loss = 0.95908492
Iteration 2740, loss = 0.77067309
Iteration 2741, loss = 0.93211822
Iteration 2742, loss = 0.77018491
Iteration 2743, loss = 0.90815564
Iteration 2744, loss = 0.76717176
Iteration 2745, loss = 0.88696976
Iteration 2746, loss = 0.76416981
Iteration 2747, loss = 0.86914519
Iteration 2748, loss = 0.76105368
Iteration 2749, loss = 0.85139773
Iteration 2750, loss = 0.75744227
Iteration 2751, loss = 0.83489889
Iteration 2752, loss = 0.75510142
Iteration 2753, loss = 0.81995809
Iteration 2754, loss = 0.75399068
Iteration 2755, loss = 0.80598001
Iteration 2756, loss = 0.75318573
Iteration 2757, loss = 0.79247065
Iteration 2758, loss = 0.75285393
Iteration 2759, loss = 0.78077754
Iteration 2760, loss = 0.75367678
Iteration 2761, loss = 0.77115356
Iteration 2762, loss = 0.75457081
Iteration 2763, loss = 0.76256716
Iteration 2764, loss = 0.75456107
Iteration 2765, loss = 0.75569949
Iteration 2766, loss = 0.75457299
Iteration 2767, loss = 0.74418052
Iteration 2768, loss = 0.74168542
Iteration 2769, loss = 0.74242495
Iteration 2770, loss = 0.74271098
Iteration 2771, loss = 0.74063984
Iteration 2772, loss = 0.73240265
Iteration 2773, loss = 0.75775709
Iteration 2774, loss = 0.75438521
Iteration 2775, loss = 0.75033791
Iteration 2776, loss = 0.75257745
Iteration 2777, loss = 0.74556258
Iteration 2778, loss = 0.75341516
Iteration 2779, loss = 0.74333855
Iteration 2780, loss = 0.75140273
Iteration 2781, loss = 0.74610975
Iteration 2782, loss = 0.74547691
Iteration 2783, loss = 0.74794412
Iteration 2784, loss = 0.74196039
Iteration 2785, loss = 0.74653496
Iteration 2786, loss = 0.74246576
Iteration 2787, loss = 0.74289555
Iteration 2788, loss = 0.74404350
Iteration 2789, loss = 0.74040998
Iteration 2790, loss = 0.74307620
Iteration 2791, loss = 0.74010127
Iteration 2792, loss = 0.74006655
Iteration 2793, loss = 0.74049254
Iteration 2794, loss = 0.73824031
Iteration 2795, loss = 0.73979277
Iteration 2796, loss = 0.73797979
Iteration 2797, loss = 0.73778405
Iteration 2798, loss = 0.73785832
Iteration 2799, loss = 0.73626657
Iteration 2800, loss = 0.73693113
Iteration 2801, loss = 0.73576473
Iteration 2802, loss = 0.73550290
Iteration 2803, loss = 0.73542695
Iteration 2804, loss = 0.73432297
Iteration 2805, loss = 0.73457497
Iteration 2806, loss = 0.73373665
Iteration 2807, loss = 0.73337452
Iteration 2808, loss = 0.73324853
Iteration 2809, loss = 0.73242096
Iteration 2810, loss = 0.73242405
Iteration 2811, loss = 0.73186680
Iteration 2812, loss = 0.73148235
Iteration 2813, loss = 0.73129864
Iteration 2814, loss = 0.73068731
Iteration 2815, loss = 0.73055641
Iteration 2816, loss = 0.73011407
Iteration 2817, loss = 0.72974726
Iteration 2818, loss = 0.72957643
Iteration 2819, loss = 0.72904847
Iteration 2820, loss = 0.72896717
Iteration 2821, loss = 0.72887721
Iteration 2822, loss = 0.72769058
Iteration 2823, loss = 0.71497317
Iteration 2824, loss = 0.74809452
Iteration 2825, loss = 0.75908305
Iteration 2826, loss = 0.73978253
Iteration 2827, loss = 0.74443942
Iteration 2828, loss = 0.77465005
Iteration 2829, loss = 0.75528838
Iteration 2830, loss = 0.74970151
Iteration 2831, loss = 0.76939445
Iteration 2832, loss = 0.75807047
Iteration 2833, loss = 0.75728489
Iteration 2834, loss = 0.77315818
Iteration 2835, loss = 0.76314784
Iteration 2836, loss = 0.76100800
Iteration 2837, loss = 0.77445623
Iteration 2838, loss = 0.76874698
Iteration 2839, loss = 0.76580961
Iteration 2840, loss = 0.77540521
Iteration 2841, loss = 0.77111919
Iteration 2842, loss = 0.76679717
Iteration 2843, loss = 0.77294259
Iteration 2844, loss = 0.77052463
Iteration 2845, loss = 0.76634218
Iteration 2846, loss = 0.76996467
Iteration 2847, loss = 0.76803039
Iteration 2848, loss = 0.76334438
Iteration 2849, loss = 0.76470795
Iteration 2850, loss = 0.76339229
Iteration 2851, loss = 0.75955213
Iteration 2852, loss = 0.75982734
Iteration 2853, loss = 0.75890047
Iteration 2854, loss = 0.75442892
Iteration 2855, loss = 0.75377944
Iteration 2856, loss = 0.75274392
Iteration 2857, loss = 0.74947518
Iteration 2858, loss = 0.74895112
Iteration 2859, loss = 0.74694212
Iteration 2860, loss = 0.74402462
Iteration 2861, loss = 0.74325538
Iteration 2862, loss = 0.74151568
Iteration 2863, loss = 0.73920710
Iteration 2864, loss = 0.73822842
Iteration 2865, loss = 0.73623145
Iteration 2866, loss = 0.73451750
Iteration 2867, loss = 0.73290898
Iteration 2868, loss = 0.73109843
Iteration 2869, loss = 0.72861021
Iteration 2870, loss = 0.72159701
Iteration 2871, loss = 0.59741387
Iteration 2872, loss = 0.73917526
Iteration 2873, loss = 0.78586735
Iteration 2874, loss = 0.78329201
Iteration 2875, loss = 0.74325174
Iteration 2876, loss = 0.77760660
Iteration 2877, loss = 0.76785540
Iteration 2878, loss = 0.73969879
Iteration 2879, loss = 0.76881757
Iteration 2880, loss = 0.76362734
Iteration 2881, loss = 0.74706827
Iteration 2882, loss = 0.76806978
Iteration 2883, loss = 0.75934846
Iteration 2884, loss = 0.74450262
Iteration 2885, loss = 0.75946657
Iteration 2886, loss = 0.70851155
Iteration 2887, loss = 0.76355930
Iteration 2888, loss = 0.77879066
Iteration 2889, loss = 0.78759885
Iteration 2890, loss = 0.79286034
Iteration 2891, loss = 0.78703982
Iteration 2892, loss = 0.77546999
Iteration 2893, loss = 0.77730409
Iteration 2894, loss = 0.88218260
Iteration 2895, loss = 0.97051148
Iteration 2896, loss = 0.81611462
Iteration 2897, loss = 0.92707248
Iteration 2898, loss = 1.10656718
Iteration 2899, loss = 0.88407756
Iteration 2900, loss = 0.92361585
Iteration 2901, loss = 1.02250451
Iteration 2902, loss = 0.82880262
Iteration 2903, loss = 0.97071788
Iteration 2904, loss = 0.91921012
Iteration 2905, loss = 0.84607841
Iteration 2906, loss = 0.96760855
Iteration 2907, loss = 0.86763467
Iteration 2908, loss = 0.87061801
Iteration 2909, loss = 0.93286667
Iteration 2910, loss = 0.84462318
Iteration 2911, loss = 0.88058151
Iteration 2912, loss = 0.89734957
Iteration 2913, loss = 0.83758236
Iteration 2914, loss = 0.88048424
Iteration 2915, loss = 0.87241883
Iteration 2916, loss = 0.83828823
Iteration 2917, loss = 0.87479557
Iteration 2918, loss = 0.85561179
Iteration 2919, loss = 0.83752410
Iteration 2920, loss = 0.86283271
Iteration 2921, loss = 0.84214387
Iteration 2922, loss = 0.83567762
Iteration 2923, loss = 0.85303033
Iteration 2924, loss = 0.83497417
Iteration 2925, loss = 0.83400874
Iteration 2926, loss = 0.84409672
Iteration 2927, loss = 0.82888873
Iteration 2928, loss = 0.83031117
Iteration 2929, loss = 0.83571308
Iteration 2930, loss = 0.82378090
Iteration 2931, loss = 0.82598932
Iteration 2932, loss = 0.82961547
Iteration 2933, loss = 0.81956687
Iteration 2934, loss = 0.82397298
Iteration 2935, loss = 0.82086923
Iteration 2936, loss = 0.81568930
Iteration 2937, loss = 0.81877330
Iteration 2938, loss = 0.81112558
Iteration 2939, loss = 0.80736639
Iteration 2940, loss = 0.83732044
Iteration 2941, loss = 0.83771068
Iteration 2942, loss = 0.81328555
Iteration 2943, loss = 0.82877438
Iteration 2944, loss = 0.82363718
Iteration 2945, loss = 0.81023140
Iteration 2946, loss = 0.82502478
Iteration 2947, loss = 0.81803171
Iteration 2948, loss = 0.80806225
Iteration 2949, loss = 0.81839752
Iteration 2950, loss = 0.81209432
Iteration 2951, loss = 0.80614149
Iteration 2952, loss = 0.81337422
Iteration 2953, loss = 0.80763206
Iteration 2954, loss = 0.80369386
Iteration 2955, loss = 0.80818364
Iteration 2956, loss = 0.80279019
Iteration 2957, loss = 0.80013836
Iteration 2958, loss = 0.80339521
Iteration 2959, loss = 0.79902836
Iteration 2960, loss = 0.79675707
Iteration 2961, loss = 0.79837817
Iteration 2962, loss = 0.79466646
Iteration 2963, loss = 0.79302487
Iteration 2964, loss = 0.79399092
Iteration 2965, loss = 0.79082305
Iteration 2966, loss = 0.78920786
Iteration 2967, loss = 0.78953556
Iteration 2968, loss = 0.78697541
Iteration 2969, loss = 0.78556864
Iteration 2970, loss = 0.78546783
Iteration 2971, loss = 0.78327896
Iteration 2972, loss = 0.78200336
Iteration 2973, loss = 0.78168440
Iteration 2974, loss = 0.77980057
Iteration 2975, loss = 0.77856705
Iteration 2976, loss = 0.77810542
Iteration 2977, loss = 0.77653652
Iteration 2978, loss = 0.77538771
Iteration 2979, loss = 0.77479844
Iteration 2980, loss = 0.77342089
Iteration 2981, loss = 0.77235602
Iteration 2982, loss = 0.77173936
Iteration 2983, loss = 0.77053282
Iteration 2984, loss = 0.76950628
Iteration 2985, loss = 0.76883368
Iteration 2986, loss = 0.76760659
Iteration 2987, loss = 0.76651386
Iteration 2988, loss = 0.76603387
Iteration 2989, loss = 0.76466105
Iteration 2990, loss = 0.76373470
Iteration 2991, loss = 0.76349040
Iteration 2992, loss = 0.76364058
Iteration 2993, loss = 0.76205788
Iteration 2994, loss = 0.76173180
Iteration 2995, loss = 0.76043216
Iteration 2996, loss = 0.75828215
Iteration 2997, loss = 0.75705725
Iteration 2998, loss = 0.74819179
Iteration 2999, loss = 0.82040115
Iteration 3000, loss = 1.18271053
Iteration 3001, loss = 0.80652536
Iteration 3002, loss = 0.90681200
Iteration 3003, loss = 1.03169944
Iteration 3004, loss = 0.76470714
Iteration 3005, loss = 0.93977243
Iteration 3006, loss = 0.92744155
Iteration 3007, loss = 0.76506900
Iteration 3008, loss = 0.91475117
Iteration 3009, loss = 0.85904546
Iteration 3010, loss = 0.76444369
Iteration 3011, loss = 0.88190331
Iteration 3012, loss = 0.82826579
Iteration 3013, loss = 0.76310299
Iteration 3014, loss = 0.84727690
Iteration 3015, loss = 0.80894283
Iteration 3016, loss = 0.75951309
Iteration 3017, loss = 0.82006001
Iteration 3018, loss = 0.79815786
Iteration 3019, loss = 0.75609259
Iteration 3020, loss = 0.79753988
Iteration 3021, loss = 0.78973184
Iteration 3022, loss = 0.75369553
Iteration 3023, loss = 0.78011843
Iteration 3024, loss = 0.78259519
Iteration 3025, loss = 0.75272876
Iteration 3026, loss = 0.76662923
Iteration 3027, loss = 0.77495024
Iteration 3028, loss = 0.75226436
Iteration 3029, loss = 0.75705379
Iteration 3030, loss = 0.76778443
Iteration 3031, loss = 0.75217089
Iteration 3032, loss = 0.75027648
Iteration 3033, loss = 0.76038289
Iteration 3034, loss = 0.75145189
Iteration 3035, loss = 0.74606272
Iteration 3036, loss = 0.75392709
Iteration 3037, loss = 0.75023256
Iteration 3038, loss = 0.74349051
Iteration 3039, loss = 0.74814237
Iteration 3040, loss = 0.74702928
Iteration 3041, loss = 0.74397628
Iteration 3042, loss = 0.74387815
Iteration 3043, loss = 0.74511295
Iteration 3044, loss = 0.74296405
Iteration 3045, loss = 0.74039136
Iteration 3046, loss = 0.74103507
Iteration 3047, loss = 0.74110700
Iteration 3048, loss = 0.75708783
Iteration 3049, loss = 0.77585465
Iteration 3050, loss = 0.75613170
Iteration 3051, loss = 0.90090129
Iteration 3052, loss = 0.85232852
Iteration 3053, loss = 0.74616285
Iteration 3054, loss = 0.83964676
Iteration 3055, loss = 0.82844002
Iteration 3056, loss = 0.74785203
Iteration 3057, loss = 0.80631767
Iteration 3058, loss = 0.81639753
Iteration 3059, loss = 0.74606171
Iteration 3060, loss = 0.77320417
Iteration 3061, loss = 0.79962011
Iteration 3062, loss = 0.74675996
Iteration 3063, loss = 0.74705529
Iteration 3064, loss = 0.75957109
Iteration 3065, loss = 0.76654881
Iteration 3066, loss = 0.81671624
Iteration 3067, loss = 0.85509698
Iteration 3068, loss = 0.76634117
Iteration 3069, loss = 0.80180054
Iteration 3070, loss = 0.80254347
Iteration 3071, loss = 0.74695669
Iteration 3072, loss = 0.79098848
Iteration 3073, loss = 0.78946503
Iteration 3074, loss = 0.75455889
Iteration 3075, loss = 0.78611562
Iteration 3076, loss = 0.77484631
Iteration 3077, loss = 0.74902737
Iteration 3078, loss = 0.77056991
Iteration 3079, loss = 0.75902852
Iteration 3080, loss = 0.72612571
Iteration 3081, loss = 0.76360437
Iteration 3082, loss = 0.84362886
Iteration 3083, loss = 0.78266111
Iteration 3084, loss = 0.78929582
Iteration 3085, loss = 0.81157175
Iteration 3086, loss = 0.75695698
Iteration 3087, loss = 0.79635498
Iteration 3088, loss = 0.77638446
Iteration 3089, loss = 0.76440475
Iteration 3090, loss = 0.79378048
Iteration 3091, loss = 0.76213951
Iteration 3092, loss = 0.77460416
Iteration 3093, loss = 0.77679670
Iteration 3094, loss = 0.75603246
Iteration 3095, loss = 0.77409017
Iteration 3096, loss = 0.76188016
Iteration 3097, loss = 0.75874834
Iteration 3098, loss = 0.76947060
Iteration 3099, loss = 0.75450108
Iteration 3100, loss = 0.76300383
Iteration 3101, loss = 0.76934019
Iteration 3102, loss = 0.74163680
Iteration 3103, loss = 0.75644218
Iteration 3104, loss = 0.75540372
Iteration 3105, loss = 0.75164053
Iteration 3106, loss = 0.75158981
Iteration 3107, loss = 0.74804677
Iteration 3108, loss = 0.74391286
Iteration 3109, loss = 0.80441159
Iteration 3110, loss = 0.88135568
Iteration 3111, loss = 0.71823761
Iteration 3112, loss = 1.35321048
Iteration 3113, loss = 0.85516871
Iteration 3114, loss = 1.38230268
Iteration 3115, loss = 1.00900626
Iteration 3116, loss = 1.34891394
Iteration 3117, loss = 1.15884700
Iteration 3118, loss = 1.17412022
Iteration 3119, loss = 1.16137482
Iteration 3120, loss = 1.00028930
Iteration 3121, loss = 1.37018028
Iteration 3122, loss = 0.95499544
Iteration 3123, loss = 1.25834913
Iteration 3124, loss = 0.82026988
Iteration 3125, loss = 1.12986495
Iteration 3126, loss = 0.72570989
Iteration 3127, loss = 1.05667489
Iteration 3128, loss = 0.89044214
Iteration 3129, loss = 1.04863511
Iteration 3130, loss = 0.94044941
Iteration 3131, loss = 0.99218689
Iteration 3132, loss = 0.96294894
Iteration 3133, loss = 0.93890174
Iteration 3134, loss = 0.97635349
Iteration 3135, loss = 0.91346688
Iteration 3136, loss = 0.98167243
Iteration 3137, loss = 0.90707098
Iteration 3138, loss = 0.97604576
Iteration 3139, loss = 0.90916617
Iteration 3140, loss = 0.95771078
Iteration 3141, loss = 0.91452483
Iteration 3142, loss = 0.93605369
Iteration 3143, loss = 0.91897156
Iteration 3144, loss = 0.91593303
Iteration 3145, loss = 0.92099996
Iteration 3146, loss = 0.90235812
Iteration 3147, loss = 0.91909728
Iteration 3148, loss = 0.89415043
Iteration 3149, loss = 0.91163950
Iteration 3150, loss = 0.88815016
Iteration 3151, loss = 0.89994260
Iteration 3152, loss = 0.88282874
Iteration 3153, loss = 0.88465303
Iteration 3154, loss = 0.92960647
Iteration 3155, loss = 0.90520332
Iteration 3156, loss = 1.00840655
Iteration 3157, loss = 0.90502198
Iteration 3158, loss = 0.92811899
Iteration 3159, loss = 0.91083618
Iteration 3160, loss = 0.93249503
Iteration 3161, loss = 0.87855830
Iteration 3162, loss = 0.90673723
Iteration 3163, loss = 0.86437798
Iteration 3164, loss = 0.89270451
Iteration 3165, loss = 0.86899539
Iteration 3166, loss = 0.86914855
Iteration 3167, loss = 0.86637442
Iteration 3168, loss = 0.85125593
Iteration 3169, loss = 0.86334676
Iteration 3170, loss = 0.84214723
Iteration 3171, loss = 0.85313064
Iteration 3172, loss = 0.83319698
Iteration 3173, loss = 0.83707906
Iteration 3174, loss = 0.82487496
Iteration 3175, loss = 0.87554765
Iteration 3176, loss = 0.83282207
Iteration 3177, loss = 0.86217346
Iteration 3178, loss = 0.82558878
Iteration 3179, loss = 0.84349160
Iteration 3180, loss = 0.82658517
Iteration 3181, loss = 0.83249830
Iteration 3182, loss = 0.82954603
Iteration 3183, loss = 0.82163761
Iteration 3184, loss = 0.82642062
Iteration 3185, loss = 0.81262671
Iteration 3186, loss = 0.82280508
Iteration 3187, loss = 0.80822081
Iteration 3188, loss = 0.81750873
Iteration 3189, loss = 0.80504492
Iteration 3190, loss = 0.81119815
Iteration 3191, loss = 0.80324112
Iteration 3192, loss = 0.80472980
Iteration 3193, loss = 0.80077448
Iteration 3194, loss = 0.79992487
Iteration 3195, loss = 0.79861003
Iteration 3196, loss = 0.79339327
Iteration 3197, loss = 0.79395127
Iteration 3198, loss = 0.78681867
Iteration 3199, loss = 0.72264769
Iteration 3200, loss = 0.83275946
Iteration 3201, loss = 0.87903912
Iteration 3202, loss = 0.85485325
Iteration 3203, loss = 0.84342456
Iteration 3204, loss = 0.83866541
Iteration 3205, loss = 0.83504186
Iteration 3206, loss = 0.83848556
Iteration 3207, loss = 0.84305056
Iteration 3208, loss = 0.83909464
Iteration 3209, loss = 0.84519118
Iteration 3210, loss = 0.83557686
Iteration 3211, loss = 0.84362654
Iteration 3212, loss = 0.82425223
Iteration 3213, loss = 1.04121777
Iteration 3214, loss = 0.88898120
Iteration 3215, loss = 0.99440162
Iteration 3216, loss = 0.87976904
Iteration 3217, loss = 0.95269555
Iteration 3218, loss = 0.86580209
Iteration 3219, loss = 0.91936321
Iteration 3220, loss = 0.90155952
Iteration 3221, loss = 1.10636838
Iteration 3222, loss = 0.98790851
Iteration 3223, loss = 0.99802989
Iteration 3224, loss = 1.02671551
Iteration 3225, loss = 0.90795254
Iteration 3226, loss = 1.01676502
Iteration 3227, loss = 0.86040359
Iteration 3228, loss = 0.99062961
Iteration 3229, loss = 0.84607743
Iteration 3230, loss = 0.96324496
Iteration 3231, loss = 0.84824998
Iteration 3232, loss = 0.93686759
Iteration 3233, loss = 0.85527657
Iteration 3234, loss = 0.91177883
Iteration 3235, loss = 0.86028615
Iteration 3236, loss = 0.88852149
Iteration 3237, loss = 0.86229584
Iteration 3238, loss = 0.86941040
Iteration 3239, loss = 0.86163885
Iteration 3240, loss = 0.85414438
Iteration 3241, loss = 0.85823585
Iteration 3242, loss = 0.84201225
Iteration 3243, loss = 0.85171902
Iteration 3244, loss = 0.83149099
Iteration 3245, loss = 0.84772918
Iteration 3246, loss = 0.82461464
Iteration 3247, loss = 0.84167427
Iteration 3248, loss = 0.81963127
Iteration 3249, loss = 0.83392236
Iteration 3250, loss = 0.81781687
Iteration 3251, loss = 0.82660218
Iteration 3252, loss = 0.81631153
Iteration 3253, loss = 0.81799705
Iteration 3254, loss = 0.81391700
Iteration 3255, loss = 0.81298070
Iteration 3256, loss = 0.81097361
Iteration 3257, loss = 0.80818755
Iteration 3258, loss = 0.80860501
Iteration 3259, loss = 0.80448847
Iteration 3260, loss = 0.80512751
Iteration 3261, loss = 0.80113301
Iteration 3262, loss = 0.80213339
Iteration 3263, loss = 0.79801844
Iteration 3264, loss = 0.79890316
Iteration 3265, loss = 0.79534747
Iteration 3266, loss = 0.79555886
Iteration 3267, loss = 0.79272524
Iteration 3268, loss = 0.79248409
Iteration 3269, loss = 0.79018213
Iteration 3270, loss = 0.78951102
Iteration 3271, loss = 0.78776566
Iteration 3272, loss = 0.78668253
Iteration 3273, loss = 0.78535415
Iteration 3274, loss = 0.78399077
Iteration 3275, loss = 0.78294503
Iteration 3276, loss = 0.78143115
Iteration 3277, loss = 0.78214399
Iteration 3278, loss = 0.78739552
Iteration 3279, loss = 0.79002575
Iteration 3280, loss = 0.79268851
Iteration 3281, loss = 0.78585186
Iteration 3282, loss = 0.78258966
Iteration 3283, loss = 0.77890440
Iteration 3284, loss = 0.78003141
Iteration 3285, loss = 0.78074000
Iteration 3286, loss = 0.77932558
Iteration 3287, loss = 0.77756640
Iteration 3288, loss = 0.77363461
Iteration 3289, loss = 0.77344187
Iteration 3290, loss = 0.77128366
Iteration 3291, loss = 0.77217697
Iteration 3292, loss = 0.76967065
Iteration 3293, loss = 0.76959717
Iteration 3294, loss = 0.76659226
Iteration 3295, loss = 0.76757236
Iteration 3296, loss = 0.76555450
Iteration 3297, loss = 0.76485479
Iteration 3298, loss = 0.76262441
Iteration 3299, loss = 0.76145686
Iteration 3300, loss = 0.75886429
Iteration 3301, loss = 0.75793018
Iteration 3302, loss = 0.75295010
Iteration 3303, loss = 0.66818054
Iteration 3304, loss = 0.82812237
Iteration 3305, loss = 0.81955597
Iteration 3306, loss = 0.84611214
Iteration 3307, loss = 0.80820669
Iteration 3308, loss = 0.80700028
Iteration 3309, loss = 0.78512938
Iteration 3310, loss = 0.79434905
Iteration 3311, loss = 0.79550551
Iteration 3312, loss = 0.80204041
Iteration 3313, loss = 0.80352533
Iteration 3314, loss = 0.79691710
Iteration 3315, loss = 0.79723558
Iteration 3316, loss = 0.72842547
Iteration 3317, loss = 0.90158925
Iteration 3318, loss = 1.01168201
Iteration 3319, loss = 0.94962614
Iteration 3320, loss = 0.95276220
Iteration 3321, loss = 0.93954339
Iteration 3322, loss = 0.89988226
Iteration 3323, loss = 0.93008030
Iteration 3324, loss = 0.87505736
Iteration 3325, loss = 0.92838258
Iteration 3326, loss = 0.87227132
Iteration 3327, loss = 0.93104415
Iteration 3328, loss = 0.87356091
Iteration 3329, loss = 0.92160439
Iteration 3330, loss = 0.86281558
Iteration 3331, loss = 0.90017183
Iteration 3332, loss = 0.88953764
Iteration 3333, loss = 0.87625148
Iteration 3334, loss = 0.89641943
Iteration 3335, loss = 0.87967159
Iteration 3336, loss = 0.89176801
Iteration 3337, loss = 0.87350456
Iteration 3338, loss = 0.87304756
Iteration 3339, loss = 0.90266558
Iteration 3340, loss = 0.93059025
Iteration 3341, loss = 0.94524668
Iteration 3342, loss = 1.04075525
Iteration 3343, loss = 0.91376622
Iteration 3344, loss = 1.00915031
Iteration 3345, loss = 0.88731007
Iteration 3346, loss = 0.97885387
Iteration 3347, loss = 0.89760582
Iteration 3348, loss = 0.95372424
Iteration 3349, loss = 0.91652099
Iteration 3350, loss = 0.92230457
Iteration 3351, loss = 0.92604444
Iteration 3352, loss = 0.89591073
Iteration 3353, loss = 0.92760521
Iteration 3354, loss = 0.88613937
Iteration 3355, loss = 0.92156535
Iteration 3356, loss = 0.88578713
Iteration 3357, loss = 0.90541994
Iteration 3358, loss = 0.88767413
Iteration 3359, loss = 0.88779615
Iteration 3360, loss = 0.88971187
Iteration 3361, loss = 0.87529369
Iteration 3362, loss = 0.88588573
Iteration 3363, loss = 0.86339573
Iteration 3364, loss = 0.86699716
Iteration 3365, loss = 0.83957296
Iteration 3366, loss = 0.79173103
Iteration 3367, loss = 1.63002390
Iteration 3368, loss = 1.85400888
Iteration 3369, loss = 1.75413220
Iteration 3370, loss = 1.37506508
Iteration 3371, loss = 1.54076579
Iteration 3372, loss = 1.15417485
Iteration 3373, loss = 1.25328327
Iteration 3374, loss = 1.14183629
Iteration 3375, loss = 1.06497672
Iteration 3376, loss = 1.20678430
Iteration 3377, loss = 0.98615143
Iteration 3378, loss = 1.27717933
Iteration 3379, loss = 0.96751811
Iteration 3380, loss = 1.32660289
Iteration 3381, loss = 0.98830879
Iteration 3382, loss = 1.35647543
Iteration 3383, loss = 1.04030052
Iteration 3384, loss = 1.35637488
Iteration 3385, loss = 1.12199007
Iteration 3386, loss = 1.29056883
Iteration 3387, loss = 1.16506602
Iteration 3388, loss = 1.18514921
Iteration 3389, loss = 1.14211819
Iteration 3390, loss = 1.09804272
Iteration 3391, loss = 1.08049332
Iteration 3392, loss = 1.05147793
Iteration 3393, loss = 1.01509376
Iteration 3394, loss = 1.00292957
Iteration 3395, loss = 0.97748103
Iteration 3396, loss = 0.97544445
Iteration 3397, loss = 0.94129579
Iteration 3398, loss = 0.95866083
Iteration 3399, loss = 0.91024480
Iteration 3400, loss = 0.94846132
Iteration 3401, loss = 0.88526427
Iteration 3402, loss = 0.94111384
Iteration 3403, loss = 0.86536737
Iteration 3404, loss = 0.93453960
Iteration 3405, loss = 0.84957552
Iteration 3406, loss = 0.92689747
Iteration 3407, loss = 0.83665545
Iteration 3408, loss = 0.91799433
Iteration 3409, loss = 0.82636375
Iteration 3410, loss = 0.90772884
Iteration 3411, loss = 0.81771624
Iteration 3412, loss = 0.89580520
Iteration 3413, loss = 0.81095359
Iteration 3414, loss = 0.88295154
Iteration 3415, loss = 0.80572014
Iteration 3416, loss = 0.86928957
Iteration 3417, loss = 0.80211815
Iteration 3418, loss = 0.85540984
Iteration 3419, loss = 0.79977667
Iteration 3420, loss = 0.84161670
Iteration 3421, loss = 0.79848572
Iteration 3422, loss = 0.82863913
Iteration 3423, loss = 0.79796489
Iteration 3424, loss = 0.81691298
Iteration 3425, loss = 0.79774185
Iteration 3426, loss = 0.80678740
Iteration 3427, loss = 0.79734284
Iteration 3428, loss = 0.79839359
Iteration 3429, loss = 0.79640037
Iteration 3430, loss = 0.79169758
Iteration 3431, loss = 0.79471842
Iteration 3432, loss = 0.78653215
Iteration 3433, loss = 0.79230941
Iteration 3434, loss = 0.78268681
Iteration 3435, loss = 0.78932438
Iteration 3436, loss = 0.77989287
Iteration 3437, loss = 0.78597017
Iteration 3438, loss = 0.77781078
Iteration 3439, loss = 0.78242056
Iteration 3440, loss = 0.77610941
Iteration 3441, loss = 0.84696332
Iteration 3442, loss = 0.92010522
Iteration 3443, loss = 0.82886764
Iteration 3444, loss = 0.96428892
Iteration 3445, loss = 0.86021934
Iteration 3446, loss = 0.94061527
Iteration 3447, loss = 0.82661733
Iteration 3448, loss = 0.88888356
Iteration 3449, loss = 0.80423452
Iteration 3450, loss = 0.87128777
Iteration 3451, loss = 0.81758974
Iteration 3452, loss = 0.87474444
Iteration 3453, loss = 0.83213891
Iteration 3454, loss = 0.86668761
Iteration 3455, loss = 0.83177611
Iteration 3456, loss = 0.85071988
Iteration 3457, loss = 0.83013283
Iteration 3458, loss = 0.84096260
Iteration 3459, loss = 0.83336141
Iteration 3460, loss = 0.83574967
Iteration 3461, loss = 0.83474215
Iteration 3462, loss = 0.82908654
Iteration 3463, loss = 0.83217082
Iteration 3464, loss = 0.82244101
Iteration 3465, loss = 0.82823157
Iteration 3466, loss = 0.81749959
Iteration 3467, loss = 0.82476197
Iteration 3468, loss = 0.81282703
Iteration 3469, loss = 0.81946591
Iteration 3470, loss = 0.76187083
Iteration 3471, loss = 0.95435691
Iteration 3472, loss = 0.85014132
Iteration 3473, loss = 0.94015292
Iteration 3474, loss = 0.84672649
Iteration 3475, loss = 0.90694024
Iteration 3476, loss = 0.84065379
Iteration 3477, loss = 0.88713052
Iteration 3478, loss = 0.84851463
Iteration 3479, loss = 0.87889826
Iteration 3480, loss = 0.85189897
Iteration 3481, loss = 0.89784956
Iteration 3482, loss = 0.92963981
Iteration 3483, loss = 0.88981195
Iteration 3484, loss = 0.92645272
Iteration 3485, loss = 0.86464180
Iteration 3486, loss = 0.91442117
Iteration 3487, loss = 0.86132564
Iteration 3488, loss = 0.90948316
Iteration 3489, loss = 0.86636582
Iteration 3490, loss = 0.89689045
Iteration 3491, loss = 0.84786519
Iteration 3492, loss = 0.91919499
Iteration 3493, loss = 1.03981125
Iteration 3494, loss = 0.88162706
Iteration 3495, loss = 1.00528198
Iteration 3496, loss = 0.90544787
Iteration 3497, loss = 0.90667189
Iteration 3498, loss = 0.95921935
Iteration 3499, loss = 0.86834603
Iteration 3500, loss = 0.94466187
Iteration 3501, loss = 0.88806390
Iteration 3502, loss = 0.88471796
Iteration 3503, loss = 0.91499994
Iteration 3504, loss = 0.85801398
Iteration 3505, loss = 0.90180953
Iteration 3506, loss = 0.87455999
Iteration 3507, loss = 0.86646412
Iteration 3508, loss = 0.88853092
Iteration 3509, loss = 0.85168287
Iteration 3510, loss = 0.87300145
Iteration 3511, loss = 0.86197843
Iteration 3512, loss = 0.85105444
Iteration 3513, loss = 0.86748679
Iteration 3514, loss = 0.84550886
Iteration 3515, loss = 0.85373242
Iteration 3516, loss = 0.85146250
Iteration 3517, loss = 0.83990979
Iteration 3518, loss = 0.85060935
Iteration 3519, loss = 0.83891434
Iteration 3520, loss = 0.83990529
Iteration 3521, loss = 0.84160944
Iteration 3522, loss = 0.83204994
Iteration 3523, loss = 0.83737088
Iteration 3524, loss = 0.83177155
Iteration 3525, loss = 0.82925314
Iteration 3526, loss = 0.83190781
Iteration 3527, loss = 0.82542079
Iteration 3528, loss = 0.82715382
Iteration 3529, loss = 0.82502971
Iteration 3530, loss = 0.82148529
Iteration 3531, loss = 0.82321284
Iteration 3532, loss = 0.81917039
Iteration 3533, loss = 0.81877414
Iteration 3534, loss = 0.81836716
Iteration 3535, loss = 0.81512254
Iteration 3536, loss = 0.81567445
Iteration 3537, loss = 0.81347694
Iteration 3538, loss = 0.81192267
Iteration 3539, loss = 0.81181998
Iteration 3540, loss = 0.80936933
Iteration 3541, loss = 0.80899892
Iteration 3542, loss = 0.80790139
Iteration 3543, loss = 0.80611134
Iteration 3544, loss = 0.80578725
Iteration 3545, loss = 0.80409222
Iteration 3546, loss = 0.80308614
Iteration 3547, loss = 0.80236366
Iteration 3548, loss = 0.80075564
Iteration 3549, loss = 0.80010180
Iteration 3550, loss = 0.79893204
Iteration 3551, loss = 0.79769331
Iteration 3552, loss = 0.79699916
Iteration 3553, loss = 0.79567930
Iteration 3554, loss = 0.79477503
Iteration 3555, loss = 0.79389467
Iteration 3556, loss = 0.79269570
Iteration 3557, loss = 0.79190111
Iteration 3558, loss = 0.79075593
Iteration 3559, loss = 0.78970462
Iteration 3560, loss = 0.78875679
Iteration 3561, loss = 0.78609821
Iteration 3562, loss = 0.78780612
Iteration 3563, loss = 0.79222658
Iteration 3564, loss = 0.79352445
Iteration 3565, loss = 0.79029350
Iteration 3566, loss = 0.78602159
Iteration 3567, loss = 0.78747990
Iteration 3568, loss = 0.78407338
Iteration 3569, loss = 0.78396140
Iteration 3570, loss = 0.78501375
Iteration 3571, loss = 0.78178191
Iteration 3572, loss = 0.78138866
Iteration 3573, loss = 0.78031181
Iteration 3574, loss = 0.77896883
Iteration 3575, loss = 0.77922459
Iteration 3576, loss = 0.77711274
Iteration 3577, loss = 0.77637766
Iteration 3578, loss = 0.77614017
Iteration 3579, loss = 0.77465892
Iteration 3580, loss = 0.80885462
Iteration 3581, loss = 0.79788570
Iteration 3582, loss = 0.78702853
Iteration 3583, loss = 0.80288794
Iteration 3584, loss = 0.77336881
Iteration 3585, loss = 0.78154761
Iteration 3586, loss = 0.77473370
Iteration 3587, loss = 0.78375828
Iteration 3588, loss = 0.78231139
Iteration 3589, loss = 0.78187456
Iteration 3590, loss = 0.77249844
Iteration 3591, loss = 0.77477864
Iteration 3592, loss = 0.77530953
Iteration 3593, loss = 0.77161659
Iteration 3594, loss = 0.77323802
Iteration 3595, loss = 0.77028025
Iteration 3596, loss = 0.77034384
Iteration 3597, loss = 0.77128196
Iteration 3598, loss = 0.76706010
Iteration 3599, loss = 0.76718224
Iteration 3600, loss = 0.76652067
Iteration 3601, loss = 0.76526465
Iteration 3602, loss = 0.76611978
Iteration 3603, loss = 0.76333859
Iteration 3604, loss = 0.76109356
Iteration 3605, loss = 0.76094622
Iteration 3606, loss = 0.75876009
Iteration 3607, loss = 0.75713823
Iteration 3608, loss = 0.78095411
Iteration 3609, loss = 0.78706440
Iteration 3610, loss = 0.76813589
Iteration 3611, loss = 0.77198185
Iteration 3612, loss = 0.77089879
Iteration 3613, loss = 0.74837432
Iteration 3614, loss = 1.08148573
Iteration 3615, loss = 1.31789622
Iteration 3616, loss = 1.03220590
Iteration 3617, loss = 1.36140020
Iteration 3618, loss = 1.10013262
Iteration 3619, loss = 1.30211352
Iteration 3620, loss = 1.14253856
Iteration 3621, loss = 1.21633795
Iteration 3622, loss = 1.14666959
Iteration 3623, loss = 1.15246117
Iteration 3624, loss = 1.11128234
Iteration 3625, loss = 1.10130743
Iteration 3626, loss = 1.05108726
Iteration 3627, loss = 1.07710017
Iteration 3628, loss = 0.99982948
Iteration 3629, loss = 1.06816105
Iteration 3630, loss = 0.96375126
Iteration 3631, loss = 1.06837107
Iteration 3632, loss = 0.93967854
Iteration 3633, loss = 1.07356182
Iteration 3634, loss = 0.91974178
Iteration 3635, loss = 1.07246588
Iteration 3636, loss = 0.90775963
Iteration 3637, loss = 1.06660758
Iteration 3638, loss = 0.89570065
Iteration 3639, loss = 1.05919582
Iteration 3640, loss = 0.88808122
Iteration 3641, loss = 1.05443242
Iteration 3642, loss = 0.88276338
Iteration 3643, loss = 1.04650309
Iteration 3644, loss = 0.87545656
Iteration 3645, loss = 1.03496240
Iteration 3646, loss = 0.86750536
Iteration 3647, loss = 1.02232482
Iteration 3648, loss = 1.04989470
Iteration 3649, loss = 1.57104260
Iteration 3650, loss = 1.27735296
Iteration 3651, loss = 1.23578230
Iteration 3652, loss = 1.39039293
Iteration 3653, loss = 0.90840395
Iteration 3654, loss = 1.25540607
Iteration 3655, loss = 0.82329839
Iteration 3656, loss = 1.17142835
Iteration 3657, loss = 0.84237896
Iteration 3658, loss = 1.13478503
Iteration 3659, loss = 0.88813767
Iteration 3660, loss = 1.10017902
Iteration 3661, loss = 0.92398074
Iteration 3662, loss = 1.05324027
Iteration 3663, loss = 0.93961718
Iteration 3664, loss = 1.00402118
Iteration 3665, loss = 0.94101112
Iteration 3666, loss = 0.96407326
Iteration 3667, loss = 0.93054792
Iteration 3668, loss = 0.93263892
Iteration 3669, loss = 0.91217064
Iteration 3670, loss = 0.90818377
Iteration 3671, loss = 0.89119325
Iteration 3672, loss = 0.89019428
Iteration 3673, loss = 0.87187808
Iteration 3674, loss = 0.87753917
Iteration 3675, loss = 0.85483022
Iteration 3676, loss = 0.86711437
Iteration 3677, loss = 0.83966888
Iteration 3678, loss = 0.85806129
Iteration 3679, loss = 0.82717593
Iteration 3680, loss = 0.85018932
Iteration 3681, loss = 0.81677363
Iteration 3682, loss = 0.84256474
Iteration 3683, loss = 0.80785367
Iteration 3684, loss = 0.83495090
Iteration 3685, loss = 0.80034721
Iteration 3686, loss = 0.82748282
Iteration 3687, loss = 0.79426806
Iteration 3688, loss = 0.82023682
Iteration 3689, loss = 0.78932649
Iteration 3690, loss = 0.81306662
Iteration 3691, loss = 0.78518467
Iteration 3692, loss = 0.80606405
Iteration 3693, loss = 0.78175016
Iteration 3694, loss = 0.79934379
Iteration 3695, loss = 0.77890841
Iteration 3696, loss = 0.79306416
Iteration 3697, loss = 0.77651149
Iteration 3698, loss = 0.78726123
Iteration 3699, loss = 0.77437793
Iteration 3700, loss = 0.78193285
Iteration 3701, loss = 0.77239741
Iteration 3702, loss = 0.77713269
Iteration 3703, loss = 0.77049901
Iteration 3704, loss = 0.77285845
Iteration 3705, loss = 0.76861844
Iteration 3706, loss = 0.76908569
Iteration 3707, loss = 0.76670381
Iteration 3708, loss = 0.76575449
Iteration 3709, loss = 0.76473395
Iteration 3710, loss = 0.76283174
Iteration 3711, loss = 0.76272813
Iteration 3712, loss = 0.76026425
Iteration 3713, loss = 0.76068918
Iteration 3714, loss = 0.75798927
Iteration 3715, loss = 0.75864154
Iteration 3716, loss = 0.75595489
Iteration 3717, loss = 0.75660746
Iteration 3718, loss = 0.75410794
Iteration 3719, loss = 0.75461479
Iteration 3720, loss = 0.75241178
Iteration 3721, loss = 0.75268749
Iteration 3722, loss = 0.75082476
Iteration 3723, loss = 0.75083332
Iteration 3724, loss = 0.74931534
Iteration 3725, loss = 0.74906963
Iteration 3726, loss = 0.74786849
Iteration 3727, loss = 0.74739956
Iteration 3728, loss = 0.74646386
Iteration 3729, loss = 0.74582566
Iteration 3730, loss = 0.74510089
Iteration 3731, loss = 0.74434601
Iteration 3732, loss = 0.74376632
Iteration 3733, loss = 0.74294707
Iteration 3734, loss = 0.74246290
Iteration 3735, loss = 0.74162771
Iteration 3736, loss = 0.74119208
Iteration 3737, loss = 0.74037556
Iteration 3738, loss = 0.73995679
Iteration 3739, loss = 0.73918462
Iteration 3740, loss = 0.73875859
Iteration 3741, loss = 0.73804365
Iteration 3742, loss = 0.73760020
Iteration 3743, loss = 0.73694924
Iteration 3744, loss = 0.73648473
Iteration 3745, loss = 0.73589398
Iteration 3746, loss = 0.73540802
Iteration 3747, loss = 0.73486659
Iteration 3748, loss = 0.73436598
Iteration 3749, loss = 0.73387108
Iteration 3750, loss = 0.73336879
Iteration 3751, loss = 0.73290524
Iteration 3752, loss = 0.73239325
Iteration 3753, loss = 0.73129867
Iteration 3754, loss = 0.73240276
Iteration 3755, loss = 0.73339522
Iteration 3756, loss = 0.73317984
Iteration 3757, loss = 0.73193285
Iteration 3758, loss = 0.73072034
Iteration 3759, loss = 0.73044280
Iteration 3760, loss = 0.73009068
Iteration 3761, loss = 0.72992207
Iteration 3762, loss = 0.72940957
Iteration 3763, loss = 0.72891561
Iteration 3764, loss = 0.72853019
Iteration 3765, loss = 0.72801779
Iteration 3766, loss = 0.72755175
Iteration 3767, loss = 0.72708543
Iteration 3768, loss = 0.72683280
Iteration 3769, loss = 0.72648593
Iteration 3770, loss = 0.72612649
Iteration 3771, loss = 0.72571516
Iteration 3772, loss = 0.72525110
Iteration 3773, loss = 0.72104631
Iteration 3774, loss = 0.74371807
Iteration 3775, loss = 0.76595209
Iteration 3776, loss = 0.74810957
Iteration 3777, loss = 0.75350723
Iteration 3778, loss = 0.74795190
Iteration 3779, loss = 0.74460487
Iteration 3780, loss = 0.75869659
Iteration 3781, loss = 0.75374860
Iteration 3782, loss = 0.75857077
Iteration 3783, loss = 0.76270789
Iteration 3784, loss = 0.75803995
Iteration 3785, loss = 0.76566953
Iteration 3786, loss = 0.76458434
Iteration 3787, loss = 0.76368192
Iteration 3788, loss = 0.76846668
Iteration 3789, loss = 0.76614906
Iteration 3790, loss = 0.76969032
Iteration 3791, loss = 0.77162597
Iteration 3792, loss = 0.76912725
Iteration 3793, loss = 0.77133463
Iteration 3794, loss = 0.77009110
Iteration 3795, loss = 0.76996406
Iteration 3796, loss = 0.77208499
Iteration 3797, loss = 0.77056315
Iteration 3798, loss = 0.77120185
Iteration 3799, loss = 0.77117565
Iteration 3800, loss = 0.76949872
Iteration 3801, loss = 0.77000904
Iteration 3802, loss = 0.76908987
Iteration 3803, loss = 0.76852222
Iteration 3804, loss = 0.76885752
Iteration 3805, loss = 0.76745909
Iteration 3806, loss = 0.76691575
Iteration 3807, loss = 0.76637278
Iteration 3808, loss = 0.76369536
Iteration 3809, loss = 0.77563348
Iteration 3810, loss = 0.79221477
Iteration 3811, loss = 0.80056916
Iteration 3812, loss = 0.79627732
Iteration 3813, loss = 0.77709284
Iteration 3814, loss = 0.77606167
Iteration 3815, loss = 0.81536351
Iteration 3816, loss = 0.79826868
Iteration 3817, loss = 0.75741753
Iteration 3818, loss = 0.77782818
Iteration 3819, loss = 0.80005963
Iteration 3820, loss = 0.77090308
Iteration 3821, loss = 0.78290613
Iteration 3822, loss = 0.77459643
Iteration 3823, loss = 0.76361141
Iteration 3824, loss = 0.77696984
Iteration 3825, loss = 0.76313896
Iteration 3826, loss = 0.76898646
Iteration 3827, loss = 0.76632303
Iteration 3828, loss = 0.75728351
Iteration 3829, loss = 0.76561442
Iteration 3830, loss = 0.75774975
Iteration 3831, loss = 0.75912616
Iteration 3832, loss = 0.76020732
Iteration 3833, loss = 0.75276884
Iteration 3834, loss = 0.75592666
Iteration 3835, loss = 0.75117443
Iteration 3836, loss = 0.74955287
Iteration 3837, loss = 0.75040024
Iteration 3838, loss = 0.74269427
Iteration 3839, loss = 0.74987459
Iteration 3840, loss = 0.75098224
Iteration 3841, loss = 0.74890902
Iteration 3842, loss = 0.74515718
Iteration 3843, loss = 0.74205635
Iteration 3844, loss = 0.74061928
Iteration 3845, loss = 0.73694230
Iteration 3846, loss = 0.73174539
Iteration 3847, loss = 0.61007719
Iteration 3848, loss = 0.76820162
Iteration 3849, loss = 0.93860697
Iteration 3850, loss = 0.79726813
Iteration 3851, loss = 0.79759348
Iteration 3852, loss = 0.89603553
Iteration 3853, loss = 0.77149277
Iteration 3854, loss = 0.80315763
Iteration 3855, loss = 0.86268159
Iteration 3856, loss = 0.76640258
Iteration 3857, loss = 1.35235118
Iteration 3858, loss = 0.87196241
Iteration 3859, loss = 1.07059399
Iteration 3860, loss = 1.03296852
Iteration 3861, loss = 0.84686350
Iteration 3862, loss = 1.13984023
Iteration 3863, loss = 0.80212669
Iteration 3864, loss = 1.07044231
Iteration 3865, loss = 0.87473111
Iteration 3866, loss = 0.90660997
Iteration 3867, loss = 0.99337007
Iteration 3868, loss = 0.82333533
Iteration 3869, loss = 0.98425526
Iteration 3870, loss = 0.85419097
Iteration 3871, loss = 0.87520155
Iteration 3872, loss = 0.92841138
Iteration 3873, loss = 0.82273731
Iteration 3874, loss = 0.91401776
Iteration 3875, loss = 0.85465906
Iteration 3876, loss = 0.84096900
Iteration 3877, loss = 0.88744127
Iteration 3878, loss = 0.81668192
Iteration 3879, loss = 0.85661330
Iteration 3880, loss = 0.83799468
Iteration 3881, loss = 0.76548122
Iteration 3882, loss = 1.11915502
Iteration 3883, loss = 1.31386849
Iteration 3884, loss = 0.91918612
Iteration 3885, loss = 1.46548361
Iteration 3886, loss = 0.85266660
Iteration 3887, loss = 1.46827752
Iteration 3888, loss = 0.83460384
Iteration 3889, loss = 1.42276030
Iteration 3890, loss = 0.83924908
Iteration 3891, loss = 1.30531695
Iteration 3892, loss = 0.86845664
Iteration 3893, loss = 1.08785147
Iteration 3894, loss = 0.98386509
Iteration 3895, loss = 0.88129127
Iteration 3896, loss = 1.08665300
Iteration 3897, loss = 0.82997166
Iteration 3898, loss = 1.01859840
Iteration 3899, loss = 0.82695080
Iteration 3900, loss = 1.20282631
Iteration 3901, loss = 1.09815467
Iteration 3902, loss = 0.95108639
Iteration 3903, loss = 1.18612427
Iteration 3904, loss = 0.89562206
Iteration 3905, loss = 1.18925483
Iteration 3906, loss = 0.85917615
Iteration 3907, loss = 1.17040296
Iteration 3908, loss = 0.85683884
Iteration 3909, loss = 1.15847434
Iteration 3910, loss = 0.86331003
Iteration 3911, loss = 1.11915408
Iteration 3912, loss = 0.86421856
Iteration 3913, loss = 1.07131794
Iteration 3914, loss = 0.87243873
Iteration 3915, loss = 1.05335587
Iteration 3916, loss = 0.87949043
Iteration 3917, loss = 1.03759425
Iteration 3918, loss = 0.88433348
Iteration 3919, loss = 1.02481818
Iteration 3920, loss = 0.88846324
Iteration 3921, loss = 1.01405180
Iteration 3922, loss = 0.89055395
Iteration 3923, loss = 1.00162748
Iteration 3924, loss = 0.88719266
Iteration 3925, loss = 0.98645532
Iteration 3926, loss = 0.88288003
Iteration 3927, loss = 0.97286698
Iteration 3928, loss = 0.87811299
Iteration 3929, loss = 0.95861541
Iteration 3930, loss = 0.87291711
Iteration 3931, loss = 0.94494717
Iteration 3932, loss = 0.86529907
Iteration 3933, loss = 0.92592545
Iteration 3934, loss = 0.79391099
Iteration 3935, loss = 0.92919964
Iteration 3936, loss = 0.89967496
Iteration 3937, loss = 0.92183278
Iteration 3938, loss = 0.89169525
Iteration 3939, loss = 0.89775580
Iteration 3940, loss = 0.95027090
Iteration 3941, loss = 0.88407234
Iteration 3942, loss = 0.93553227
Iteration 3943, loss = 0.89005832
Iteration 3944, loss = 0.92291071
Iteration 3945, loss = 0.89977730
Iteration 3946, loss = 0.90991883
Iteration 3947, loss = 0.90106040
Iteration 3948, loss = 0.89525081
Iteration 3949, loss = 0.90204277
Iteration 3950, loss = 0.88848985
Iteration 3951, loss = 0.90337221
Iteration 3952, loss = 0.88597487
Iteration 3953, loss = 0.90173610
Iteration 3954, loss = 0.88301844
Iteration 3955, loss = 0.89505738
Iteration 3956, loss = 0.88040536
Iteration 3957, loss = 0.88847751
Iteration 3958, loss = 0.87925760
Iteration 3959, loss = 0.88249622
Iteration 3960, loss = 0.87876729
Iteration 3961, loss = 0.87655750
Iteration 3962, loss = 0.87787026
Iteration 3963, loss = 0.87116363
Iteration 3964, loss = 0.87461686
Iteration 3965, loss = 0.86799389
Iteration 3966, loss = 0.86862752
Iteration 3967, loss = 0.86538948
Iteration 3968, loss = 0.85685215
Iteration 3969, loss = 0.86514449
Iteration 3970, loss = 0.87015506
Iteration 3971, loss = 0.86366815
Iteration 3972, loss = 0.86256637
Iteration 3973, loss = 0.85786954
Iteration 3974, loss = 0.85716705
Iteration 3975, loss = 0.85643759
Iteration 3976, loss = 0.85506234
Iteration 3977, loss = 0.85468876
Iteration 3978, loss = 0.86205033
Iteration 3979, loss = 0.87572165
Iteration 3980, loss = 0.87027617
Iteration 3981, loss = 0.86098837
Iteration 3982, loss = 0.85270375
Iteration 3983, loss = 0.85409302
Iteration 3984, loss = 0.85438747
Iteration 3985, loss = 0.85491946
Iteration 3986, loss = 0.85161390
Iteration 3987, loss = 0.84925317
Iteration 3988, loss = 0.84715243
Iteration 3989, loss = 0.84482754
Iteration 3990, loss = 0.84265337
Iteration 3991, loss = 0.83956290
Iteration 3992, loss = 0.83774138
Iteration 3993, loss = 0.83473714
Iteration 3994, loss = 0.83267599
Iteration 3995, loss = 0.82864957
Iteration 3996, loss = 0.82654096
Iteration 3997, loss = 0.82052354
Iteration 3998, loss = 0.81047120
Iteration 3999, loss = 0.92760840
Iteration 4000, loss = 0.95329111
Iteration 4001, loss = 0.87765940
Iteration 4002, loss = 0.94886356
Iteration 4003, loss = 0.83696071
Iteration 4004, loss = 0.94990189
Iteration 4005, loss = 0.83172813
Iteration 4006, loss = 0.92940887
Iteration 4007, loss = 0.82808080
Iteration 4008, loss = 0.89533955
Iteration 4009, loss = 0.83361596
Iteration 4010, loss = 0.85849910
Iteration 4011, loss = 0.84267021
Iteration 4012, loss = 0.82980131
Iteration 4013, loss = 0.85721032
Iteration 4014, loss = 0.84745290
Iteration 4015, loss = 0.84550121
Iteration 4016, loss = 0.87014578
Iteration 4017, loss = 0.84444205
Iteration 4018, loss = 0.87045901
Iteration 4019, loss = 0.85108905
Iteration 4020, loss = 0.87092946
Iteration 4021, loss = 0.86025328
Iteration 4022, loss = 0.86757836
Iteration 4023, loss = 0.87146255
Iteration 4024, loss = 0.87420459
Iteration 4025, loss = 0.88809554
Iteration 4026, loss = 0.88502119
Iteration 4027, loss = 0.89856874
Iteration 4028, loss = 0.89012000
Iteration 4029, loss = 0.90000904
Iteration 4030, loss = 0.89296877
Iteration 4031, loss = 0.90033982
Iteration 4032, loss = 0.89699638
Iteration 4033, loss = 0.89954347
Iteration 4034, loss = 0.89868489
Iteration 4035, loss = 0.89758972
Iteration 4036, loss = 0.89933201
Iteration 4037, loss = 0.89586048
Iteration 4038, loss = 0.89748088
Iteration 4039, loss = 0.89224563
Iteration 4040, loss = 0.89290829
Iteration 4041, loss = 0.88838163
Iteration 4042, loss = 0.88825661
Iteration 4043, loss = 0.88507485
Iteration 4044, loss = 0.88350273
Iteration 4045, loss = 0.88129543
Iteration 4046, loss = 0.87855185
Iteration 4047, loss = 0.87714736
Iteration 4048, loss = 0.87396750
Iteration 4049, loss = 0.87287025
Iteration 4050, loss = 0.86965591
Iteration 4051, loss = 0.86833341
Iteration 4052, loss = 0.86552253
Iteration 4053, loss = 0.86394087
Iteration 4054, loss = 0.86178432
Iteration 4055, loss = 0.85990918
Iteration 4056, loss = 0.85819292
Iteration 4057, loss = 0.85598044
Iteration 4058, loss = 0.85463722
Iteration 4059, loss = 0.85268092
Iteration 4060, loss = 0.85222228
Iteration 4061, loss = 0.84983442
Iteration 4062, loss = 0.84752620
Iteration 4063, loss = 0.84544716
Iteration 4064, loss = 0.84018639
Iteration 4065, loss = 0.87943663
Iteration 4066, loss = 0.89621997
Iteration 4067, loss = 0.85881952
Iteration 4068, loss = 0.89212426
Iteration 4069, loss = 0.84082365
Iteration 4070, loss = 0.88267404
Iteration 4071, loss = 0.84788144
Iteration 4072, loss = 0.86660641
Iteration 4073, loss = 0.85179889
Iteration 4074, loss = 0.84461207
Iteration 4075, loss = 0.85488318
Iteration 4076, loss = 0.83622146
Iteration 4077, loss = 0.85436609
Iteration 4078, loss = 0.83291562
Iteration 4079, loss = 0.84366007
Iteration 4080, loss = 0.83365367
Iteration 4081, loss = 0.83396421
Iteration 4082, loss = 0.83532834
Iteration 4083, loss = 0.82467315
Iteration 4084, loss = 0.84184437
Iteration 4085, loss = 0.82891850
Iteration 4086, loss = 0.83132586
Iteration 4087, loss = 0.83265296
Iteration 4088, loss = 0.82292789
Iteration 4089, loss = 0.83088010
Iteration 4090, loss = 0.82080335
Iteration 4091, loss = 0.82579182
Iteration 4092, loss = 0.82297968
Iteration 4093, loss = 0.81995942
Iteration 4094, loss = 0.82312862
Iteration 4095, loss = 0.81636578
Iteration 4096, loss = 0.81975661
Iteration 4097, loss = 0.81632574
Iteration 4098, loss = 0.81558865
Iteration 4099, loss = 0.81570929
Iteration 4100, loss = 0.81196478
Iteration 4101, loss = 0.81368576
Iteration 4102, loss = 0.81018987
Iteration 4103, loss = 0.80972851
Iteration 4104, loss = 0.80857160
Iteration 4105, loss = 0.80604670
Iteration 4106, loss = 0.80608155
Iteration 4107, loss = 0.80296289
Iteration 4108, loss = 0.80272265
Iteration 4109, loss = 0.80039942
Iteration 4110, loss = 0.79840890
Iteration 4111, loss = 0.79765771
Iteration 4112, loss = 0.79423784
Iteration 4113, loss = 0.79451429
Iteration 4114, loss = 0.79182624
Iteration 4115, loss = 0.79045170
Iteration 4116, loss = 0.79162587
Iteration 4117, loss = 0.78211939
Iteration 4118, loss = 0.75014181
Iteration 4119, loss = 0.84079422
Iteration 4120, loss = 0.89600764
Iteration 4121, loss = 0.81050601
Iteration 4122, loss = 0.87622505
Iteration 4123, loss = 0.80484357
Iteration 4124, loss = 0.85522714
Iteration 4125, loss = 0.82416400
Iteration 4126, loss = 0.83234518
Iteration 4127, loss = 0.84107896
Iteration 4128, loss = 0.81667594
Iteration 4129, loss = 0.84806579
Iteration 4130, loss = 0.81240583
Iteration 4131, loss = 0.83649940
Iteration 4132, loss = 0.81411498
Iteration 4133, loss = 0.82206463
Iteration 4134, loss = 0.82383300
Iteration 4135, loss = 0.81432379
Iteration 4136, loss = 0.82642946
Iteration 4137, loss = 0.80767630
Iteration 4138, loss = 0.81833703
Iteration 4139, loss = 0.80731007
Iteration 4140, loss = 0.81056220
Iteration 4141, loss = 0.80850665
Iteration 4142, loss = 0.80243567
Iteration 4143, loss = 0.80718360
Iteration 4144, loss = 0.79473171
Iteration 4145, loss = 0.78831719
Iteration 4146, loss = 0.59514272
Iteration 4147, loss = 0.79162755
Iteration 4148, loss = 0.93002820
Iteration 4149, loss = 0.82157067
Iteration 4150, loss = 0.91608492
Iteration 4151, loss = 0.83386313
Iteration 4152, loss = 0.88176676
Iteration 4153, loss = 0.83340248
Iteration 4154, loss = 0.84063025
Iteration 4155, loss = 0.85700808
Iteration 4156, loss = 0.80576009
Iteration 4157, loss = 0.85128467
Iteration 4158, loss = 0.80887225
Iteration 4159, loss = 0.85032906
Iteration 4160, loss = 0.81223966
Iteration 4161, loss = 0.84656553
Iteration 4162, loss = 0.81230503
Iteration 4163, loss = 0.83940677
Iteration 4164, loss = 0.80990375
Iteration 4165, loss = 0.82582635
Iteration 4166, loss = 0.81096584
Iteration 4167, loss = 0.82370901
Iteration 4168, loss = 0.81049382
Iteration 4169, loss = 0.82012852
Iteration 4170, loss = 0.80957235
Iteration 4171, loss = 0.81738694
Iteration 4172, loss = 0.80841894
Iteration 4173, loss = 0.81392268
Iteration 4174, loss = 0.80596968
Iteration 4175, loss = 0.81010680
Iteration 4176, loss = 0.80350561
Iteration 4177, loss = 0.80639173
Iteration 4178, loss = 0.80023498
Iteration 4179, loss = 0.80224406
Iteration 4180, loss = 0.79710951
Iteration 4181, loss = 0.79840314
Iteration 4182, loss = 0.79396710
Iteration 4183, loss = 0.79427789
Iteration 4184, loss = 0.79053147
Iteration 4185, loss = 0.78997981
Iteration 4186, loss = 0.78606980
Iteration 4187, loss = 0.78759132
Iteration 4188, loss = 0.78481041
Iteration 4189, loss = 0.78332307
Iteration 4190, loss = 0.78046001
Iteration 4191, loss = 0.77671402
Iteration 4192, loss = 0.77344769
Iteration 4193, loss = 0.80323961
Iteration 4194, loss = 0.90597652
Iteration 4195, loss = 0.79620259
Iteration 4196, loss = 0.89730300
Iteration 4197, loss = 0.78697624
Iteration 4198, loss = 0.85739163
Iteration 4199, loss = 0.77254828
Iteration 4200, loss = 0.90134473
Iteration 4201, loss = 0.89610986
Iteration 4202, loss = 0.86574602
Iteration 4203, loss = 0.91178956
Iteration 4204, loss = 0.83584314
Iteration 4205, loss = 0.87921658
Iteration 4206, loss = 0.81282112
Iteration 4207, loss = 0.87721554
Iteration 4208, loss = 0.81998053
Iteration 4209, loss = 0.88337124
Iteration 4210, loss = 0.82332819
Iteration 4211, loss = 0.87738160
Iteration 4212, loss = 0.81930580
Iteration 4213, loss = 0.86614867
Iteration 4214, loss = 0.81604363
Iteration 4215, loss = 0.85807397
Iteration 4216, loss = 0.81938725
Iteration 4217, loss = 0.85416016
Iteration 4218, loss = 0.82333817
Iteration 4219, loss = 0.84680928
Iteration 4220, loss = 0.82276238
Iteration 4221, loss = 0.83720749
Iteration 4222, loss = 0.82213565
Iteration 4223, loss = 0.83072709
Iteration 4224, loss = 0.82372897
Iteration 4225, loss = 0.82650449
Iteration 4226, loss = 0.82383227
Iteration 4227, loss = 0.82108958
Iteration 4228, loss = 0.82165903
Iteration 4229, loss = 0.81609520
Iteration 4230, loss = 0.81923240
Iteration 4231, loss = 0.81271693
Iteration 4232, loss = 0.81692046
Iteration 4233, loss = 0.80990283
Iteration 4234, loss = 0.81384100
Iteration 4235, loss = 0.80716641
Iteration 4236, loss = 0.81012619
Iteration 4237, loss = 0.80444033
Iteration 4238, loss = 0.80644400
Iteration 4239, loss = 0.80216403
Iteration 4240, loss = 0.80300308
Iteration 4241, loss = 0.79991799
Iteration 4242, loss = 0.79952456
Iteration 4243, loss = 0.79744338
Iteration 4244, loss = 0.79617909
Iteration 4245, loss = 0.79492700
Iteration 4246, loss = 0.79306636
Iteration 4247, loss = 0.79233663
Iteration 4248, loss = 0.79012723
Iteration 4249, loss = 0.78964569
Iteration 4250, loss = 0.78737669
Iteration 4251, loss = 0.78693658
Iteration 4252, loss = 0.78474202
Iteration 4253, loss = 0.78418660
Iteration 4254, loss = 0.78215780
Iteration 4255, loss = 0.78119792
Iteration 4256, loss = 0.77139323
Iteration 4257, loss = 0.78837693
Iteration 4258, loss = 0.80521940
Iteration 4259, loss = 0.81033320
Iteration 4260, loss = 0.80785358
Iteration 4261, loss = 0.79771517
Iteration 4262, loss = 0.79187033
Iteration 4263, loss = 0.78959517
Iteration 4264, loss = 0.79146111
Iteration 4265, loss = 0.79357895
Iteration 4266, loss = 0.80232174
Iteration 4267, loss = 0.81183846
Iteration 4268, loss = 0.81351799
Iteration 4269, loss = 0.80691871
Iteration 4270, loss = 0.80027611
Iteration 4271, loss = 0.79685240
Iteration 4272, loss = 0.79676460
Iteration 4273, loss = 0.79685008
Iteration 4274, loss = 0.79757856
Iteration 4275, loss = 0.79364909
Iteration 4276, loss = 0.78734980
Iteration 4277, loss = 0.94438587
Iteration 4278, loss = 0.91348183
Iteration 4279, loss = 0.81543180
Iteration 4280, loss = 0.95055471
Iteration 4281, loss = 0.80587091
Iteration 4282, loss = 0.91300058
Iteration 4283, loss = 0.81524293
Iteration 4284, loss = 0.87679387
Iteration 4285, loss = 0.83817193
Iteration 4286, loss = 0.84336881
Iteration 4287, loss = 0.85329863
Iteration 4288, loss = 0.82012686
Iteration 4289, loss = 0.86223203
Iteration 4290, loss = 0.81471629
Iteration 4291, loss = 0.85785767
Iteration 4292, loss = 0.81630730
Iteration 4293, loss = 0.84157120
Iteration 4294, loss = 0.82146556
Iteration 4295, loss = 0.82480412
Iteration 4296, loss = 0.82703021
Iteration 4297, loss = 0.81453894
Iteration 4298, loss = 0.82828149
Iteration 4299, loss = 0.80730806
Iteration 4300, loss = 0.82219888
Iteration 4301, loss = 0.77990422
Iteration 4302, loss = 0.88316540
Iteration 4303, loss = 0.98310685
Iteration 4304, loss = 0.85203275
Iteration 4305, loss = 0.97049182
Iteration 4306, loss = 0.82234267
Iteration 4307, loss = 0.95076343
Iteration 4308, loss = 0.82423558
Iteration 4309, loss = 0.92944503
Iteration 4310, loss = 0.83380212
Iteration 4311, loss = 0.89263276
Iteration 4312, loss = 0.84358540
Iteration 4313, loss = 0.85725855
Iteration 4314, loss = 0.85566720
Iteration 4315, loss = 0.83315560
Iteration 4316, loss = 0.86189764
Iteration 4317, loss = 0.82072766
Iteration 4318, loss = 0.85835807
Iteration 4319, loss = 0.81757485
Iteration 4320, loss = 0.84559182
Iteration 4321, loss = 0.81963582
Iteration 4322, loss = 0.83020791
Iteration 4323, loss = 0.82374707
Iteration 4324, loss = 0.81731962
Iteration 4325, loss = 0.82533365
Iteration 4326, loss = 0.80893837
Iteration 4327, loss = 0.82203891
Iteration 4328, loss = 0.80529952
Iteration 4329, loss = 0.81525311
Iteration 4330, loss = 0.80473800
Iteration 4331, loss = 0.80694884
Iteration 4332, loss = 0.80453275
Iteration 4333, loss = 0.79992421
Iteration 4334, loss = 0.80290882
Iteration 4335, loss = 0.79499179
Iteration 4336, loss = 0.79949279
Iteration 4337, loss = 0.79229527
Iteration 4338, loss = 0.79458069
Iteration 4339, loss = 0.79053766
Iteration 4340, loss = 0.78958412
Iteration 4341, loss = 0.78879299
Iteration 4342, loss = 0.78520142
Iteration 4343, loss = 0.78620995
Iteration 4344, loss = 0.78211396
Iteration 4345, loss = 0.78300128
Iteration 4346, loss = 0.77978192
Iteration 4347, loss = 0.77940478
Iteration 4348, loss = 0.77775376
Iteration 4349, loss = 0.77599012
Iteration 4350, loss = 0.77552162
Iteration 4351, loss = 0.77312958
Iteration 4352, loss = 0.77304356
Iteration 4353, loss = 0.77081012
Iteration 4354, loss = 0.77030950
Iteration 4355, loss = 0.76873643
Iteration 4356, loss = 0.76761243
Iteration 4357, loss = 0.76670335
Iteration 4358, loss = 0.76515209
Iteration 4359, loss = 0.76456978
Iteration 4360, loss = 0.76299857
Iteration 4361, loss = 0.76235483
Iteration 4362, loss = 0.76104378
Iteration 4363, loss = 0.76011810
Iteration 4364, loss = 0.75914482
Iteration 4365, loss = 0.75800532
Iteration 4366, loss = 0.75725961
Iteration 4367, loss = 0.75607460
Iteration 4368, loss = 0.75535161
Iteration 4369, loss = 0.75428086
Iteration 4370, loss = 0.75345953
Iteration 4371, loss = 0.75256627
Iteration 4372, loss = 0.75164737
Iteration 4373, loss = 0.75089333
Iteration 4374, loss = 0.74995177
Iteration 4375, loss = 0.74923590
Iteration 4376, loss = 0.74835105
Iteration 4377, loss = 0.74760939
Iteration 4378, loss = 0.74682358
Iteration 4379, loss = 0.74604362
Iteration 4380, loss = 0.74533637
Iteration 4381, loss = 0.74455072
Iteration 4382, loss = 0.74387964
Iteration 4383, loss = 0.74313238
Iteration 4384, loss = 0.74246109
Iteration 4385, loss = 0.74176798
Iteration 4386, loss = 0.74108295
Iteration 4387, loss = 0.74043510
Iteration 4388, loss = 0.73975620
Iteration 4389, loss = 0.73913864
Iteration 4390, loss = 0.73849130
Iteration 4391, loss = 0.73788668
Iteration 4392, loss = 0.73727687
Iteration 4393, loss = 0.73667028
Iteration 4394, loss = 0.73585436
Iteration 4395, loss = 0.73574526
Iteration 4396, loss = 0.73611806
Iteration 4397, loss = 0.73510729
Iteration 4398, loss = 0.73109944
Iteration 4399, loss = 0.74834881
Iteration 4400, loss = 0.84262743
Iteration 4401, loss = 0.85172532
Iteration 4402, loss = 0.74206094
Iteration 4403, loss = 0.79868677
Iteration 4404, loss = 0.87540314
Iteration 4405, loss = 0.70318946
Iteration 4406, loss = 0.77914405
Iteration 4407, loss = 0.74385566
Iteration 4408, loss = 0.76059186
Iteration 4409, loss = 0.76008315
Iteration 4410, loss = 0.74874883
Iteration 4411, loss = 0.77003448
Iteration 4412, loss = 0.74595925
Iteration 4413, loss = 0.77129036
Iteration 4414, loss = 0.75337997
Iteration 4415, loss = 0.76692643
Iteration 4416, loss = 0.76342389
Iteration 4417, loss = 0.76140194
Iteration 4418, loss = 0.77012977
Iteration 4419, loss = 0.75983842
Iteration 4420, loss = 0.77209188
Iteration 4421, loss = 0.76303792
Iteration 4422, loss = 0.76998252
Iteration 4423, loss = 0.76732768
Iteration 4424, loss = 0.76638456
Iteration 4425, loss = 0.76989619
Iteration 4426, loss = 0.76409623
Iteration 4427, loss = 0.78899497
Iteration 4428, loss = 0.78127107
Iteration 4429, loss = 0.78088275
Iteration 4430, loss = 0.78888753
Iteration 4431, loss = 0.77268252
Iteration 4432, loss = 0.78770839
Iteration 4433, loss = 0.76822881
Iteration 4434, loss = 0.78402547
Iteration 4435, loss = 0.76988283
Iteration 4436, loss = 0.77923533
Iteration 4437, loss = 0.77288383
Iteration 4438, loss = 0.77336360
Iteration 4439, loss = 0.77421211
Iteration 4440, loss = 0.76848629
Iteration 4441, loss = 0.77361567
Iteration 4442, loss = 0.76571228
Iteration 4443, loss = 0.77100158
Iteration 4444, loss = 0.76433945
Iteration 4445, loss = 0.76699539
Iteration 4446, loss = 0.76353540
Iteration 4447, loss = 0.76293628
Iteration 4448, loss = 0.76263264
Iteration 4449, loss = 0.75953243
Iteration 4450, loss = 0.76073889
Iteration 4451, loss = 0.75667556
Iteration 4452, loss = 0.75781407
Iteration 4453, loss = 0.75450218
Iteration 4454, loss = 0.75464704
Iteration 4455, loss = 0.75279297
Iteration 4456, loss = 0.75159158
Iteration 4457, loss = 0.75091937
Iteration 4458, loss = 0.74878865
Iteration 4459, loss = 0.74866824
Iteration 4460, loss = 0.74641559
Iteration 4461, loss = 0.74620935
Iteration 4462, loss = 0.74440931
Iteration 4463, loss = 0.74370424
Iteration 4464, loss = 0.74255056
Iteration 4465, loss = 0.74135020
Iteration 4466, loss = 0.74067136
Iteration 4467, loss = 0.73922779
Iteration 4468, loss = 0.73872244
Iteration 4469, loss = 0.73736877
Iteration 4470, loss = 0.73675522
Iteration 4471, loss = 0.73566694
Iteration 4472, loss = 0.73484589
Iteration 4473, loss = 0.73406150
Iteration 4474, loss = 0.73310003
Iteration 4475, loss = 0.73248995
Iteration 4476, loss = 0.73150436
Iteration 4477, loss = 0.73091148
Iteration 4478, loss = 0.73002808
Iteration 4479, loss = 0.72937954
Iteration 4480, loss = 0.72865948
Iteration 4481, loss = 0.72794623
Iteration 4482, loss = 0.72734454
Iteration 4483, loss = 0.72660570
Iteration 4484, loss = 0.72605846
Iteration 4485, loss = 0.72536972
Iteration 4486, loss = 0.72482519
Iteration 4487, loss = 0.72421165
Iteration 4488, loss = 0.72364241
Iteration 4489, loss = 0.72311156
Iteration 4490, loss = 0.72254532
Iteration 4491, loss = 0.72206092
Iteration 4492, loss = 0.72150643
Iteration 4493, loss = 0.72103279
Iteration 4494, loss = 0.72052458
Iteration 4495, loss = 0.72005455
Iteration 4496, loss = 0.71959260
Iteration 4497, loss = 0.71912699
Iteration 4498, loss = 0.71870251
Iteration 4499, loss = 0.71825025
Iteration 4500, loss = 0.71784008
Iteration 4501, loss = 0.71741677
Iteration 4502, loss = 0.71702232
Iteration 4503, loss = 0.71662805
Iteration 4504, loss = 0.71623500
Iteration 4505, loss = 0.71586655
Iteration 4506, loss = 0.71549438
Iteration 4507, loss = 0.71514334
Iteration 4508, loss = 0.71478194
Iteration 4509, loss = 0.71443682
Iteration 4510, loss = 0.71409689
Iteration 4511, loss = 0.71375771
Iteration 4512, loss = 0.71328352
Iteration 4513, loss = 0.71388790
Iteration 4514, loss = 0.71356812
Iteration 4515, loss = 0.71249044
Iteration 4516, loss = 0.71229551
Iteration 4517, loss = 0.71194889
Iteration 4518, loss = 0.71158241
Iteration 4519, loss = 0.71121841
Iteration 4520, loss = 0.71085247
Iteration 4521, loss = 0.71017991
Iteration 4522, loss = 0.70982181
Iteration 4523, loss = 0.70950370
Iteration 4524, loss = 0.70920356
Iteration 4525, loss = 0.70847704
Iteration 4526, loss = 0.70851360
Iteration 4527, loss = 0.70733291
Iteration 4528, loss = 0.70529320
Iteration 4529, loss = 0.69515203
Iteration 4530, loss = 0.77393302
Iteration 4531, loss = 0.79978241
Iteration 4532, loss = 0.75314087
Iteration 4533, loss = 0.80277888
Iteration 4534, loss = 0.72387311
Iteration 4535, loss = 0.79537018
Iteration 4536, loss = 0.71555978
Iteration 4537, loss = 0.79204971
Iteration 4538, loss = 0.71350461
Iteration 4539, loss = 0.77608547
Iteration 4540, loss = 0.71115688
Iteration 4541, loss = 0.75651286
Iteration 4542, loss = 0.71467846
Iteration 4543, loss = 0.74017696
Iteration 4544, loss = 0.73336394
Iteration 4545, loss = 0.71085856
Iteration 4546, loss = 0.72259945
Iteration 4547, loss = 0.71376068
Iteration 4548, loss = 0.71847794
Iteration 4549, loss = 0.71548157
Iteration 4550, loss = 0.72098768
Iteration 4551, loss = 0.71412916
Iteration 4552, loss = 0.71859698
Iteration 4553, loss = 0.71667480
Iteration 4554, loss = 0.72001760
Iteration 4555, loss = 0.71754355
Iteration 4556, loss = 0.71897625
Iteration 4557, loss = 0.71774978
Iteration 4558, loss = 0.71818596
Iteration 4559, loss = 0.71734983
Iteration 4560, loss = 0.71674887
Iteration 4561, loss = 0.71544820
Iteration 4562, loss = 0.71147181
Iteration 4563, loss = 0.74054368
Iteration 4564, loss = 0.73215645
Iteration 4565, loss = 0.73182103
Iteration 4566, loss = 0.69660077
Iteration 4567, loss = 0.73389219
Iteration 4568, loss = 0.73810834
Iteration 4569, loss = 0.73517043
Iteration 4570, loss = 0.72939589
Iteration 4571, loss = 0.72626758
Iteration 4572, loss = 0.73029730
Iteration 4573, loss = 0.73499600
Iteration 4574, loss = 0.73998266
Iteration 4575, loss = 0.74260429
Iteration 4576, loss = 0.74441120
Iteration 4577, loss = 0.74462510
Iteration 4578, loss = 0.74533762
Iteration 4579, loss = 0.74530064
Iteration 4580, loss = 0.74576162
Iteration 4581, loss = 0.74587293
Iteration 4582, loss = 0.74568714
Iteration 4583, loss = 0.74716695
Iteration 4584, loss = 0.74571559
Iteration 4585, loss = 0.73086056
Iteration 4586, loss = 0.83304110
Iteration 4587, loss = 0.87459050
Iteration 4588, loss = 0.81703926
Iteration 4589, loss = 0.87953797
Iteration 4590, loss = 0.78038927
Iteration 4591, loss = 0.86381361
Iteration 4592, loss = 0.76369484
Iteration 4593, loss = 0.86086350
Iteration 4594, loss = 0.76833468
Iteration 4595, loss = 0.84829883
Iteration 4596, loss = 0.76384498
Iteration 4597, loss = 0.82065953
Iteration 4598, loss = 0.76283950
Iteration 4599, loss = 0.79760774
Iteration 4600, loss = 0.76799997
Iteration 4601, loss = 0.77839900
Iteration 4602, loss = 0.77138129
Iteration 4603, loss = 0.76195096
Iteration 4604, loss = 0.76304021
Iteration 4605, loss = 0.82304867
Iteration 4606, loss = 0.97294408
Iteration 4607, loss = 0.84472822
Iteration 4608, loss = 1.00937011
Iteration 4609, loss = 0.85931932
Iteration 4610, loss = 0.90673424
Iteration 4611, loss = 0.82066153
Iteration 4612, loss = 0.82624126
Iteration 4613, loss = 0.84222589
Iteration 4614, loss = 0.81518554
Iteration 4615, loss = 0.87683136
Iteration 4616, loss = 0.82038394
Iteration 4617, loss = 0.87319795
Iteration 4618, loss = 0.81917775
Iteration 4619, loss = 0.84529791
Iteration 4620, loss = 0.82498931
Iteration 4621, loss = 0.82414957
Iteration 4622, loss = 0.83812296
Iteration 4623, loss = 0.81809515
Iteration 4624, loss = 0.84232574
Iteration 4625, loss = 0.81620158
Iteration 4626, loss = 0.83453732
Iteration 4627, loss = 0.82127296
Iteration 4628, loss = 0.82635713
Iteration 4629, loss = 0.82804380
Iteration 4630, loss = 0.81937733
Iteration 4631, loss = 0.82857658
Iteration 4632, loss = 0.81560229
Iteration 4633, loss = 0.82436548
Iteration 4634, loss = 0.81637696
Iteration 4635, loss = 0.81949852
Iteration 4636, loss = 0.82028776
Iteration 4637, loss = 0.81571068
Iteration 4638, loss = 0.81897203
Iteration 4639, loss = 0.81447591
Iteration 4640, loss = 0.81316665
Iteration 4641, loss = 0.81451186
Iteration 4642, loss = 0.80923791
Iteration 4643, loss = 0.80865175
Iteration 4644, loss = 0.80590882
Iteration 4645, loss = 0.76759941
Iteration 4646, loss = 0.83088227
Iteration 4647, loss = 0.86321800
Iteration 4648, loss = 0.84721738
Iteration 4649, loss = 0.86573921
Iteration 4650, loss = 0.83671975
Iteration 4651, loss = 0.84294207
Iteration 4652, loss = 0.83817550
Iteration 4653, loss = 0.84129134
Iteration 4654, loss = 0.85430757
Iteration 4655, loss = 0.84770254
Iteration 4656, loss = 0.85983570
Iteration 4657, loss = 0.85083761
Iteration 4658, loss = 0.85734961
Iteration 4659, loss = 0.85584850
Iteration 4660, loss = 0.85561629
Iteration 4661, loss = 0.85979029
Iteration 4662, loss = 0.85470684
Iteration 4663, loss = 0.85990330
Iteration 4664, loss = 0.85586432
Iteration 4665, loss = 0.85897498
Iteration 4666, loss = 0.85881625
Iteration 4667, loss = 0.85801340
Iteration 4668, loss = 0.85965997
Iteration 4669, loss = 0.85601306
Iteration 4670, loss = 0.85730201
Iteration 4671, loss = 0.85442763
Iteration 4672, loss = 0.85457936
Iteration 4673, loss = 0.85400944
Iteration 4674, loss = 0.85262342
Iteration 4675, loss = 0.85306291
Iteration 4676, loss = 0.85066238
Iteration 4677, loss = 0.85048787
Iteration 4678, loss = 0.84844163
Iteration 4679, loss = 0.84735048
Iteration 4680, loss = 0.84636616
Iteration 4681, loss = 0.84458388
Iteration 4682, loss = 0.84401489
Iteration 4683, loss = 0.84212551
Iteration 4684, loss = 0.84130805
Iteration 4685, loss = 0.83984196
Iteration 4686, loss = 0.83846263
Iteration 4687, loss = 0.83732882
Iteration 4688, loss = 0.83557014
Iteration 4689, loss = 0.83451359
Iteration 4690, loss = 0.83291200
Iteration 4691, loss = 0.83174798
Iteration 4692, loss = 0.83045939
Iteration 4693, loss = 0.82902778
Iteration 4694, loss = 0.82785712
Iteration 4695, loss = 0.82632786
Iteration 4696, loss = 0.82514139
Iteration 4697, loss = 0.82375306
Iteration 4698, loss = 0.82247202
Iteration 4699, loss = 0.82125147
Iteration 4700, loss = 0.81989213
Iteration 4701, loss = 0.81872223
Iteration 4702, loss = 0.81738373
Iteration 4703, loss = 0.81617902
Iteration 4704, loss = 0.81493916
Iteration 4705, loss = 0.81369128
Iteration 4706, loss = 0.81253662
Iteration 4707, loss = 0.81129748
Iteration 4708, loss = 0.81015955
Iteration 4709, loss = 0.80888146
Iteration 4710, loss = 0.80799639
Iteration 4711, loss = 0.80722976
Iteration 4712, loss = 0.80607583
Iteration 4713, loss = 0.80493852
Iteration 4714, loss = 0.80379104
Iteration 4715, loss = 0.80270024
Iteration 4716, loss = 0.80154296
Iteration 4717, loss = 0.80085649
Iteration 4718, loss = 0.80576802
Iteration 4719, loss = 0.80041808
Iteration 4720, loss = 0.81294246
Iteration 4721, loss = 0.80926999
Iteration 4722, loss = 0.79889325
Iteration 4723, loss = 0.80630679
Iteration 4724, loss = 1.05119684
Iteration 4725, loss = 2.17263190
Iteration 4726, loss = 1.44619042
Iteration 4727, loss = 2.23107973
Iteration 4728, loss = 2.10279705
Iteration 4729, loss = 1.22587262
Iteration 4730, loss = 1.53308273
Iteration 4731, loss = 1.12335710
Iteration 4732, loss = 1.12450006
Iteration 4733, loss = 1.28812306
Iteration 4734, loss = 0.96053003
Iteration 4735, loss = 1.47602506
Iteration 4736, loss = 0.95098515
Iteration 4737, loss = 1.83525527
Iteration 4738, loss = 1.41176882
Iteration 4739, loss = 1.51461713
Iteration 4740, loss = 1.66623268
Iteration 4741, loss = 0.99807334
Iteration 4742, loss = 1.43272954
Iteration 4743, loss = 0.85052776
Iteration 4744, loss = 1.50387766
Iteration 4745, loss = 0.91278788
Iteration 4746, loss = 1.44510127
Iteration 4747, loss = 1.15190408
Iteration 4748, loss = 1.24360267
Iteration 4749, loss = 1.26863403
Iteration 4750, loss = 0.98619108
Iteration 4751, loss = 1.25510729
Iteration 4752, loss = 1.13551411
Iteration 4753, loss = 1.39451422
Iteration 4754, loss = 0.90904823
Iteration 4755, loss = 1.29896476
Iteration 4756, loss = 0.99973841
Iteration 4757, loss = 1.14655093
Iteration 4758, loss = 1.14762945
Iteration 4759, loss = 0.96890680
Iteration 4760, loss = 1.16499033
Iteration 4761, loss = 0.92722349
Iteration 4762, loss = 1.09315142
Iteration 4763, loss = 0.98419654
Iteration 4764, loss = 1.01360811
Iteration 4765, loss = 1.04221688
Iteration 4766, loss = 0.95162027
Iteration 4767, loss = 1.05060531
Iteration 4768, loss = 0.94295660
Iteration 4769, loss = 1.02070298
Iteration 4770, loss = 0.96531659
Iteration 4771, loss = 0.97628078
Iteration 4772, loss = 0.98339742
Iteration 4773, loss = 0.94219946
Iteration 4774, loss = 0.98441907
Iteration 4775, loss = 0.93133513
Iteration 4776, loss = 0.96567231
Iteration 4777, loss = 0.93437372
Iteration 4778, loss = 0.93838136
Iteration 4779, loss = 0.93877447
Iteration 4780, loss = 0.91837900
Iteration 4781, loss = 0.93543150
Iteration 4782, loss = 0.90979271
Iteration 4783, loss = 0.92188210
Iteration 4784, loss = 0.90842240
Iteration 4785, loss = 0.90548324
Iteration 4786, loss = 0.90654810
Iteration 4787, loss = 0.89348929
Iteration 4788, loss = 0.90090178
Iteration 4789, loss = 0.88712126
Iteration 4790, loss = 0.89082034
Iteration 4791, loss = 1.69150681
Iteration 4792, loss = 1.28203116
Iteration 4793, loss = 1.22840777
Iteration 4794, loss = 1.06691856
Iteration 4795, loss = 1.42452529
Iteration 4796, loss = 1.22673024
Iteration 4797, loss = 1.38166457
Iteration 4798, loss = 1.45585037
Iteration 4799, loss = 1.26162016
Iteration 4800, loss = 1.44151507
Iteration 4801, loss = 1.27050912
Iteration 4802, loss = 1.26488327
Iteration 4803, loss = 1.26461304
Iteration 4804, loss = 1.09498293
Iteration 4805, loss = 1.16918614
Iteration 4806, loss = 1.03696480
Iteration 4807, loss = 1.03900454
Iteration 4808, loss = 1.02778371
Iteration 4809, loss = 0.94827440
Iteration 4810, loss = 1.00647253
Iteration 4811, loss = 0.93378280
Iteration 4812, loss = 0.97003000
Iteration 4813, loss = 0.95895574
Iteration 4814, loss = 0.94013329
Iteration 4815, loss = 0.97513093
Iteration 4816, loss = 0.93501851
Iteration 4817, loss = 0.96821451
Iteration 4818, loss = 0.94645923
Iteration 4819, loss = 0.94786512
Iteration 4820, loss = 0.95437705
Iteration 4821, loss = 0.93116400
Iteration 4822, loss = 0.94782866
Iteration 4823, loss = 0.92432246
Iteration 4824, loss = 0.93079847
Iteration 4825, loss = 0.92296470
Iteration 4826, loss = 0.91461579
Iteration 4827, loss = 0.92037504
Iteration 4828, loss = 0.90616712
Iteration 4829, loss = 0.91399266
Iteration 4830, loss = 0.90497489
Iteration 4831, loss = 0.90622787
Iteration 4832, loss = 0.90600142
Iteration 4833, loss = 0.90057399
Iteration 4834, loss = 0.90508683
Iteration 4835, loss = 0.89832787
Iteration 4836, loss = 0.90149302
Iteration 4837, loss = 0.89798922
Iteration 4838, loss = 0.89689527
Iteration 4839, loss = 0.89720668
Iteration 4840, loss = 0.89323580
Iteration 4841, loss = 0.89490916
Iteration 4842, loss = 0.89109006
Iteration 4843, loss = 0.89153762
Iteration 4844, loss = 0.88978212
Iteration 4845, loss = 0.88828070
Iteration 4846, loss = 0.88837032
Iteration 4847, loss = 0.88592546
Iteration 4848, loss = 0.88644578
Iteration 4849, loss = 0.88446673
Iteration 4850, loss = 0.88423188
Iteration 4851, loss = 0.88335713
Iteration 4852, loss = 0.88218630
Iteration 4853, loss = 0.88207236
Iteration 4854, loss = 0.88055696
Iteration 4855, loss = 0.88046970
Iteration 4856, loss = 0.87926158
Iteration 4857, loss = 0.87871730
Iteration 4858, loss = 0.87803361
Iteration 4859, loss = 0.87705834
Iteration 4860, loss = 0.87669069
Iteration 4861, loss = 0.87560323
Iteration 4862, loss = 0.87518951
Iteration 4863, loss = 0.87428612
Iteration 4864, loss = 0.87364163
Iteration 4865, loss = 0.87294823
Iteration 4866, loss = 0.88531043
Iteration 4867, loss = 0.85161830
Iteration 4868, loss = 0.92747968
Iteration 4869, loss = 0.88551869
Iteration 4870, loss = 0.91203706
Iteration 4871, loss = 0.88329640
Iteration 4872, loss = 0.90802378
Iteration 4873, loss = 0.90040580
Iteration 4874, loss = 0.89410843
Iteration 4875, loss = 0.90622356
Iteration 4876, loss = 0.88958938
Iteration 4877, loss = 0.90824629
Iteration 4878, loss = 0.89515756
Iteration 4879, loss = 0.90289913
Iteration 4880, loss = 0.90122439
Iteration 4881, loss = 0.89664223
Iteration 4882, loss = 0.90363094
Iteration 4883, loss = 0.89457617
Iteration 4884, loss = 0.90277569
Iteration 4885, loss = 0.89599633
Iteration 4886, loss = 0.89765521
Iteration 4887, loss = 0.89622911
Iteration 4888, loss = 0.89298979
Iteration 4889, loss = 0.89609901
Iteration 4890, loss = 0.89045516
Iteration 4891, loss = 0.89270735
Iteration 4892, loss = 0.88833764
Iteration 4893, loss = 0.88828326
Iteration 4894, loss = 0.88690220
Iteration 4895, loss = 0.88389368
Iteration 4896, loss = 0.88395814
Iteration 4897, loss = 0.88009230
Iteration 4898, loss = 0.88003004
Iteration 4899, loss = 0.87666922
Iteration 4900, loss = 0.87499758
Iteration 4901, loss = 0.87252066
Iteration 4902, loss = 0.86911902
Iteration 4903, loss = 0.86607234
Iteration 4904, loss = 0.86280330
Iteration 4905, loss = 0.84979085
Iteration 4906, loss = 0.96147348
Iteration 4907, loss = 0.91691284
Iteration 4908, loss = 0.98001654
Iteration 4909, loss = 0.87716045
Iteration 4910, loss = 0.94828471
Iteration 4911, loss = 0.88162584
Iteration 4912, loss = 0.92465751
Iteration 4913, loss = 0.90024504
Iteration 4914, loss = 0.89178931
Iteration 4915, loss = 0.90669177
Iteration 4916, loss = 0.87070805
Iteration 4917, loss = 0.90310626
Iteration 4918, loss = 0.86390005
Iteration 4919, loss = 0.89289594
Iteration 4920, loss = 0.86711408
Iteration 4921, loss = 0.87892215
Iteration 4922, loss = 0.87090032
Iteration 4923, loss = 0.86607375
Iteration 4924, loss = 0.87259364
Iteration 4925, loss = 0.85786254
Iteration 4926, loss = 0.87029812
Iteration 4927, loss = 0.85450448
Iteration 4928, loss = 0.86563703
Iteration 4929, loss = 0.85439979
Iteration 4930, loss = 0.85938914
Iteration 4931, loss = 0.85472604
Iteration 4932, loss = 0.85340007
Iteration 4933, loss = 0.85448417
Iteration 4934, loss = 0.84932535
Iteration 4935, loss = 0.85325575
Iteration 4936, loss = 0.86247382
Iteration 4937, loss = 0.87192640
Iteration 4938, loss = 0.90452705
Iteration 4939, loss = 0.92908048
Iteration 4940, loss = 0.92313925
Iteration 4941, loss = 0.90415344
Iteration 4942, loss = 0.88677189
Iteration 4943, loss = 0.87662216
Iteration 4944, loss = 0.88088165
Iteration 4945, loss = 0.88520322
Iteration 4946, loss = 0.88859521
Iteration 4947, loss = 0.94293650
Iteration 4948, loss = 0.93643821
Iteration 4949, loss = 0.95423216
Iteration 4950, loss = 0.91677994
Iteration 4951, loss = 0.94889141
Iteration 4952, loss = 0.90237297
Iteration 4953, loss = 0.94137722
Iteration 4954, loss = 0.89926096
Iteration 4955, loss = 0.93547848
Iteration 4956, loss = 0.90036368
Iteration 4957, loss = 0.92616668
Iteration 4958, loss = 0.89989430
Iteration 4959, loss = 0.91669564
Iteration 4960, loss = 0.90159633
Iteration 4961, loss = 0.90954310
Iteration 4962, loss = 0.90195153
Iteration 4963, loss = 0.90158603
Iteration 4964, loss = 0.89957104
Iteration 4965, loss = 0.89411714
Iteration 4966, loss = 0.89644505
Iteration 4967, loss = 0.88930311
Iteration 4968, loss = 0.89448526
Iteration 4969, loss = 0.88589173
Iteration 4970, loss = 0.89091394
Iteration 4971, loss = 0.88223881
Iteration 4972, loss = 0.88639293
Iteration 4973, loss = 0.87872699
Iteration 4974, loss = 0.88241952
Iteration 4975, loss = 0.87613426
Iteration 4976, loss = 0.87765992
Iteration 4977, loss = 0.87184923
Iteration 4978, loss = 0.87194636
Iteration 4979, loss = 0.86748996
Iteration 4980, loss = 0.86528831
Iteration 4981, loss = 0.86411248
Iteration 4982, loss = 0.86296113
Iteration 4983, loss = 0.84938934
Iteration 4984, loss = 0.94331525
Iteration 4985, loss = 0.92661766
Iteration 4986, loss = 0.97591680
Iteration 4987, loss = 0.88397942
Iteration 4988, loss = 0.96283631
Iteration 4989, loss = 0.86781324
Iteration 4990, loss = 0.93117091
Iteration 4991, loss = 0.87738966
Iteration 4992, loss = 0.89972848
Iteration 4993, loss = 0.89383068
Iteration 4994, loss = 0.87620013
Iteration 4995, loss = 0.89921312
Iteration 4996, loss = 0.85886762
Iteration 4997, loss = 0.89094690
Iteration 4998, loss = 0.85248975
Iteration 4999, loss = 0.87948545
Iteration 5000, loss = 0.85574251
