Iteration 1, loss = 0.69546790
Iteration 2, loss = 3.55478968
Iteration 3, loss = 0.79874210
Iteration 4, loss = 2.20543943
Iteration 5, loss = 1.92490119
Iteration 6, loss = 0.68996297
Iteration 7, loss = 2.43482648
Iteration 8, loss = 1.63635218
Iteration 9, loss = 1.03107430
Iteration 10, loss = 1.35518456
Iteration 11, loss = 1.34736006
Iteration 12, loss = 1.01023636
Iteration 13, loss = 0.79680326
Iteration 14, loss = 0.75673671
Iteration 15, loss = 0.83537512
Iteration 16, loss = 0.83256019
Iteration 17, loss = 0.86768888
Iteration 18, loss = 1.00310484
Iteration 19, loss = 0.98631171
Iteration 20, loss = 0.78065315
Iteration 21, loss = 0.81070728
Iteration 22, loss = 0.76658009
Iteration 23, loss = 1.16746116
Iteration 24, loss = 0.80866302
Iteration 25, loss = 1.10278409
Iteration 26, loss = 0.93179304
Iteration 27, loss = 1.11208574
Iteration 28, loss = 1.07330051
Iteration 29, loss = 0.87988015
Iteration 30, loss = 0.99269432
Iteration 31, loss = 0.84399235
Iteration 32, loss = 0.69701983
Iteration 33, loss = 1.01376003
Iteration 34, loss = 0.82337929
Iteration 35, loss = 0.92627811
Iteration 36, loss = 1.17718849
Iteration 37, loss = 0.79627402
Iteration 38, loss = 1.16293503
Iteration 39, loss = 1.17558759
Iteration 40, loss = 1.07755393
Iteration 41, loss = 0.96748351
Iteration 42, loss = 1.75980545
Iteration 43, loss = 1.44148903
Iteration 44, loss = 0.83969538
Iteration 45, loss = 1.18341889
Iteration 46, loss = 1.30342570
Iteration 47, loss = 0.90510785
Iteration 48, loss = 1.23885443
Iteration 49, loss = 0.98493041
Iteration 50, loss = 0.80172475
Iteration 51, loss = 0.79990226
Iteration 52, loss = 0.96546383
Iteration 53, loss = 0.89074372
Iteration 54, loss = 0.87657457
Iteration 55, loss = 0.82761227
Iteration 56, loss = 0.88863904
Iteration 57, loss = 0.74720469
Iteration 58, loss = 0.80474657
Iteration 59, loss = 0.82798710
Iteration 60, loss = 0.82286345
Iteration 61, loss = 0.82523654
Iteration 62, loss = 0.87963660
Iteration 63, loss = 0.80912504
Iteration 64, loss = 0.92405931
Iteration 65, loss = 0.81232443
Iteration 66, loss = 0.86066986
Iteration 67, loss = 0.79727447
Iteration 68, loss = 0.84975154
Iteration 69, loss = 0.80257554
Iteration 70, loss = 1.72987279
Iteration 71, loss = 0.96957204
Iteration 72, loss = 1.95491957
Iteration 73, loss = 1.20003345
Iteration 74, loss = 0.88944769
Iteration 75, loss = 1.09285498
Iteration 76, loss = 1.17834657
Iteration 77, loss = 0.91758577
Iteration 78, loss = 1.03956177
Iteration 79, loss = 0.93932765
Iteration 80, loss = 0.87846981
Iteration 81, loss = 0.88548916
Iteration 82, loss = 0.88231903
Iteration 83, loss = 0.82947541
Iteration 84, loss = 0.83413848
Iteration 85, loss = 0.83453541
Iteration 86, loss = 0.80398467
Iteration 87, loss = 0.80761962
Iteration 88, loss = 0.80477569
Iteration 89, loss = 0.80651413
Iteration 90, loss = 0.80254756
Iteration 91, loss = 0.79235183
Iteration 92, loss = 0.89917171
Iteration 93, loss = 0.99539298
Iteration 94, loss = 0.93713116
Iteration 95, loss = 0.79750657
Iteration 96, loss = 0.93801343
Iteration 97, loss = 0.91143533
Iteration 98, loss = 1.11779075
Iteration 99, loss = 0.81810834
Iteration 100, loss = 0.82715785
Iteration 101, loss = 0.80677794
Iteration 102, loss = 0.83077044
Iteration 103, loss = 0.81108880
Iteration 104, loss = 0.82711006
Iteration 105, loss = 0.81676476
Iteration 106, loss = 0.81707796
Iteration 107, loss = 0.82846922
Iteration 108, loss = 0.81701938
Iteration 109, loss = 0.81897097
Iteration 110, loss = 0.82147237
Iteration 111, loss = 0.80956844
Iteration 112, loss = 0.80875770
Iteration 113, loss = 0.81164307
Iteration 114, loss = 0.80336324
Iteration 115, loss = 0.80910200
Iteration 116, loss = 0.79981753
Iteration 117, loss = 0.80605801
Iteration 118, loss = 0.85273453
Iteration 119, loss = 0.81117756
Iteration 120, loss = 0.81456519
Iteration 121, loss = 0.78964592
Iteration 122, loss = 0.90373032
Iteration 123, loss = 0.78637754
Iteration 124, loss = 0.86768819
Iteration 125, loss = 0.60664872
Iteration 126, loss = 1.34371259
Iteration 127, loss = 0.87926750
Iteration 128, loss = 1.07448230
Iteration 129, loss = 1.26052895
Iteration 130, loss = 0.90054727
Iteration 131, loss = 0.98017125
Iteration 132, loss = 1.15258202
Iteration 133, loss = 0.88497878
Iteration 134, loss = 0.90460707
Iteration 135, loss = 1.05513458
Iteration 136, loss = 0.85887447
Iteration 137, loss = 0.86500371
Iteration 138, loss = 0.98339434
Iteration 139, loss = 0.79428902
Iteration 140, loss = 0.80007947
Iteration 141, loss = 0.83049073
Iteration 142, loss = 0.83213065
Iteration 143, loss = 0.80129157
Iteration 144, loss = 0.80617917
Iteration 145, loss = 0.82033530
Iteration 146, loss = 0.80606691
Iteration 147, loss = 0.86144360
Iteration 148, loss = 0.80813864
Iteration 149, loss = 0.87664217
Iteration 150, loss = 0.86238031
Iteration 151, loss = 0.79943734
Iteration 152, loss = 0.83303525
Iteration 153, loss = 0.85457005
Iteration 154, loss = 0.80852970
Iteration 155, loss = 0.81271890
Iteration 156, loss = 0.84157392
Iteration 157, loss = 0.81199347
Iteration 158, loss = 0.80577108
Iteration 159, loss = 0.82171144
Iteration 160, loss = 0.87401991
Iteration 161, loss = 0.81438406
Iteration 162, loss = 0.88563315
Iteration 163, loss = 0.92502590
Iteration 164, loss = 0.90800972
Iteration 165, loss = 0.91044591
Iteration 166, loss = 0.86356125
Iteration 167, loss = 0.90184445
Iteration 168, loss = 0.86834223
Iteration 169, loss = 0.84081605
Iteration 170, loss = 0.84956742
Iteration 171, loss = 0.82525059
Iteration 172, loss = 0.80194295
Iteration 173, loss = 0.81688526
Iteration 174, loss = 0.81546795
Iteration 175, loss = 0.80323216
Iteration 176, loss = 0.81502539
Iteration 177, loss = 0.81583346
Iteration 178, loss = 0.79791855
Iteration 179, loss = 0.77002896
Iteration 180, loss = 0.99175119
Iteration 181, loss = 0.82447841
Iteration 182, loss = 0.91366763
Iteration 183, loss = 0.98044165
Iteration 184, loss = 0.85062350
Iteration 185, loss = 0.83271056
Iteration 186, loss = 0.91688413
Iteration 187, loss = 0.97405556
Iteration 188, loss = 0.82397105
Iteration 189, loss = 0.88544550
Iteration 190, loss = 0.92197929
Iteration 191, loss = 0.80913937
Iteration 192, loss = 0.87420591
Iteration 193, loss = 0.86990233
Iteration 194, loss = 0.81874935
Iteration 195, loss = 0.83814033
Iteration 196, loss = 0.81084772
Iteration 197, loss = 0.82538410
Iteration 198, loss = 0.81128928
Iteration 199, loss = 0.81608107
Iteration 200, loss = 0.81757307
Iteration 201, loss = 0.80865369
Iteration 202, loss = 0.81498816
Iteration 203, loss = 0.79723974
Iteration 204, loss = 0.78849406
Iteration 205, loss = 1.29299288
Iteration 206, loss = 1.29829115
Iteration 207, loss = 1.19384471
Iteration 208, loss = 0.85742821
Iteration 209, loss = 1.21884143
Iteration 210, loss = 1.11055187
Iteration 211, loss = 0.86530056
Iteration 212, loss = 1.11257873
Iteration 213, loss = 0.99821428
Iteration 214, loss = 0.83518113
Iteration 215, loss = 1.01542285
Iteration 216, loss = 0.90820508
Iteration 217, loss = 0.82279990
Iteration 218, loss = 0.95202317
Iteration 219, loss = 0.84156289
Iteration 220, loss = 1.02957844
Iteration 221, loss = 0.96004985
Iteration 222, loss = 0.83660045
Iteration 223, loss = 1.05339028
Iteration 224, loss = 0.89399717
Iteration 225, loss = 0.84720859
Iteration 226, loss = 0.91083722
Iteration 227, loss = 0.83804938
Iteration 228, loss = 0.88104928
Iteration 229, loss = 0.92024124
Iteration 230, loss = 0.85138206
Iteration 231, loss = 0.88558478
Iteration 232, loss = 0.90626400
Iteration 233, loss = 0.84815875
Iteration 234, loss = 0.86895393
Iteration 235, loss = 0.87653658
Iteration 236, loss = 0.83288987
Iteration 237, loss = 0.85034475
Iteration 238, loss = 0.95013917
Iteration 239, loss = 0.83079615
Iteration 240, loss = 0.92595347
Iteration 241, loss = 0.90586134
Iteration 242, loss = 0.85184133
Iteration 243, loss = 0.90562703
Iteration 244, loss = 0.96263503
Iteration 245, loss = 0.84825673
Iteration 246, loss = 0.87995845
Iteration 247, loss = 0.92465518
Iteration 248, loss = 0.84056554
Iteration 249, loss = 0.86489147
Iteration 250, loss = 0.89796899
Iteration 251, loss = 0.83520000
Iteration 252, loss = 0.85493207
Iteration 253, loss = 0.87672546
Iteration 254, loss = 0.82983506
Iteration 255, loss = 0.84687616
Iteration 256, loss = 0.85914324
Iteration 257, loss = 0.82262924
Iteration 258, loss = 0.84131820
Iteration 259, loss = 0.83594192
Iteration 260, loss = 0.82162286
Iteration 261, loss = 0.83534777
Iteration 262, loss = 0.82452657
Iteration 263, loss = 0.81923323
Iteration 264, loss = 0.82859056
Iteration 265, loss = 0.81618310
Iteration 266, loss = 0.81946086
Iteration 267, loss = 0.81552378
Iteration 268, loss = 0.81622414
Iteration 269, loss = 0.81460331
Iteration 270, loss = 0.81134552
Iteration 271, loss = 0.81127665
Iteration 272, loss = 0.80731335
Iteration 273, loss = 0.80871456
Iteration 274, loss = 0.80489518
Iteration 275, loss = 0.80605053
Iteration 276, loss = 0.80181346
Iteration 277, loss = 0.79074951
Iteration 278, loss = 0.81079630
Iteration 279, loss = 0.81428661
Iteration 280, loss = 0.81221867
Iteration 281, loss = 0.85441933
Iteration 282, loss = 0.82266150
Iteration 283, loss = 0.82010977
Iteration 284, loss = 0.86261616
Iteration 285, loss = 0.81009298
Iteration 286, loss = 0.83282358
Iteration 287, loss = 0.82831542
Iteration 288, loss = 0.75993297
Iteration 289, loss = 0.88236280
Iteration 290, loss = 0.87968775
Iteration 291, loss = 0.92416904
Iteration 292, loss = 0.84525708
Iteration 293, loss = 0.92080485
Iteration 294, loss = 0.84964766
Iteration 295, loss = 0.88321089
Iteration 296, loss = 0.86609339
Iteration 297, loss = 0.84253107
Iteration 298, loss = 0.87461094
Iteration 299, loss = 0.83093575
Iteration 300, loss = 0.86815184
Iteration 301, loss = 0.84219494
Iteration 302, loss = 0.85108959
Iteration 303, loss = 0.85454239
Iteration 304, loss = 0.83625210
Iteration 305, loss = 0.84028767
Iteration 306, loss = 0.82791661
Iteration 307, loss = 0.82429338
Iteration 308, loss = 0.85379413
Iteration 309, loss = 0.74658119
Iteration 310, loss = 1.24770980
Iteration 311, loss = 0.86593860
Iteration 312, loss = 1.19651669
Iteration 313, loss = 0.88344202
Iteration 314, loss = 1.09674191
Iteration 315, loss = 0.88497451
Iteration 316, loss = 0.91374504
Iteration 317, loss = 0.85593764
Iteration 318, loss = 1.11644426
Iteration 319, loss = 0.89035133
Iteration 320, loss = 1.09049424
Iteration 321, loss = 0.89212394
Iteration 322, loss = 1.05015705
Iteration 323, loss = 0.89119690
Iteration 324, loss = 1.00830493
Iteration 325, loss = 0.90127720
Iteration 326, loss = 0.97406685
Iteration 327, loss = 0.92011919
Iteration 328, loss = 0.94679266
Iteration 329, loss = 0.93412297
Iteration 330, loss = 0.92026854
Iteration 331, loss = 0.93755073
Iteration 332, loss = 0.89841333
Iteration 333, loss = 0.93181008
Iteration 334, loss = 0.88244534
Iteration 335, loss = 0.92177069
Iteration 336, loss = 0.87452401
Iteration 337, loss = 0.91132937
Iteration 338, loss = 0.87121820
Iteration 339, loss = 0.91667320
Iteration 340, loss = 0.80191926
Iteration 341, loss = 0.90460229
Iteration 342, loss = 0.90571213
Iteration 343, loss = 0.90050136
Iteration 344, loss = 0.90085730
Iteration 345, loss = 0.88499048
Iteration 346, loss = 0.89138353
Iteration 347, loss = 0.87906811
Iteration 348, loss = 0.89172987
Iteration 349, loss = 0.88369062
Iteration 350, loss = 0.89374754
Iteration 351, loss = 0.88612043
Iteration 352, loss = 0.89029279
Iteration 353, loss = 0.88343210
Iteration 354, loss = 0.88116227
Iteration 355, loss = 0.89180680
Iteration 356, loss = 0.88174648
Iteration 357, loss = 0.88744887
Iteration 358, loss = 0.87537412
Iteration 359, loss = 0.90829477
Iteration 360, loss = 0.90450372
Iteration 361, loss = 0.92054462
Iteration 362, loss = 0.90666037
Iteration 363, loss = 0.91127731
Iteration 364, loss = 0.89605597
Iteration 365, loss = 0.90014847
Iteration 366, loss = 0.88996651
Iteration 367, loss = 0.89270736
Iteration 368, loss = 0.91247016
Iteration 369, loss = 0.90156966
Iteration 370, loss = 0.91277344
Iteration 371, loss = 0.89795480
Iteration 372, loss = 0.90643125
Iteration 373, loss = 0.89359889
Iteration 374, loss = 0.90136583
Iteration 375, loss = 0.89164634
Iteration 376, loss = 0.89659711
Iteration 377, loss = 0.88875766
Iteration 378, loss = 0.89080772
Iteration 379, loss = 0.88508579
Iteration 380, loss = 0.88464270
Iteration 381, loss = 0.87748019
Iteration 382, loss = 0.88211236
Iteration 383, loss = 0.89225329
Iteration 384, loss = 0.88088657
Iteration 385, loss = 0.88612457
Iteration 386, loss = 0.87335153
Iteration 387, loss = 0.82251092
Iteration 388, loss = 0.93578213
Iteration 389, loss = 0.89389963
Iteration 390, loss = 0.92625924
Iteration 391, loss = 0.89943439
Iteration 392, loss = 0.91277634
Iteration 393, loss = 0.89754194
Iteration 394, loss = 0.89854872
Iteration 395, loss = 0.89301927
Iteration 396, loss = 0.88967367
Iteration 397, loss = 0.89187636
Iteration 398, loss = 0.88486391
Iteration 399, loss = 0.89057696
Iteration 400, loss = 0.88187927
Iteration 401, loss = 0.88932078
Iteration 402, loss = 0.87915844
Iteration 403, loss = 0.88643474
Iteration 404, loss = 0.87549984
Iteration 405, loss = 0.88232597
Iteration 406, loss = 0.87172242
Iteration 407, loss = 0.87804049
Iteration 408, loss = 0.86830330
Iteration 409, loss = 0.87378478
Iteration 410, loss = 0.86498815
Iteration 411, loss = 0.86986997
Iteration 412, loss = 0.86258071
Iteration 413, loss = 0.86625082
Iteration 414, loss = 0.85975123
Iteration 415, loss = 0.86213916
Iteration 416, loss = 0.85661768
Iteration 417, loss = 0.85803181
Iteration 418, loss = 0.85359737
Iteration 419, loss = 0.85424911
Iteration 420, loss = 0.85066479
Iteration 421, loss = 0.85046541
Iteration 422, loss = 0.84781112
Iteration 423, loss = 0.84713237
Iteration 424, loss = 0.84503610
Iteration 425, loss = 0.84366979
Iteration 426, loss = 0.84200757
Iteration 427, loss = 0.84033899
Iteration 428, loss = 0.83904987
Iteration 429, loss = 0.83711616
Iteration 430, loss = 0.83595433
Iteration 431, loss = 0.83384675
Iteration 432, loss = 0.83264025
Iteration 433, loss = 0.82915078
Iteration 434, loss = 0.83814945
Iteration 435, loss = 0.83322487
Iteration 436, loss = 0.83642888
Iteration 437, loss = 0.83034348
Iteration 438, loss = 0.83040012
Iteration 439, loss = 0.82393796
Iteration 440, loss = 0.82071101
Iteration 441, loss = 0.82807225
Iteration 442, loss = 0.85460676
Iteration 443, loss = 0.82328604
Iteration 444, loss = 0.84903873
Iteration 445, loss = 0.81877058
Iteration 446, loss = 0.84307790
Iteration 447, loss = 0.81587758
Iteration 448, loss = 0.83630991
Iteration 449, loss = 0.81325350
Iteration 450, loss = 0.82974407
Iteration 451, loss = 0.81010770
Iteration 452, loss = 0.82325709
Iteration 453, loss = 0.80857231
Iteration 454, loss = 0.81823338
Iteration 455, loss = 0.80687446
Iteration 456, loss = 0.81291723
Iteration 457, loss = 0.80476531
Iteration 458, loss = 0.80794604
Iteration 459, loss = 0.80259279
Iteration 460, loss = 0.80354278
Iteration 461, loss = 0.80028870
Iteration 462, loss = 0.79806627
Iteration 463, loss = 0.76442154
Iteration 464, loss = 0.80883319
Iteration 465, loss = 0.81857661
Iteration 466, loss = 0.81341135
Iteration 467, loss = 0.82093521
Iteration 468, loss = 0.81354240
Iteration 469, loss = 0.81215174
Iteration 470, loss = 0.82587562
Iteration 471, loss = 0.83490820
Iteration 472, loss = 0.82609738
Iteration 473, loss = 0.82573100
Iteration 474, loss = 0.82409627
Iteration 475, loss = 0.81816895
Iteration 476, loss = 0.82232733
Iteration 477, loss = 0.81393671
Iteration 478, loss = 0.82191622
Iteration 479, loss = 0.81245828
Iteration 480, loss = 0.82174921
Iteration 481, loss = 0.81160187
Iteration 482, loss = 0.82026966
Iteration 483, loss = 0.80992759
Iteration 484, loss = 0.81742710
Iteration 485, loss = 0.80795821
Iteration 486, loss = 0.81450926
Iteration 487, loss = 0.80658196
Iteration 488, loss = 0.81216607
Iteration 489, loss = 0.80555828
Iteration 490, loss = 0.80979268
Iteration 491, loss = 0.80424585
Iteration 492, loss = 0.80719331
Iteration 493, loss = 0.80263283
Iteration 494, loss = 0.80459582
Iteration 495, loss = 0.80095970
Iteration 496, loss = 0.80211466
Iteration 497, loss = 0.79926673
Iteration 498, loss = 0.79983620
Iteration 499, loss = 0.79754852
Iteration 500, loss = 0.79745290
Iteration 501, loss = 0.79525741
Iteration 502, loss = 0.79446346
Iteration 503, loss = 0.79276732
Iteration 504, loss = 0.79204948
Iteration 505, loss = 0.79052558
Iteration 506, loss = 0.78936612
Iteration 507, loss = 0.78775751
Iteration 508, loss = 0.78631743
Iteration 509, loss = 0.78498648
Iteration 510, loss = 0.80122000
Iteration 511, loss = 0.86010774
Iteration 512, loss = 0.78480696
Iteration 513, loss = 0.84707914
Iteration 514, loss = 0.78811941
Iteration 515, loss = 0.82636681
Iteration 516, loss = 0.76128964
Iteration 517, loss = 0.83611909
Iteration 518, loss = 0.76703367
Iteration 519, loss = 1.06348657
Iteration 520, loss = 1.04579997
Iteration 521, loss = 0.93751509
Iteration 522, loss = 1.06181495
Iteration 523, loss = 0.99868648
Iteration 524, loss = 0.99688331
Iteration 525, loss = 0.98537981
Iteration 526, loss = 0.90935034
Iteration 527, loss = 0.94676688
Iteration 528, loss = 0.85002812
Iteration 529, loss = 0.91946976
Iteration 530, loss = 0.82622367
Iteration 531, loss = 0.90649978
Iteration 532, loss = 0.82373783
Iteration 533, loss = 0.89571330
Iteration 534, loss = 0.82631543
Iteration 535, loss = 0.88313387
Iteration 536, loss = 0.82754027
Iteration 537, loss = 0.86532446
Iteration 538, loss = 0.82128816
Iteration 539, loss = 0.82574985
Iteration 540, loss = 0.83668660
Iteration 541, loss = 0.85414804
Iteration 542, loss = 0.83773954
Iteration 543, loss = 0.85620594
Iteration 544, loss = 0.83476932
Iteration 545, loss = 0.85125734
Iteration 546, loss = 0.82914628
Iteration 547, loss = 0.84434380
Iteration 548, loss = 0.82581223
Iteration 549, loss = 0.83995519
Iteration 550, loss = 0.82563083
Iteration 551, loss = 0.83839359
Iteration 552, loss = 0.82796705
Iteration 553, loss = 0.83856986
Iteration 554, loss = 0.83057379
Iteration 555, loss = 0.83762927
Iteration 556, loss = 0.83040130
Iteration 557, loss = 0.84651846
Iteration 558, loss = 0.83901854
Iteration 559, loss = 0.84528483
Iteration 560, loss = 0.84886846
Iteration 561, loss = 0.84755675
Iteration 562, loss = 0.84037941
Iteration 563, loss = 0.83782414
Iteration 564, loss = 0.83379922
Iteration 565, loss = 0.83774425
Iteration 566, loss = 0.83674061
Iteration 567, loss = 0.84041214
Iteration 568, loss = 0.83668038
Iteration 569, loss = 0.83779626
Iteration 570, loss = 0.83330461
Iteration 571, loss = 0.83473462
Iteration 572, loss = 0.83151092
Iteration 573, loss = 0.83330515
Iteration 574, loss = 0.83043888
Iteration 575, loss = 0.83160731
Iteration 576, loss = 0.82872119
Iteration 577, loss = 0.82941678
Iteration 578, loss = 0.82680280
Iteration 579, loss = 0.82719481
Iteration 580, loss = 0.82458549
Iteration 581, loss = 0.82627711
Iteration 582, loss = 0.82327040
Iteration 583, loss = 0.82394886
Iteration 584, loss = 0.82080488
Iteration 585, loss = 0.82087652
Iteration 586, loss = 0.81820333
Iteration 587, loss = 0.81833410
Iteration 588, loss = 0.81618645
Iteration 589, loss = 0.81609405
Iteration 590, loss = 0.81400316
Iteration 591, loss = 0.81356194
Iteration 592, loss = 0.81161987
Iteration 593, loss = 0.81110740
Iteration 594, loss = 0.80942259
Iteration 595, loss = 0.80886963
Iteration 596, loss = 0.80733528
Iteration 597, loss = 0.80668625
Iteration 598, loss = 0.80524055
Iteration 599, loss = 0.80452875
Iteration 600, loss = 0.80319647
Iteration 601, loss = 0.80246536
Iteration 602, loss = 0.80121841
Iteration 603, loss = 0.80044856
Iteration 604, loss = 0.79926207
Iteration 605, loss = 0.79846554
Iteration 606, loss = 0.79730179
Iteration 607, loss = 0.79637190
Iteration 608, loss = 0.79489012
Iteration 609, loss = 0.79145659
Iteration 610, loss = 0.79595138
Iteration 611, loss = 0.79574229
Iteration 612, loss = 0.79565119
Iteration 613, loss = 0.79315490
Iteration 614, loss = 0.79247148
Iteration 615, loss = 0.79069990
Iteration 616, loss = 0.79086885
Iteration 617, loss = 0.78967133
Iteration 618, loss = 0.78955306
Iteration 619, loss = 0.78808460
Iteration 620, loss = 0.78776982
Iteration 621, loss = 0.78649097
Iteration 622, loss = 0.78621998
Iteration 623, loss = 0.78505778
Iteration 624, loss = 0.78471863
Iteration 625, loss = 0.78360872
Iteration 626, loss = 0.78317104
Iteration 627, loss = 0.78204512
Iteration 628, loss = 0.78078340
Iteration 629, loss = 0.74804633
Iteration 630, loss = 0.79593603
Iteration 631, loss = 0.78982489
Iteration 632, loss = 0.80146084
Iteration 633, loss = 0.79281038
Iteration 634, loss = 0.79867334
Iteration 635, loss = 0.79065752
Iteration 636, loss = 0.79637732
Iteration 637, loss = 0.79135438
Iteration 638, loss = 0.79648728
Iteration 639, loss = 0.79309712
Iteration 640, loss = 0.79797058
Iteration 641, loss = 0.79520681
Iteration 642, loss = 0.79870831
Iteration 643, loss = 0.79674008
Iteration 644, loss = 0.79941501
Iteration 645, loss = 0.79731678
Iteration 646, loss = 0.79910553
Iteration 647, loss = 0.79748635
Iteration 648, loss = 0.79914696
Iteration 649, loss = 0.79767789
Iteration 650, loss = 0.79854243
Iteration 651, loss = 0.79715810
Iteration 652, loss = 0.79793908
Iteration 653, loss = 0.79697072
Iteration 654, loss = 0.79765544
Iteration 655, loss = 0.79671439
Iteration 656, loss = 0.79693258
Iteration 657, loss = 0.79576400
Iteration 658, loss = 0.79562563
Iteration 659, loss = 0.79451849
Iteration 660, loss = 0.79441003
Iteration 661, loss = 0.79356264
Iteration 662, loss = 0.79345951
Iteration 663, loss = 0.79255475
Iteration 664, loss = 0.79213466
Iteration 665, loss = 0.79111266
Iteration 666, loss = 0.79063420
Iteration 667, loss = 0.78964320
Iteration 668, loss = 0.78901810
Iteration 669, loss = 0.78791666
Iteration 670, loss = 0.78705876
Iteration 671, loss = 0.78574033
Iteration 672, loss = 0.78445585
Iteration 673, loss = 0.78271712
Iteration 674, loss = 0.78056899
Iteration 675, loss = 0.77966441
Iteration 676, loss = 0.77751081
Iteration 677, loss = 0.77306714
Iteration 678, loss = 0.75765759
Iteration 679, loss = 0.87513452
Iteration 680, loss = 0.85764250
Iteration 681, loss = 0.88959612
Iteration 682, loss = 0.82725468
Iteration 683, loss = 0.87700549
Iteration 684, loss = 0.80019063
Iteration 685, loss = 0.85803095
Iteration 686, loss = 0.78685448
Iteration 687, loss = 0.84589861
Iteration 688, loss = 0.78893382
Iteration 689, loss = 0.83775758
Iteration 690, loss = 0.79001031
Iteration 691, loss = 0.82291778
Iteration 692, loss = 0.78829122
Iteration 693, loss = 0.80985508
Iteration 694, loss = 0.78875419
Iteration 695, loss = 0.80084295
Iteration 696, loss = 0.79011003
Iteration 697, loss = 0.79410078
Iteration 698, loss = 0.79027950
Iteration 699, loss = 0.78788726
Iteration 700, loss = 0.78853016
Iteration 701, loss = 0.79557705
Iteration 702, loss = 0.77441566
Iteration 703, loss = 0.80915369
Iteration 704, loss = 0.77766156
Iteration 705, loss = 0.81707295
Iteration 706, loss = 0.78423851
Iteration 707, loss = 0.80299106
Iteration 708, loss = 0.77993897
Iteration 709, loss = 0.79027186
Iteration 710, loss = 0.78571808
Iteration 711, loss = 0.78475243
Iteration 712, loss = 0.78791711
Iteration 713, loss = 0.77675971
Iteration 714, loss = 0.78494114
Iteration 715, loss = 0.77245059
Iteration 716, loss = 0.78114308
Iteration 717, loss = 0.77000371
Iteration 718, loss = 0.77443225
Iteration 719, loss = 0.75163380
Iteration 720, loss = 0.85798445
Iteration 721, loss = 1.01812277
Iteration 722, loss = 0.80189380
Iteration 723, loss = 0.93670216
Iteration 724, loss = 0.81995233
Iteration 725, loss = 0.92614924
Iteration 726, loss = 0.81497405
Iteration 727, loss = 0.89810620
Iteration 728, loss = 0.79971007
Iteration 729, loss = 0.87054788
Iteration 730, loss = 0.79084074
Iteration 731, loss = 0.85459104
Iteration 732, loss = 0.79237695
Iteration 733, loss = 0.84806722
Iteration 734, loss = 0.79713289
Iteration 735, loss = 0.84211549
Iteration 736, loss = 0.79853253
Iteration 737, loss = 0.83447725
Iteration 738, loss = 0.79771546
Iteration 739, loss = 0.82885812
Iteration 740, loss = 0.79858772
Iteration 741, loss = 0.82189862
Iteration 742, loss = 0.79562471
Iteration 743, loss = 0.81488744
Iteration 744, loss = 0.79464041
Iteration 745, loss = 0.81171574
Iteration 746, loss = 0.79554460
Iteration 747, loss = 0.80925185
Iteration 748, loss = 0.79545533
Iteration 749, loss = 0.80642862
Iteration 750, loss = 0.79484393
Iteration 751, loss = 0.80368941
Iteration 752, loss = 0.79379869
Iteration 753, loss = 0.80055873
Iteration 754, loss = 0.79134376
Iteration 755, loss = 0.78196824
Iteration 756, loss = 0.79630821
Iteration 757, loss = 0.80156747
Iteration 758, loss = 0.80377689
Iteration 759, loss = 0.80477799
Iteration 760, loss = 0.80303451
Iteration 761, loss = 0.80211767
Iteration 762, loss = 0.80097933
Iteration 763, loss = 0.80195328
Iteration 764, loss = 0.80279750
Iteration 765, loss = 0.80468891
Iteration 766, loss = 0.80604305
Iteration 767, loss = 0.81002457
Iteration 768, loss = 0.80964839
Iteration 769, loss = 0.81245249
Iteration 770, loss = 0.81125556
Iteration 771, loss = 0.81070293
Iteration 772, loss = 0.78621775
Iteration 773, loss = 0.81899284
Iteration 774, loss = 0.81936431
Iteration 775, loss = 0.81751111
Iteration 776, loss = 0.81359005
Iteration 777, loss = 0.81434924
Iteration 778, loss = 0.81423505
Iteration 779, loss = 0.81531108
Iteration 780, loss = 0.81428458
Iteration 781, loss = 0.81563056
Iteration 782, loss = 0.81449454
Iteration 783, loss = 0.81448832
Iteration 784, loss = 0.81231554
Iteration 785, loss = 0.81163319
Iteration 786, loss = 0.81073926
Iteration 787, loss = 0.81148086
Iteration 788, loss = 0.81066484
Iteration 789, loss = 0.81053791
Iteration 790, loss = 0.80832952
Iteration 791, loss = 0.80893108
Iteration 792, loss = 0.80704560
Iteration 793, loss = 0.80703288
Iteration 794, loss = 0.80564429
Iteration 795, loss = 0.80490729
Iteration 796, loss = 0.80342937
Iteration 797, loss = 0.80277597
Iteration 798, loss = 0.80162801
Iteration 799, loss = 0.80029501
Iteration 800, loss = 0.79922936
Iteration 801, loss = 0.79795942
Iteration 802, loss = 0.79504663
Iteration 803, loss = 0.79322882
Iteration 804, loss = 0.78671421
Iteration 805, loss = 0.74712084
Iteration 806, loss = 0.80244487
Iteration 807, loss = 0.81105714
Iteration 808, loss = 0.79292755
Iteration 809, loss = 0.88829974
Iteration 810, loss = 0.86329820
Iteration 811, loss = 0.87255819
Iteration 812, loss = 0.83795219
Iteration 813, loss = 0.85674693
Iteration 814, loss = 0.82898072
Iteration 815, loss = 0.85578337
Iteration 816, loss = 0.82837706
Iteration 817, loss = 0.85114669
Iteration 818, loss = 0.82137724
Iteration 819, loss = 0.84233883
Iteration 820, loss = 0.81677745
Iteration 821, loss = 0.83757015
Iteration 822, loss = 0.81543399
Iteration 823, loss = 0.83059921
Iteration 824, loss = 0.80955250
Iteration 825, loss = 0.92656510
Iteration 826, loss = 0.83213121
Iteration 827, loss = 1.02877793
Iteration 828, loss = 0.85195053
Iteration 829, loss = 0.87597680
Iteration 830, loss = 0.84091257
Iteration 831, loss = 0.85630909
Iteration 832, loss = 0.86044982
Iteration 833, loss = 0.86009655
Iteration 834, loss = 0.85682291
Iteration 835, loss = 0.84217387
Iteration 836, loss = 0.83378612
Iteration 837, loss = 0.81881891
Iteration 838, loss = 0.86731496
Iteration 839, loss = 0.86512004
Iteration 840, loss = 0.86091209
Iteration 841, loss = 0.85996231
Iteration 842, loss = 0.85248519
Iteration 843, loss = 0.86179349
Iteration 844, loss = 0.87011265
Iteration 845, loss = 0.85508478
Iteration 846, loss = 0.87327390
Iteration 847, loss = 0.87771118
Iteration 848, loss = 0.86999873
Iteration 849, loss = 0.87323315
Iteration 850, loss = 0.86546635
Iteration 851, loss = 0.85779815
Iteration 852, loss = 0.86258172
Iteration 853, loss = 0.85969809
Iteration 854, loss = 0.86037615
Iteration 855, loss = 0.86478210
Iteration 856, loss = 0.86051515
Iteration 857, loss = 0.86019019
Iteration 858, loss = 0.85905794
Iteration 859, loss = 0.85417104
Iteration 860, loss = 0.85522295
Iteration 861, loss = 0.85401363
Iteration 862, loss = 0.85200180
Iteration 863, loss = 0.85274582
Iteration 864, loss = 0.84987312
Iteration 865, loss = 0.84849418
Iteration 866, loss = 0.84816684
Iteration 867, loss = 0.84548030
Iteration 868, loss = 0.84344666
Iteration 869, loss = 0.84190321
Iteration 870, loss = 0.84031062
Iteration 871, loss = 0.83794702
Iteration 872, loss = 0.83514280
Iteration 873, loss = 0.82916524
Iteration 874, loss = 0.81618482
Iteration 875, loss = 1.00526498
Iteration 876, loss = 1.68438339
Iteration 877, loss = 1.07703799
Iteration 878, loss = 1.53608890
Iteration 879, loss = 1.48058912
Iteration 880, loss = 0.95081402
Iteration 881, loss = 1.38245650
Iteration 882, loss = 0.87464993
Iteration 883, loss = 1.25694441
Iteration 884, loss = 1.09325719
Iteration 885, loss = 0.99525427
Iteration 886, loss = 1.05376354
Iteration 887, loss = 0.84366738
Iteration 888, loss = 1.01541312
Iteration 889, loss = 0.88520037
Iteration 890, loss = 0.91288299
Iteration 891, loss = 0.91968240
Iteration 892, loss = 0.87703237
Iteration 893, loss = 0.90940201
Iteration 894, loss = 0.83842512
Iteration 895, loss = 0.90057813
Iteration 896, loss = 0.84325176
Iteration 897, loss = 0.83036410
Iteration 898, loss = 0.92991709
Iteration 899, loss = 0.86265664
Iteration 900, loss = 0.91088062
Iteration 901, loss = 0.89390504
Iteration 902, loss = 0.92313382
Iteration 903, loss = 0.89841728
Iteration 904, loss = 0.86747749
Iteration 905, loss = 0.90148334
Iteration 906, loss = 0.87043895
Iteration 907, loss = 0.88233307
Iteration 908, loss = 0.90175430
Iteration 909, loss = 0.87632269
Iteration 910, loss = 0.89550845
Iteration 911, loss = 0.88920677
Iteration 912, loss = 0.87600339
Iteration 913, loss = 0.89230867
Iteration 914, loss = 0.87833053
Iteration 915, loss = 0.88013639
Iteration 916, loss = 0.88727642
Iteration 917, loss = 0.87544955
Iteration 918, loss = 0.88384773
Iteration 919, loss = 0.88164141
Iteration 920, loss = 0.87542749
Iteration 921, loss = 0.88119567
Iteration 922, loss = 0.87340365
Iteration 923, loss = 0.87281336
Iteration 924, loss = 0.87454592
Iteration 925, loss = 0.86837398
Iteration 926, loss = 0.87104413
Iteration 927, loss = 0.86866564
Iteration 928, loss = 0.86505857
Iteration 929, loss = 0.86652645
Iteration 930, loss = 0.86209624
Iteration 931, loss = 0.86105387
Iteration 932, loss = 0.86037042
Iteration 933, loss = 0.85639723
Iteration 934, loss = 0.85631466
Iteration 935, loss = 0.85384458
Iteration 936, loss = 0.85128129
Iteration 937, loss = 0.85060283
Iteration 938, loss = 0.84698291
Iteration 939, loss = 0.84459729
Iteration 940, loss = 0.84160786
Iteration 941, loss = 0.81546113
Iteration 942, loss = 0.86002410
Iteration 943, loss = 0.85398418
Iteration 944, loss = 0.86124002
Iteration 945, loss = 0.89224701
Iteration 946, loss = 0.86283605
Iteration 947, loss = 0.87198744
Iteration 948, loss = 0.87164592
Iteration 949, loss = 0.85507819
Iteration 950, loss = 0.86881021
Iteration 951, loss = 0.87122688
Iteration 952, loss = 0.86062435
Iteration 953, loss = 0.86970186
Iteration 954, loss = 0.86775970
Iteration 955, loss = 0.85813839
Iteration 956, loss = 0.86481896
Iteration 957, loss = 0.86368845
Iteration 958, loss = 0.85776145
Iteration 959, loss = 0.86257173
Iteration 960, loss = 0.85983581
Iteration 961, loss = 0.85415222
Iteration 962, loss = 0.85684925
Iteration 963, loss = 0.85476613
Iteration 964, loss = 0.85181451
Iteration 965, loss = 0.85357797
Iteration 966, loss = 0.85029775
Iteration 967, loss = 0.84646857
Iteration 968, loss = 0.84585757
Iteration 969, loss = 0.84209571
Iteration 970, loss = 0.83832863
Iteration 971, loss = 0.83891208
Iteration 972, loss = 0.83488690
Iteration 973, loss = 0.82803601
Iteration 974, loss = 0.80857781
Iteration 975, loss = 0.94246728
Iteration 976, loss = 0.86621475
Iteration 977, loss = 0.95312195
Iteration 978, loss = 0.90548648
Iteration 979, loss = 0.85852436
Iteration 980, loss = 0.90972282
Iteration 981, loss = 0.85184182
Iteration 982, loss = 0.85546827
Iteration 983, loss = 0.88762329
Iteration 984, loss = 0.84204493
Iteration 985, loss = 0.86553163
Iteration 986, loss = 0.86658357
Iteration 987, loss = 0.83327853
Iteration 988, loss = 0.85685162
Iteration 989, loss = 0.84126017
Iteration 990, loss = 0.82866348
Iteration 991, loss = 0.84667375
Iteration 992, loss = 0.82848789
Iteration 993, loss = 0.83094011
Iteration 994, loss = 0.83732180
Iteration 995, loss = 0.82097839
Iteration 996, loss = 0.82831923
Iteration 997, loss = 0.82533278
Iteration 998, loss = 0.81590887
Iteration 999, loss = 0.82292587
Iteration 1000, loss = 0.81549105
