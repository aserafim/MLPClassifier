Iteration 1, loss = 0.72027374
Iteration 2, loss = 0.77810170
Iteration 3, loss = 0.82419117
Iteration 4, loss = 1.32214247
Iteration 5, loss = 0.64079716
Iteration 6, loss = 0.79993522
Iteration 7, loss = 0.70182741
Iteration 8, loss = 1.11058226
Iteration 9, loss = 0.87683703
Iteration 10, loss = 1.13823275
Iteration 11, loss = 0.80044529
Iteration 12, loss = 0.72845923
Iteration 13, loss = 0.80442086
Iteration 14, loss = 0.92292355
Iteration 15, loss = 0.71319189
Iteration 16, loss = 0.74688582
Iteration 17, loss = 0.91173223
Iteration 18, loss = 0.67028821
Iteration 19, loss = 1.45535647
Iteration 20, loss = 0.87501819
Iteration 21, loss = 0.72805305
Iteration 22, loss = 0.98256311
Iteration 23, loss = 0.72531457
Iteration 24, loss = 0.91571861
Iteration 25, loss = 0.71448938
Iteration 26, loss = 0.77008935
Iteration 27, loss = 0.74122495
Iteration 28, loss = 0.59397484
Iteration 29, loss = 0.50318740
Iteration 30, loss = 0.53345874
Iteration 31, loss = 0.48672418
Iteration 32, loss = 0.44250784
Iteration 33, loss = 0.50475667
Iteration 34, loss = 0.53886083
Iteration 35, loss = 0.71522781
Iteration 36, loss = 0.66218682
Iteration 37, loss = 0.86019550
Iteration 38, loss = 0.70535447
Iteration 39, loss = 0.74335864
Iteration 40, loss = 0.78745439
Iteration 41, loss = 0.73238559
Iteration 42, loss = 0.75596530
Iteration 43, loss = 0.78490727
Iteration 44, loss = 0.73939154
Iteration 45, loss = 0.73850169
Iteration 46, loss = 0.76174192
Iteration 47, loss = 0.72723601
Iteration 48, loss = 0.70860541
Iteration 49, loss = 0.72150774
Iteration 50, loss = 0.69359056
Iteration 51, loss = 0.64614131
Iteration 52, loss = 0.60206630
Iteration 53, loss = 0.41882245
Iteration 54, loss = 1.09084393
Iteration 55, loss = 0.67346301
Iteration 56, loss = 1.02739366
Iteration 57, loss = 1.18600790
Iteration 58, loss = 0.81244884
Iteration 59, loss = 1.02471743
Iteration 60, loss = 1.07404414
Iteration 61, loss = 0.55172956
Iteration 62, loss = 1.36969018
Iteration 63, loss = 1.18201768
Iteration 64, loss = 0.79076297
Iteration 65, loss = 0.83206063
Iteration 66, loss = 1.14696807
Iteration 67, loss = 0.88130635
Iteration 68, loss = 0.74306646
Iteration 69, loss = 0.89985528
Iteration 70, loss = 0.88042033
Iteration 71, loss = 0.74242205
Iteration 72, loss = 0.77392876
Iteration 73, loss = 0.67677684
Iteration 74, loss = 0.87322914
Iteration 75, loss = 0.75102833
Iteration 76, loss = 0.87648343
Iteration 77, loss = 0.75603542
Iteration 78, loss = 0.77440311
Iteration 79, loss = 0.75512897
Iteration 80, loss = 0.74400180
Iteration 81, loss = 0.75104972
Iteration 82, loss = 0.72100116
Iteration 83, loss = 0.73236821
Iteration 84, loss = 0.70908853
Iteration 85, loss = 0.69701243
Iteration 86, loss = 0.69304226
Iteration 87, loss = 0.66430390
Iteration 88, loss = 0.63299191
Iteration 89, loss = 0.54815004
Iteration 90, loss = 0.42580599
Iteration 91, loss = 0.32673881
Iteration 92, loss = 0.78490451
Iteration 93, loss = 0.65570436
Iteration 94, loss = 0.90785415
Iteration 95, loss = 0.63820645
Iteration 96, loss = 0.58508285
Iteration 97, loss = 0.65600055
Iteration 98, loss = 0.42836953
Iteration 99, loss = 0.47158916
Iteration 100, loss = 0.51189525
Iteration 101, loss = 0.64842410
Iteration 102, loss = 0.51264756
Iteration 103, loss = 0.50457892
Iteration 104, loss = 0.68491491
Iteration 105, loss = 0.82978444
Iteration 106, loss = 1.11354446
Iteration 107, loss = 0.76925570
Iteration 108, loss = 1.03323302
Iteration 109, loss = 1.08285070
Iteration 110, loss = 0.77509022
Iteration 111, loss = 1.02480829
Iteration 112, loss = 0.92733261
Iteration 113, loss = 0.78866325
Iteration 114, loss = 0.93213392
Iteration 115, loss = 0.87578245
Iteration 116, loss = 0.79549085
Iteration 117, loss = 0.90190197
Iteration 118, loss = 0.83103896
Iteration 119, loss = 0.79800593
Iteration 120, loss = 0.86685964
Iteration 121, loss = 0.79162528
Iteration 122, loss = 0.79474280
Iteration 123, loss = 0.82706484
Iteration 124, loss = 0.76262819
Iteration 125, loss = 0.78355205
Iteration 126, loss = 0.78155137
Iteration 127, loss = 0.73715930
Iteration 128, loss = 0.73409148
Iteration 129, loss = 0.83094301
Iteration 130, loss = 0.76541160
Iteration 131, loss = 0.86973861
Iteration 132, loss = 0.78012290
Iteration 133, loss = 0.77144800
Iteration 134, loss = 0.82955561
Iteration 135, loss = 0.74480490
Iteration 136, loss = 0.76994114
Iteration 137, loss = 0.78520849
Iteration 138, loss = 0.71816594
Iteration 139, loss = 0.75752861
Iteration 140, loss = 0.74138143
Iteration 141, loss = 0.70368017
Iteration 142, loss = 0.73402514
Iteration 143, loss = 0.85091864
Iteration 144, loss = 0.73075416
Iteration 145, loss = 0.88283616
Iteration 146, loss = 0.77244935
Iteration 147, loss = 0.80748071
Iteration 148, loss = 0.82541561
Iteration 149, loss = 0.73015055
Iteration 150, loss = 0.77228457
Iteration 151, loss = 0.73991916
Iteration 152, loss = 0.73842495
Iteration 153, loss = 0.74913776
Iteration 154, loss = 0.72797847
Iteration 155, loss = 0.73127632
Iteration 156, loss = 0.72699393
Iteration 157, loss = 0.71424780
Iteration 158, loss = 0.54389069
Iteration 159, loss = 0.81453095
Iteration 160, loss = 0.73752648
Iteration 161, loss = 0.87868930
Iteration 162, loss = 0.76450294
Iteration 163, loss = 0.76329013
Iteration 164, loss = 0.83462237
Iteration 165, loss = 0.69107143
Iteration 166, loss = 0.78023210
Iteration 167, loss = 0.78113052
Iteration 168, loss = 0.72012546
Iteration 169, loss = 0.76132352
Iteration 170, loss = 0.76365612
Iteration 171, loss = 0.73461671
Iteration 172, loss = 0.75636907
Iteration 173, loss = 0.74058839
Iteration 174, loss = 0.72597692
Iteration 175, loss = 0.74019284
Iteration 176, loss = 0.71986255
Iteration 177, loss = 0.71828172
Iteration 178, loss = 0.72163970
Iteration 179, loss = 0.69479199
Iteration 180, loss = 1.11424049
Iteration 181, loss = 1.28048006
Iteration 182, loss = 1.32819743
Iteration 183, loss = 0.79691985
Iteration 184, loss = 1.02311687
Iteration 185, loss = 1.27628674
Iteration 186, loss = 0.92496847
Iteration 187, loss = 0.84568606
Iteration 188, loss = 1.14023128
Iteration 189, loss = 0.96361965
Iteration 190, loss = 0.78023865
Iteration 191, loss = 1.01271717
Iteration 192, loss = 0.94531155
Iteration 193, loss = 0.81348925
Iteration 194, loss = 0.92041781
Iteration 195, loss = 0.80996396
Iteration 196, loss = 0.78419052
Iteration 197, loss = 0.87597890
Iteration 198, loss = 0.80708744
Iteration 199, loss = 0.76078877
Iteration 200, loss = 0.80049053
Iteration 201, loss = 0.81384710
Iteration 202, loss = 0.74282151
Iteration 203, loss = 0.79371869
Iteration 204, loss = 0.79411357
Iteration 205, loss = 0.73666823
Iteration 206, loss = 0.76846319
Iteration 207, loss = 0.77500360
Iteration 208, loss = 0.73162022
Iteration 209, loss = 0.75275013
Iteration 210, loss = 0.76157427
Iteration 211, loss = 0.72959011
Iteration 212, loss = 0.74346515
Iteration 213, loss = 0.75131676
Iteration 214, loss = 0.72727324
Iteration 215, loss = 0.73615890
Iteration 216, loss = 0.74188176
Iteration 217, loss = 0.72312968
Iteration 218, loss = 0.72787184
Iteration 219, loss = 0.72857021
Iteration 220, loss = 0.67247557
Iteration 221, loss = 0.72343774
Iteration 222, loss = 0.72690693
Iteration 223, loss = 0.72887195
Iteration 224, loss = 0.74374885
Iteration 225, loss = 0.73094877
Iteration 226, loss = 0.74299250
Iteration 227, loss = 0.73409183
Iteration 228, loss = 0.83163129
Iteration 229, loss = 0.73208720
Iteration 230, loss = 0.85428066
Iteration 231, loss = 0.80977525
Iteration 232, loss = 0.70240926
Iteration 233, loss = 0.73044471
Iteration 234, loss = 0.79549464
Iteration 235, loss = 0.78233825
Iteration 236, loss = 0.73456477
Iteration 237, loss = 0.77451996
Iteration 238, loss = 0.75050386
Iteration 239, loss = 0.73701666
Iteration 240, loss = 0.76222765
Iteration 241, loss = 0.72933747
Iteration 242, loss = 0.74057370
Iteration 243, loss = 0.74267204
Iteration 244, loss = 0.71957814
Iteration 245, loss = 0.73136792
Iteration 246, loss = 0.68212377
Iteration 247, loss = 0.86449451
Iteration 248, loss = 0.75039402
Iteration 249, loss = 0.83318817
Iteration 250, loss = 0.82775243
Iteration 251, loss = 0.75438813
Iteration 252, loss = 0.82546753
Iteration 253, loss = 0.77849259
Iteration 254, loss = 0.75969740
Iteration 255, loss = 0.79853322
Iteration 256, loss = 0.74371165
Iteration 257, loss = 0.77104447
Iteration 258, loss = 0.76815868
Iteration 259, loss = 0.74096862
Iteration 260, loss = 0.77258998
Iteration 261, loss = 0.74605228
Iteration 262, loss = 0.75139935
Iteration 263, loss = 0.76064335
Iteration 264, loss = 0.73858567
Iteration 265, loss = 0.75655875
Iteration 266, loss = 0.74573900
Iteration 267, loss = 0.74247841
Iteration 268, loss = 0.75241264
Iteration 269, loss = 0.73812436
Iteration 270, loss = 0.74473757
Iteration 271, loss = 0.73784747
Iteration 272, loss = 0.73622373
Iteration 273, loss = 0.76349153
Iteration 274, loss = 0.74408409
Iteration 275, loss = 0.76044228
Iteration 276, loss = 0.75020824
Iteration 277, loss = 0.75140420
Iteration 278, loss = 0.75500121
Iteration 279, loss = 0.74441645
Iteration 280, loss = 0.75287358
Iteration 281, loss = 0.74661237
Iteration 282, loss = 0.74680082
Iteration 283, loss = 0.74953969
Iteration 284, loss = 0.74236836
Iteration 285, loss = 0.74461690
Iteration 286, loss = 0.73940875
Iteration 287, loss = 0.73515043
Iteration 288, loss = 0.72331497
Iteration 289, loss = 0.75428133
Iteration 290, loss = 0.74247738
Iteration 291, loss = 0.75412377
Iteration 292, loss = 0.74440882
Iteration 293, loss = 0.74325350
Iteration 294, loss = 0.76033276
Iteration 295, loss = 0.74122176
Iteration 296, loss = 0.76086460
Iteration 297, loss = 0.74123239
Iteration 298, loss = 0.74555617
Iteration 299, loss = 0.74601085
Iteration 300, loss = 0.73153330
Iteration 301, loss = 0.74057145
Iteration 302, loss = 0.71205811
Iteration 303, loss = 0.81024024
Iteration 304, loss = 0.74412472
Iteration 305, loss = 0.76942514
Iteration 306, loss = 0.76045547
Iteration 307, loss = 0.75438795
Iteration 308, loss = 0.76376466
Iteration 309, loss = 0.75517937
Iteration 310, loss = 0.76065538
Iteration 311, loss = 0.75335526
Iteration 312, loss = 0.75589743
Iteration 313, loss = 0.74969454
Iteration 314, loss = 0.75093640
Iteration 315, loss = 0.74736271
Iteration 316, loss = 0.74854037
Iteration 317, loss = 0.74728275
Iteration 318, loss = 0.74811806
Iteration 319, loss = 0.74742035
Iteration 320, loss = 0.74724152
Iteration 321, loss = 0.74649892
Iteration 322, loss = 0.74525810
Iteration 323, loss = 0.74399633
Iteration 324, loss = 0.74140590
Iteration 325, loss = 0.73451933
Iteration 326, loss = 0.75123199
Iteration 327, loss = 0.75488154
Iteration 328, loss = 0.75136262
Iteration 329, loss = 0.74947091
Iteration 330, loss = 0.74678678
Iteration 331, loss = 0.74160552
Iteration 332, loss = 0.73922035
Iteration 333, loss = 0.72901726
Iteration 334, loss = 0.85389724
Iteration 335, loss = 0.91295185
Iteration 336, loss = 0.82881315
Iteration 337, loss = 0.87554090
Iteration 338, loss = 0.83698874
Iteration 339, loss = 0.81364554
Iteration 340, loss = 0.81499875
Iteration 341, loss = 1.41045829
Iteration 342, loss = 0.85747870
Iteration 343, loss = 0.75075324
Iteration 344, loss = 0.78478864
Iteration 345, loss = 0.79098432
Iteration 346, loss = 0.80795764
Iteration 347, loss = 0.80461203
Iteration 348, loss = 0.81051420
Iteration 349, loss = 0.80111452
Iteration 350, loss = 0.79952337
Iteration 351, loss = 0.78689521
Iteration 352, loss = 0.78256027
Iteration 353, loss = 0.77027288
Iteration 354, loss = 0.76543988
Iteration 355, loss = 0.75298011
Iteration 356, loss = 0.73947482
Iteration 357, loss = 0.82388994
Iteration 358, loss = 0.98977364
Iteration 359, loss = 0.75486353
Iteration 360, loss = 0.90221418
Iteration 361, loss = 0.81993008
Iteration 362, loss = 0.84863214
Iteration 363, loss = 0.83530570
Iteration 364, loss = 0.77031110
Iteration 365, loss = 0.82673701
Iteration 366, loss = 0.58737048
Iteration 367, loss = 1.19012783
Iteration 368, loss = 0.89875762
Iteration 369, loss = 0.99181892
Iteration 370, loss = 1.07624639
Iteration 371, loss = 0.76936788
Iteration 372, loss = 1.04194962
Iteration 373, loss = 0.87971363
Iteration 374, loss = 0.85060770
Iteration 375, loss = 0.96810988
Iteration 376, loss = 0.76281089
Iteration 377, loss = 0.90891378
Iteration 378, loss = 0.83938837
Iteration 379, loss = 0.79016127
Iteration 380, loss = 0.88219851
Iteration 381, loss = 0.75850573
Iteration 382, loss = 0.84054474
Iteration 383, loss = 0.80716586
Iteration 384, loss = 0.77277910
Iteration 385, loss = 0.83091849
Iteration 386, loss = 0.75574091
Iteration 387, loss = 0.80450735
Iteration 388, loss = 0.78212681
Iteration 389, loss = 0.76411578
Iteration 390, loss = 0.79707976
Iteration 391, loss = 0.75183606
Iteration 392, loss = 0.78302959
Iteration 393, loss = 0.76538076
Iteration 394, loss = 0.75896402
Iteration 395, loss = 0.77535219
Iteration 396, loss = 0.74859182
Iteration 397, loss = 0.76840438
Iteration 398, loss = 0.75339211
Iteration 399, loss = 0.75261517
Iteration 400, loss = 0.75241245
Iteration 401, loss = 0.75095843
Iteration 402, loss = 0.76913139
Iteration 403, loss = 0.75227317
Iteration 404, loss = 0.76634113
Iteration 405, loss = 0.75792237
Iteration 406, loss = 0.75436755
Iteration 407, loss = 0.75917407
Iteration 408, loss = 0.74677625
Iteration 409, loss = 0.75472063
Iteration 410, loss = 0.74707894
Iteration 411, loss = 0.74803068
Iteration 412, loss = 0.74832783
Iteration 413, loss = 0.74145390
Iteration 414, loss = 0.74439519
Iteration 415, loss = 0.73539590
Iteration 416, loss = 0.68039906
Iteration 417, loss = 0.75866756
Iteration 418, loss = 0.77051548
Iteration 419, loss = 0.77527848
Iteration 420, loss = 0.76159371
Iteration 421, loss = 0.77511102
Iteration 422, loss = 0.75838737
Iteration 423, loss = 0.76218903
Iteration 424, loss = 0.75978654
Iteration 425, loss = 0.75130415
Iteration 426, loss = 0.75873824
Iteration 427, loss = 0.74916791
Iteration 428, loss = 0.75417991
Iteration 429, loss = 0.75256594
Iteration 430, loss = 0.75019937
Iteration 431, loss = 0.75491438
Iteration 432, loss = 0.74964045
Iteration 433, loss = 0.75349900
Iteration 434, loss = 0.75109075
Iteration 435, loss = 0.75023067
Iteration 436, loss = 0.75159752
Iteration 437, loss = 0.74799367
Iteration 438, loss = 0.75003689
Iteration 439, loss = 0.74750156
Iteration 440, loss = 0.74752236
Iteration 441, loss = 0.74753709
Iteration 442, loss = 0.74574214
Iteration 443, loss = 0.74700504
Iteration 444, loss = 0.74528789
Iteration 445, loss = 0.74587553
Iteration 446, loss = 0.74542707
Iteration 447, loss = 0.74472172
Iteration 448, loss = 0.74519287
Iteration 449, loss = 0.74395588
Iteration 450, loss = 0.74431413
Iteration 451, loss = 0.74350416
Iteration 452, loss = 0.74317196
Iteration 453, loss = 0.74302998
Iteration 454, loss = 0.74221841
Iteration 455, loss = 0.74232839
Iteration 456, loss = 0.74147024
Iteration 457, loss = 0.74152241
Iteration 458, loss = 0.74221804
Iteration 459, loss = 0.74186019
Iteration 460, loss = 0.74104728
Iteration 461, loss = 0.74114428
Iteration 462, loss = 0.74061038
Iteration 463, loss = 0.74003253
Iteration 464, loss = 0.74021247
Iteration 465, loss = 0.73985311
Iteration 466, loss = 0.73932899
Iteration 467, loss = 0.73930495
Iteration 468, loss = 0.73892834
Iteration 469, loss = 0.73850331
Iteration 470, loss = 0.73842643
Iteration 471, loss = 0.73804225
Iteration 472, loss = 0.73763336
Iteration 473, loss = 0.73747775
Iteration 474, loss = 0.73708746
Iteration 475, loss = 0.73667583
Iteration 476, loss = 0.73641668
Iteration 477, loss = 0.73595498
Iteration 478, loss = 0.73544357
Iteration 479, loss = 0.73492845
Iteration 480, loss = 0.73398241
Iteration 481, loss = 0.73207366
Iteration 482, loss = 0.73425367
Iteration 483, loss = 0.74258912
Iteration 484, loss = 0.75757178
Iteration 485, loss = 0.74040292
Iteration 486, loss = 0.75713182
Iteration 487, loss = 0.73859540
Iteration 488, loss = 0.74867940
Iteration 489, loss = 0.73534010
Iteration 490, loss = 0.74194149
Iteration 491, loss = 0.73467088
Iteration 492, loss = 0.73355735
Iteration 493, loss = 0.73126021
Iteration 494, loss = 0.72695511
Iteration 495, loss = 0.74469581
Iteration 496, loss = 0.73920128
Iteration 497, loss = 0.74206713
Iteration 498, loss = 0.73726647
Iteration 499, loss = 0.73551771
Iteration 500, loss = 0.73497411
Iteration 501, loss = 0.74802470
Iteration 502, loss = 0.73457815
Iteration 503, loss = 0.74493040
Iteration 504, loss = 0.73461914
Iteration 505, loss = 0.74274967
Iteration 506, loss = 0.73435568
Iteration 507, loss = 0.74015849
Iteration 508, loss = 0.73383485
Iteration 509, loss = 0.73802656
Iteration 510, loss = 0.73298284
Iteration 511, loss = 0.73585983
Iteration 512, loss = 0.73227851
Iteration 513, loss = 0.73421559
Iteration 514, loss = 0.73111727
Iteration 515, loss = 0.73183859
Iteration 516, loss = 0.72852302
Iteration 517, loss = 0.72746052
Iteration 518, loss = 0.69271431
Iteration 519, loss = 0.83722984
Iteration 520, loss = 0.81653843
Iteration 521, loss = 0.88369103
Iteration 522, loss = 0.75448362
Iteration 523, loss = 0.87582650
Iteration 524, loss = 0.75698153
Iteration 525, loss = 0.82202507
Iteration 526, loss = 0.78965407
Iteration 527, loss = 0.75941880
Iteration 528, loss = 0.80582670
Iteration 529, loss = 0.73305485
Iteration 530, loss = 0.79289695
Iteration 531, loss = 0.74606075
Iteration 532, loss = 0.76398093
Iteration 533, loss = 0.76762920
Iteration 534, loss = 0.74030356
Iteration 535, loss = 0.77255085
Iteration 536, loss = 0.73585579
Iteration 537, loss = 0.75990387
Iteration 538, loss = 0.74315113
Iteration 539, loss = 0.73924981
Iteration 540, loss = 0.74916173
Iteration 541, loss = 0.73137851
Iteration 542, loss = 0.90076579
Iteration 543, loss = 0.79154666
Iteration 544, loss = 0.85461951
Iteration 545, loss = 0.76098245
Iteration 546, loss = 0.82478542
Iteration 547, loss = 0.79791930
Iteration 548, loss = 0.74841113
Iteration 549, loss = 0.80051637
Iteration 550, loss = 0.74747484
Iteration 551, loss = 0.75648654
Iteration 552, loss = 0.77671893
Iteration 553, loss = 0.73514715
Iteration 554, loss = 0.76720498
Iteration 555, loss = 0.75374551
Iteration 556, loss = 0.73905895
Iteration 557, loss = 0.76157463
Iteration 558, loss = 0.73537334
Iteration 559, loss = 0.74215329
Iteration 560, loss = 0.76733552
Iteration 561, loss = 0.73940592
Iteration 562, loss = 0.78653607
Iteration 563, loss = 0.79448128
Iteration 564, loss = 0.74087239
Iteration 565, loss = 0.79236953
Iteration 566, loss = 0.75389384
Iteration 567, loss = 0.74624542
Iteration 568, loss = 0.77236139
Iteration 569, loss = 0.73215186
Iteration 570, loss = 0.75622960
Iteration 571, loss = 0.75176978
Iteration 572, loss = 0.73343714
Iteration 573, loss = 0.75649273
Iteration 574, loss = 0.73556892
Iteration 575, loss = 0.73924118
Iteration 576, loss = 0.77226091
Iteration 577, loss = 0.74023710
Iteration 578, loss = 0.76620156
Iteration 579, loss = 0.73523481
Iteration 580, loss = 0.75136142
Iteration 581, loss = 0.74471225
Iteration 582, loss = 0.73890738
Iteration 583, loss = 0.72647068
Iteration 584, loss = 0.72572539
Iteration 585, loss = 0.74547616
Iteration 586, loss = 0.71682691
Iteration 587, loss = 0.77313151
Iteration 588, loss = 0.73496189
Iteration 589, loss = 0.78292097
Iteration 590, loss = 0.73460459
Iteration 591, loss = 0.76681250
Iteration 592, loss = 0.75172033
Iteration 593, loss = 0.78490005
Iteration 594, loss = 0.77439198
Iteration 595, loss = 0.77450088
Iteration 596, loss = 0.78743604
Iteration 597, loss = 0.76732101
Iteration 598, loss = 0.77711449
Iteration 599, loss = 0.76747071
Iteration 600, loss = 0.75723900
Iteration 601, loss = 0.76330650
Iteration 602, loss = 0.74896583
Iteration 603, loss = 0.75233940
Iteration 604, loss = 0.74985540
Iteration 605, loss = 0.74337718
Iteration 606, loss = 0.74914033
Iteration 607, loss = 0.74207277
Iteration 608, loss = 0.74385809
Iteration 609, loss = 0.74394311
Iteration 610, loss = 0.73969279
Iteration 611, loss = 0.74319129
Iteration 612, loss = 0.73905135
Iteration 613, loss = 0.73911897
Iteration 614, loss = 0.73912437
Iteration 615, loss = 0.73567358
Iteration 616, loss = 0.73697676
Iteration 617, loss = 0.73400062
Iteration 618, loss = 0.73301241
Iteration 619, loss = 0.73294250
Iteration 620, loss = 0.73048435
Iteration 621, loss = 0.73102476
Iteration 622, loss = 0.72925201
Iteration 623, loss = 0.72811132
Iteration 624, loss = 0.72761416
Iteration 625, loss = 0.72514483
Iteration 626, loss = 0.72380892
Iteration 627, loss = 0.72210049
Iteration 628, loss = 0.72053745
Iteration 629, loss = 0.71821449
Iteration 630, loss = 0.71670793
Iteration 631, loss = 0.71565833
Iteration 632, loss = 0.71264814
Iteration 633, loss = 0.70811996
Iteration 634, loss = 0.69803648
Iteration 635, loss = 0.65152432
Iteration 636, loss = 0.74777629
Iteration 637, loss = 0.60113020
Iteration 638, loss = 1.06150337
Iteration 639, loss = 0.75586535
Iteration 640, loss = 1.02395541
Iteration 641, loss = 0.99066135
Iteration 642, loss = 0.77420113
Iteration 643, loss = 0.98765936
Iteration 644, loss = 0.89205179
Iteration 645, loss = 0.79053181
Iteration 646, loss = 0.93838825
Iteration 647, loss = 0.80362482
Iteration 648, loss = 0.80884300
Iteration 649, loss = 0.87330053
Iteration 650, loss = 0.75515812
Iteration 651, loss = 0.80749920
Iteration 652, loss = 0.82062634
Iteration 653, loss = 0.73769526
Iteration 654, loss = 0.79802745
Iteration 655, loss = 0.77817720
Iteration 656, loss = 0.73748429
Iteration 657, loss = 0.78826238
Iteration 658, loss = 0.74210374
Iteration 659, loss = 0.76666780
Iteration 660, loss = 0.80209742
Iteration 661, loss = 0.74366202
Iteration 662, loss = 0.77812348
Iteration 663, loss = 0.77746725
Iteration 664, loss = 0.73974663
Iteration 665, loss = 0.77372799
Iteration 666, loss = 0.75418746
Iteration 667, loss = 0.74169558
Iteration 668, loss = 0.76537905
Iteration 669, loss = 0.74147174
Iteration 670, loss = 0.74633838
Iteration 671, loss = 0.75569347
Iteration 672, loss = 0.73617348
Iteration 673, loss = 0.74804892
Iteration 674, loss = 0.74567415
Iteration 675, loss = 0.73550404
Iteration 676, loss = 0.74668336
Iteration 677, loss = 0.73864875
Iteration 678, loss = 0.73679007
Iteration 679, loss = 0.74303435
Iteration 680, loss = 0.73433327
Iteration 681, loss = 0.73735646
Iteration 682, loss = 0.73822002
Iteration 683, loss = 0.73239331
Iteration 684, loss = 0.73680528
Iteration 685, loss = 0.73431645
Iteration 686, loss = 0.73213708
Iteration 687, loss = 0.73530626
Iteration 688, loss = 0.73171915
Iteration 689, loss = 0.73221416
Iteration 690, loss = 0.73307303
Iteration 691, loss = 0.73011370
Iteration 692, loss = 0.73166101
Iteration 693, loss = 0.73071050
Iteration 694, loss = 0.72926010
Iteration 695, loss = 0.73052459
Iteration 696, loss = 0.72888213
Iteration 697, loss = 0.72879823
Iteration 698, loss = 0.72914560
Iteration 699, loss = 0.72769582
Iteration 700, loss = 0.72820100
Iteration 701, loss = 0.72773440
Iteration 702, loss = 0.72698016
Iteration 703, loss = 0.72737675
Iteration 704, loss = 0.72651941
Iteration 705, loss = 0.72615624
Iteration 706, loss = 0.72619338
Iteration 707, loss = 0.72537545
Iteration 708, loss = 0.72524056
Iteration 709, loss = 0.72459691
Iteration 710, loss = 0.72352033
Iteration 711, loss = 0.71873543
Iteration 712, loss = 0.73372787
Iteration 713, loss = 0.72756572
Iteration 714, loss = 0.73756450
Iteration 715, loss = 0.73109337
Iteration 716, loss = 0.74062261
Iteration 717, loss = 0.72788927
Iteration 718, loss = 0.73283619
Iteration 719, loss = 0.74122041
Iteration 720, loss = 0.74763046
Iteration 721, loss = 0.75647271
Iteration 722, loss = 0.76087959
Iteration 723, loss = 0.76310204
Iteration 724, loss = 0.76405268
Iteration 725, loss = 0.76162126
Iteration 726, loss = 0.75919106
Iteration 727, loss = 0.75521819
Iteration 728, loss = 0.75080084
Iteration 729, loss = 0.74755151
Iteration 730, loss = 0.74328052
Iteration 731, loss = 0.74038309
Iteration 732, loss = 0.73779540
Iteration 733, loss = 0.73529757
Iteration 734, loss = 0.73407579
Iteration 735, loss = 0.73273124
Iteration 736, loss = 0.73212917
Iteration 737, loss = 0.73189679
Iteration 738, loss = 0.73110064
Iteration 739, loss = 0.73047451
Iteration 740, loss = 0.72948640
Iteration 741, loss = 0.72917676
Iteration 742, loss = 0.72831772
Iteration 743, loss = 0.72705076
Iteration 744, loss = 0.72519969
Iteration 745, loss = 0.72034819
Iteration 746, loss = 0.61492111
Iteration 747, loss = 0.84323592
Iteration 748, loss = 0.79977638
Iteration 749, loss = 0.86032919
Iteration 750, loss = 0.74937610
Iteration 751, loss = 0.85291320
Iteration 752, loss = 0.74208184
Iteration 753, loss = 0.82232674
Iteration 754, loss = 0.76124483
Iteration 755, loss = 0.77822889
Iteration 756, loss = 0.78090976
Iteration 757, loss = 0.74396753
Iteration 758, loss = 0.78652198
Iteration 759, loss = 0.73359356
Iteration 760, loss = 0.77657360
Iteration 761, loss = 0.74211966
Iteration 762, loss = 0.75845580
Iteration 763, loss = 0.75454603
Iteration 764, loss = 0.74225943
Iteration 765, loss = 0.75972919
Iteration 766, loss = 0.73500124
Iteration 767, loss = 0.75588237
Iteration 768, loss = 0.73658345
Iteration 769, loss = 0.74685324
Iteration 770, loss = 0.74141779
Iteration 771, loss = 0.73813084
Iteration 772, loss = 0.74432642
Iteration 773, loss = 0.73354722
Iteration 774, loss = 0.74346234
Iteration 775, loss = 0.73338742
Iteration 776, loss = 0.73981692
Iteration 777, loss = 0.73526163
Iteration 778, loss = 0.73531736
Iteration 779, loss = 0.73687739
Iteration 780, loss = 0.73267261
Iteration 781, loss = 0.73608010
Iteration 782, loss = 0.72863550
Iteration 783, loss = 0.75954512
Iteration 784, loss = 0.76931530
Iteration 785, loss = 0.75817808
Iteration 786, loss = 0.75785438
Iteration 787, loss = 0.77120695
Iteration 788, loss = 0.74447217
Iteration 789, loss = 0.76611963
Iteration 790, loss = 0.73883269
Iteration 791, loss = 0.75227691
Iteration 792, loss = 0.74061576
Iteration 793, loss = 0.74045847
Iteration 794, loss = 0.74557787
Iteration 795, loss = 0.73455253
Iteration 796, loss = 0.74602151
Iteration 797, loss = 0.73353141
Iteration 798, loss = 0.74129783
Iteration 799, loss = 0.73467545
Iteration 800, loss = 0.73516933
Iteration 801, loss = 0.73500346
Iteration 802, loss = 0.72681393
Iteration 803, loss = 0.71574252
Iteration 804, loss = 0.80084047
Iteration 805, loss = 0.74307978
Iteration 806, loss = 0.81747664
Iteration 807, loss = 0.76139400
Iteration 808, loss = 0.78988107
Iteration 809, loss = 0.78460431
Iteration 810, loss = 0.75289618
Iteration 811, loss = 0.78397022
Iteration 812, loss = 0.73984600
Iteration 813, loss = 0.76416301
Iteration 814, loss = 0.74840708
Iteration 815, loss = 0.74266749
Iteration 816, loss = 0.75612110
Iteration 817, loss = 0.73333836
Iteration 818, loss = 0.75259129
Iteration 819, loss = 0.73823144
Iteration 820, loss = 0.74232199
Iteration 821, loss = 0.74001027
Iteration 822, loss = 0.72938325
Iteration 823, loss = 0.73631471
Iteration 824, loss = 0.72230779
Iteration 825, loss = 0.72486348
Iteration 826, loss = 0.67377519
Iteration 827, loss = 0.78119771
Iteration 828, loss = 0.81411865
Iteration 829, loss = 0.85090111
Iteration 830, loss = 0.75785322
Iteration 831, loss = 0.84662065
Iteration 832, loss = 0.75727842
Iteration 833, loss = 0.79543596
Iteration 834, loss = 0.78170172
Iteration 835, loss = 0.74504940
Iteration 836, loss = 0.78809315
Iteration 837, loss = 0.73143719
Iteration 838, loss = 0.77212566
Iteration 839, loss = 0.74655631
Iteration 840, loss = 0.74787900
Iteration 841, loss = 0.76114168
Iteration 842, loss = 0.73354257
Iteration 843, loss = 0.75941264
Iteration 844, loss = 0.73361191
Iteration 845, loss = 0.74538185
Iteration 846, loss = 0.74001838
Iteration 847, loss = 0.73175126
Iteration 848, loss = 0.74281728
Iteration 849, loss = 0.72688304
Iteration 850, loss = 0.73919027
Iteration 851, loss = 0.72967754
Iteration 852, loss = 0.73191371
Iteration 853, loss = 0.73276285
Iteration 854, loss = 0.72580138
Iteration 855, loss = 0.73225629
Iteration 856, loss = 0.72413371
Iteration 857, loss = 0.72853706
Iteration 858, loss = 0.72522399
Iteration 859, loss = 0.72418520
Iteration 860, loss = 0.72537170
Iteration 861, loss = 0.72065395
Iteration 862, loss = 0.72373404
Iteration 863, loss = 0.72090577
Iteration 864, loss = 0.72230174
Iteration 865, loss = 0.72062348
Iteration 866, loss = 0.71827212
Iteration 867, loss = 0.71931997
Iteration 868, loss = 0.71596095
Iteration 869, loss = 0.71752103
Iteration 870, loss = 0.71605218
Iteration 871, loss = 0.71590278
Iteration 872, loss = 0.71549110
Iteration 873, loss = 0.71349872
Iteration 874, loss = 0.71357407
Iteration 875, loss = 0.72721742
Iteration 876, loss = 0.74238349
Iteration 877, loss = 0.72696695
Iteration 878, loss = 0.73778545
Iteration 879, loss = 0.74223075
Iteration 880, loss = 0.72777959
Iteration 881, loss = 0.73936847
Iteration 882, loss = 0.71942558
Iteration 883, loss = 0.72621534
Iteration 884, loss = 0.71739176
Iteration 885, loss = 0.70596010
Iteration 886, loss = 0.66159608
Iteration 887, loss = 0.80730838
Iteration 888, loss = 0.85385815
Iteration 889, loss = 0.92400900
Iteration 890, loss = 0.76463209
Iteration 891, loss = 0.90516290
Iteration 892, loss = 0.81074779
Iteration 893, loss = 0.80457698
Iteration 894, loss = 0.85360357
Iteration 895, loss = 0.74721951
Iteration 896, loss = 0.82400268
Iteration 897, loss = 0.75748198
Iteration 898, loss = 0.74794699
Iteration 899, loss = 0.83514501
Iteration 900, loss = 0.75852195
Iteration 901, loss = 0.79099117
Iteration 902, loss = 0.78678805
Iteration 903, loss = 0.74791984
Iteration 904, loss = 0.79312988
Iteration 905, loss = 0.74071579
Iteration 906, loss = 0.77635312
Iteration 907, loss = 0.75758447
Iteration 908, loss = 0.75281307
Iteration 909, loss = 0.76970451
Iteration 910, loss = 0.74063854
Iteration 911, loss = 0.76566214
Iteration 912, loss = 0.74368783
Iteration 913, loss = 0.75212768
Iteration 914, loss = 0.75151148
Iteration 915, loss = 0.74093772
Iteration 916, loss = 0.75378368
Iteration 917, loss = 0.73823917
Iteration 918, loss = 0.74880033
Iteration 919, loss = 0.74142110
Iteration 920, loss = 0.74141123
Iteration 921, loss = 0.74444623
Iteration 922, loss = 0.73688333
Iteration 923, loss = 0.74382045
Iteration 924, loss = 0.73651236
Iteration 925, loss = 0.74018329
Iteration 926, loss = 0.73807150
Iteration 927, loss = 0.73639703
Iteration 928, loss = 0.73889159
Iteration 929, loss = 0.73459813
Iteration 930, loss = 0.73792431
Iteration 931, loss = 0.73473551
Iteration 932, loss = 0.73582655
Iteration 933, loss = 0.73536218
Iteration 934, loss = 0.73388207
Iteration 935, loss = 0.73524811
Iteration 936, loss = 0.73286999
Iteration 937, loss = 0.73419417
Iteration 938, loss = 0.73265978
Iteration 939, loss = 0.73275416
Iteration 940, loss = 0.73253630
Iteration 941, loss = 0.73039674
Iteration 942, loss = 0.73165619
Iteration 943, loss = 0.73289784
Iteration 944, loss = 0.73306592
Iteration 945, loss = 0.73261027
Iteration 946, loss = 0.73205377
Iteration 947, loss = 0.73109641
Iteration 948, loss = 0.73082469
Iteration 949, loss = 0.73031055
Iteration 950, loss = 0.73028819
Iteration 951, loss = 0.73027340
Iteration 952, loss = 0.73000379
Iteration 953, loss = 0.72994124
Iteration 954, loss = 0.72945117
Iteration 955, loss = 0.72916830
Iteration 956, loss = 0.72859289
Iteration 957, loss = 0.72695393
Iteration 958, loss = 0.71359718
Iteration 959, loss = 0.75603055
Iteration 960, loss = 0.74425235
Iteration 961, loss = 0.75419542
Iteration 962, loss = 0.75582722
Iteration 963, loss = 0.74259576
Iteration 964, loss = 0.75135188
Iteration 965, loss = 0.73491653
Iteration 966, loss = 0.74147699
Iteration 967, loss = 0.73679312
Iteration 968, loss = 0.73553506
Iteration 969, loss = 0.74125806
Iteration 970, loss = 0.73464588
Iteration 971, loss = 0.74151457
Iteration 972, loss = 0.73635000
Iteration 973, loss = 0.73806102
Iteration 974, loss = 0.73788035
Iteration 975, loss = 0.73461875
Iteration 976, loss = 0.73760489
Iteration 977, loss = 0.73339238
Iteration 978, loss = 0.73578398
Iteration 979, loss = 0.73405604
Iteration 980, loss = 0.73385526
Iteration 981, loss = 0.73477462
Iteration 982, loss = 0.73273673
Iteration 983, loss = 0.73443334
Iteration 984, loss = 0.73256882
Iteration 985, loss = 0.73326215
Iteration 986, loss = 0.73274391
Iteration 987, loss = 0.73203008
Iteration 988, loss = 0.73257295
Iteration 989, loss = 0.73126901
Iteration 990, loss = 0.73189965
Iteration 991, loss = 0.73100184
Iteration 992, loss = 0.73102494
Iteration 993, loss = 0.73086668
Iteration 994, loss = 0.73027166
Iteration 995, loss = 0.73051650
Iteration 996, loss = 0.72976486
Iteration 997, loss = 0.72991522
Iteration 998, loss = 0.72943795
Iteration 999, loss = 0.72924587
Iteration 1000, loss = 0.72911942
Iteration 1001, loss = 0.72866340
Iteration 1002, loss = 0.72868036
Iteration 1003, loss = 0.72820364
Iteration 1004, loss = 0.72813477
Iteration 1005, loss = 0.72781773
Iteration 1006, loss = 0.72757923
Iteration 1007, loss = 0.72742882
Iteration 1008, loss = 0.72708653
Iteration 1009, loss = 0.72699207
Iteration 1010, loss = 0.72666130
Iteration 1011, loss = 0.72651216
Iteration 1012, loss = 0.72626049
Iteration 1013, loss = 0.72602455
Iteration 1014, loss = 0.72584605
Iteration 1015, loss = 0.72556600
Iteration 1016, loss = 0.72541070
Iteration 1017, loss = 0.72514487
Iteration 1018, loss = 0.72496390
Iteration 1019, loss = 0.72473986
Iteration 1020, loss = 0.72451939
Iteration 1021, loss = 0.72432992
Iteration 1022, loss = 0.72408919
Iteration 1023, loss = 0.72390708
Iteration 1024, loss = 0.72365983
Iteration 1025, loss = 0.72331562
Iteration 1026, loss = 0.72310908
Iteration 1027, loss = 0.72287288
Iteration 1028, loss = 0.72254977
Iteration 1029, loss = 0.72220890
Iteration 1030, loss = 0.72183173
Iteration 1031, loss = 0.72075289
Iteration 1032, loss = 0.71473189
Iteration 1033, loss = 0.73254613
Iteration 1034, loss = 0.72682062
Iteration 1035, loss = 0.73586680
Iteration 1036, loss = 0.72502678
Iteration 1037, loss = 0.73027969
Iteration 1038, loss = 0.72599826
Iteration 1039, loss = 0.72402026
Iteration 1040, loss = 0.72769918
Iteration 1041, loss = 0.72221217
Iteration 1042, loss = 0.72705765
Iteration 1043, loss = 0.72335900
Iteration 1044, loss = 0.72406603
Iteration 1045, loss = 0.72444721
Iteration 1046, loss = 0.72161431
Iteration 1047, loss = 0.72417654
Iteration 1048, loss = 0.72126772
Iteration 1049, loss = 0.72272335
Iteration 1050, loss = 0.72191035
Iteration 1051, loss = 0.72102886
Iteration 1052, loss = 0.72198478
Iteration 1053, loss = 0.72005081
Iteration 1054, loss = 0.72106473
Iteration 1055, loss = 0.71971559
Iteration 1056, loss = 0.71945611
Iteration 1057, loss = 0.71923601
Iteration 1058, loss = 0.71823629
Iteration 1059, loss = 0.71888748
Iteration 1060, loss = 0.71796660
Iteration 1061, loss = 0.71815555
Iteration 1062, loss = 0.71763150
Iteration 1063, loss = 0.71708760
Iteration 1064, loss = 0.71706048
Iteration 1065, loss = 0.71632086
Iteration 1066, loss = 0.71649125
Iteration 1067, loss = 0.71604856
Iteration 1068, loss = 0.71595271
Iteration 1069, loss = 0.71579069
Iteration 1070, loss = 0.71538738
Iteration 1071, loss = 0.71537829
Iteration 1072, loss = 0.71492930
Iteration 1073, loss = 0.71484163
Iteration 1074, loss = 0.71453294
Iteration 1075, loss = 0.71425588
Iteration 1076, loss = 0.71404054
Iteration 1077, loss = 0.71358366
Iteration 1078, loss = 0.71331866
Iteration 1079, loss = 0.71286498
Iteration 1080, loss = 0.71258202
Iteration 1081, loss = 0.71207578
Iteration 1082, loss = 0.71156975
Iteration 1083, loss = 0.71142291
Iteration 1084, loss = 0.70950451
Iteration 1085, loss = 0.71136983
Iteration 1086, loss = 0.71122059
Iteration 1087, loss = 0.74037919
Iteration 1088, loss = 0.69019087
Iteration 1089, loss = 0.72901255
Iteration 1090, loss = 0.72946750
Iteration 1091, loss = 0.72571804
Iteration 1092, loss = 0.72134038
Iteration 1093, loss = 0.71880659
Iteration 1094, loss = 0.71617547
Iteration 1095, loss = 0.71622274
Iteration 1096, loss = 0.71582120
Iteration 1097, loss = 0.71596181
Iteration 1098, loss = 0.71642236
Iteration 1099, loss = 0.71584427
Iteration 1100, loss = 0.71601285
Iteration 1101, loss = 0.71536280
Iteration 1102, loss = 0.71501146
Iteration 1103, loss = 0.71463275
Iteration 1104, loss = 0.71399892
Iteration 1105, loss = 0.71388721
Iteration 1106, loss = 0.71331232
Iteration 1107, loss = 0.71306577
Iteration 1108, loss = 0.71272134
Iteration 1109, loss = 0.71229369
Iteration 1110, loss = 0.71211936
Iteration 1111, loss = 0.71166787
Iteration 1112, loss = 0.71144039
Iteration 1113, loss = 0.71107641
Iteration 1114, loss = 0.71070959
Iteration 1115, loss = 0.71032658
Iteration 1116, loss = 0.70957192
Iteration 1117, loss = 0.70864645
Iteration 1118, loss = 0.70721828
Iteration 1119, loss = 0.70592795
Iteration 1120, loss = 0.70479095
Iteration 1121, loss = 0.70358763
Iteration 1122, loss = 0.70256315
Iteration 1123, loss = 0.70054076
Iteration 1124, loss = 0.69730042
Iteration 1125, loss = 0.69386190
Iteration 1126, loss = 0.69216466
Iteration 1127, loss = 0.68925643
Iteration 1128, loss = 0.68216350
Iteration 1129, loss = 0.66165929
Iteration 1130, loss = 0.98885031
Iteration 1131, loss = 1.18487869
Iteration 1132, loss = 1.11060061
Iteration 1133, loss = 0.77887496
Iteration 1134, loss = 1.16977075
Iteration 1135, loss = 0.97475046
Iteration 1136, loss = 0.85878762
Iteration 1137, loss = 1.08977160
Iteration 1138, loss = 0.84045023
Iteration 1139, loss = 0.90757965
Iteration 1140, loss = 0.98039814
Iteration 1141, loss = 0.76403207
Iteration 1142, loss = 0.91291595
Iteration 1143, loss = 0.85425487
Iteration 1144, loss = 0.76172544
Iteration 1145, loss = 0.87817671
Iteration 1146, loss = 0.75866481
Iteration 1147, loss = 0.78919321
Iteration 1148, loss = 0.81860005
Iteration 1149, loss = 0.72668601
Iteration 1150, loss = 0.80087684
Iteration 1151, loss = 0.75812958
Iteration 1152, loss = 0.74114487
Iteration 1153, loss = 0.78512469
Iteration 1154, loss = 0.72678268
Iteration 1155, loss = 0.76019392
Iteration 1156, loss = 0.75299480
Iteration 1157, loss = 0.72677001
Iteration 1158, loss = 0.75962224
Iteration 1159, loss = 0.72781114
Iteration 1160, loss = 0.73811161
Iteration 1161, loss = 0.74340398
Iteration 1162, loss = 0.72146934
Iteration 1163, loss = 0.74151444
Iteration 1164, loss = 0.72620783
Iteration 1165, loss = 0.72632930
Iteration 1166, loss = 0.73380199
Iteration 1167, loss = 0.71845085
Iteration 1168, loss = 0.72878456
Iteration 1169, loss = 0.72182460
Iteration 1170, loss = 0.71833834
Iteration 1171, loss = 0.72420024
Iteration 1172, loss = 0.71425444
Iteration 1173, loss = 0.71864638
Iteration 1174, loss = 0.71570900
Iteration 1175, loss = 0.71144527
Iteration 1176, loss = 0.71505275
Iteration 1177, loss = 0.70837798
Iteration 1178, loss = 0.70756670
Iteration 1179, loss = 0.70350190
Iteration 1180, loss = 0.71735621
Iteration 1181, loss = 0.75674447
Iteration 1182, loss = 0.75025974
Iteration 1183, loss = 0.74710806
Iteration 1184, loss = 0.76919497
Iteration 1185, loss = 0.73437011
Iteration 1186, loss = 0.74767543
Iteration 1187, loss = 0.73917201
Iteration 1188, loss = 0.72495223
Iteration 1189, loss = 0.74096899
Iteration 1190, loss = 0.72341223
Iteration 1191, loss = 0.73123652
Iteration 1192, loss = 0.73207625
Iteration 1193, loss = 0.72263637
Iteration 1194, loss = 0.73285301
Iteration 1195, loss = 0.72333214
Iteration 1196, loss = 0.72598145
Iteration 1197, loss = 0.72780079
Iteration 1198, loss = 0.72081371
Iteration 1199, loss = 0.72654160
Iteration 1200, loss = 0.72114132
Iteration 1201, loss = 0.72127864
Iteration 1202, loss = 0.72290979
Iteration 1203, loss = 0.71823833
Iteration 1204, loss = 0.72158284
Iteration 1205, loss = 0.71893933
Iteration 1206, loss = 0.71851645
Iteration 1207, loss = 0.71986298
Iteration 1208, loss = 0.71692117
Iteration 1209, loss = 0.71872131
Iteration 1210, loss = 0.71730555
Iteration 1211, loss = 0.71666885
Iteration 1212, loss = 0.71743799
Iteration 1213, loss = 0.71540387
Iteration 1214, loss = 0.71611187
Iteration 1215, loss = 0.71507560
Iteration 1216, loss = 0.71420335
Iteration 1217, loss = 0.71435279
Iteration 1218, loss = 0.71274349
Iteration 1219, loss = 0.71289043
Iteration 1220, loss = 0.71213252
Iteration 1221, loss = 0.71124981
Iteration 1222, loss = 0.71090485
Iteration 1223, loss = 0.70944129
Iteration 1224, loss = 0.70880648
Iteration 1225, loss = 0.70756923
Iteration 1226, loss = 0.70652852
Iteration 1227, loss = 0.70423147
Iteration 1228, loss = 0.70120317
Iteration 1229, loss = 0.70232763
Iteration 1230, loss = 0.82183490
Iteration 1231, loss = 0.77580359
Iteration 1232, loss = 0.78431447
Iteration 1233, loss = 0.83128988
Iteration 1234, loss = 0.75936058
Iteration 1235, loss = 0.79727639
Iteration 1236, loss = 0.76864394
Iteration 1237, loss = 0.74465178
Iteration 1238, loss = 0.77673527
Iteration 1239, loss = 0.73716789
Iteration 1240, loss = 0.76146282
Iteration 1241, loss = 0.75901277
Iteration 1242, loss = 0.74386400
Iteration 1243, loss = 0.76776510
Iteration 1244, loss = 0.74562827
Iteration 1245, loss = 0.75611729
Iteration 1246, loss = 0.75657750
Iteration 1247, loss = 0.74407534
Iteration 1248, loss = 0.75780087
Iteration 1249, loss = 0.74462224
Iteration 1250, loss = 0.74880899
Iteration 1251, loss = 0.75017785
Iteration 1252, loss = 0.74178296
Iteration 1253, loss = 0.75010026
Iteration 1254, loss = 0.74279236
Iteration 1255, loss = 0.74468744
Iteration 1256, loss = 0.74625250
Iteration 1257, loss = 0.74109247
Iteration 1258, loss = 0.74617656
Iteration 1259, loss = 0.74214937
Iteration 1260, loss = 0.74296115
Iteration 1261, loss = 0.74393019
Iteration 1262, loss = 0.74038642
Iteration 1263, loss = 0.74290530
Iteration 1264, loss = 0.74011166
Iteration 1265, loss = 0.74012522
Iteration 1266, loss = 0.74057635
Iteration 1267, loss = 0.73840388
Iteration 1268, loss = 0.73994667
Iteration 1269, loss = 0.73837809
Iteration 1270, loss = 0.73837558
Iteration 1271, loss = 0.73857946
Iteration 1272, loss = 0.73713236
Iteration 1273, loss = 0.73783756
Iteration 1274, loss = 0.73668067
Iteration 1275, loss = 0.73648118
Iteration 1276, loss = 0.73641368
Iteration 1277, loss = 0.73542299
Iteration 1278, loss = 0.73572528
Iteration 1279, loss = 0.73491975
Iteration 1280, loss = 0.73471015
Iteration 1281, loss = 0.73453488
Iteration 1282, loss = 0.73383587
Iteration 1283, loss = 0.73388958
Iteration 1284, loss = 0.73327182
Iteration 1285, loss = 0.73303626
Iteration 1286, loss = 0.73278145
Iteration 1287, loss = 0.73224034
Iteration 1288, loss = 0.73212783
Iteration 1289, loss = 0.73160159
Iteration 1290, loss = 0.73132177
Iteration 1291, loss = 0.73100307
Iteration 1292, loss = 0.73054794
Iteration 1293, loss = 0.73034762
Iteration 1294, loss = 0.72990765
Iteration 1295, loss = 0.72963528
Iteration 1296, loss = 0.72931833
Iteration 1297, loss = 0.72893728
Iteration 1298, loss = 0.72869643
Iteration 1299, loss = 0.72831454
Iteration 1300, loss = 0.72804682
Iteration 1301, loss = 0.72774116
Iteration 1302, loss = 0.72741366
Iteration 1303, loss = 0.72716215
Iteration 1304, loss = 0.72682998
Iteration 1305, loss = 0.72657510
Iteration 1306, loss = 0.72629206
Iteration 1307, loss = 0.72601015
Iteration 1308, loss = 0.72576858
Iteration 1309, loss = 0.72548123
Iteration 1310, loss = 0.72524128
Iteration 1311, loss = 0.72497672
Iteration 1312, loss = 0.72471847
Iteration 1313, loss = 0.72447785
Iteration 1314, loss = 0.72421155
Iteration 1315, loss = 0.72397226
Iteration 1316, loss = 0.72370967
Iteration 1317, loss = 0.72344665
Iteration 1318, loss = 0.72319232
Iteration 1319, loss = 0.72294268
Iteration 1320, loss = 0.72271430
Iteration 1321, loss = 0.72246674
Iteration 1322, loss = 0.72222313
Iteration 1323, loss = 0.72198913
Iteration 1324, loss = 0.72175512
Iteration 1325, loss = 0.72151905
Iteration 1326, loss = 0.72126661
Iteration 1327, loss = 0.72102732
Iteration 1328, loss = 0.72079158
Iteration 1329, loss = 0.72053834
Iteration 1330, loss = 0.72009054
Iteration 1331, loss = 0.71931256
Iteration 1332, loss = 0.71920878
Iteration 1333, loss = 0.71902910
Iteration 1334, loss = 0.71791192
Iteration 1335, loss = 0.71769475
Iteration 1336, loss = 0.71755406
Iteration 1337, loss = 0.71729286
Iteration 1338, loss = 0.71675317
Iteration 1339, loss = 0.71594662
Iteration 1340, loss = 0.71548613
Iteration 1341, loss = 0.71525448
Iteration 1342, loss = 0.71569238
Iteration 1343, loss = 0.71488251
Iteration 1344, loss = 0.71455145
Iteration 1345, loss = 0.71424984
Iteration 1346, loss = 0.71391473
Iteration 1347, loss = 0.71359789
Iteration 1348, loss = 0.71329189
Iteration 1349, loss = 0.71292228
Iteration 1350, loss = 0.71247921
Iteration 1351, loss = 0.71203282
Iteration 1352, loss = 0.71162610
Iteration 1353, loss = 0.71121005
Iteration 1354, loss = 0.71081479
Iteration 1355, loss = 0.71082302
Iteration 1356, loss = 0.71008679
Iteration 1357, loss = 0.70877568
Iteration 1358, loss = 0.70838772
Iteration 1359, loss = 0.70872666
Iteration 1360, loss = 0.70774901
Iteration 1361, loss = 0.70655397
Iteration 1362, loss = 0.70462231
Iteration 1363, loss = 0.70315127
Iteration 1364, loss = 0.69195940
Iteration 1365, loss = 0.71454605
Iteration 1366, loss = 0.71416397
Iteration 1367, loss = 0.72180352
Iteration 1368, loss = 0.71056448
Iteration 1369, loss = 0.71565508
Iteration 1370, loss = 0.70746646
Iteration 1371, loss = 0.70679091
Iteration 1372, loss = 0.70890713
Iteration 1373, loss = 0.70434415
Iteration 1374, loss = 0.70929869
Iteration 1375, loss = 0.70483223
Iteration 1376, loss = 0.70541759
Iteration 1377, loss = 0.70420171
Iteration 1378, loss = 0.70083415
Iteration 1379, loss = 0.70257984
Iteration 1380, loss = 0.69875007
Iteration 1381, loss = 0.69877036
Iteration 1382, loss = 0.69740201
Iteration 1383, loss = 0.69623410
Iteration 1384, loss = 0.69551078
Iteration 1385, loss = 0.69132284
Iteration 1386, loss = 0.68946780
Iteration 1387, loss = 0.68478565
Iteration 1388, loss = 0.68103101
Iteration 1389, loss = 0.67480931
Iteration 1390, loss = 0.66863348
Iteration 1391, loss = 0.65325185
Iteration 1392, loss = 0.59325225
Iteration 1393, loss = 0.85010973
Iteration 1394, loss = 0.90524410
Iteration 1395, loss = 0.87800570
Iteration 1396, loss = 0.78265194
Iteration 1397, loss = 0.95169234
Iteration 1398, loss = 0.86793451
Iteration 1399, loss = 0.87934705
Iteration 1400, loss = 0.95075159
Iteration 1401, loss = 0.83849677
Iteration 1402, loss = 0.80145229
Iteration 1403, loss = 0.88409409
Iteration 1404, loss = 0.88308658
Iteration 1405, loss = 0.90469624
Iteration 1406, loss = 0.86152811
Iteration 1407, loss = 0.87494373
Iteration 1408, loss = 0.81976688
Iteration 1409, loss = 0.83193535
Iteration 1410, loss = 0.78516727
Iteration 1411, loss = 0.79788033
Iteration 1412, loss = 0.77024011
Iteration 1413, loss = 0.77847377
Iteration 1414, loss = 0.76717348
Iteration 1415, loss = 0.76699891
Iteration 1416, loss = 0.76479866
Iteration 1417, loss = 0.75696495
Iteration 1418, loss = 0.76114101
Iteration 1419, loss = 0.74003985
Iteration 1420, loss = 0.81797837
Iteration 1421, loss = 0.77031976
Iteration 1422, loss = 0.84842363
Iteration 1423, loss = 0.77406607
Iteration 1424, loss = 0.80582307
Iteration 1425, loss = 0.80845382
Iteration 1426, loss = 0.75991369
Iteration 1427, loss = 0.80520120
Iteration 1428, loss = 0.76417702
Iteration 1429, loss = 0.77177952
Iteration 1430, loss = 0.78320794
Iteration 1431, loss = 0.75251438
Iteration 1432, loss = 0.78125290
Iteration 1433, loss = 0.76115312
Iteration 1434, loss = 0.76094244
Iteration 1435, loss = 0.77049288
Iteration 1436, loss = 0.74983425
Iteration 1437, loss = 0.76507132
Iteration 1438, loss = 0.75454309
Iteration 1439, loss = 0.75237691
Iteration 1440, loss = 0.75983369
Iteration 1441, loss = 0.74729925
Iteration 1442, loss = 0.75607177
Iteration 1443, loss = 0.75077198
Iteration 1444, loss = 0.74834656
Iteration 1445, loss = 0.75329664
Iteration 1446, loss = 0.74538787
Iteration 1447, loss = 0.75009482
Iteration 1448, loss = 0.74712013
Iteration 1449, loss = 0.74520680
Iteration 1450, loss = 0.74834988
Iteration 1451, loss = 0.74371036
Iteration 1452, loss = 0.74640469
Iteration 1453, loss = 0.74479258
Iteration 1454, loss = 0.74346404
Iteration 1455, loss = 0.74517626
Iteration 1456, loss = 0.74204509
Iteration 1457, loss = 0.74336982
Iteration 1458, loss = 0.74238908
Iteration 1459, loss = 0.74133286
Iteration 1460, loss = 0.74234389
Iteration 1461, loss = 0.74051963
Iteration 1462, loss = 0.74118960
Iteration 1463, loss = 0.74046370
Iteration 1464, loss = 0.73971338
Iteration 1465, loss = 0.74065421
Iteration 1466, loss = 0.73976552
Iteration 1467, loss = 0.73994368
Iteration 1468, loss = 0.73902159
Iteration 1469, loss = 0.73822939
Iteration 1470, loss = 0.73854346
Iteration 1471, loss = 0.73782317
Iteration 1472, loss = 0.73771205
Iteration 1473, loss = 0.73712849
Iteration 1474, loss = 0.73678297
Iteration 1475, loss = 0.73672110
Iteration 1476, loss = 0.73599819
Iteration 1477, loss = 0.73573954
Iteration 1478, loss = 0.73499572
Iteration 1479, loss = 0.73360242
Iteration 1480, loss = 0.73065369
Iteration 1481, loss = 0.69994443
Iteration 1482, loss = 0.74500201
Iteration 1483, loss = 0.74504037
Iteration 1484, loss = 0.75296876
Iteration 1485, loss = 0.74208087
Iteration 1486, loss = 0.74566797
Iteration 1487, loss = 0.74309029
Iteration 1488, loss = 0.73805456
Iteration 1489, loss = 0.74323806
Iteration 1490, loss = 0.73816049
Iteration 1491, loss = 0.74011448
Iteration 1492, loss = 0.74105387
Iteration 1493, loss = 0.73740523
Iteration 1494, loss = 0.74052202
Iteration 1495, loss = 0.73798717
Iteration 1496, loss = 0.73801652
Iteration 1497, loss = 0.73924693
Iteration 1498, loss = 0.73671127
Iteration 1499, loss = 0.73827664
Iteration 1500, loss = 0.73704555
Iteration 1501, loss = 0.73631077
Iteration 1502, loss = 0.73725390
Iteration 1503, loss = 0.73568599
Iteration 1504, loss = 0.73648176
Iteration 1505, loss = 0.73577781
Iteration 1506, loss = 0.73497229
Iteration 1507, loss = 0.73729346
Iteration 1508, loss = 0.73736261
Iteration 1509, loss = 0.73749375
Iteration 1510, loss = 0.73706163
Iteration 1511, loss = 0.73467607
Iteration 1512, loss = 0.73314910
Iteration 1513, loss = 0.73310602
Iteration 1514, loss = 0.73149643
Iteration 1515, loss = 0.73148657
Iteration 1516, loss = 0.73075006
Iteration 1517, loss = 0.73033364
Iteration 1518, loss = 0.73513794
Iteration 1519, loss = 0.75015777
Iteration 1520, loss = 0.74814040
Iteration 1521, loss = 0.74837326
Iteration 1522, loss = 0.76452402
Iteration 1523, loss = 0.74844881
Iteration 1524, loss = 0.75070036
Iteration 1525, loss = 0.74308171
Iteration 1526, loss = 0.72397360
Iteration 1527, loss = 0.71568032
Iteration 1528, loss = 0.62004435
Iteration 1529, loss = 1.29805967
Iteration 1530, loss = 0.87582951
Iteration 1531, loss = 1.35168324
Iteration 1532, loss = 0.89681189
Iteration 1533, loss = 1.08839596
Iteration 1534, loss = 1.16871331
Iteration 1535, loss = 0.76996292
Iteration 1536, loss = 1.09216113
Iteration 1537, loss = 0.91968987
Iteration 1538, loss = 0.82549908
Iteration 1539, loss = 1.00768889
Iteration 1540, loss = 0.76364543
Iteration 1541, loss = 0.91668893
Iteration 1542, loss = 0.89546149
Iteration 1543, loss = 0.76543944
Iteration 1544, loss = 0.91019978
Iteration 1545, loss = 0.77739665
Iteration 1546, loss = 0.82000524
Iteration 1547, loss = 0.84431423
Iteration 1548, loss = 0.74644346
Iteration 1549, loss = 0.83619721
Iteration 1550, loss = 0.76799128
Iteration 1551, loss = 0.77405642
Iteration 1552, loss = 0.80406308
Iteration 1553, loss = 0.74002964
Iteration 1554, loss = 0.79230976
Iteration 1555, loss = 0.75894535
Iteration 1556, loss = 0.75369241
Iteration 1557, loss = 0.77643537
Iteration 1558, loss = 0.73646314
Iteration 1559, loss = 0.76657357
Iteration 1560, loss = 0.75117980
Iteration 1561, loss = 0.74207494
Iteration 1562, loss = 0.75823687
Iteration 1563, loss = 0.72649004
Iteration 1564, loss = 0.80127665
Iteration 1565, loss = 1.28643369
Iteration 1566, loss = 1.36556841
Iteration 1567, loss = 1.54110290
Iteration 1568, loss = 0.91235359
Iteration 1569, loss = 1.12776491
Iteration 1570, loss = 1.45186580
Iteration 1571, loss = 1.01109219
Iteration 1572, loss = 0.95126102
Iteration 1573, loss = 1.27738336
Iteration 1574, loss = 0.98095780
Iteration 1575, loss = 0.85609378
Iteration 1576, loss = 1.11883512
Iteration 1577, loss = 0.91622390
Iteration 1578, loss = 0.80830870
Iteration 1579, loss = 1.01209503
Iteration 1580, loss = 0.85893495
Iteration 1581, loss = 0.79172870
Iteration 1582, loss = 0.94043506
Iteration 1583, loss = 0.81927273
Iteration 1584, loss = 0.78642222
Iteration 1585, loss = 0.86133152
Iteration 1586, loss = 0.77169535
Iteration 1587, loss = 0.79435552
Iteration 1588, loss = 0.81830203
Iteration 1589, loss = 0.78014692
Iteration 1590, loss = 0.79037261
Iteration 1591, loss = 0.79810472
Iteration 1592, loss = 0.76539766
Iteration 1593, loss = 0.77447980
Iteration 1594, loss = 0.78046180
Iteration 1595, loss = 0.76021665
Iteration 1596, loss = 0.77161847
Iteration 1597, loss = 0.77590727
Iteration 1598, loss = 0.76166742
Iteration 1599, loss = 0.77060297
Iteration 1600, loss = 0.77142166
Iteration 1601, loss = 0.76085848
Iteration 1602, loss = 0.76723521
Iteration 1603, loss = 0.76581175
Iteration 1604, loss = 0.75841291
Iteration 1605, loss = 0.76383682
Iteration 1606, loss = 0.76223116
Iteration 1607, loss = 0.75761076
Iteration 1608, loss = 0.76827047
Iteration 1609, loss = 0.75910124
Iteration 1610, loss = 0.76263213
Iteration 1611, loss = 0.76502907
Iteration 1612, loss = 0.75786567
Iteration 1613, loss = 0.76273652
Iteration 1614, loss = 0.75953733
Iteration 1615, loss = 0.75686615
Iteration 1616, loss = 0.76038597
Iteration 1617, loss = 0.75600595
Iteration 1618, loss = 0.75720059
Iteration 1619, loss = 0.75794288
Iteration 1620, loss = 0.75474701
Iteration 1621, loss = 0.75678644
Iteration 1622, loss = 0.75509194
Iteration 1623, loss = 0.75386420
Iteration 1624, loss = 0.75508441
Iteration 1625, loss = 0.75291840
Iteration 1626, loss = 0.75334317
Iteration 1627, loss = 0.75334505
Iteration 1628, loss = 0.75186353
Iteration 1629, loss = 0.75262170
Iteration 1630, loss = 0.75166534
Iteration 1631, loss = 0.75114271
Iteration 1632, loss = 0.75150039
Iteration 1633, loss = 0.75039471
Iteration 1634, loss = 0.75046523
Iteration 1635, loss = 0.75016470
Iteration 1636, loss = 0.74937862
Iteration 1637, loss = 0.74953208
Iteration 1638, loss = 0.74887355
Iteration 1639, loss = 0.74853083
Iteration 1640, loss = 0.74846158
Iteration 1641, loss = 0.74781167
Iteration 1642, loss = 0.74772049
Iteration 1643, loss = 0.74738489
Iteration 1644, loss = 0.74693804
Iteration 1645, loss = 0.74685369
Iteration 1646, loss = 0.74638427
Iteration 1647, loss = 0.74611836
Iteration 1648, loss = 0.74590294
Iteration 1649, loss = 0.74547234
Iteration 1650, loss = 0.74528379
Iteration 1651, loss = 0.74550177
Iteration 1652, loss = 0.74681193
Iteration 1653, loss = 0.74884875
Iteration 1654, loss = 0.74959039
Iteration 1655, loss = 0.75023709
Iteration 1656, loss = 0.74809595
Iteration 1657, loss = 0.74633452
Iteration 1658, loss = 0.74525471
Iteration 1659, loss = 0.74413584
Iteration 1660, loss = 0.74465277
Iteration 1661, loss = 0.74472250
Iteration 1662, loss = 0.74460158
Iteration 1663, loss = 0.74467093
Iteration 1664, loss = 0.74386461
Iteration 1665, loss = 0.74345837
Iteration 1666, loss = 0.74294957
Iteration 1667, loss = 0.74259238
Iteration 1668, loss = 0.74244797
Iteration 1669, loss = 0.74213676
Iteration 1670, loss = 0.74162449
Iteration 1671, loss = 0.74161191
Iteration 1672, loss = 0.74111558
Iteration 1673, loss = 0.74092155
Iteration 1674, loss = 0.74052434
Iteration 1675, loss = 0.74001063
Iteration 1676, loss = 0.73982812
Iteration 1677, loss = 0.73942007
Iteration 1678, loss = 0.73878198
Iteration 1679, loss = 0.73832319
Iteration 1680, loss = 0.73729468
Iteration 1681, loss = 0.73574149
Iteration 1682, loss = 0.72198942
Iteration 1683, loss = 0.75304992
Iteration 1684, loss = 0.74732925
Iteration 1685, loss = 0.75910112
Iteration 1686, loss = 0.75097249
Iteration 1687, loss = 0.74581312
Iteration 1688, loss = 0.74858895
Iteration 1689, loss = 0.73037085
Iteration 1690, loss = 0.76185621
Iteration 1691, loss = 0.74133384
Iteration 1692, loss = 0.81062110
Iteration 1693, loss = 0.76576426
Iteration 1694, loss = 0.81697354
Iteration 1695, loss = 0.79965813
Iteration 1696, loss = 0.77364449
Iteration 1697, loss = 0.79853491
Iteration 1698, loss = 0.77770330
Iteration 1699, loss = 0.75618625
Iteration 1700, loss = 0.77583100
Iteration 1701, loss = 0.76401960
Iteration 1702, loss = 0.75308201
Iteration 1703, loss = 0.77114303
Iteration 1704, loss = 0.76369929
Iteration 1705, loss = 0.75649401
Iteration 1706, loss = 0.76882290
Iteration 1707, loss = 0.76193588
Iteration 1708, loss = 0.75594563
Iteration 1709, loss = 0.76375509
Iteration 1710, loss = 0.75706688
Iteration 1711, loss = 0.75268624
Iteration 1712, loss = 0.75865067
Iteration 1713, loss = 0.75390111
Iteration 1714, loss = 0.75112838
Iteration 1715, loss = 0.75548325
Iteration 1716, loss = 0.75073740
Iteration 1717, loss = 0.82526162
Iteration 1718, loss = 0.76621044
Iteration 1719, loss = 0.78402438
Iteration 1720, loss = 0.82131101
Iteration 1721, loss = 0.77529645
Iteration 1722, loss = 0.76755058
Iteration 1723, loss = 0.79533870
Iteration 1724, loss = 0.76686983
Iteration 1725, loss = 0.75393789
Iteration 1726, loss = 0.77951423
Iteration 1727, loss = 0.76591716
Iteration 1728, loss = 0.75056541
Iteration 1729, loss = 0.76778911
Iteration 1730, loss = 0.76206189
Iteration 1731, loss = 0.74504185
Iteration 1732, loss = 0.75039487
Iteration 1733, loss = 0.74772139
Iteration 1734, loss = 0.71686171
Iteration 1735, loss = 0.94518771
Iteration 1736, loss = 0.78231290
Iteration 1737, loss = 0.92093212
Iteration 1738, loss = 0.97471282
Iteration 1739, loss = 0.81650511
Iteration 1740, loss = 0.81251349
Iteration 1741, loss = 0.91164325
Iteration 1742, loss = 0.83821633
Iteration 1743, loss = 0.76472356
Iteration 1744, loss = 0.84218337
Iteration 1745, loss = 0.84508195
Iteration 1746, loss = 0.76858524
Iteration 1747, loss = 0.79710120
Iteration 1748, loss = 0.83584653
Iteration 1749, loss = 0.78453782
Iteration 1750, loss = 0.77099469
Iteration 1751, loss = 0.81000306
Iteration 1752, loss = 0.78954001
Iteration 1753, loss = 0.75980614
Iteration 1754, loss = 0.78522204
Iteration 1755, loss = 0.78751852
Iteration 1756, loss = 0.75918589
Iteration 1757, loss = 0.76773245
Iteration 1758, loss = 0.78093697
Iteration 1759, loss = 0.76244860
Iteration 1760, loss = 0.75890419
Iteration 1761, loss = 0.77295948
Iteration 1762, loss = 0.76475473
Iteration 1763, loss = 0.75521497
Iteration 1764, loss = 0.76450119
Iteration 1765, loss = 0.76365204
Iteration 1766, loss = 0.75353483
Iteration 1767, loss = 0.75725512
Iteration 1768, loss = 0.76054985
Iteration 1769, loss = 0.75324674
Iteration 1770, loss = 0.75291025
Iteration 1771, loss = 0.75690095
Iteration 1772, loss = 0.75214372
Iteration 1773, loss = 0.75910416
Iteration 1774, loss = 0.76904128
Iteration 1775, loss = 0.75379763
Iteration 1776, loss = 0.76050063
Iteration 1777, loss = 0.75710310
Iteration 1778, loss = 0.75289207
Iteration 1779, loss = 0.75616113
Iteration 1780, loss = 0.74979171
Iteration 1781, loss = 0.75503372
Iteration 1782, loss = 0.74865802
Iteration 1783, loss = 0.75330399
Iteration 1784, loss = 0.74755211
Iteration 1785, loss = 0.75152413
Iteration 1786, loss = 0.74678824
Iteration 1787, loss = 0.75000646
Iteration 1788, loss = 0.74617964
Iteration 1789, loss = 0.74879512
Iteration 1790, loss = 0.74559692
Iteration 1791, loss = 0.74752385
Iteration 1792, loss = 0.74477821
Iteration 1793, loss = 0.74632082
Iteration 1794, loss = 0.74414473
Iteration 1795, loss = 0.74543034
Iteration 1796, loss = 0.74363190
Iteration 1797, loss = 0.74458922
Iteration 1798, loss = 0.74303093
Iteration 1799, loss = 0.74372298
Iteration 1800, loss = 0.74243454
Iteration 1801, loss = 0.74297340
Iteration 1802, loss = 0.74190047
Iteration 1803, loss = 0.74224676
Iteration 1804, loss = 0.74130944
Iteration 1805, loss = 0.74151768
Iteration 1806, loss = 0.74073475
Iteration 1807, loss = 0.74084889
Iteration 1808, loss = 0.74018272
Iteration 1809, loss = 0.74020328
Iteration 1810, loss = 0.73952308
Iteration 1811, loss = 0.73922982
Iteration 1812, loss = 0.73874276
Iteration 1813, loss = 0.73904818
Iteration 1814, loss = 0.73115282
Iteration 1815, loss = 0.74250466
Iteration 1816, loss = 0.74921582
Iteration 1817, loss = 0.74818621
Iteration 1818, loss = 0.75759970
Iteration 1819, loss = 0.75208129
Iteration 1820, loss = 0.75451474
Iteration 1821, loss = 0.74846946
Iteration 1822, loss = 0.74732467
Iteration 1823, loss = 0.74141033
Iteration 1824, loss = 0.73570911
Iteration 1825, loss = 0.72281565
Iteration 1826, loss = 0.63029759
Iteration 1827, loss = 1.17310343
Iteration 1828, loss = 1.03134258
Iteration 1829, loss = 1.12390099
Iteration 1830, loss = 0.83221360
Iteration 1831, loss = 1.09808302
Iteration 1832, loss = 0.79885190
Iteration 1833, loss = 1.00006315
Iteration 1834, loss = 0.88073944
Iteration 1835, loss = 0.84160658
Iteration 1836, loss = 0.93332342
Iteration 1837, loss = 0.76436410
Iteration 1838, loss = 0.91561690
Iteration 1839, loss = 0.80720744
Iteration 1840, loss = 0.84008921
Iteration 1841, loss = 0.86102531
Iteration 1842, loss = 0.77663715
Iteration 1843, loss = 0.86152169
Iteration 1844, loss = 0.77930583
Iteration 1845, loss = 0.81827903
Iteration 1846, loss = 0.81089691
Iteration 1847, loss = 0.77561176
Iteration 1848, loss = 0.82174518
Iteration 1849, loss = 0.76931681
Iteration 1850, loss = 0.80260636
Iteration 1851, loss = 0.78670769
Iteration 1852, loss = 0.77577999
Iteration 1853, loss = 0.79704544
Iteration 1854, loss = 0.76597587
Iteration 1855, loss = 0.78948135
Iteration 1856, loss = 0.77347490
Iteration 1857, loss = 0.77372032
Iteration 1858, loss = 0.78128791
Iteration 1859, loss = 0.76457314
Iteration 1860, loss = 0.77920926
Iteration 1861, loss = 0.76622397
Iteration 1862, loss = 0.77028717
Iteration 1863, loss = 0.77097833
Iteration 1864, loss = 0.76322787
Iteration 1865, loss = 0.77139303
Iteration 1866, loss = 0.76238475
Iteration 1867, loss = 0.76666416
Iteration 1868, loss = 0.76447356
Iteration 1869, loss = 0.76174538
Iteration 1870, loss = 0.76547757
Iteration 1871, loss = 0.75988717
Iteration 1872, loss = 0.76306740
Iteration 1873, loss = 0.75997775
Iteration 1874, loss = 0.75967888
Iteration 1875, loss = 0.76066967
Iteration 1876, loss = 0.75725129
Iteration 1877, loss = 0.75971728
Iteration 1878, loss = 0.75727113
Iteration 1879, loss = 0.75712329
Iteration 1880, loss = 0.75652890
Iteration 1881, loss = 0.75481197
Iteration 1882, loss = 0.75545558
Iteration 1883, loss = 0.75283355
Iteration 1884, loss = 0.75308548
Iteration 1885, loss = 0.75086181
Iteration 1886, loss = 0.74385388
Iteration 1887, loss = 0.77348649
Iteration 1888, loss = 0.88923141
Iteration 1889, loss = 0.79984966
Iteration 1890, loss = 0.87395761
Iteration 1891, loss = 0.85198088
Iteration 1892, loss = 0.82783688
Iteration 1893, loss = 0.85894350
Iteration 1894, loss = 0.78179670
Iteration 1895, loss = 0.82567145
Iteration 1896, loss = 0.77732036
Iteration 1897, loss = 0.78113504
Iteration 1898, loss = 0.76531837
Iteration 1899, loss = 0.77840098
Iteration 1900, loss = 0.76867161
Iteration 1901, loss = 0.77122006
Iteration 1902, loss = 0.77463600
Iteration 1903, loss = 0.76640243
Iteration 1904, loss = 0.77261054
Iteration 1905, loss = 0.76554733
Iteration 1906, loss = 0.76565083
Iteration 1907, loss = 0.76429764
Iteration 1908, loss = 0.75732775
Iteration 1909, loss = 0.75857954
Iteration 1910, loss = 0.74783084
Iteration 1911, loss = 0.72666861
Iteration 1912, loss = 0.92389457
Iteration 1913, loss = 0.80756333
Iteration 1914, loss = 0.95946720
Iteration 1915, loss = 0.80216141
Iteration 1916, loss = 0.87911628
Iteration 1917, loss = 0.86688437
Iteration 1918, loss = 0.78353507
Iteration 1919, loss = 0.87422057
Iteration 1920, loss = 0.77890447
Iteration 1921, loss = 0.82390923
Iteration 1922, loss = 0.82107279
Iteration 1923, loss = 0.77536043
Iteration 1924, loss = 0.83239078
Iteration 1925, loss = 0.77526425
Iteration 1926, loss = 0.80335917
Iteration 1927, loss = 0.79799764
Iteration 1928, loss = 0.77189865
Iteration 1929, loss = 0.80369366
Iteration 1930, loss = 0.76807047
Iteration 1931, loss = 0.78672395
Iteration 1932, loss = 0.78072174
Iteration 1933, loss = 0.76773940
Iteration 1934, loss = 0.78560439
Iteration 1935, loss = 0.76404788
Iteration 1936, loss = 0.77668262
Iteration 1937, loss = 0.77066274
Iteration 1938, loss = 0.76487878
Iteration 1939, loss = 0.77417768
Iteration 1940, loss = 0.76118067
Iteration 1941, loss = 0.76947969
Iteration 1942, loss = 0.76419534
Iteration 1943, loss = 0.76200121
Iteration 1944, loss = 0.76627996
Iteration 1945, loss = 0.75854570
Iteration 1946, loss = 0.76369187
Iteration 1947, loss = 0.75935321
Iteration 1948, loss = 0.75890601
Iteration 1949, loss = 0.76050306
Iteration 1950, loss = 0.75612059
Iteration 1951, loss = 0.75931256
Iteration 1952, loss = 0.75620778
Iteration 1953, loss = 0.75659711
Iteration 1954, loss = 0.75689744
Iteration 1955, loss = 0.75449470
Iteration 1956, loss = 0.75618867
Iteration 1957, loss = 0.75385209
Iteration 1958, loss = 0.75426738
Iteration 1959, loss = 0.75387687
Iteration 1960, loss = 0.75259524
Iteration 1961, loss = 0.75340235
Iteration 1962, loss = 0.75181667
Iteration 1963, loss = 0.75218519
Iteration 1964, loss = 0.75157787
Iteration 1965, loss = 0.75088463
Iteration 1966, loss = 0.75109889
Iteration 1967, loss = 0.74999739
Iteration 1968, loss = 0.75017198
Iteration 1969, loss = 0.74946336
Iteration 1970, loss = 0.74649423
Iteration 1971, loss = 0.75603303
Iteration 1972, loss = 0.75128921
Iteration 1973, loss = 0.75535126
Iteration 1974, loss = 0.75677504
Iteration 1975, loss = 0.74806056
Iteration 1976, loss = 0.74453587
Iteration 1977, loss = 0.74794430
Iteration 1978, loss = 0.74090491
Iteration 1979, loss = 0.74936070
Iteration 1980, loss = 0.74057607
Iteration 1981, loss = 0.75369398
Iteration 1982, loss = 0.75898359
Iteration 1983, loss = 0.75504644
Iteration 1984, loss = 0.75525837
Iteration 1985, loss = 0.75183067
Iteration 1986, loss = 0.74815793
Iteration 1987, loss = 0.74607741
Iteration 1988, loss = 0.74285487
Iteration 1989, loss = 0.74348912
Iteration 1990, loss = 0.74107316
Iteration 1991, loss = 0.73890573
Iteration 1992, loss = 0.72094081
Iteration 1993, loss = 0.80535587
Iteration 1994, loss = 0.79152063
Iteration 1995, loss = 0.83818055
Iteration 1996, loss = 0.75939069
Iteration 1997, loss = 0.82355849
Iteration 1998, loss = 0.76764732
Iteration 1999, loss = 0.78452285
Iteration 2000, loss = 0.78744420
Iteration 2001, loss = 0.75605214
Iteration 2002, loss = 0.79282566
Iteration 2003, loss = 0.75301381
Iteration 2004, loss = 0.77989800
Iteration 2005, loss = 0.76583773
Iteration 2006, loss = 0.76248686
Iteration 2007, loss = 0.77455376
Iteration 2008, loss = 0.75255680
Iteration 2009, loss = 0.77114905
Iteration 2010, loss = 0.75385596
Iteration 2011, loss = 0.76207049
Iteration 2012, loss = 0.75913650
Iteration 2013, loss = 0.75159426
Iteration 2014, loss = 0.76039040
Iteration 2015, loss = 0.74867137
Iteration 2016, loss = 0.75707489
Iteration 2017, loss = 0.74742946
Iteration 2018, loss = 0.74687831
Iteration 2019, loss = 0.74190709
Iteration 2020, loss = 0.70973983
Iteration 2021, loss = 1.01495624
Iteration 2022, loss = 0.81705075
Iteration 2023, loss = 1.07153174
Iteration 2024, loss = 0.81305110
Iteration 2025, loss = 0.96218352
Iteration 2026, loss = 0.94384730
Iteration 2027, loss = 0.79829187
Iteration 2028, loss = 0.95104007
Iteration 2029, loss = 0.77877797
Iteration 2030, loss = 0.86743304
Iteration 2031, loss = 0.84354546
Iteration 2032, loss = 0.77677844
Iteration 2033, loss = 0.86763263
Iteration 2034, loss = 0.76442835
Iteration 2035, loss = 0.83569729
Iteration 2036, loss = 0.80130315
Iteration 2037, loss = 0.78154165
Iteration 2038, loss = 0.82113401
Iteration 2039, loss = 0.75747348
Iteration 2040, loss = 0.80646208
Iteration 2041, loss = 0.76960029
Iteration 2042, loss = 0.77545839
Iteration 2043, loss = 0.78530651
Iteration 2044, loss = 0.75498817
Iteration 2045, loss = 0.78472067
Iteration 2046, loss = 0.75520997
Iteration 2047, loss = 0.76918196
Iteration 2048, loss = 0.76419336
Iteration 2049, loss = 0.75373352
Iteration 2050, loss = 0.76748111
Iteration 2051, loss = 0.74848410
Iteration 2052, loss = 0.76110363
Iteration 2053, loss = 0.75129217
Iteration 2054, loss = 0.75064951
Iteration 2055, loss = 0.75410941
Iteration 2056, loss = 0.74422576
Iteration 2057, loss = 0.75182868
Iteration 2058, loss = 0.74242133
Iteration 2059, loss = 0.74501029
Iteration 2060, loss = 0.74332101
Iteration 2061, loss = 0.73931802
Iteration 2062, loss = 0.74208171
Iteration 2063, loss = 0.73438701
Iteration 2064, loss = 0.73486523
Iteration 2065, loss = 0.72923539
Iteration 2066, loss = 0.72707724
Iteration 2067, loss = 0.72259857
Iteration 2068, loss = 0.67800135
Iteration 2069, loss = 0.87674779
Iteration 2070, loss = 0.79833610
Iteration 2071, loss = 0.94179392
Iteration 2072, loss = 0.78944686
Iteration 2073, loss = 0.86650575
Iteration 2074, loss = 0.86463161
Iteration 2075, loss = 0.77280437
Iteration 2076, loss = 0.86494306
Iteration 2077, loss = 0.77858779
Iteration 2078, loss = 0.79981396
Iteration 2079, loss = 0.81632004
Iteration 2080, loss = 0.75297771
Iteration 2081, loss = 0.81017265
Iteration 2082, loss = 0.76491967
Iteration 2083, loss = 0.77208411
Iteration 2084, loss = 0.78856086
Iteration 2085, loss = 0.74957774
Iteration 2086, loss = 0.78402402
Iteration 2087, loss = 0.75889495
Iteration 2088, loss = 0.76105805
Iteration 2089, loss = 0.77209916
Iteration 2090, loss = 0.74815317
Iteration 2091, loss = 0.76821911
Iteration 2092, loss = 0.75325577
Iteration 2093, loss = 0.75405227
Iteration 2094, loss = 0.76050250
Iteration 2095, loss = 0.74612311
Iteration 2096, loss = 0.75789006
Iteration 2097, loss = 0.74860306
Iteration 2098, loss = 0.74918599
Iteration 2099, loss = 0.75251805
Iteration 2100, loss = 0.74395945
Iteration 2101, loss = 0.75081637
Iteration 2102, loss = 0.74486828
Iteration 2103, loss = 0.74547265
Iteration 2104, loss = 0.74701031
Iteration 2105, loss = 0.74207032
Iteration 2106, loss = 0.74614395
Iteration 2107, loss = 0.74238350
Iteration 2108, loss = 0.74307400
Iteration 2109, loss = 0.74368028
Iteration 2110, loss = 0.74090394
Iteration 2111, loss = 0.74326037
Iteration 2112, loss = 0.74078517
Iteration 2113, loss = 0.74131112
Iteration 2114, loss = 0.74129075
Iteration 2115, loss = 0.73963741
Iteration 2116, loss = 0.74085021
Iteration 2117, loss = 0.73914513
Iteration 2118, loss = 0.73948811
Iteration 2119, loss = 0.73919503
Iteration 2120, loss = 0.73824196
Iteration 2121, loss = 0.73884121
Iteration 2122, loss = 0.73771377
Iteration 2123, loss = 0.73794854
Iteration 2124, loss = 0.73758828
Iteration 2125, loss = 0.73704289
Iteration 2126, loss = 0.73727945
Iteration 2127, loss = 0.73651565
Iteration 2128, loss = 0.73662891
Iteration 2129, loss = 0.73625275
Iteration 2130, loss = 0.73590933
Iteration 2131, loss = 0.73592262
Iteration 2132, loss = 0.73538325
Iteration 2133, loss = 0.73539193
Iteration 2134, loss = 0.73503448
Iteration 2135, loss = 0.73479149
Iteration 2136, loss = 0.73468219
Iteration 2137, loss = 0.73428850
Iteration 2138, loss = 0.73422368
Iteration 2139, loss = 0.73390397
Iteration 2140, loss = 0.73371100
Iteration 2141, loss = 0.73354262
Iteration 2142, loss = 0.73324310
Iteration 2143, loss = 0.73312963
Iteration 2144, loss = 0.73284952
Iteration 2145, loss = 0.73267774
Iteration 2146, loss = 0.73248432
Iteration 2147, loss = 0.73224235
Iteration 2148, loss = 0.73209704
Iteration 2149, loss = 0.73184619
Iteration 2150, loss = 0.73162412
Iteration 2151, loss = 0.73108717
Iteration 2152, loss = 0.72838624
Iteration 2153, loss = 0.73233220
Iteration 2154, loss = 0.73304672
Iteration 2155, loss = 0.73334498
Iteration 2156, loss = 0.73257553
Iteration 2157, loss = 0.73202846
Iteration 2158, loss = 0.73130142
Iteration 2159, loss = 0.73081456
Iteration 2160, loss = 0.73094456
Iteration 2161, loss = 0.73096935
Iteration 2162, loss = 0.73096989
Iteration 2163, loss = 0.73079870
Iteration 2164, loss = 0.73047236
Iteration 2165, loss = 0.73030134
Iteration 2166, loss = 0.73006064
Iteration 2167, loss = 0.72994155
Iteration 2168, loss = 0.72977506
Iteration 2169, loss = 0.72956677
Iteration 2170, loss = 0.72940087
Iteration 2171, loss = 0.72916476
Iteration 2172, loss = 0.72901047
Iteration 2173, loss = 0.72883589
Iteration 2174, loss = 0.72869069
Iteration 2175, loss = 0.72856736
Iteration 2176, loss = 0.72839157
Iteration 2177, loss = 0.72822453
Iteration 2178, loss = 0.72799785
Iteration 2179, loss = 0.72778729
Iteration 2180, loss = 0.72759941
Iteration 2181, loss = 0.72743272
Iteration 2182, loss = 0.72730767
Iteration 2183, loss = 0.72715662
Iteration 2184, loss = 0.72699881
Iteration 2185, loss = 0.72680877
Iteration 2186, loss = 0.72660861
Iteration 2187, loss = 0.72642584
Iteration 2188, loss = 0.72624946
Iteration 2189, loss = 0.72609824
Iteration 2190, loss = 0.72594092
Iteration 2191, loss = 0.72578024
Iteration 2192, loss = 0.72561233
Iteration 2193, loss = 0.72543561
Iteration 2194, loss = 0.72526696
Iteration 2195, loss = 0.72509684
Iteration 2196, loss = 0.72493503
Iteration 2197, loss = 0.72477334
Iteration 2198, loss = 0.72461026
Iteration 2199, loss = 0.72444857
Iteration 2200, loss = 0.72428254
Iteration 2201, loss = 0.72411984
Iteration 2202, loss = 0.72395572
Iteration 2203, loss = 0.72379307
Iteration 2204, loss = 0.72363114
Iteration 2205, loss = 0.72346739
Iteration 2206, loss = 0.72330488
Iteration 2207, loss = 0.72314001
Iteration 2208, loss = 0.72297568
Iteration 2209, loss = 0.72281020
Iteration 2210, loss = 0.72264335
Iteration 2211, loss = 0.72247570
Iteration 2212, loss = 0.72230501
Iteration 2213, loss = 0.72213270
Iteration 2214, loss = 0.72195387
Iteration 2215, loss = 0.72149908
Iteration 2216, loss = 0.72251735
Iteration 2217, loss = 0.72236595
Iteration 2218, loss = 0.72354982
Iteration 2219, loss = 0.72277164
Iteration 2220, loss = 0.72290143
Iteration 2221, loss = 0.72158852
Iteration 2222, loss = 0.72170294
Iteration 2223, loss = 0.72126499
Iteration 2224, loss = 0.72126605
Iteration 2225, loss = 0.72113222
Iteration 2226, loss = 0.72072872
Iteration 2227, loss = 0.72075077
Iteration 2228, loss = 0.72023982
Iteration 2229, loss = 0.72033037
Iteration 2230, loss = 0.71984556
Iteration 2231, loss = 0.71978390
Iteration 2232, loss = 0.71941046
Iteration 2233, loss = 0.71925665
Iteration 2234, loss = 0.71908633
Iteration 2235, loss = 0.71885145
Iteration 2236, loss = 0.71874994
Iteration 2237, loss = 0.71842053
Iteration 2238, loss = 0.71830004
Iteration 2239, loss = 0.71796545
Iteration 2240, loss = 0.71782650
Iteration 2241, loss = 0.71756534
Iteration 2242, loss = 0.71740433
Iteration 2243, loss = 0.71721369
Iteration 2244, loss = 0.71701467
Iteration 2245, loss = 0.71685877
Iteration 2246, loss = 0.71663129
Iteration 2247, loss = 0.71648119
Iteration 2248, loss = 0.71624547
Iteration 2249, loss = 0.71608006
Iteration 2250, loss = 0.71584466
Iteration 2251, loss = 0.71562722
Iteration 2252, loss = 0.71534264
Iteration 2253, loss = 0.71505003
Iteration 2254, loss = 0.71481765
Iteration 2255, loss = 0.71456396
Iteration 2256, loss = 0.71431062
Iteration 2257, loss = 0.71403314
Iteration 2258, loss = 0.71378902
Iteration 2259, loss = 0.71351280
Iteration 2260, loss = 0.71320745
Iteration 2261, loss = 0.71280935
Iteration 2262, loss = 0.71243943
Iteration 2263, loss = 0.71208883
Iteration 2264, loss = 0.71155344
Iteration 2265, loss = 0.71079448
Iteration 2266, loss = 0.71014807
Iteration 2267, loss = 0.70953725
Iteration 2268, loss = 0.70879036
Iteration 2269, loss = 0.70768106
Iteration 2270, loss = 0.70666823
Iteration 2271, loss = 0.70598235
Iteration 2272, loss = 0.70530079
Iteration 2273, loss = 0.70434103
Iteration 2274, loss = 0.70375423
Iteration 2275, loss = 0.70057441
Iteration 2276, loss = 0.69807536
Iteration 2277, loss = 0.69674177
Iteration 2278, loss = 0.67173050
Iteration 2279, loss = 0.80905508
Iteration 2280, loss = 0.76304017
Iteration 2281, loss = 0.84470347
Iteration 2282, loss = 0.73953231
Iteration 2283, loss = 0.81468030
Iteration 2284, loss = 0.74612024
Iteration 2285, loss = 0.76176645
Iteration 2286, loss = 0.76347859
Iteration 2287, loss = 0.72555207
Iteration 2288, loss = 0.77036939
Iteration 2289, loss = 0.72079912
Iteration 2290, loss = 0.76045660
Iteration 2291, loss = 0.73267133
Iteration 2292, loss = 0.73961715
Iteration 2293, loss = 0.74265146
Iteration 2294, loss = 0.72197703
Iteration 2295, loss = 0.74251247
Iteration 2296, loss = 0.71651437
Iteration 2297, loss = 0.73390289
Iteration 2298, loss = 0.71942659
Iteration 2299, loss = 0.72038799
Iteration 2300, loss = 0.68047871
Iteration 2301, loss = 0.79967223
Iteration 2302, loss = 0.80386553
Iteration 2303, loss = 0.89417710
Iteration 2304, loss = 0.74947252
Iteration 2305, loss = 0.86443977
Iteration 2306, loss = 0.79570458
Iteration 2307, loss = 0.77089518
Iteration 2308, loss = 0.82393443
Iteration 2309, loss = 0.72938516
Iteration 2310, loss = 0.79502058
Iteration 2311, loss = 0.75624092
Iteration 2312, loss = 0.74547984
Iteration 2313, loss = 0.78197397
Iteration 2314, loss = 0.72973796
Iteration 2315, loss = 0.77212884
Iteration 2316, loss = 0.74773799
Iteration 2317, loss = 0.74351002
Iteration 2318, loss = 0.76183739
Iteration 2319, loss = 0.72881897
Iteration 2320, loss = 0.75262950
Iteration 2321, loss = 0.73193720
Iteration 2322, loss = 0.72539829
Iteration 2323, loss = 0.65468523
Iteration 2324, loss = 1.02572037
Iteration 2325, loss = 0.79433475
Iteration 2326, loss = 1.01427139
Iteration 2327, loss = 0.76751142
Iteration 2328, loss = 0.97832258
Iteration 2329, loss = 0.81361301
Iteration 2330, loss = 0.89797432
Iteration 2331, loss = 0.86451250
Iteration 2332, loss = 0.80333081
Iteration 2333, loss = 0.87480694
Iteration 2334, loss = 0.75275619
Iteration 2335, loss = 0.85250664
Iteration 2336, loss = 0.75644102
Iteration 2337, loss = 0.81163403
Iteration 2338, loss = 0.78127220
Iteration 2339, loss = 0.77026506
Iteration 2340, loss = 0.79782553
Iteration 2341, loss = 0.74747246
Iteration 2342, loss = 0.79694486
Iteration 2343, loss = 0.74779681
Iteration 2344, loss = 0.78192947
Iteration 2345, loss = 0.75843285
Iteration 2346, loss = 0.76246223
Iteration 2347, loss = 0.76765734
Iteration 2348, loss = 0.74872504
Iteration 2349, loss = 0.76924711
Iteration 2350, loss = 0.74466857
Iteration 2351, loss = 0.76345066
Iteration 2352, loss = 0.74688952
Iteration 2353, loss = 0.75384478
Iteration 2354, loss = 0.75100860
Iteration 2355, loss = 0.74623437
Iteration 2356, loss = 0.75315548
Iteration 2357, loss = 0.74251283
Iteration 2358, loss = 0.75186455
Iteration 2359, loss = 0.74221843
Iteration 2360, loss = 0.74796082
Iteration 2361, loss = 0.74367986
Iteration 2362, loss = 0.74386551
Iteration 2363, loss = 0.74497712
Iteration 2364, loss = 0.74121858
Iteration 2365, loss = 0.74499970
Iteration 2366, loss = 0.74024422
Iteration 2367, loss = 0.74369359
Iteration 2368, loss = 0.74043683
Iteration 2369, loss = 0.74180286
Iteration 2370, loss = 0.74092604
Iteration 2371, loss = 0.74007776
Iteration 2372, loss = 0.74101260
Iteration 2373, loss = 0.73897056
Iteration 2374, loss = 0.74050468
Iteration 2375, loss = 0.73850705
Iteration 2376, loss = 0.73955421
Iteration 2377, loss = 0.73837669
Iteration 2378, loss = 0.73848042
Iteration 2379, loss = 0.73828285
Iteration 2380, loss = 0.73762947
Iteration 2381, loss = 0.73807457
Iteration 2382, loss = 0.73712342
Iteration 2383, loss = 0.73766972
Iteration 2384, loss = 0.73683648
Iteration 2385, loss = 0.73635147
Iteration 2386, loss = 0.73576062
Iteration 2387, loss = 0.73605955
Iteration 2388, loss = 0.73608785
Iteration 2389, loss = 0.73577006
Iteration 2390, loss = 0.73521146
Iteration 2391, loss = 0.73451539
Iteration 2392, loss = 0.73411930
Iteration 2393, loss = 0.73389826
Iteration 2394, loss = 0.73360536
Iteration 2395, loss = 0.73302587
Iteration 2396, loss = 0.73269548
Iteration 2397, loss = 0.73240151
Iteration 2398, loss = 0.73190239
Iteration 2399, loss = 0.73114598
Iteration 2400, loss = 0.73036006
Iteration 2401, loss = 0.72900743
Iteration 2402, loss = 0.72739883
Iteration 2403, loss = 0.72526047
Iteration 2404, loss = 0.72443948
Iteration 2405, loss = 0.69181272
Iteration 2406, loss = 0.79296861
Iteration 2407, loss = 0.79082320
Iteration 2408, loss = 0.82880902
Iteration 2409, loss = 0.75692332
Iteration 2410, loss = 0.82162004
Iteration 2411, loss = 0.74783456
Iteration 2412, loss = 0.79206762
Iteration 2413, loss = 0.76125458
Iteration 2414, loss = 0.76372891
Iteration 2415, loss = 0.77723217
Iteration 2416, loss = 0.74864777
Iteration 2417, loss = 0.78145671
Iteration 2418, loss = 0.74737284
Iteration 2419, loss = 0.77303091
Iteration 2420, loss = 0.75391038
Iteration 2421, loss = 0.75981537
Iteration 2422, loss = 0.76067086
Iteration 2423, loss = 0.74966267
Iteration 2424, loss = 0.76251218
Iteration 2425, loss = 0.74586972
Iteration 2426, loss = 0.75909105
Iteration 2427, loss = 0.74740314
Iteration 2428, loss = 0.75334833
Iteration 2429, loss = 0.75077525
Iteration 2430, loss = 0.74832733
Iteration 2431, loss = 0.75267157
Iteration 2432, loss = 0.74562256
Iteration 2433, loss = 0.75186220
Iteration 2434, loss = 0.74514331
Iteration 2435, loss = 0.74902922
Iteration 2436, loss = 0.74569611
Iteration 2437, loss = 0.74576542
Iteration 2438, loss = 0.74615181
Iteration 2439, loss = 0.74349309
Iteration 2440, loss = 0.74590847
Iteration 2441, loss = 0.74255487
Iteration 2442, loss = 0.74479299
Iteration 2443, loss = 0.74238074
Iteration 2444, loss = 0.74312079
Iteration 2445, loss = 0.74230172
Iteration 2446, loss = 0.74149193
Iteration 2447, loss = 0.74192921
Iteration 2448, loss = 0.74030871
Iteration 2449, loss = 0.74115877
Iteration 2450, loss = 0.73960265
Iteration 2451, loss = 0.74011893
Iteration 2452, loss = 0.73916862
Iteration 2453, loss = 0.73902975
Iteration 2454, loss = 0.73874574
Iteration 2455, loss = 0.73806059
Iteration 2456, loss = 0.73816897
Iteration 2457, loss = 0.73727503
Iteration 2458, loss = 0.73741636
Iteration 2459, loss = 0.73663461
Iteration 2460, loss = 0.73656133
Iteration 2461, loss = 0.73604756
Iteration 2462, loss = 0.73569662
Iteration 2463, loss = 0.73542289
Iteration 2464, loss = 0.73487445
Iteration 2465, loss = 0.73469880
Iteration 2466, loss = 0.73407387
Iteration 2467, loss = 0.73382169
Iteration 2468, loss = 0.73317064
Iteration 2469, loss = 0.73264594
Iteration 2470, loss = 0.73175823
Iteration 2471, loss = 0.73037883
Iteration 2472, loss = 0.72734183
Iteration 2473, loss = 0.73022053
Iteration 2474, loss = 0.74793250
Iteration 2475, loss = 0.74242769
Iteration 2476, loss = 0.75143385
Iteration 2477, loss = 0.74611567
Iteration 2478, loss = 0.74191424
Iteration 2479, loss = 0.74168478
Iteration 2480, loss = 0.73386507
Iteration 2481, loss = 0.73961208
Iteration 2482, loss = 0.73336342
Iteration 2483, loss = 0.73924944
Iteration 2484, loss = 0.73566052
Iteration 2485, loss = 0.73810328
Iteration 2486, loss = 0.73674724
Iteration 2487, loss = 0.73516276
Iteration 2488, loss = 0.73552877
Iteration 2489, loss = 0.73213728
Iteration 2490, loss = 0.73402915
Iteration 2491, loss = 0.73130574
Iteration 2492, loss = 0.73328486
Iteration 2493, loss = 0.73184525
Iteration 2494, loss = 0.73265645
Iteration 2495, loss = 0.73209410
Iteration 2496, loss = 0.73131934
Iteration 2497, loss = 0.73153228
Iteration 2498, loss = 0.73014489
Iteration 2499, loss = 0.73072341
Iteration 2500, loss = 0.72946199
Iteration 2501, loss = 0.73007099
Iteration 2502, loss = 0.72928291
Iteration 2503, loss = 0.72938503
Iteration 2504, loss = 0.72900406
Iteration 2505, loss = 0.72866147
Iteration 2506, loss = 0.72865637
Iteration 2507, loss = 0.72804906
Iteration 2508, loss = 0.72815226
Iteration 2509, loss = 0.72751167
Iteration 2510, loss = 0.72759792
Iteration 2511, loss = 0.72713957
Iteration 2512, loss = 0.72708232
Iteration 2513, loss = 0.72678515
Iteration 2514, loss = 0.72654718
Iteration 2515, loss = 0.72639484
Iteration 2516, loss = 0.72605682
Iteration 2517, loss = 0.72597987
Iteration 2518, loss = 0.72563174
Iteration 2519, loss = 0.72555714
Iteration 2520, loss = 0.72523972
Iteration 2521, loss = 0.72509450
Iteration 2522, loss = 0.72483139
Iteration 2523, loss = 0.72462953
Iteration 2524, loss = 0.72443357
Iteration 2525, loss = 0.72419353
Iteration 2526, loss = 0.72403801
Iteration 2527, loss = 0.72379079
Iteration 2528, loss = 0.72364707
Iteration 2529, loss = 0.72340747
Iteration 2530, loss = 0.72324914
Iteration 2531, loss = 0.72303499
Iteration 2532, loss = 0.72286131
Iteration 2533, loss = 0.72267275
Iteration 2534, loss = 0.72248244
Iteration 2535, loss = 0.72231417
Iteration 2536, loss = 0.72211976
Iteration 2537, loss = 0.72196081
Iteration 2538, loss = 0.72176627
Iteration 2539, loss = 0.72160595
Iteration 2540, loss = 0.72141811
Iteration 2541, loss = 0.72125069
Iteration 2542, loss = 0.72106783
Iteration 2543, loss = 0.72088913
Iteration 2544, loss = 0.72070839
Iteration 2545, loss = 0.72052001
Iteration 2546, loss = 0.72034220
Iteration 2547, loss = 0.72015807
Iteration 2548, loss = 0.71999132
Iteration 2549, loss = 0.71981291
Iteration 2550, loss = 0.71964033
Iteration 2551, loss = 0.71945562
Iteration 2552, loss = 0.71927490
Iteration 2553, loss = 0.71909099
Iteration 2554, loss = 0.71890678
Iteration 2555, loss = 0.71872061
Iteration 2556, loss = 0.71852547
Iteration 2557, loss = 0.71831867
Iteration 2558, loss = 0.71808154
Iteration 2559, loss = 0.71782885
Iteration 2560, loss = 0.71757865
Iteration 2561, loss = 0.71734677
Iteration 2562, loss = 0.71710495
Iteration 2563, loss = 0.71685161
Iteration 2564, loss = 0.71661746
Iteration 2565, loss = 0.71636996
Iteration 2566, loss = 0.71610362
Iteration 2567, loss = 0.71585476
Iteration 2568, loss = 0.71563266
Iteration 2569, loss = 0.71541455
Iteration 2570, loss = 0.71518369
Iteration 2571, loss = 0.71490607
Iteration 2572, loss = 0.71437523
Iteration 2573, loss = 0.71389822
Iteration 2574, loss = 0.71388352
Iteration 2575, loss = 0.71379417
Iteration 2576, loss = 0.71347358
Iteration 2577, loss = 0.71302196
Iteration 2578, loss = 0.71284757
Iteration 2579, loss = 0.71269304
Iteration 2580, loss = 0.71236306
Iteration 2581, loss = 0.71231246
Iteration 2582, loss = 0.71185767
Iteration 2583, loss = 0.71197787
Iteration 2584, loss = 0.71184902
Iteration 2585, loss = 0.71206541
Iteration 2586, loss = 0.71163578
Iteration 2587, loss = 0.71041201
Iteration 2588, loss = 0.70966745
Iteration 2589, loss = 0.70905980
Iteration 2590, loss = 0.70879305
Iteration 2591, loss = 0.70780113
Iteration 2592, loss = 0.70683413
Iteration 2593, loss = 0.70693825
Iteration 2594, loss = 0.70204345
Iteration 2595, loss = 0.67770330
Iteration 2596, loss = 0.82018881
Iteration 2597, loss = 0.74835054
Iteration 2598, loss = 0.85958448
Iteration 2599, loss = 0.73494784
Iteration 2600, loss = 0.82393954
Iteration 2601, loss = 0.76574821
Iteration 2602, loss = 0.75656647
Iteration 2603, loss = 0.78444756
Iteration 2604, loss = 0.71551000
Iteration 2605, loss = 0.77658936
Iteration 2606, loss = 0.72103829
Iteration 2607, loss = 0.75371749
Iteration 2608, loss = 0.74286569
Iteration 2609, loss = 0.72600328
Iteration 2610, loss = 0.75198768
Iteration 2611, loss = 0.71515874
Iteration 2612, loss = 0.74380011
Iteration 2613, loss = 0.71995529
Iteration 2614, loss = 0.72696831
Iteration 2615, loss = 0.72761730
Iteration 2616, loss = 0.71476414
Iteration 2617, loss = 0.73067166
Iteration 2618, loss = 0.71264094
Iteration 2619, loss = 0.72567226
Iteration 2620, loss = 0.71632978
Iteration 2621, loss = 0.71728627
Iteration 2622, loss = 0.71971191
Iteration 2623, loss = 0.71160682
Iteration 2624, loss = 0.71961712
Iteration 2625, loss = 0.71081915
Iteration 2626, loss = 0.71635930
Iteration 2627, loss = 0.71279648
Iteration 2628, loss = 0.71249636
Iteration 2629, loss = 0.71451183
Iteration 2630, loss = 0.71005888
Iteration 2631, loss = 0.71387131
Iteration 2632, loss = 0.70964960
Iteration 2633, loss = 0.71197638
Iteration 2634, loss = 0.71055644
Iteration 2635, loss = 0.71003226
Iteration 2636, loss = 0.71117483
Iteration 2637, loss = 0.70894915
Iteration 2638, loss = 0.71083619
Iteration 2639, loss = 0.70882250
Iteration 2640, loss = 0.70977564
Iteration 2641, loss = 0.70909302
Iteration 2642, loss = 0.70866788
Iteration 2643, loss = 0.70918559
Iteration 2644, loss = 0.70801134
Iteration 2645, loss = 0.70885719
Iteration 2646, loss = 0.70786176
Iteration 2647, loss = 0.70827885
Iteration 2648, loss = 0.70794605
Iteration 2649, loss = 0.70769275
Iteration 2650, loss = 0.70788870
Iteration 2651, loss = 0.70724504
Iteration 2652, loss = 0.70754290
Iteration 2653, loss = 0.70688229
Iteration 2654, loss = 0.70668017
Iteration 2655, loss = 0.70596977
Iteration 2656, loss = 0.70577232
Iteration 2657, loss = 0.70560882
Iteration 2658, loss = 0.70457075
Iteration 2659, loss = 0.70324054
Iteration 2660, loss = 0.70207706
Iteration 2661, loss = 0.70123370
Iteration 2662, loss = 0.69940146
Iteration 2663, loss = 0.69810468
Iteration 2664, loss = 0.69446786
Iteration 2665, loss = 0.68929375
Iteration 2666, loss = 0.60386868
Iteration 2667, loss = 0.80018104
Iteration 2668, loss = 0.82209264
Iteration 2669, loss = 0.85617131
Iteration 2670, loss = 0.76632632
Iteration 2671, loss = 0.85632152
Iteration 2672, loss = 0.73822059
Iteration 2673, loss = 0.81620574
Iteration 2674, loss = 0.74579467
Iteration 2675, loss = 0.77321404
Iteration 2676, loss = 0.76876901
Iteration 2677, loss = 0.74338176
Iteration 2678, loss = 0.78119247
Iteration 2679, loss = 0.73220128
Iteration 2680, loss = 0.77703090
Iteration 2681, loss = 0.73715459
Iteration 2682, loss = 0.76260468
Iteration 2683, loss = 0.74832750
Iteration 2684, loss = 0.74658741
Iteration 2685, loss = 0.75544174
Iteration 2686, loss = 0.73603492
Iteration 2687, loss = 0.75499409
Iteration 2688, loss = 0.73325765
Iteration 2689, loss = 0.74905601
Iteration 2690, loss = 0.73590702
Iteration 2691, loss = 0.74125043
Iteration 2692, loss = 0.73974709
Iteration 2693, loss = 0.73535284
Iteration 2694, loss = 0.74193463
Iteration 2695, loss = 0.73289220
Iteration 2696, loss = 0.74117583
Iteration 2697, loss = 0.73301876
Iteration 2698, loss = 0.73828628
Iteration 2699, loss = 0.73437901
Iteration 2700, loss = 0.73492844
Iteration 2701, loss = 0.73531676
Iteration 2702, loss = 0.73223220
Iteration 2703, loss = 0.73507280
Iteration 2704, loss = 0.73091167
Iteration 2705, loss = 0.73394168
Iteration 2706, loss = 0.73082812
Iteration 2707, loss = 0.73240511
Iteration 2708, loss = 0.73115590
Iteration 2709, loss = 0.73088598
Iteration 2710, loss = 0.73128967
Iteration 2711, loss = 0.72982051
Iteration 2712, loss = 0.73099125
Iteration 2713, loss = 0.72922601
Iteration 2714, loss = 0.73023271
Iteration 2715, loss = 0.72891658
Iteration 2716, loss = 0.72926429
Iteration 2717, loss = 0.72870532
Iteration 2718, loss = 0.72835677
Iteration 2719, loss = 0.72841774
Iteration 2720, loss = 0.72765532
Iteration 2721, loss = 0.72800066
Iteration 2722, loss = 0.72719413
Iteration 2723, loss = 0.72747132
Iteration 2724, loss = 0.72685905
Iteration 2725, loss = 0.72686468
Iteration 2726, loss = 0.72653895
Iteration 2727, loss = 0.72628116
Iteration 2728, loss = 0.72619714
Iteration 2729, loss = 0.72578659
Iteration 2730, loss = 0.72580217
Iteration 2731, loss = 0.72536535
Iteration 2732, loss = 0.72535135
Iteration 2733, loss = 0.72499135
Iteration 2734, loss = 0.72488385
Iteration 2735, loss = 0.72463798
Iteration 2736, loss = 0.72443033
Iteration 2737, loss = 0.72427506
Iteration 2738, loss = 0.72400430
Iteration 2739, loss = 0.72389284
Iteration 2740, loss = 0.72361248
Iteration 2741, loss = 0.72349960
Iteration 2742, loss = 0.72324829
Iteration 2743, loss = 0.72310507
Iteration 2744, loss = 0.72289744
Iteration 2745, loss = 0.72271861
Iteration 2746, loss = 0.72254935
Iteration 2747, loss = 0.72234685
Iteration 2748, loss = 0.72219952
Iteration 2749, loss = 0.72199166
Iteration 2750, loss = 0.72184896
Iteration 2751, loss = 0.72165112
Iteration 2752, loss = 0.72150141
Iteration 2753, loss = 0.72132109
Iteration 2754, loss = 0.72116084
Iteration 2755, loss = 0.72099796
Iteration 2756, loss = 0.72083005
Iteration 2757, loss = 0.72067921
Iteration 2758, loss = 0.72050912
Iteration 2759, loss = 0.72036344
Iteration 2760, loss = 0.72019685
Iteration 2761, loss = 0.72005160
Iteration 2762, loss = 0.71989235
Iteration 2763, loss = 0.71974533
Iteration 2764, loss = 0.71959402
Iteration 2765, loss = 0.71944503
Iteration 2766, loss = 0.71930001
Iteration 2767, loss = 0.71915049
Iteration 2768, loss = 0.71900936
Iteration 2769, loss = 0.71886100
Iteration 2770, loss = 0.71872109
Iteration 2771, loss = 0.71857443
Iteration 2772, loss = 0.71843303
Iteration 2773, loss = 0.71828667
Iteration 2774, loss = 0.71814016
Iteration 2775, loss = 0.71798853
Iteration 2776, loss = 0.71782826
Iteration 2777, loss = 0.71765724
Iteration 2778, loss = 0.71746789
Iteration 2779, loss = 0.71726725
Iteration 2780, loss = 0.71705683
Iteration 2781, loss = 0.71685939
Iteration 2782, loss = 0.71670412
Iteration 2783, loss = 0.71657490
Iteration 2784, loss = 0.71641900
Iteration 2785, loss = 0.71622557
Iteration 2786, loss = 0.71601172
Iteration 2787, loss = 0.71580082
Iteration 2788, loss = 0.71560854
Iteration 2789, loss = 0.71542813
Iteration 2790, loss = 0.71523778
Iteration 2791, loss = 0.71500768
Iteration 2792, loss = 0.71471623
Iteration 2793, loss = 0.71434800
Iteration 2794, loss = 0.71392128
Iteration 2795, loss = 0.71351205
Iteration 2796, loss = 0.71326350
Iteration 2797, loss = 0.71308580
Iteration 2798, loss = 0.71287104
Iteration 2799, loss = 0.71261163
Iteration 2800, loss = 0.71230480
Iteration 2801, loss = 0.71198025
Iteration 2802, loss = 0.71170135
Iteration 2803, loss = 0.71152205
Iteration 2804, loss = 0.71136565
Iteration 2805, loss = 0.71095984
Iteration 2806, loss = 0.71030994
Iteration 2807, loss = 0.70996515
Iteration 2808, loss = 0.70946134
Iteration 2809, loss = 0.70926479
Iteration 2810, loss = 0.70884627
Iteration 2811, loss = 0.70798007
Iteration 2812, loss = 0.70713269
Iteration 2813, loss = 0.70640363
Iteration 2814, loss = 0.70542586
Iteration 2815, loss = 0.70354636
Iteration 2816, loss = 0.70139322
Iteration 2817, loss = 0.69838507
Iteration 2818, loss = 0.69483645
Iteration 2819, loss = 0.69098175
Iteration 2820, loss = 0.67941740
Iteration 2821, loss = 0.79262745
Iteration 2822, loss = 0.89388316
Iteration 2823, loss = 1.11991716
Iteration 2824, loss = 0.77852787
Iteration 2825, loss = 1.18408845
Iteration 2826, loss = 0.88307445
Iteration 2827, loss = 0.85373612
Iteration 2828, loss = 1.01383603
Iteration 2829, loss = 0.75928484
Iteration 2830, loss = 0.85891764
Iteration 2831, loss = 0.88576848
Iteration 2832, loss = 0.70413533
Iteration 2833, loss = 0.80643069
Iteration 2834, loss = 0.83350987
Iteration 2835, loss = 0.74161884
Iteration 2836, loss = 0.84373783
Iteration 2837, loss = 0.76864031
Iteration 2838, loss = 0.79588412
Iteration 2839, loss = 0.80973032
Iteration 2840, loss = 0.75148325
Iteration 2841, loss = 0.80538657
Iteration 2842, loss = 0.75108088
Iteration 2843, loss = 0.76772377
Iteration 2844, loss = 0.76906481
Iteration 2845, loss = 0.73828907
Iteration 2846, loss = 0.77173025
Iteration 2847, loss = 0.73995828
Iteration 2848, loss = 0.75678078
Iteration 2849, loss = 0.75533751
Iteration 2850, loss = 0.74177630
Iteration 2851, loss = 0.76052776
Iteration 2852, loss = 0.74006324
Iteration 2853, loss = 0.75187207
Iteration 2854, loss = 0.74664893
Iteration 2855, loss = 0.74063074
Iteration 2856, loss = 0.74967350
Iteration 2857, loss = 0.73707819
Iteration 2858, loss = 0.74545217
Iteration 2859, loss = 0.74023360
Iteration 2860, loss = 0.73888963
Iteration 2861, loss = 0.74292796
Iteration 2862, loss = 0.73588060
Iteration 2863, loss = 0.74143172
Iteration 2864, loss = 0.73704794
Iteration 2865, loss = 0.73761529
Iteration 2866, loss = 0.73880806
Iteration 2867, loss = 0.73511222
Iteration 2868, loss = 0.73840320
Iteration 2869, loss = 0.73509952
Iteration 2870, loss = 0.73617715
Iteration 2871, loss = 0.73596105
Iteration 2872, loss = 0.73420522
Iteration 2873, loss = 0.73589825
Iteration 2874, loss = 0.73364585
Iteration 2875, loss = 0.73465424
Iteration 2876, loss = 0.73392306
Iteration 2877, loss = 0.73323794
Iteration 2878, loss = 0.73392101
Iteration 2879, loss = 0.73249863
Iteration 2880, loss = 0.73320383
Iteration 2881, loss = 0.73239027
Iteration 2882, loss = 0.73221127
Iteration 2883, loss = 0.73233254
Iteration 2884, loss = 0.73151640
Iteration 2885, loss = 0.73191883
Iteration 2886, loss = 0.73123121
Iteration 2887, loss = 0.73123307
Iteration 2888, loss = 0.73105079
Iteration 2889, loss = 0.73057252
Iteration 2890, loss = 0.73067768
Iteration 2891, loss = 0.73012018
Iteration 2892, loss = 0.73011346
Iteration 2893, loss = 0.72950094
Iteration 2894, loss = 0.72919816
Iteration 2895, loss = 0.72865424
Iteration 2896, loss = 0.72785174
Iteration 2897, loss = 0.72719473
Iteration 2898, loss = 0.72004343
Iteration 2899, loss = 0.76410308
Iteration 2900, loss = 0.73709413
Iteration 2901, loss = 0.77277054
Iteration 2902, loss = 0.73374191
Iteration 2903, loss = 0.76066226
Iteration 2904, loss = 0.74061034
Iteration 2905, loss = 0.74212250
Iteration 2906, loss = 0.74797099
Iteration 2907, loss = 0.73112204
Iteration 2908, loss = 0.74902882
Iteration 2909, loss = 0.73049103
Iteration 2910, loss = 0.74300566
Iteration 2911, loss = 0.73486223
Iteration 2912, loss = 0.73482086
Iteration 2913, loss = 0.73833313
Iteration 2914, loss = 0.72944865
Iteration 2915, loss = 0.73771366
Iteration 2916, loss = 0.72835829
Iteration 2917, loss = 0.73386529
Iteration 2918, loss = 0.73015952
Iteration 2919, loss = 0.72985602
Iteration 2920, loss = 0.73098585
Iteration 2921, loss = 0.72639043
Iteration 2922, loss = 0.72972800
Iteration 2923, loss = 0.71761544
Iteration 2924, loss = 0.73560507
Iteration 2925, loss = 0.73917627
Iteration 2926, loss = 0.74946959
Iteration 2927, loss = 0.73364093
Iteration 2928, loss = 0.74392699
Iteration 2929, loss = 0.73323137
Iteration 2930, loss = 0.73154667
Iteration 2931, loss = 0.73635419
Iteration 2932, loss = 0.72827199
Iteration 2933, loss = 0.73658793
Iteration 2934, loss = 0.73205313
Iteration 2935, loss = 0.73176000
Iteration 2936, loss = 0.73397488
Iteration 2937, loss = 0.72787555
Iteration 2938, loss = 0.73171732
Iteration 2939, loss = 0.72829927
Iteration 2940, loss = 0.72835229
Iteration 2941, loss = 0.72998433
Iteration 2942, loss = 0.72669751
Iteration 2943, loss = 0.72747402
Iteration 2944, loss = 0.74212089
Iteration 2945, loss = 0.71058824
Iteration 2946, loss = 0.81671976
Iteration 2947, loss = 0.73526498
Iteration 2948, loss = 0.80118635
Iteration 2949, loss = 0.77752526
Iteration 2950, loss = 0.72820793
Iteration 2951, loss = 0.72438872
Iteration 2952, loss = 0.73763733
Iteration 2953, loss = 0.72783008
Iteration 2954, loss = 0.73128261
Iteration 2955, loss = 0.72541541
Iteration 2956, loss = 0.71906952
Iteration 2957, loss = 0.70895083
Iteration 2958, loss = 0.87195175
Iteration 2959, loss = 0.73932323
Iteration 2960, loss = 0.90327837
Iteration 2961, loss = 0.77703058
Iteration 2962, loss = 0.79422926
Iteration 2963, loss = 0.85242839
Iteration 2964, loss = 0.73169240
Iteration 2965, loss = 0.81771444
Iteration 2966, loss = 0.77883941
Iteration 2967, loss = 0.73923284
Iteration 2968, loss = 0.80252816
Iteration 2969, loss = 0.73179841
Iteration 2970, loss = 0.76538927
Iteration 2971, loss = 0.76830800
Iteration 2972, loss = 0.72791465
Iteration 2973, loss = 0.77119554
Iteration 2974, loss = 0.73534351
Iteration 2975, loss = 0.74061537
Iteration 2976, loss = 0.75328594
Iteration 2977, loss = 0.72253269
Iteration 2978, loss = 0.74683826
Iteration 2979, loss = 0.73142009
Iteration 2980, loss = 0.72712939
Iteration 2981, loss = 0.73957695
Iteration 2982, loss = 0.71862336
Iteration 2983, loss = 0.72716705
Iteration 2984, loss = 0.65417464
Iteration 2985, loss = 0.75881355
Iteration 2986, loss = 0.74054146
Iteration 2987, loss = 0.76785979
Iteration 2988, loss = 0.76035073
Iteration 2989, loss = 0.75009799
Iteration 2990, loss = 0.76166593
Iteration 2991, loss = 0.74180373
Iteration 2992, loss = 0.74325252
Iteration 2993, loss = 0.74575960
Iteration 2994, loss = 0.73392265
Iteration 2995, loss = 0.74357279
Iteration 2996, loss = 0.74026730
Iteration 2997, loss = 0.73752228
Iteration 2998, loss = 0.74486542
Iteration 2999, loss = 0.73842699
Iteration 3000, loss = 0.74083869
Iteration 3001, loss = 0.74252376
Iteration 3002, loss = 0.73770502
Iteration 3003, loss = 0.74188537
Iteration 3004, loss = 0.73996507
Iteration 3005, loss = 0.73869820
Iteration 3006, loss = 0.74134376
Iteration 3007, loss = 0.73794895
Iteration 3008, loss = 0.73862998
Iteration 3009, loss = 0.73863552
Iteration 3010, loss = 0.73626236
Iteration 3011, loss = 0.73776669
Iteration 3012, loss = 0.73643602
Iteration 3013, loss = 0.73599330
Iteration 3014, loss = 0.73721115
Iteration 3015, loss = 0.73583827
Iteration 3016, loss = 0.73629016
Iteration 3017, loss = 0.73605352
Iteration 3018, loss = 0.73495869
Iteration 3019, loss = 0.73543054
Iteration 3020, loss = 0.73445101
Iteration 3021, loss = 0.73402783
Iteration 3022, loss = 0.73409493
Iteration 3023, loss = 0.73312745
Iteration 3024, loss = 0.73304754
Iteration 3025, loss = 0.73253291
Iteration 3026, loss = 0.73160679
Iteration 3027, loss = 0.73084610
Iteration 3028, loss = 0.72868612
Iteration 3029, loss = 0.72640355
Iteration 3030, loss = 0.72218053
Iteration 3031, loss = 0.69714483
Iteration 3032, loss = 0.84337168
Iteration 3033, loss = 0.76122691
Iteration 3034, loss = 0.86828839
Iteration 3035, loss = 0.76307816
Iteration 3036, loss = 0.80633252
Iteration 3037, loss = 0.80558760
Iteration 3038, loss = 0.74400681
Iteration 3039, loss = 0.80916593
Iteration 3040, loss = 0.74976516
Iteration 3041, loss = 0.77531863
Iteration 3042, loss = 0.78173731
Iteration 3043, loss = 0.74609187
Iteration 3044, loss = 0.78559252
Iteration 3045, loss = 0.74885314
Iteration 3046, loss = 0.76244734
Iteration 3047, loss = 0.76448085
Iteration 3048, loss = 0.74325626
Iteration 3049, loss = 0.76668650
Iteration 3050, loss = 0.74463950
Iteration 3051, loss = 0.75404318
Iteration 3052, loss = 0.75418448
Iteration 3053, loss = 0.74242206
Iteration 3054, loss = 0.75589507
Iteration 3055, loss = 0.74222839
Iteration 3056, loss = 0.74875607
Iteration 3057, loss = 0.74776388
Iteration 3058, loss = 0.74161755
Iteration 3059, loss = 0.74910701
Iteration 3060, loss = 0.74042195
Iteration 3061, loss = 0.74462045
Iteration 3062, loss = 0.74286360
Iteration 3063, loss = 0.73973302
Iteration 3064, loss = 0.74379538
Iteration 3065, loss = 0.73860176
Iteration 3066, loss = 0.74159423
Iteration 3067, loss = 0.73996751
Iteration 3068, loss = 0.73853269
Iteration 3069, loss = 0.74043231
Iteration 3070, loss = 0.73710007
Iteration 3071, loss = 0.73885243
Iteration 3072, loss = 0.73729911
Iteration 3073, loss = 0.73668023
Iteration 3074, loss = 0.73748758
Iteration 3075, loss = 0.73554104
Iteration 3076, loss = 0.73663807
Iteration 3077, loss = 0.73540779
Iteration 3078, loss = 0.73516304
Iteration 3079, loss = 0.73530570
Iteration 3080, loss = 0.73408152
Iteration 3081, loss = 0.73462615
Iteration 3082, loss = 0.73366100
Iteration 3083, loss = 0.73357879
Iteration 3084, loss = 0.73343371
Iteration 3085, loss = 0.73269163
Iteration 3086, loss = 0.73290885
Iteration 3087, loss = 0.73217616
Iteration 3088, loss = 0.73211562
Iteration 3089, loss = 0.73183028
Iteration 3090, loss = 0.73135350
Iteration 3091, loss = 0.73136051
Iteration 3092, loss = 0.73081062
Iteration 3093, loss = 0.73072947
Iteration 3094, loss = 0.73040123
Iteration 3095, loss = 0.73006964
Iteration 3096, loss = 0.72994968
Iteration 3097, loss = 0.72952502
Iteration 3098, loss = 0.72940341
Iteration 3099, loss = 0.72907973
Iteration 3100, loss = 0.72882731
Iteration 3101, loss = 0.72864179
Iteration 3102, loss = 0.72830687
Iteration 3103, loss = 0.72815247
Iteration 3104, loss = 0.72785303
Iteration 3105, loss = 0.72763715
Iteration 3106, loss = 0.72742014
Iteration 3107, loss = 0.72714356
Iteration 3108, loss = 0.72696501
Iteration 3109, loss = 0.72669393
Iteration 3110, loss = 0.72649403
Iteration 3111, loss = 0.72626926
Iteration 3112, loss = 0.72603237
Iteration 3113, loss = 0.72584158
Iteration 3114, loss = 0.72559766
Iteration 3115, loss = 0.72540434
Iteration 3116, loss = 0.72518288
Iteration 3117, loss = 0.72496964
Iteration 3118, loss = 0.72477309
Iteration 3119, loss = 0.72455064
Iteration 3120, loss = 0.72436020
Iteration 3121, loss = 0.72414738
Iteration 3122, loss = 0.72394849
Iteration 3123, loss = 0.72375127
Iteration 3124, loss = 0.72354369
Iteration 3125, loss = 0.72335194
Iteration 3126, loss = 0.72314150
Iteration 3127, loss = 0.72293484
Iteration 3128, loss = 0.72270342
Iteration 3129, loss = 0.72243766
Iteration 3130, loss = 0.72220154
Iteration 3131, loss = 0.72203911
Iteration 3132, loss = 0.72188297
Iteration 3133, loss = 0.72167600
Iteration 3134, loss = 0.72144658
Iteration 3135, loss = 0.72124035
Iteration 3136, loss = 0.72106614
Iteration 3137, loss = 0.72089554
Iteration 3138, loss = 0.72069804
Iteration 3139, loss = 0.72050004
Iteration 3140, loss = 0.72032298
Iteration 3141, loss = 0.72015370
Iteration 3142, loss = 0.71997430
Iteration 3143, loss = 0.71977542
Iteration 3144, loss = 0.71957140
Iteration 3145, loss = 0.71936526
Iteration 3146, loss = 0.71914496
Iteration 3147, loss = 0.71888992
Iteration 3148, loss = 0.71860193
Iteration 3149, loss = 0.71833973
Iteration 3150, loss = 0.71814511
Iteration 3151, loss = 0.71797740
Iteration 3152, loss = 0.71777650
Iteration 3153, loss = 0.71752385
Iteration 3154, loss = 0.71722925
Iteration 3155, loss = 0.71689042
Iteration 3156, loss = 0.71648316
Iteration 3157, loss = 0.71610383
Iteration 3158, loss = 0.71595747
Iteration 3159, loss = 0.71587487
Iteration 3160, loss = 0.71572174
Iteration 3161, loss = 0.71549284
Iteration 3162, loss = 0.71523902
Iteration 3163, loss = 0.71501701
Iteration 3164, loss = 0.71484395
Iteration 3165, loss = 0.71468951
Iteration 3166, loss = 0.71450868
Iteration 3167, loss = 0.71428566
Iteration 3168, loss = 0.71404778
Iteration 3169, loss = 0.71384917
Iteration 3170, loss = 0.71369774
Iteration 3171, loss = 0.71355255
Iteration 3172, loss = 0.71338887
Iteration 3173, loss = 0.71320218
Iteration 3174, loss = 0.71300188
Iteration 3175, loss = 0.71280890
Iteration 3176, loss = 0.71263640
Iteration 3177, loss = 0.71247095
Iteration 3178, loss = 0.71229104
Iteration 3179, loss = 0.71210079
Iteration 3180, loss = 0.71191605
Iteration 3181, loss = 0.71173392
Iteration 3182, loss = 0.71154860
Iteration 3183, loss = 0.71136214
Iteration 3184, loss = 0.71117313
Iteration 3185, loss = 0.71097043
Iteration 3186, loss = 0.71074096
Iteration 3187, loss = 0.71046709
Iteration 3188, loss = 0.71004104
Iteration 3189, loss = 0.70949368
Iteration 3190, loss = 0.70899359
Iteration 3191, loss = 0.70806482
Iteration 3192, loss = 0.70355939
Iteration 3193, loss = 0.71116520
Iteration 3194, loss = 0.70915899
Iteration 3195, loss = 0.70942539
Iteration 3196, loss = 0.69187136
Iteration 3197, loss = 0.73212179
Iteration 3198, loss = 0.72504705
Iteration 3199, loss = 0.73370111
Iteration 3200, loss = 0.69440410
Iteration 3201, loss = 0.62844467
Iteration 3202, loss = 0.85610657
Iteration 3203, loss = 0.80301750
Iteration 3204, loss = 0.79986029
Iteration 3205, loss = 0.84852963
Iteration 3206, loss = 0.75254156
Iteration 3207, loss = 0.84342121
Iteration 3208, loss = 0.74178214
Iteration 3209, loss = 0.80761566
Iteration 3210, loss = 0.75517180
Iteration 3211, loss = 0.76416174
Iteration 3212, loss = 0.76973672
Iteration 3213, loss = 0.73488937
Iteration 3214, loss = 0.77407267
Iteration 3215, loss = 0.72749041
Iteration 3216, loss = 0.76806673
Iteration 3217, loss = 0.73592159
Iteration 3218, loss = 0.75491614
Iteration 3219, loss = 0.74630613
Iteration 3220, loss = 0.74057856
Iteration 3221, loss = 0.75123600
Iteration 3222, loss = 0.73188554
Iteration 3223, loss = 0.74970946
Iteration 3224, loss = 0.73008905
Iteration 3225, loss = 0.74352729
Iteration 3226, loss = 0.73237081
Iteration 3227, loss = 0.73616256
Iteration 3228, loss = 0.73540610
Iteration 3229, loss = 0.73092503
Iteration 3230, loss = 0.73712215
Iteration 3231, loss = 0.72895592
Iteration 3232, loss = 0.73648329
Iteration 3233, loss = 0.72656830
Iteration 3234, loss = 0.73259065
Iteration 3235, loss = 0.73848920
Iteration 3236, loss = 0.73494373
Iteration 3237, loss = 0.73819087
Iteration 3238, loss = 0.73246244
Iteration 3239, loss = 0.73267350
Iteration 3240, loss = 0.73193260
Iteration 3241, loss = 0.73076202
Iteration 3242, loss = 0.73285545
Iteration 3243, loss = 0.73049676
Iteration 3244, loss = 0.73238621
Iteration 3245, loss = 0.73036403
Iteration 3246, loss = 0.73071040
Iteration 3247, loss = 0.73028630
Iteration 3248, loss = 0.72939080
Iteration 3249, loss = 0.73018846
Iteration 3250, loss = 0.72881046
Iteration 3251, loss = 0.72953671
Iteration 3252, loss = 0.72851750
Iteration 3253, loss = 0.72870256
Iteration 3254, loss = 0.72859799
Iteration 3255, loss = 0.72815861
Iteration 3256, loss = 0.72841660
Iteration 3257, loss = 0.72758867
Iteration 3258, loss = 0.72783917
Iteration 3259, loss = 0.72730745
Iteration 3260, loss = 0.72733934
Iteration 3261, loss = 0.72712349
Iteration 3262, loss = 0.72486324
Iteration 3263, loss = 0.73218107
Iteration 3264, loss = 0.73073876
Iteration 3265, loss = 0.73737505
Iteration 3266, loss = 0.73086379
Iteration 3267, loss = 0.73418088
Iteration 3268, loss = 0.73073293
Iteration 3269, loss = 0.72900762
Iteration 3270, loss = 0.73124204
Iteration 3271, loss = 0.72806592
Iteration 3272, loss = 0.73160467
Iteration 3273, loss = 0.72970599
Iteration 3274, loss = 0.73011290
Iteration 3275, loss = 0.73060903
Iteration 3276, loss = 0.72844287
Iteration 3277, loss = 0.72995055
Iteration 3278, loss = 0.72815455
Iteration 3279, loss = 0.72895861
Iteration 3280, loss = 0.72892965
Iteration 3281, loss = 0.72816299
Iteration 3282, loss = 0.72901849
Iteration 3283, loss = 0.72776276
Iteration 3284, loss = 0.72832315
Iteration 3285, loss = 0.72785195
Iteration 3286, loss = 0.72760657
Iteration 3287, loss = 0.72793544
Iteration 3288, loss = 0.72719363
Iteration 3289, loss = 0.72755224
Iteration 3290, loss = 0.72700757
Iteration 3291, loss = 0.72694287
Iteration 3292, loss = 0.72692098
Iteration 3293, loss = 0.72651970
Iteration 3294, loss = 0.72671700
Iteration 3295, loss = 0.72629368
Iteration 3296, loss = 0.72629102
Iteration 3297, loss = 0.72608311
Iteration 3298, loss = 0.72582165
Iteration 3299, loss = 0.72582372
Iteration 3300, loss = 0.72550585
Iteration 3301, loss = 0.72551100
Iteration 3302, loss = 0.72529212
Iteration 3303, loss = 0.72514392
Iteration 3304, loss = 0.72503894
Iteration 3305, loss = 0.72478827
Iteration 3306, loss = 0.72472684
Iteration 3307, loss = 0.72450581
Iteration 3308, loss = 0.72439819
Iteration 3309, loss = 0.72425497
Iteration 3310, loss = 0.72407461
Iteration 3311, loss = 0.72397366
Iteration 3312, loss = 0.72377367
Iteration 3313, loss = 0.72366382
Iteration 3314, loss = 0.72350073
Iteration 3315, loss = 0.72335586
Iteration 3316, loss = 0.72323131
Iteration 3317, loss = 0.72306127
Iteration 3318, loss = 0.72294352
Iteration 3319, loss = 0.72277949
Iteration 3320, loss = 0.72264684
Iteration 3321, loss = 0.72250799
Iteration 3322, loss = 0.72236019
Iteration 3323, loss = 0.72223663
Iteration 3324, loss = 0.72208445
Iteration 3325, loss = 0.72195684
Iteration 3326, loss = 0.72181333
Iteration 3327, loss = 0.72167601
Iteration 3328, loss = 0.72154549
Iteration 3329, loss = 0.72140422
Iteration 3330, loss = 0.72127880
Iteration 3331, loss = 0.72114027
Iteration 3332, loss = 0.72101097
Iteration 3333, loss = 0.72087876
Iteration 3334, loss = 0.72074504
Iteration 3335, loss = 0.72061840
Iteration 3336, loss = 0.72048501
Iteration 3337, loss = 0.72035986
Iteration 3338, loss = 0.72023025
Iteration 3339, loss = 0.72010341
Iteration 3340, loss = 0.71997781
Iteration 3341, loss = 0.71984992
Iteration 3342, loss = 0.71972677
Iteration 3343, loss = 0.71960047
Iteration 3344, loss = 0.71947794
Iteration 3345, loss = 0.71935462
Iteration 3346, loss = 0.71923191
Iteration 3347, loss = 0.71911111
Iteration 3348, loss = 0.71898897
Iteration 3349, loss = 0.71886961
Iteration 3350, loss = 0.71874924
Iteration 3351, loss = 0.71863056
Iteration 3352, loss = 0.71851235
Iteration 3353, loss = 0.71839428
Iteration 3354, loss = 0.71827779
Iteration 3355, loss = 0.71816085
Iteration 3356, loss = 0.71804553
Iteration 3357, loss = 0.71793022
Iteration 3358, loss = 0.71781578
Iteration 3359, loss = 0.71770211
Iteration 3360, loss = 0.71758864
Iteration 3361, loss = 0.71747633
Iteration 3362, loss = 0.71736412
Iteration 3363, loss = 0.71725293
Iteration 3364, loss = 0.71714214
Iteration 3365, loss = 0.71703196
Iteration 3366, loss = 0.71692253
Iteration 3367, loss = 0.71681343
Iteration 3368, loss = 0.71670521
Iteration 3369, loss = 0.71659735
Iteration 3370, loss = 0.71649022
Iteration 3371, loss = 0.71638362
Iteration 3372, loss = 0.71627755
Iteration 3373, loss = 0.71617216
Iteration 3374, loss = 0.71606720
Iteration 3375, loss = 0.71596294
Iteration 3376, loss = 0.71585913
Iteration 3377, loss = 0.71575594
Iteration 3378, loss = 0.71565330
Iteration 3379, loss = 0.71555116
Iteration 3380, loss = 0.71544963
Iteration 3381, loss = 0.71534857
Iteration 3382, loss = 0.71524811
Iteration 3383, loss = 0.71514814
Iteration 3384, loss = 0.71504871
Iteration 3385, loss = 0.71494982
Iteration 3386, loss = 0.71485143
Iteration 3387, loss = 0.71475358
Iteration 3388, loss = 0.71465622
Iteration 3389, loss = 0.71455939
Iteration 3390, loss = 0.71446306
Iteration 3391, loss = 0.71436723
Iteration 3392, loss = 0.71427190
Iteration 3393, loss = 0.71417706
Iteration 3394, loss = 0.71408272
Iteration 3395, loss = 0.71398885
Iteration 3396, loss = 0.71389546
Iteration 3397, loss = 0.71380252
Iteration 3398, loss = 0.71370999
Iteration 3399, loss = 0.71361772
Iteration 3400, loss = 0.71352492
Iteration 3401, loss = 0.71341843
Iteration 3402, loss = 0.71298538
Iteration 3403, loss = 0.71229094
Iteration 3404, loss = 0.70985401
Iteration 3405, loss = 0.71494968
Iteration 3406, loss = 0.71488069
Iteration 3407, loss = 0.71556106
Iteration 3408, loss = 0.71432447
Iteration 3409, loss = 0.71423109
Iteration 3410, loss = 0.71358306
Iteration 3411, loss = 0.71328199
Iteration 3412, loss = 0.71337816
Iteration 3413, loss = 0.71301735
Iteration 3414, loss = 0.71332095
Iteration 3415, loss = 0.71294973
Iteration 3416, loss = 0.71308895
Iteration 3417, loss = 0.71289130
Iteration 3418, loss = 0.71276600
Iteration 3419, loss = 0.71271079
Iteration 3420, loss = 0.71239267
Iteration 3421, loss = 0.71239888
Iteration 3422, loss = 0.71212801
Iteration 3423, loss = 0.71216360
Iteration 3424, loss = 0.71206784
Iteration 3425, loss = 0.71203060
Iteration 3426, loss = 0.71199609
Iteration 3427, loss = 0.71181229
Iteration 3428, loss = 0.71175118
Iteration 3429, loss = 0.71154851
Iteration 3430, loss = 0.71150384
Iteration 3431, loss = 0.71139831
Iteration 3432, loss = 0.71133737
Iteration 3433, loss = 0.71127089
Iteration 3434, loss = 0.71114757
Iteration 3435, loss = 0.71108599
Iteration 3436, loss = 0.71095518
Iteration 3437, loss = 0.71089089
Iteration 3438, loss = 0.71078535
Iteration 3439, loss = 0.71070956
Iteration 3440, loss = 0.71063022
Iteration 3441, loss = 0.71053464
Iteration 3442, loss = 0.71046667
Iteration 3443, loss = 0.71036736
Iteration 3444, loss = 0.71030098
Iteration 3445, loss = 0.71021150
Iteration 3446, loss = 0.71013958
Iteration 3447, loss = 0.71006260
Iteration 3448, loss = 0.70998164
Iteration 3449, loss = 0.70991039
Iteration 3450, loss = 0.70982494
Iteration 3451, loss = 0.70975504
Iteration 3452, loss = 0.70967321
Iteration 3453, loss = 0.70960238
Iteration 3454, loss = 0.70952750
Iteration 3455, loss = 0.70945283
Iteration 3456, loss = 0.70938031
Iteration 3457, loss = 0.70930192
Iteration 3458, loss = 0.70923100
Iteration 3459, loss = 0.70915457
Iteration 3460, loss = 0.70908412
Iteration 3461, loss = 0.70901055
Iteration 3462, loss = 0.70893896
Iteration 3463, loss = 0.70886815
Iteration 3464, loss = 0.70879587
Iteration 3465, loss = 0.70872673
Iteration 3466, loss = 0.70865505
Iteration 3467, loss = 0.70858658
Iteration 3468, loss = 0.70851622
Iteration 3469, loss = 0.70844764
Iteration 3470, loss = 0.70837915
Iteration 3471, loss = 0.70831082
Iteration 3472, loss = 0.70824372
Iteration 3473, loss = 0.70817571
Iteration 3474, loss = 0.70810940
Iteration 3475, loss = 0.70804220
Iteration 3476, loss = 0.70797614
Iteration 3477, loss = 0.70790984
Iteration 3478, loss = 0.70784418
Iteration 3479, loss = 0.70777916
Iteration 3480, loss = 0.70771407
Iteration 3481, loss = 0.70764977
Iteration 3482, loss = 0.70758513
Iteration 3483, loss = 0.70752134
Iteration 3484, loss = 0.70745753
Iteration 3485, loss = 0.70739437
Iteration 3486, loss = 0.70733151
Iteration 3487, loss = 0.70726891
Iteration 3488, loss = 0.70720677
Iteration 3489, loss = 0.70714468
Iteration 3490, loss = 0.70708315
Iteration 3491, loss = 0.70702172
Iteration 3492, loss = 0.70696082
Iteration 3493, loss = 0.70690015
Iteration 3494, loss = 0.70683985
Iteration 3495, loss = 0.70677984
Iteration 3496, loss = 0.70672006
Iteration 3497, loss = 0.70666066
Iteration 3498, loss = 0.70660146
Iteration 3499, loss = 0.70654266
Iteration 3500, loss = 0.70648406
Iteration 3501, loss = 0.70642582
Iteration 3502, loss = 0.70636784
Iteration 3503, loss = 0.70631016
Iteration 3504, loss = 0.70625277
Iteration 3505, loss = 0.70619563
Iteration 3506, loss = 0.70613880
Iteration 3507, loss = 0.70608220
Iteration 3508, loss = 0.70602590
Iteration 3509, loss = 0.70596985
Iteration 3510, loss = 0.70591409
Iteration 3511, loss = 0.70585859
Iteration 3512, loss = 0.70580334
Iteration 3513, loss = 0.70574836
Iteration 3514, loss = 0.70569361
Iteration 3515, loss = 0.70563911
Iteration 3516, loss = 0.70558484
Iteration 3517, loss = 0.70553081
Iteration 3518, loss = 0.70547701
Iteration 3519, loss = 0.70542342
Iteration 3520, loss = 0.70537003
Iteration 3521, loss = 0.70531681
Iteration 3522, loss = 0.70526374
Iteration 3523, loss = 0.70521073
Iteration 3524, loss = 0.70515763
Iteration 3525, loss = 0.70510401
Iteration 3526, loss = 0.70504849
Iteration 3527, loss = 0.70498498
Iteration 3528, loss = 0.70486552
Iteration 3529, loss = 0.70444322
Iteration 3530, loss = 0.70439014
Iteration 3531, loss = 0.70444001
Iteration 3532, loss = 0.70394953
Iteration 3533, loss = 0.70430458
Iteration 3534, loss = 0.70405314
Iteration 3535, loss = 0.70392121
Iteration 3536, loss = 0.70430954
Iteration 3537, loss = 0.70401832
Iteration 3538, loss = 0.70419110
Iteration 3539, loss = 0.70372618
Iteration 3540, loss = 0.70282435
Iteration 3541, loss = 0.70266903
Iteration 3542, loss = 0.70309921
Iteration 3543, loss = 0.70308933
Iteration 3544, loss = 0.70285200
Iteration 3545, loss = 0.70269616
Iteration 3546, loss = 0.70241128
Iteration 3547, loss = 0.70215157
Iteration 3548, loss = 0.70116430
Iteration 3549, loss = 0.69926629
Iteration 3550, loss = 0.69753556
Iteration 3551, loss = 0.69375568
Iteration 3552, loss = 0.67009725
Iteration 3553, loss = 0.81857702
Iteration 3554, loss = 0.76428750
Iteration 3555, loss = 0.83972404
Iteration 3556, loss = 0.72832313
Iteration 3557, loss = 0.82802968
Iteration 3558, loss = 0.71325394
Iteration 3559, loss = 0.80140060
Iteration 3560, loss = 0.71515311
Iteration 3561, loss = 0.77285275
Iteration 3562, loss = 0.72727346
Iteration 3563, loss = 0.74828508
Iteration 3564, loss = 0.73837357
Iteration 3565, loss = 0.72733489
Iteration 3566, loss = 0.74309434
Iteration 3567, loss = 0.71321853
Iteration 3568, loss = 0.74201582
Iteration 3569, loss = 0.70674793
Iteration 3570, loss = 0.73688803
Iteration 3571, loss = 0.70662730
Iteration 3572, loss = 0.72900193
Iteration 3573, loss = 0.70745697
Iteration 3574, loss = 0.71994776
Iteration 3575, loss = 0.71103509
Iteration 3576, loss = 0.71332281
Iteration 3577, loss = 0.71291446
Iteration 3578, loss = 0.70805931
Iteration 3579, loss = 0.71338913
Iteration 3580, loss = 0.70407849
Iteration 3581, loss = 0.71101881
Iteration 3582, loss = 0.70072331
Iteration 3583, loss = 0.70721008
Iteration 3584, loss = 0.68941764
Iteration 3585, loss = 0.76565560
Iteration 3586, loss = 0.91424461
Iteration 3587, loss = 0.73539101
Iteration 3588, loss = 0.78843769
Iteration 3589, loss = 0.76320464
Iteration 3590, loss = 0.77743511
Iteration 3591, loss = 0.75612005
Iteration 3592, loss = 0.73676309
Iteration 3593, loss = 0.73896203
Iteration 3594, loss = 0.71630172
Iteration 3595, loss = 0.73092852
Iteration 3596, loss = 0.71841554
Iteration 3597, loss = 0.72720064
Iteration 3598, loss = 0.72724361
Iteration 3599, loss = 0.72314025
Iteration 3600, loss = 0.73010389
Iteration 3601, loss = 0.72027952
Iteration 3602, loss = 0.72661157
Iteration 3603, loss = 0.71896822
Iteration 3604, loss = 0.72095931
Iteration 3605, loss = 0.71454571
Iteration 3606, loss = 0.72049100
Iteration 3607, loss = 0.71943773
Iteration 3608, loss = 0.71788494
Iteration 3609, loss = 0.71893691
Iteration 3610, loss = 0.71529995
Iteration 3611, loss = 0.71705031
Iteration 3612, loss = 0.71448435
Iteration 3613, loss = 0.71534528
Iteration 3614, loss = 0.71492659
Iteration 3615, loss = 0.71377964
Iteration 3616, loss = 0.71473337
Iteration 3617, loss = 0.71314302
Iteration 3618, loss = 0.71392233
Iteration 3619, loss = 0.71244260
Iteration 3620, loss = 0.71264729
Iteration 3621, loss = 0.71222809
Iteration 3622, loss = 0.71158490
Iteration 3623, loss = 0.71181151
Iteration 3624, loss = 0.71087176
Iteration 3625, loss = 0.71117235
Iteration 3626, loss = 0.71056720
Iteration 3627, loss = 0.71036502
Iteration 3628, loss = 0.70972681
Iteration 3629, loss = 0.70891081
Iteration 3630, loss = 0.70866834
Iteration 3631, loss = 0.70781231
Iteration 3632, loss = 0.70746866
Iteration 3633, loss = 0.70681045
Iteration 3634, loss = 0.70592585
Iteration 3635, loss = 0.70466595
Iteration 3636, loss = 0.70236808
Iteration 3637, loss = 0.69954584
Iteration 3638, loss = 0.69508795
Iteration 3639, loss = 0.68722089
Iteration 3640, loss = 0.62712430
Iteration 3641, loss = 0.92647199
Iteration 3642, loss = 0.87704425
Iteration 3643, loss = 0.95294626
Iteration 3644, loss = 0.77036272
Iteration 3645, loss = 0.92708518
Iteration 3646, loss = 0.72894234
Iteration 3647, loss = 0.88418868
Iteration 3648, loss = 0.73717643
Iteration 3649, loss = 0.83141019
Iteration 3650, loss = 0.76946191
Iteration 3651, loss = 0.78043964
Iteration 3652, loss = 0.79538766
Iteration 3653, loss = 0.74151263
Iteration 3654, loss = 0.80040120
Iteration 3655, loss = 0.72383094
Iteration 3656, loss = 0.78870076
Iteration 3657, loss = 0.72567624
Iteration 3658, loss = 0.76902655
Iteration 3659, loss = 0.73694921
Iteration 3660, loss = 0.74789390
Iteration 3661, loss = 0.74675774
Iteration 3662, loss = 0.73090236
Iteration 3663, loss = 0.74979454
Iteration 3664, loss = 0.72182573
Iteration 3665, loss = 0.74674402
Iteration 3666, loss = 0.72078957
Iteration 3667, loss = 0.74023403
Iteration 3668, loss = 0.72440086
Iteration 3669, loss = 0.73245547
Iteration 3670, loss = 0.72812824
Iteration 3671, loss = 0.72515705
Iteration 3672, loss = 0.72953435
Iteration 3673, loss = 0.72015482
Iteration 3674, loss = 0.72869977
Iteration 3675, loss = 0.71860055
Iteration 3676, loss = 0.72668567
Iteration 3677, loss = 0.71910810
Iteration 3678, loss = 0.72354811
Iteration 3679, loss = 0.72004137
Iteration 3680, loss = 0.72050465
Iteration 3681, loss = 0.72084683
Iteration 3682, loss = 0.71843816
Iteration 3683, loss = 0.72090624
Iteration 3684, loss = 0.71714642
Iteration 3685, loss = 0.72001235
Iteration 3686, loss = 0.71656702
Iteration 3687, loss = 0.71872022
Iteration 3688, loss = 0.71656117
Iteration 3689, loss = 0.71736645
Iteration 3690, loss = 0.71660046
Iteration 3691, loss = 0.71617374
Iteration 3692, loss = 0.71652419
Iteration 3693, loss = 0.71533277
Iteration 3694, loss = 0.71616054
Iteration 3695, loss = 0.71473599
Iteration 3696, loss = 0.71553534
Iteration 3697, loss = 0.71435678
Iteration 3698, loss = 0.71481819
Iteration 3699, loss = 0.71327674
Iteration 3700, loss = 0.71481147
Iteration 3701, loss = 0.71875026
Iteration 3702, loss = 0.71919100
Iteration 3703, loss = 0.71853294
Iteration 3704, loss = 0.71721972
Iteration 3705, loss = 0.71508997
Iteration 3706, loss = 0.71546987
Iteration 3707, loss = 0.71460099
Iteration 3708, loss = 0.71579864
Iteration 3709, loss = 0.71526388
Iteration 3710, loss = 0.71523546
Iteration 3711, loss = 0.71465880
Iteration 3712, loss = 0.71388149
Iteration 3713, loss = 0.71382656
Iteration 3714, loss = 0.71305883
Iteration 3715, loss = 0.71297904
Iteration 3716, loss = 0.71170348
Iteration 3717, loss = 0.71086801
Iteration 3718, loss = 0.70927684
Iteration 3719, loss = 0.70623132
Iteration 3720, loss = 0.70451079
Iteration 3721, loss = 0.70018799
Iteration 3722, loss = 0.69419976
Iteration 3723, loss = 0.66024769
Iteration 3724, loss = 0.94432108
Iteration 3725, loss = 0.76536308
Iteration 3726, loss = 1.00262909
Iteration 3727, loss = 0.81188886
Iteration 3728, loss = 0.84412141
Iteration 3729, loss = 0.91739876
Iteration 3730, loss = 0.73745340
Iteration 3731, loss = 0.86127264
Iteration 3732, loss = 0.80728383
Iteration 3733, loss = 0.74053741
Iteration 3734, loss = 0.83804336
Iteration 3735, loss = 0.73804082
Iteration 3736, loss = 0.77857433
Iteration 3737, loss = 0.79581922
Iteration 3738, loss = 0.72749015
Iteration 3739, loss = 0.79147462
Iteration 3740, loss = 0.74825644
Iteration 3741, loss = 0.74267471
Iteration 3742, loss = 0.77324630
Iteration 3743, loss = 0.72482877
Iteration 3744, loss = 0.75566211
Iteration 3745, loss = 0.74458430
Iteration 3746, loss = 0.72645744
Iteration 3747, loss = 0.75222055
Iteration 3748, loss = 0.72489893
Iteration 3749, loss = 0.73552408
Iteration 3750, loss = 0.73825494
Iteration 3751, loss = 0.72149995
Iteration 3752, loss = 0.73832887
Iteration 3753, loss = 0.72549440
Iteration 3754, loss = 0.72635291
Iteration 3755, loss = 0.73251091
Iteration 3756, loss = 0.72030163
Iteration 3757, loss = 0.72917569
Iteration 3758, loss = 0.72414317
Iteration 3759, loss = 0.72135386
Iteration 3760, loss = 0.72693593
Iteration 3761, loss = 0.71936846
Iteration 3762, loss = 0.72336729
Iteration 3763, loss = 0.72220838
Iteration 3764, loss = 0.71891617
Iteration 3765, loss = 0.72286894
Iteration 3766, loss = 0.71865582
Iteration 3767, loss = 0.72000980
Iteration 3768, loss = 0.72037349
Iteration 3769, loss = 0.71767803
Iteration 3770, loss = 0.72008751
Iteration 3771, loss = 0.71792412
Iteration 3772, loss = 0.71799616
Iteration 3773, loss = 0.71867717
Iteration 3774, loss = 0.71671743
Iteration 3775, loss = 0.71797215
Iteration 3776, loss = 0.71693189
Iteration 3777, loss = 0.71653446
Iteration 3778, loss = 0.71715029
Iteration 3779, loss = 0.71587842
Iteration 3780, loss = 0.71646195
Iteration 3781, loss = 0.71601342
Iteration 3782, loss = 0.71552636
Iteration 3783, loss = 0.71594494
Iteration 3784, loss = 0.71513792
Iteration 3785, loss = 0.71532197
Iteration 3786, loss = 0.71511750
Iteration 3787, loss = 0.71466339
Iteration 3788, loss = 0.71488523
Iteration 3789, loss = 0.71437292
Iteration 3790, loss = 0.71435759
Iteration 3791, loss = 0.71425163
Iteration 3792, loss = 0.71388290
Iteration 3793, loss = 0.71396893
Iteration 3794, loss = 0.71363774
Iteration 3795, loss = 0.71353488
Iteration 3796, loss = 0.71345609
Iteration 3797, loss = 0.71316545
Iteration 3798, loss = 0.71316072
Iteration 3799, loss = 0.71292948
Iteration 3800, loss = 0.71279150
Iteration 3801, loss = 0.71270935
Iteration 3802, loss = 0.71247616
Iteration 3803, loss = 0.71241425
Iteration 3804, loss = 0.71223295
Iteration 3805, loss = 0.71207447
Iteration 3806, loss = 0.71190662
Iteration 3807, loss = 0.71151219
Iteration 3808, loss = 0.71149905
Iteration 3809, loss = 0.71137175
Iteration 3810, loss = 0.71109823
Iteration 3811, loss = 0.71094390
Iteration 3812, loss = 0.71086748
Iteration 3813, loss = 0.71060404
Iteration 3814, loss = 0.71028624
Iteration 3815, loss = 0.71040012
Iteration 3816, loss = 0.71204040
Iteration 3817, loss = 0.71327445
Iteration 3818, loss = 0.71297939
Iteration 3819, loss = 0.71143573
Iteration 3820, loss = 0.70950316
Iteration 3821, loss = 0.70880211
Iteration 3822, loss = 0.70845625
Iteration 3823, loss = 0.70837561
Iteration 3824, loss = 0.70645261
Iteration 3825, loss = 0.70275656
Iteration 3826, loss = 0.68844255
Iteration 3827, loss = 0.75818501
Iteration 3828, loss = 0.71874924
Iteration 3829, loss = 0.77778006
Iteration 3830, loss = 0.71704463
Iteration 3831, loss = 0.75206547
Iteration 3832, loss = 0.72777812
Iteration 3833, loss = 0.70052135
Iteration 3834, loss = 0.91335183
Iteration 3835, loss = 0.70159913
Iteration 3836, loss = 0.74047165
Iteration 3837, loss = 0.75778579
Iteration 3838, loss = 0.75901380
Iteration 3839, loss = 0.76297965
Iteration 3840, loss = 0.74555500
Iteration 3841, loss = 0.73482236
Iteration 3842, loss = 0.72665659
Iteration 3843, loss = 0.71597723
Iteration 3844, loss = 0.71823771
Iteration 3845, loss = 0.71713441
Iteration 3846, loss = 0.72099337
Iteration 3847, loss = 0.72622319
Iteration 3848, loss = 0.72489180
Iteration 3849, loss = 0.72745991
Iteration 3850, loss = 0.72527737
Iteration 3851, loss = 0.72269625
Iteration 3852, loss = 0.72150816
Iteration 3853, loss = 0.71822516
Iteration 3854, loss = 0.71872690
Iteration 3855, loss = 0.71834460
Iteration 3856, loss = 0.71790951
Iteration 3857, loss = 0.71915561
Iteration 3858, loss = 0.71814221
Iteration 3859, loss = 0.71842185
Iteration 3860, loss = 0.71807272
Iteration 3861, loss = 0.71719118
Iteration 3862, loss = 0.71752328
Iteration 3863, loss = 0.71673612
Iteration 3864, loss = 0.71682098
Iteration 3865, loss = 0.71689930
Iteration 3866, loss = 0.71650641
Iteration 3867, loss = 0.71681546
Iteration 3868, loss = 0.71635264
Iteration 3869, loss = 0.71616872
Iteration 3870, loss = 0.71599874
Iteration 3871, loss = 0.71545731
Iteration 3872, loss = 0.71541742
Iteration 3873, loss = 0.71505819
Iteration 3874, loss = 0.71491333
Iteration 3875, loss = 0.71491939
Iteration 3876, loss = 0.71471183
Iteration 3877, loss = 0.71479797
Iteration 3878, loss = 0.71467084
Iteration 3879, loss = 0.71456639
Iteration 3880, loss = 0.71450907
Iteration 3881, loss = 0.71425579
Iteration 3882, loss = 0.71414927
Iteration 3883, loss = 0.71393775
Iteration 3884, loss = 0.71375324
Iteration 3885, loss = 0.71365586
Iteration 3886, loss = 0.71347942
Iteration 3887, loss = 0.71341700
Iteration 3888, loss = 0.71331198
Iteration 3889, loss = 0.71320642
Iteration 3890, loss = 0.71314018
Iteration 3891, loss = 0.71300137
Iteration 3892, loss = 0.71290755
Iteration 3893, loss = 0.71278075
Iteration 3894, loss = 0.71264597
Iteration 3895, loss = 0.71254293
Iteration 3896, loss = 0.71240622
Iteration 3897, loss = 0.71230572
Iteration 3898, loss = 0.71219676
Iteration 3899, loss = 0.71208543
Iteration 3900, loss = 0.71199490
Iteration 3901, loss = 0.71188177
Iteration 3902, loss = 0.71178545
Iteration 3903, loss = 0.71168141
Iteration 3904, loss = 0.71157212
Iteration 3905, loss = 0.71147453
Iteration 3906, loss = 0.71136380
Iteration 3907, loss = 0.71126400
Iteration 3908, loss = 0.71116194
Iteration 3909, loss = 0.71105809
Iteration 3910, loss = 0.71096271
Iteration 3911, loss = 0.71086031
Iteration 3912, loss = 0.71076445
Iteration 3913, loss = 0.71066723
Iteration 3914, loss = 0.71056832
Iteration 3915, loss = 0.71047398
Iteration 3916, loss = 0.71037509
Iteration 3917, loss = 0.71027989
Iteration 3918, loss = 0.71018417
Iteration 3919, loss = 0.71008795
Iteration 3920, loss = 0.70999516
Iteration 3921, loss = 0.70990039
Iteration 3922, loss = 0.70980841
Iteration 3923, loss = 0.70971641
Iteration 3924, loss = 0.70962418
Iteration 3925, loss = 0.70953382
Iteration 3926, loss = 0.70944209
Iteration 3927, loss = 0.70935190
Iteration 3928, loss = 0.70926172
Iteration 3929, loss = 0.70917168
Iteration 3930, loss = 0.70908313
Iteration 3931, loss = 0.70899422
Iteration 3932, loss = 0.70890665
Iteration 3933, loss = 0.70881936
Iteration 3934, loss = 0.70873238
Iteration 3935, loss = 0.70864634
Iteration 3936, loss = 0.70856013
Iteration 3937, loss = 0.70847480
Iteration 3938, loss = 0.70838971
Iteration 3939, loss = 0.70830499
Iteration 3940, loss = 0.70822104
Iteration 3941, loss = 0.70813723
Iteration 3942, loss = 0.70805417
Iteration 3943, loss = 0.70797145
Iteration 3944, loss = 0.70788915
Iteration 3945, loss = 0.70780745
Iteration 3946, loss = 0.70772599
Iteration 3947, loss = 0.70764513
Iteration 3948, loss = 0.70756462
Iteration 3949, loss = 0.70748455
Iteration 3950, loss = 0.70740500
Iteration 3951, loss = 0.70732576
Iteration 3952, loss = 0.70724706
Iteration 3953, loss = 0.70716871
Iteration 3954, loss = 0.70709078
Iteration 3955, loss = 0.70701330
Iteration 3956, loss = 0.70693614
Iteration 3957, loss = 0.70685945
Iteration 3958, loss = 0.70678311
Iteration 3959, loss = 0.70670717
Iteration 3960, loss = 0.70663161
Iteration 3961, loss = 0.70655638
Iteration 3962, loss = 0.70648150
Iteration 3963, loss = 0.70640685
Iteration 3964, loss = 0.70633234
Iteration 3965, loss = 0.70625770
Iteration 3966, loss = 0.70618205
Iteration 3967, loss = 0.70610231
Iteration 3968, loss = 0.70600334
Iteration 3969, loss = 0.70587337
Iteration 3970, loss = 0.70580840
Iteration 3971, loss = 0.70571782
Iteration 3972, loss = 0.70552869
Iteration 3973, loss = 0.70545825
Iteration 3974, loss = 0.70536775
Iteration 3975, loss = 0.70527225
Iteration 3976, loss = 0.70513906
Iteration 3977, loss = 0.70506593
Iteration 3978, loss = 0.70500320
Iteration 3979, loss = 0.70486813
Iteration 3980, loss = 0.70471959
Iteration 3981, loss = 0.70455048
Iteration 3982, loss = 0.70438938
Iteration 3983, loss = 0.70410429
Iteration 3984, loss = 0.70376543
Iteration 3985, loss = 0.70241270
Iteration 3986, loss = 0.66737852
Iteration 3987, loss = 0.71974215
Iteration 3988, loss = 0.71704338
Iteration 3989, loss = 0.72849854
Iteration 3990, loss = 0.71433546
Iteration 3991, loss = 0.72396401
Iteration 3992, loss = 0.71353007
Iteration 3993, loss = 0.71771460
Iteration 3994, loss = 0.71763511
Iteration 3995, loss = 0.71527512
Iteration 3996, loss = 0.72152575
Iteration 3997, loss = 0.71561985
Iteration 3998, loss = 0.72131746
Iteration 3999, loss = 0.71710667
Iteration 4000, loss = 0.71963363
Iteration 4001, loss = 0.71999428
Iteration 4002, loss = 0.71872636
Iteration 4003, loss = 0.72136290
Iteration 4004, loss = 0.71821670
Iteration 4005, loss = 0.72081107
Iteration 4006, loss = 0.71886591
Iteration 4007, loss = 0.72017735
Iteration 4008, loss = 0.72041039
Iteration 4009, loss = 0.71991202
Iteration 4010, loss = 0.72116593
Iteration 4011, loss = 0.71962626
Iteration 4012, loss = 0.72078094
Iteration 4013, loss = 0.71966166
Iteration 4014, loss = 0.72016322
Iteration 4015, loss = 0.72006025
Iteration 4016, loss = 0.71977900
Iteration 4017, loss = 0.72031239
Iteration 4018, loss = 0.71958565
Iteration 4019, loss = 0.72011815
Iteration 4020, loss = 0.71948233
Iteration 4021, loss = 0.71965769
Iteration 4022, loss = 0.71942937
Iteration 4023, loss = 0.71877959
Iteration 4024, loss = 0.72388065
Iteration 4025, loss = 0.73002658
Iteration 4026, loss = 0.73614492
Iteration 4027, loss = 0.73861769
Iteration 4028, loss = 0.73438864
Iteration 4029, loss = 0.73070437
Iteration 4030, loss = 0.72451587
Iteration 4031, loss = 0.72301139
Iteration 4032, loss = 0.72175494
Iteration 4033, loss = 0.72259067
Iteration 4034, loss = 0.72369072
Iteration 4035, loss = 0.72352068
Iteration 4036, loss = 0.72369835
Iteration 4037, loss = 0.72202316
Iteration 4038, loss = 0.72162586
Iteration 4039, loss = 0.72066362
Iteration 4040, loss = 0.72056454
Iteration 4041, loss = 0.72040726
Iteration 4042, loss = 0.71996757
Iteration 4043, loss = 0.71985046
Iteration 4044, loss = 0.71905142
Iteration 4045, loss = 0.71885630
Iteration 4046, loss = 0.71824346
Iteration 4047, loss = 0.71811104
Iteration 4048, loss = 0.71790541
Iteration 4049, loss = 0.71772868
Iteration 4050, loss = 0.71767290
Iteration 4051, loss = 0.71732870
Iteration 4052, loss = 0.71721276
Iteration 4053, loss = 0.71681565
Iteration 4054, loss = 0.71662757
Iteration 4055, loss = 0.71632753
Iteration 4056, loss = 0.71610664
Iteration 4057, loss = 0.71593645
Iteration 4058, loss = 0.71570560
Iteration 4059, loss = 0.71559401
Iteration 4060, loss = 0.71536002
Iteration 4061, loss = 0.71523466
Iteration 4062, loss = 0.71502422
Iteration 4063, loss = 0.71486513
Iteration 4064, loss = 0.71469016
Iteration 4065, loss = 0.71449973
Iteration 4066, loss = 0.71434844
Iteration 4067, loss = 0.71415007
Iteration 4068, loss = 0.71400908
Iteration 4069, loss = 0.71382309
Iteration 4070, loss = 0.71365037
Iteration 4071, loss = 0.71336512
Iteration 4072, loss = 0.71165881
Iteration 4073, loss = 0.71511988
Iteration 4074, loss = 0.71532617
Iteration 4075, loss = 0.71514100
Iteration 4076, loss = 0.71392449
Iteration 4077, loss = 0.71346437
Iteration 4078, loss = 0.71294231
Iteration 4079, loss = 0.71323511
Iteration 4080, loss = 0.71299920
Iteration 4081, loss = 0.71287258
Iteration 4082, loss = 0.71275530
Iteration 4083, loss = 0.71238149
Iteration 4084, loss = 0.71218582
Iteration 4085, loss = 0.71167766
Iteration 4086, loss = 0.71153690
Iteration 4087, loss = 0.71140129
Iteration 4088, loss = 0.71119072
Iteration 4089, loss = 0.71080335
Iteration 4090, loss = 0.71025478
Iteration 4091, loss = 0.70984109
Iteration 4092, loss = 0.70935911
Iteration 4093, loss = 0.70904895
Iteration 4094, loss = 0.70874502
Iteration 4095, loss = 0.70785066
Iteration 4096, loss = 0.70704919
Iteration 4097, loss = 0.70851986
Iteration 4098, loss = 0.71052939
Iteration 4099, loss = 0.71012114
Iteration 4100, loss = 0.70653093
Iteration 4101, loss = 0.70214336
Iteration 4102, loss = 0.69649671
Iteration 4103, loss = 0.64188856
Iteration 4104, loss = 0.76097236
Iteration 4105, loss = 0.75815825
Iteration 4106, loss = 0.78297056
Iteration 4107, loss = 0.72615945
Iteration 4108, loss = 0.77111162
Iteration 4109, loss = 0.71676432
Iteration 4110, loss = 0.75071542
Iteration 4111, loss = 0.72878047
Iteration 4112, loss = 0.73302073
Iteration 4113, loss = 0.74165036
Iteration 4114, loss = 0.72158468
Iteration 4115, loss = 0.74300403
Iteration 4116, loss = 0.71608513
Iteration 4117, loss = 0.73522929
Iteration 4118, loss = 0.71757211
Iteration 4119, loss = 0.71899534
Iteration 4120, loss = 0.71112814
Iteration 4121, loss = 0.83412077
Iteration 4122, loss = 0.73910473
Iteration 4123, loss = 0.82897576
Iteration 4124, loss = 0.74174897
Iteration 4125, loss = 0.79873292
Iteration 4126, loss = 0.74900680
Iteration 4127, loss = 0.76396665
Iteration 4128, loss = 0.75961188
Iteration 4129, loss = 0.74252008
Iteration 4130, loss = 0.76884123
Iteration 4131, loss = 0.73448153
Iteration 4132, loss = 0.76874576
Iteration 4133, loss = 0.73270459
Iteration 4134, loss = 0.75922832
Iteration 4135, loss = 0.73418913
Iteration 4136, loss = 0.74706587
Iteration 4137, loss = 0.73804981
Iteration 4138, loss = 0.73774079
Iteration 4139, loss = 0.74180727
Iteration 4140, loss = 0.73226334
Iteration 4141, loss = 0.74281147
Iteration 4142, loss = 0.72966808
Iteration 4143, loss = 0.74071954
Iteration 4144, loss = 0.72918003
Iteration 4145, loss = 0.73687264
Iteration 4146, loss = 0.72799741
Iteration 4147, loss = 0.72937213
Iteration 4148, loss = 0.73304670
Iteration 4149, loss = 0.70267615
Iteration 4150, loss = 0.69153628
Iteration 4151, loss = 0.77029834
Iteration 4152, loss = 0.73944070
Iteration 4153, loss = 0.76320515
Iteration 4154, loss = 0.73090562
Iteration 4155, loss = 0.75402474
Iteration 4156, loss = 0.73388423
Iteration 4157, loss = 0.74803093
Iteration 4158, loss = 0.73973922
Iteration 4159, loss = 0.73981773
Iteration 4160, loss = 0.74131653
Iteration 4161, loss = 0.73295406
Iteration 4162, loss = 0.74099645
Iteration 4163, loss = 0.72947245
Iteration 4164, loss = 0.73874273
Iteration 4165, loss = 0.72916582
Iteration 4166, loss = 0.73593156
Iteration 4167, loss = 0.72949371
Iteration 4168, loss = 0.73200308
Iteration 4169, loss = 0.72971311
Iteration 4170, loss = 0.72883100
Iteration 4171, loss = 0.73004615
Iteration 4172, loss = 0.72710310
Iteration 4173, loss = 0.72992656
Iteration 4174, loss = 0.72611721
Iteration 4175, loss = 0.72876454
Iteration 4176, loss = 0.72530170
Iteration 4177, loss = 0.72695364
Iteration 4178, loss = 0.72477351
Iteration 4179, loss = 0.72537994
Iteration 4180, loss = 0.72474736
Iteration 4181, loss = 0.72440483
Iteration 4182, loss = 0.72472337
Iteration 4183, loss = 0.72355954
Iteration 4184, loss = 0.72416225
Iteration 4185, loss = 0.72266213
Iteration 4186, loss = 0.72325581
Iteration 4187, loss = 0.72199649
Iteration 4188, loss = 0.72244538
Iteration 4189, loss = 0.72166609
Iteration 4190, loss = 0.72179194
Iteration 4191, loss = 0.72138808
Iteration 4192, loss = 0.72110722
Iteration 4193, loss = 0.72093444
Iteration 4194, loss = 0.72039404
Iteration 4195, loss = 0.72039141
Iteration 4196, loss = 0.71981036
Iteration 4197, loss = 0.71988425
Iteration 4198, loss = 0.71936524
Iteration 4199, loss = 0.71938121
Iteration 4200, loss = 0.71894757
Iteration 4201, loss = 0.71884184
Iteration 4202, loss = 0.71851442
Iteration 4203, loss = 0.71830644
Iteration 4204, loss = 0.71808615
Iteration 4205, loss = 0.71781471
Iteration 4206, loss = 0.71766518
Iteration 4207, loss = 0.71736208
Iteration 4208, loss = 0.71723742
Iteration 4209, loss = 0.71693318
Iteration 4210, loss = 0.71680295
Iteration 4211, loss = 0.71652278
Iteration 4212, loss = 0.71637133
Iteration 4213, loss = 0.71612576
Iteration 4214, loss = 0.71594804
Iteration 4215, loss = 0.71573643
Iteration 4216, loss = 0.71553784
Iteration 4217, loss = 0.71535362
Iteration 4218, loss = 0.71514341
Iteration 4219, loss = 0.71497522
Iteration 4220, loss = 0.71476161
Iteration 4221, loss = 0.71459898
Iteration 4222, loss = 0.71439007
Iteration 4223, loss = 0.71422733
Iteration 4224, loss = 0.71402886
Iteration 4225, loss = 0.71386293
Iteration 4226, loss = 0.71367632
Iteration 4227, loss = 0.71350628
Iteration 4228, loss = 0.71333050
Iteration 4229, loss = 0.71315768
Iteration 4230, loss = 0.71299055
Iteration 4231, loss = 0.71281712
Iteration 4232, loss = 0.71265594
Iteration 4233, loss = 0.71248422
Iteration 4234, loss = 0.71232683
Iteration 4235, loss = 0.71215882
Iteration 4236, loss = 0.71200379
Iteration 4237, loss = 0.71184063
Iteration 4238, loss = 0.71168714
Iteration 4239, loss = 0.71152920
Iteration 4240, loss = 0.71137688
Iteration 4241, loss = 0.71122308
Iteration 4242, loss = 0.71107095
Iteration 4243, loss = 0.71092102
Iteration 4244, loss = 0.71077186
Iteration 4245, loss = 0.71062647
Iteration 4246, loss = 0.71047897
Iteration 4247, loss = 0.71033558
Iteration 4248, loss = 0.71019115
Iteration 4249, loss = 0.71005113
Iteration 4250, loss = 0.70990935
Iteration 4251, loss = 0.70977107
Iteration 4252, loss = 0.70963270
Iteration 4253, loss = 0.70949691
Iteration 4254, loss = 0.70936101
Iteration 4255, loss = 0.70922704
Iteration 4256, loss = 0.70909432
Iteration 4257, loss = 0.70896259
Iteration 4258, loss = 0.70883222
Iteration 4259, loss = 0.70870280
Iteration 4260, loss = 0.70857517
Iteration 4261, loss = 0.70844785
Iteration 4262, loss = 0.70832236
Iteration 4263, loss = 0.70819748
Iteration 4264, loss = 0.70807422
Iteration 4265, loss = 0.70795146
Iteration 4266, loss = 0.70783035
Iteration 4267, loss = 0.70770997
Iteration 4268, loss = 0.70759085
Iteration 4269, loss = 0.70747262
Iteration 4270, loss = 0.70735560
Iteration 4271, loss = 0.70723952
Iteration 4272, loss = 0.70712442
Iteration 4273, loss = 0.70701042
Iteration 4274, loss = 0.70689733
Iteration 4275, loss = 0.70678530
Iteration 4276, loss = 0.70667414
Iteration 4277, loss = 0.70656410
Iteration 4278, loss = 0.70645486
Iteration 4279, loss = 0.70634668
Iteration 4280, loss = 0.70623934
Iteration 4281, loss = 0.70613302
Iteration 4282, loss = 0.70602751
Iteration 4283, loss = 0.70592299
Iteration 4284, loss = 0.70581932
Iteration 4285, loss = 0.70571655
Iteration 4286, loss = 0.70561464
Iteration 4287, loss = 0.70551362
Iteration 4288, loss = 0.70541345
Iteration 4289, loss = 0.70531411
Iteration 4290, loss = 0.70521564
Iteration 4291, loss = 0.70511798
Iteration 4292, loss = 0.70502116
Iteration 4293, loss = 0.70492513
Iteration 4294, loss = 0.70482994
Iteration 4295, loss = 0.70473552
Iteration 4296, loss = 0.70464191
Iteration 4297, loss = 0.70454907
Iteration 4298, loss = 0.70445702
Iteration 4299, loss = 0.70436572
Iteration 4300, loss = 0.70427518
Iteration 4301, loss = 0.70418540
Iteration 4302, loss = 0.70409637
Iteration 4303, loss = 0.70400807
Iteration 4304, loss = 0.70392050
Iteration 4305, loss = 0.70383365
Iteration 4306, loss = 0.70374752
Iteration 4307, loss = 0.70366210
Iteration 4308, loss = 0.70357738
Iteration 4309, loss = 0.70349335
Iteration 4310, loss = 0.70341002
Iteration 4311, loss = 0.70332736
Iteration 4312, loss = 0.70324539
Iteration 4313, loss = 0.70316408
Iteration 4314, loss = 0.70308343
Iteration 4315, loss = 0.70300344
Iteration 4316, loss = 0.70292410
Iteration 4317, loss = 0.70284541
Iteration 4318, loss = 0.70276736
Iteration 4319, loss = 0.70268993
Iteration 4320, loss = 0.70261314
Iteration 4321, loss = 0.70253697
Iteration 4322, loss = 0.70246142
Iteration 4323, loss = 0.70238649
Iteration 4324, loss = 0.70231219
Iteration 4325, loss = 0.70223855
Iteration 4326, loss = 0.70216561
Iteration 4327, loss = 0.70209342
Iteration 4328, loss = 0.70202191
Iteration 4329, loss = 0.70195069
Iteration 4330, loss = 0.70187931
Iteration 4331, loss = 0.70180825
Iteration 4332, loss = 0.70173849
Iteration 4333, loss = 0.70166987
Iteration 4334, loss = 0.70160135
Iteration 4335, loss = 0.70153277
Iteration 4336, loss = 0.70146509
Iteration 4337, loss = 0.70139847
Iteration 4338, loss = 0.70133206
Iteration 4339, loss = 0.70126579
Iteration 4340, loss = 0.70120037
Iteration 4341, loss = 0.70113573
Iteration 4342, loss = 0.70107128
Iteration 4343, loss = 0.70100721
Iteration 4344, loss = 0.70094396
Iteration 4345, loss = 0.70088121
Iteration 4346, loss = 0.70081871
Iteration 4347, loss = 0.70075678
Iteration 4348, loss = 0.70069552
Iteration 4349, loss = 0.70063460
Iteration 4350, loss = 0.70057408
Iteration 4351, loss = 0.70051418
Iteration 4352, loss = 0.70045476
Iteration 4353, loss = 0.70039568
Iteration 4354, loss = 0.70033711
Iteration 4355, loss = 0.70027909
Iteration 4356, loss = 0.70022144
Iteration 4357, loss = 0.70016421
Iteration 4358, loss = 0.70010751
Iteration 4359, loss = 0.70005124
Iteration 4360, loss = 0.69999535
Iteration 4361, loss = 0.69993993
Iteration 4362, loss = 0.69988498
Iteration 4363, loss = 0.69983042
Iteration 4364, loss = 0.69977627
Iteration 4365, loss = 0.69972257
Iteration 4366, loss = 0.69966929
Iteration 4367, loss = 0.69961640
Iteration 4368, loss = 0.69956394
Iteration 4369, loss = 0.69951189
Iteration 4370, loss = 0.69946024
Iteration 4371, loss = 0.69940898
Iteration 4372, loss = 0.69935815
Iteration 4373, loss = 0.69930771
Iteration 4374, loss = 0.69925767
Iteration 4375, loss = 0.69920808
Iteration 4376, loss = 0.69915897
Iteration 4377, loss = 0.69911039
Iteration 4378, loss = 0.69906237
Iteration 4379, loss = 0.69901476
Iteration 4380, loss = 0.69896715
Iteration 4381, loss = 0.69891947
Iteration 4382, loss = 0.69887224
Iteration 4383, loss = 0.69882542
Iteration 4384, loss = 0.69877865
Iteration 4385, loss = 0.69873228
Iteration 4386, loss = 0.69868676
Iteration 4387, loss = 0.69864176
Iteration 4388, loss = 0.69859663
Iteration 4389, loss = 0.69855168
Iteration 4390, loss = 0.69850753
Iteration 4391, loss = 0.69846385
Iteration 4392, loss = 0.69842011
Iteration 4393, loss = 0.69837667
Iteration 4394, loss = 0.69833392
Iteration 4395, loss = 0.69829144
Iteration 4396, loss = 0.69824902
Iteration 4397, loss = 0.69820707
Iteration 4398, loss = 0.69816560
Iteration 4399, loss = 0.69812429
Iteration 4400, loss = 0.69808324
Iteration 4401, loss = 0.69804264
Iteration 4402, loss = 0.69800236
Iteration 4403, loss = 0.69796228
Iteration 4404, loss = 0.69792255
Iteration 4405, loss = 0.69788319
Iteration 4406, loss = 0.69784407
Iteration 4407, loss = 0.69780524
Iteration 4408, loss = 0.69776676
Iteration 4409, loss = 0.69772856
Iteration 4410, loss = 0.69769063
Iteration 4411, loss = 0.69765303
Iteration 4412, loss = 0.69761575
Iteration 4413, loss = 0.69757876
Iteration 4414, loss = 0.69754211
Iteration 4415, loss = 0.69750582
Iteration 4416, loss = 0.69746982
Iteration 4417, loss = 0.69743400
Iteration 4418, loss = 0.69739821
Iteration 4419, loss = 0.69736245
Iteration 4420, loss = 0.69732705
Iteration 4421, loss = 0.69729226
Iteration 4422, loss = 0.69725791
Iteration 4423, loss = 0.69722368
Iteration 4424, loss = 0.69718945
Iteration 4425, loss = 0.69715547
Iteration 4426, loss = 0.69712196
Iteration 4427, loss = 0.69708884
Iteration 4428, loss = 0.69705586
Iteration 4429, loss = 0.69702300
Iteration 4430, loss = 0.69699044
Iteration 4431, loss = 0.69695832
Iteration 4432, loss = 0.69692651
Iteration 4433, loss = 0.69689485
Iteration 4434, loss = 0.69686335
Iteration 4435, loss = 0.69683201
Iteration 4436, loss = 0.69680076
Iteration 4437, loss = 0.69676966
Iteration 4438, loss = 0.69673892
Iteration 4439, loss = 0.69670866
Iteration 4440, loss = 0.69667872
Iteration 4441, loss = 0.69664884
Iteration 4442, loss = 0.69661899
Iteration 4443, loss = 0.69658940
Iteration 4444, loss = 0.69656022
Iteration 4445, loss = 0.69653135
Iteration 4446, loss = 0.69650259
Iteration 4447, loss = 0.69647392
Iteration 4448, loss = 0.69644550
Iteration 4449, loss = 0.69641742
Iteration 4450, loss = 0.69638958
Iteration 4451, loss = 0.69636187
Iteration 4452, loss = 0.69633431
Iteration 4453, loss = 0.69630701
Iteration 4454, loss = 0.69627997
Iteration 4455, loss = 0.69625313
Iteration 4456, loss = 0.69622645
Iteration 4457, loss = 0.69619996
Iteration 4458, loss = 0.69617370
Iteration 4459, loss = 0.69614766
Iteration 4460, loss = 0.69612181
Iteration 4461, loss = 0.69609614
Iteration 4462, loss = 0.69607065
Iteration 4463, loss = 0.69604538
Iteration 4464, loss = 0.69602031
Iteration 4465, loss = 0.69599542
Iteration 4466, loss = 0.69597071
Iteration 4467, loss = 0.69594619
Iteration 4468, loss = 0.69592187
Iteration 4469, loss = 0.69589773
Iteration 4470, loss = 0.69587377
Iteration 4471, loss = 0.69584999
Iteration 4472, loss = 0.69582639
Iteration 4473, loss = 0.69580298
Iteration 4474, loss = 0.69577974
Iteration 4475, loss = 0.69575668
Iteration 4476, loss = 0.69573379
Iteration 4477, loss = 0.69571107
Iteration 4478, loss = 0.69568853
Iteration 4479, loss = 0.69566617
Iteration 4480, loss = 0.69564397
Iteration 4481, loss = 0.69562193
Iteration 4482, loss = 0.69560007
Iteration 4483, loss = 0.69557837
Iteration 4484, loss = 0.69555684
Iteration 4485, loss = 0.69553547
Iteration 4486, loss = 0.69551427
Iteration 4487, loss = 0.69549322
Iteration 4488, loss = 0.69547234
Iteration 4489, loss = 0.69545161
Iteration 4490, loss = 0.69543104
Iteration 4491, loss = 0.69541062
Iteration 4492, loss = 0.69539037
Iteration 4493, loss = 0.69537026
Iteration 4494, loss = 0.69535031
Iteration 4495, loss = 0.69533051
Iteration 4496, loss = 0.69531086
Iteration 4497, loss = 0.69529136
Iteration 4498, loss = 0.69527200
Iteration 4499, loss = 0.69525280
Iteration 4500, loss = 0.69523374
Iteration 4501, loss = 0.69521482
Iteration 4502, loss = 0.69519605
Iteration 4503, loss = 0.69517742
Iteration 4504, loss = 0.69515893
Iteration 4505, loss = 0.69514058
Iteration 4506, loss = 0.69512237
Iteration 4507, loss = 0.69510430
Iteration 4508, loss = 0.69508637
Iteration 4509, loss = 0.69506857
Iteration 4510, loss = 0.69505090
Iteration 4511, loss = 0.69503337
Iteration 4512, loss = 0.69501598
Iteration 4513, loss = 0.69499871
Iteration 4514, loss = 0.69498158
Iteration 4515, loss = 0.69496458
Iteration 4516, loss = 0.69494770
Iteration 4517, loss = 0.69493096
Iteration 4518, loss = 0.69491434
Iteration 4519, loss = 0.69489784
Iteration 4520, loss = 0.69488147
Iteration 4521, loss = 0.69486523
Iteration 4522, loss = 0.69484911
Iteration 4523, loss = 0.69483311
Iteration 4524, loss = 0.69481723
Iteration 4525, loss = 0.69480147
Iteration 4526, loss = 0.69478583
Iteration 4527, loss = 0.69477031
Iteration 4528, loss = 0.69475491
Iteration 4529, loss = 0.69473962
Iteration 4530, loss = 0.69472445
Iteration 4531, loss = 0.69470940
Iteration 4532, loss = 0.69469446
Iteration 4533, loss = 0.69467963
Iteration 4534, loss = 0.69466491
Iteration 4535, loss = 0.69465031
Iteration 4536, loss = 0.69463581
Iteration 4537, loss = 0.69462143
Iteration 4538, loss = 0.69460715
Iteration 4539, loss = 0.69459298
Iteration 4540, loss = 0.69457892
Iteration 4541, loss = 0.69456497
Iteration 4542, loss = 0.69455112
Iteration 4543, loss = 0.69453738
Iteration 4544, loss = 0.69452374
Iteration 4545, loss = 0.69451020
Iteration 4546, loss = 0.69449676
Iteration 4547, loss = 0.69448343
Iteration 4548, loss = 0.69447020
Iteration 4549, loss = 0.69445706
Iteration 4550, loss = 0.69444403
Iteration 4551, loss = 0.69443110
Iteration 4552, loss = 0.69441826
Iteration 4553, loss = 0.69440553
Iteration 4554, loss = 0.69439290
Iteration 4555, loss = 0.69438038
Iteration 4556, loss = 0.69436799
Iteration 4557, loss = 0.69435578
Iteration 4558, loss = 0.69434381
Iteration 4559, loss = 0.69433213
Iteration 4560, loss = 0.69432053
Iteration 4561, loss = 0.69430843
Iteration 4562, loss = 0.69429566
Iteration 4563, loss = 0.69428327
Iteration 4564, loss = 0.69427194
Iteration 4565, loss = 0.69426076
Iteration 4566, loss = 0.69424882
Iteration 4567, loss = 0.69423688
Iteration 4568, loss = 0.69422577
Iteration 4569, loss = 0.69421474
Iteration 4570, loss = 0.69420317
Iteration 4571, loss = 0.69419183
Iteration 4572, loss = 0.69418102
Iteration 4573, loss = 0.69416998
Iteration 4574, loss = 0.69415860
Iteration 4575, loss = 0.69414703
Iteration 4576, loss = 0.69412863
Iteration 4577, loss = 0.69340714
Iteration 4578, loss = 0.68208572
Iteration 4579, loss = 0.70145085
Iteration 4580, loss = 0.70430861
Iteration 4581, loss = 0.70778389
Iteration 4582, loss = 0.70701439
Iteration 4583, loss = 0.70522430
Iteration 4584, loss = 0.70265214
Iteration 4585, loss = 0.70057755
Iteration 4586, loss = 0.69993963
Iteration 4587, loss = 0.69987357
Iteration 4588, loss = 0.70108015
Iteration 4589, loss = 0.70136121
Iteration 4590, loss = 0.70243027
Iteration 4591, loss = 0.70195097
Iteration 4592, loss = 0.70247649
Iteration 4593, loss = 0.70175008
Iteration 4594, loss = 0.70233571
Iteration 4595, loss = 0.70180367
Iteration 4596, loss = 0.70239404
Iteration 4597, loss = 0.70186053
Iteration 4598, loss = 0.70223879
Iteration 4599, loss = 0.70168278
Iteration 4600, loss = 0.70193494
Iteration 4601, loss = 0.70151604
Iteration 4602, loss = 0.70178299
Iteration 4603, loss = 0.70156979
Iteration 4604, loss = 0.70182033
Iteration 4605, loss = 0.70166600
Iteration 4606, loss = 0.70174237
Iteration 4607, loss = 0.70152529
Iteration 4608, loss = 0.70143969
Iteration 4609, loss = 0.70123442
Iteration 4610, loss = 0.70111731
Iteration 4611, loss = 0.70099895
Iteration 4612, loss = 0.70090078
Iteration 4613, loss = 0.70084589
Iteration 4614, loss = 0.70073636
Iteration 4615, loss = 0.70068158
Iteration 4616, loss = 0.70053074
Iteration 4617, loss = 0.70045618
Iteration 4618, loss = 0.70028975
Iteration 4619, loss = 0.70021882
Iteration 4620, loss = 0.70006371
Iteration 4621, loss = 0.69999457
Iteration 4622, loss = 0.69984440
Iteration 4623, loss = 0.69976389
Iteration 4624, loss = 0.69961771
Iteration 4625, loss = 0.69952926
Iteration 4626, loss = 0.69939586
Iteration 4627, loss = 0.69930735
Iteration 4628, loss = 0.69919106
Iteration 4629, loss = 0.69910251
Iteration 4630, loss = 0.69899536
Iteration 4631, loss = 0.69889785
Iteration 4632, loss = 0.69879036
Iteration 4633, loss = 0.69868355
Iteration 4634, loss = 0.69857892
Iteration 4635, loss = 0.69847368
Iteration 4636, loss = 0.69838066
Iteration 4637, loss = 0.69828315
Iteration 4638, loss = 0.69819681
Iteration 4639, loss = 0.69810072
Iteration 4640, loss = 0.69801538
Iteration 4641, loss = 0.69791965
Iteration 4642, loss = 0.69783334
Iteration 4643, loss = 0.69773974
Iteration 4644, loss = 0.69765695
Iteration 4645, loss = 0.69756952
Iteration 4646, loss = 0.69748944
Iteration 4647, loss = 0.69740615
Iteration 4648, loss = 0.69732769
Iteration 4649, loss = 0.69724722
Iteration 4650, loss = 0.69716966
Iteration 4651, loss = 0.69709278
Iteration 4652, loss = 0.69701760
Iteration 4653, loss = 0.69694406
Iteration 4654, loss = 0.69687131
Iteration 4655, loss = 0.69680099
Iteration 4656, loss = 0.69673030
Iteration 4657, loss = 0.69666221
Iteration 4658, loss = 0.69659383
Iteration 4659, loss = 0.69652810
Iteration 4660, loss = 0.69646205
Iteration 4661, loss = 0.69639863
Iteration 4662, loss = 0.69633518
Iteration 4663, loss = 0.69627386
Iteration 4664, loss = 0.69621289
Iteration 4665, loss = 0.69615372
Iteration 4666, loss = 0.69609507
Iteration 4667, loss = 0.69603773
Iteration 4668, loss = 0.69598123
Iteration 4669, loss = 0.69592571
Iteration 4670, loss = 0.69587123
Iteration 4671, loss = 0.69581761
Iteration 4672, loss = 0.69576520
Iteration 4673, loss = 0.69571347
Iteration 4674, loss = 0.69566295
Iteration 4675, loss = 0.69561307
Iteration 4676, loss = 0.69556431
Iteration 4677, loss = 0.69551612
Iteration 4678, loss = 0.69546898
Iteration 4679, loss = 0.69542243
Iteration 4680, loss = 0.69537680
Iteration 4681, loss = 0.69533176
Iteration 4682, loss = 0.69528746
Iteration 4683, loss = 0.69524360
Iteration 4684, loss = 0.69520003
Iteration 4685, loss = 0.69515615
Iteration 4686, loss = 0.69511024
Iteration 4687, loss = 0.69505601
Iteration 4688, loss = 0.69495676
Iteration 4689, loss = 0.69458474
Iteration 4690, loss = 0.69437349
Iteration 4691, loss = 0.69444564
Iteration 4692, loss = 0.69451604
Iteration 4693, loss = 0.69439702
Iteration 4694, loss = 0.69416314
Iteration 4695, loss = 0.69395581
Iteration 4696, loss = 0.69404750
Iteration 4697, loss = 0.69395661
Iteration 4698, loss = 0.69370768
Iteration 4699, loss = 0.69373128
Iteration 4700, loss = 0.69373224
Iteration 4701, loss = 0.69364402
Iteration 4702, loss = 0.69349877
Iteration 4703, loss = 0.69340652
Iteration 4704, loss = 0.69340738
Iteration 4705, loss = 0.69325707
Iteration 4706, loss = 0.69311157
Iteration 4707, loss = 0.69313791
Iteration 4708, loss = 0.69316544
Iteration 4709, loss = 0.69311509
Iteration 4710, loss = 0.69302150
Iteration 4711, loss = 0.69294588
Iteration 4712, loss = 0.69226683
Iteration 4713, loss = 0.69251081
Iteration 4714, loss = 0.69230364
Iteration 4715, loss = 0.69377582
Iteration 4716, loss = 0.69502048
Iteration 4717, loss = 0.69546985
Iteration 4718, loss = 0.69479537
Iteration 4719, loss = 0.69368129
Iteration 4720, loss = 0.69258819
Iteration 4721, loss = 0.69156648
Iteration 4722, loss = 0.69162773
Iteration 4723, loss = 0.69251874
Iteration 4724, loss = 0.69225390
Iteration 4725, loss = 0.69200696
Iteration 4726, loss = 0.69160280
Iteration 4727, loss = 0.69185217
Iteration 4728, loss = 0.69190853
Iteration 4729, loss = 0.69125218
Iteration 4730, loss = 0.68990406
Iteration 4731, loss = 0.68849511
Iteration 4732, loss = 0.68795108
Iteration 4733, loss = 0.68725883
Iteration 4734, loss = 0.68606296
Iteration 4735, loss = 0.68504580
Iteration 4736, loss = 0.68439578
Iteration 4737, loss = 0.67988734
Iteration 4738, loss = 0.67487100
Iteration 4739, loss = 0.63977966
Iteration 4740, loss = 1.21633307
Iteration 4741, loss = 1.05443984
Iteration 4742, loss = 1.05630406
Iteration 4743, loss = 0.93249110
Iteration 4744, loss = 0.97962421
Iteration 4745, loss = 1.13697720
Iteration 4746, loss = 0.71714154
Iteration 4747, loss = 0.81012802
Iteration 4748, loss = 0.77631907
Iteration 4749, loss = 0.81926833
Iteration 4750, loss = 0.77820071
Iteration 4751, loss = 0.79047662
Iteration 4752, loss = 0.75875913
Iteration 4753, loss = 0.75437236
Iteration 4754, loss = 0.73783695
Iteration 4755, loss = 0.72357325
Iteration 4756, loss = 0.72234297
Iteration 4757, loss = 0.70747593
Iteration 4758, loss = 0.71836920
Iteration 4759, loss = 0.70538863
Iteration 4760, loss = 0.71920092
Iteration 4761, loss = 0.70466708
Iteration 4762, loss = 0.71662009
Iteration 4763, loss = 0.70586334
Iteration 4764, loss = 0.71556626
Iteration 4765, loss = 0.70691220
Iteration 4766, loss = 0.71162573
Iteration 4767, loss = 0.70604821
Iteration 4768, loss = 0.70754469
Iteration 4769, loss = 0.70526531
Iteration 4770, loss = 0.70420481
Iteration 4771, loss = 0.70435701
Iteration 4772, loss = 0.70145440
Iteration 4773, loss = 0.70263887
Iteration 4774, loss = 0.69914978
Iteration 4775, loss = 0.70151628
Iteration 4776, loss = 0.69822816
Iteration 4777, loss = 0.70037697
Iteration 4778, loss = 0.69763017
Iteration 4779, loss = 0.69922568
Iteration 4780, loss = 0.69702200
Iteration 4781, loss = 0.69487746
Iteration 4782, loss = 0.70286584
Iteration 4783, loss = 0.69868484
Iteration 4784, loss = 0.70085861
Iteration 4785, loss = 0.71121156
Iteration 4786, loss = 0.70786497
Iteration 4787, loss = 0.71206439
Iteration 4788, loss = 0.70167667
Iteration 4789, loss = 0.70609998
Iteration 4790, loss = 0.69799674
Iteration 4791, loss = 0.70367814
Iteration 4792, loss = 0.69858151
Iteration 4793, loss = 0.70324796
Iteration 4794, loss = 0.69971507
Iteration 4795, loss = 0.70163724
Iteration 4796, loss = 0.69942264
Iteration 4797, loss = 0.69943519
Iteration 4798, loss = 0.69903593
Iteration 4799, loss = 0.69813418
Iteration 4800, loss = 0.69906476
Iteration 4801, loss = 0.69754629
Iteration 4802, loss = 0.69890549
Iteration 4803, loss = 0.69709197
Iteration 4804, loss = 0.69841010
Iteration 4805, loss = 0.69684072
Iteration 4806, loss = 0.69796228
Iteration 4807, loss = 0.69692876
Iteration 4808, loss = 0.69763312
Iteration 4809, loss = 0.69703860
Iteration 4810, loss = 0.69716733
Iteration 4811, loss = 0.69690287
Iteration 4812, loss = 0.69663275
Iteration 4813, loss = 0.69673220
Iteration 4814, loss = 0.69635531
Iteration 4815, loss = 0.69671878
Iteration 4816, loss = 0.69632364
Iteration 4817, loss = 0.69669786
Iteration 4818, loss = 0.69629253
Iteration 4819, loss = 0.69653426
Iteration 4820, loss = 0.69620690
Iteration 4821, loss = 0.69632885
Iteration 4822, loss = 0.69615819
Iteration 4823, loss = 0.69618431
Iteration 4824, loss = 0.69615071
Iteration 4825, loss = 0.69608953
Iteration 4826, loss = 0.69613641
Iteration 4827, loss = 0.69601803
Iteration 4828, loss = 0.69609738
Iteration 4829, loss = 0.69596203
Iteration 4830, loss = 0.69603383
Iteration 4831, loss = 0.69591267
Iteration 4832, loss = 0.69595762
Iteration 4833, loss = 0.69587643
Iteration 4834, loss = 0.69589182
Iteration 4835, loss = 0.69585492
Iteration 4836, loss = 0.69584046
Iteration 4837, loss = 0.69583393
Iteration 4838, loss = 0.69579466
Iteration 4839, loss = 0.69580305
Iteration 4840, loss = 0.69575338
Iteration 4841, loss = 0.69576655
Iteration 4842, loss = 0.69572074
Iteration 4843, loss = 0.69572976
Iteration 4844, loss = 0.69569408
Iteration 4845, loss = 0.69569247
Iteration 4846, loss = 0.69566845
Iteration 4847, loss = 0.69565576
Iteration 4848, loss = 0.69564221
Iteration 4849, loss = 0.69562227
Iteration 4850, loss = 0.69561616
Iteration 4851, loss = 0.69559335
Iteration 4852, loss = 0.69558959
Iteration 4853, loss = 0.69556698
Iteration 4854, loss = 0.69556135
Iteration 4855, loss = 0.69554131
Iteration 4856, loss = 0.69553232
Iteration 4857, loss = 0.69551667
Iteration 4858, loss = 0.69550502
Iteration 4859, loss = 0.69549368
Iteration 4860, loss = 0.69548005
Iteration 4861, loss = 0.69547091
Iteration 4862, loss = 0.69545596
Iteration 4863, loss = 0.69544708
Iteration 4864, loss = 0.69543221
Iteration 4865, loss = 0.69542281
Iteration 4866, loss = 0.69540939
Iteration 4867, loss = 0.69539930
Iteration 4868, loss = 0.69538765
Iteration 4869, loss = 0.69537670
Iteration 4870, loss = 0.69536631
Iteration 4871, loss = 0.69535472
Iteration 4872, loss = 0.69534501
Iteration 4873, loss = 0.69533331
Iteration 4874, loss = 0.69532379
Iteration 4875, loss = 0.69531249
Iteration 4876, loss = 0.69530285
Iteration 4877, loss = 0.69529219
Iteration 4878, loss = 0.69528233
Iteration 4879, loss = 0.69527237
Iteration 4880, loss = 0.69526239
Iteration 4881, loss = 0.69525301
Iteration 4882, loss = 0.69524316
Iteration 4883, loss = 0.69523425
Iteration 4884, loss = 0.69522477
Iteration 4885, loss = 0.69521578
Iteration 4886, loss = 0.69520572
Iteration 4887, loss = 0.69519586
Iteration 4888, loss = 0.69518653
Iteration 4889, loss = 0.69517798
Iteration 4890, loss = 0.69516940
Iteration 4891, loss = 0.69516023
Iteration 4892, loss = 0.69515164
Iteration 4893, loss = 0.69514316
Iteration 4894, loss = 0.69513430
Iteration 4895, loss = 0.69512463
Iteration 4896, loss = 0.69511596
Iteration 4897, loss = 0.69510830
Iteration 4898, loss = 0.69510046
Iteration 4899, loss = 0.69509191
Iteration 4900, loss = 0.69508334
Iteration 4901, loss = 0.69507500
Iteration 4902, loss = 0.69506629
Iteration 4903, loss = 0.69505791
Iteration 4904, loss = 0.69505019
Iteration 4905, loss = 0.69504256
Iteration 4906, loss = 0.69503422
Iteration 4907, loss = 0.69502599
Iteration 4908, loss = 0.69501854
Iteration 4909, loss = 0.69501106
Iteration 4910, loss = 0.69500309
Iteration 4911, loss = 0.69499530
Iteration 4912, loss = 0.69498811
Iteration 4913, loss = 0.69498080
Iteration 4914, loss = 0.69497329
Iteration 4915, loss = 0.69496618
Iteration 4916, loss = 0.69495946
Iteration 4917, loss = 0.69495243
Iteration 4918, loss = 0.69494484
Iteration 4919, loss = 0.69493715
Iteration 4920, loss = 0.69492984
Iteration 4921, loss = 0.69492302
Iteration 4922, loss = 0.69491632
Iteration 4923, loss = 0.69490933
Iteration 4924, loss = 0.69490212
Iteration 4925, loss = 0.69489526
Iteration 4926, loss = 0.69488878
Iteration 4927, loss = 0.69488210
Iteration 4928, loss = 0.69487517
Iteration 4929, loss = 0.69486852
Iteration 4930, loss = 0.69486219
Iteration 4931, loss = 0.69485567
Iteration 4932, loss = 0.69484901
Iteration 4933, loss = 0.69484262
Iteration 4934, loss = 0.69483640
Iteration 4935, loss = 0.69483003
Iteration 4936, loss = 0.69482363
Iteration 4937, loss = 0.69481746
Iteration 4938, loss = 0.69481136
Iteration 4939, loss = 0.69480515
Iteration 4940, loss = 0.69479900
Iteration 4941, loss = 0.69479301
Iteration 4942, loss = 0.69478703
Iteration 4943, loss = 0.69478100
Iteration 4944, loss = 0.69477508
Iteration 4945, loss = 0.69476926
Iteration 4946, loss = 0.69476346
Iteration 4947, loss = 0.69475771
Iteration 4948, loss = 0.69475214
Iteration 4949, loss = 0.69474681
Iteration 4950, loss = 0.69474169
Iteration 4951, loss = 0.69473670
Iteration 4952, loss = 0.69473136
Iteration 4953, loss = 0.69472517
Iteration 4954, loss = 0.69471861
Iteration 4955, loss = 0.69471273
Iteration 4956, loss = 0.69470767
Iteration 4957, loss = 0.69470250
Iteration 4958, loss = 0.69469677
Iteration 4959, loss = 0.69469107
Iteration 4960, loss = 0.69468578
Iteration 4961, loss = 0.69468057
Iteration 4962, loss = 0.69467517
Iteration 4963, loss = 0.69466980
Iteration 4964, loss = 0.69466455
Iteration 4965, loss = 0.69465926
Iteration 4966, loss = 0.69465394
Iteration 4967, loss = 0.69464863
Iteration 4968, loss = 0.69464307
Iteration 4969, loss = 0.69463676
Iteration 4970, loss = 0.69462638
Iteration 4971, loss = 0.69445907
Iteration 4972, loss = 0.69476468
Iteration 4973, loss = 0.69508411
Iteration 4974, loss = 0.69493639
Iteration 4975, loss = 0.69520151
Iteration 4976, loss = 0.69509303
Iteration 4977, loss = 0.69487373
Iteration 4978, loss = 0.69492508
Iteration 4979, loss = 0.69462880
Iteration 4980, loss = 0.69441084
Iteration 4981, loss = 0.69426024
Iteration 4982, loss = 0.69385309
Iteration 4983, loss = 0.69362871
Iteration 4984, loss = 0.69310673
Iteration 4985, loss = 0.69234109
Iteration 4986, loss = 0.69225741
Iteration 4987, loss = 0.69076471
Iteration 4988, loss = 0.68946420
Iteration 4989, loss = 0.68355968
Iteration 4990, loss = 0.54747816
Iteration 4991, loss = 0.87435574
Iteration 4992, loss = 0.75648357
Iteration 4993, loss = 0.78275148
Iteration 4994, loss = 0.82279421
Iteration 4995, loss = 0.72034016
Iteration 4996, loss = 0.82060096
Iteration 4997, loss = 0.71294235
Iteration 4998, loss = 0.77062556
Iteration 4999, loss = 0.73906387
Iteration 5000, loss = 0.72559116
