Iteration 1, loss = 0.70090195
Iteration 2, loss = 4.65591055
Iteration 3, loss = 1.64268316
Iteration 4, loss = 0.99172338
Iteration 5, loss = 1.53069499
Iteration 6, loss = 1.52906014
Iteration 7, loss = 1.11768047
Iteration 8, loss = 0.70577299
Iteration 9, loss = 1.05066994
Iteration 10, loss = 0.89224771
Iteration 11, loss = 0.72829013
Iteration 12, loss = 0.70325997
Iteration 13, loss = 0.85396517
Iteration 14, loss = 0.75147683
Iteration 15, loss = 0.77519119
Iteration 16, loss = 0.69594976
Iteration 17, loss = 0.47564578
Iteration 18, loss = 0.95227220
Iteration 19, loss = 0.99603875
Iteration 20, loss = 0.72991757
Iteration 21, loss = 0.78323059
Iteration 22, loss = 0.84414891
Iteration 23, loss = 0.86754760
Iteration 24, loss = 0.94269494
Iteration 25, loss = 0.77012292
Iteration 26, loss = 0.96114825
Iteration 27, loss = 0.80144317
Iteration 28, loss = 0.77886812
Iteration 29, loss = 0.78277112
Iteration 30, loss = 0.84725234
Iteration 31, loss = 0.81287320
Iteration 32, loss = 0.83901236
Iteration 33, loss = 0.78928764
Iteration 34, loss = 0.80685885
Iteration 35, loss = 0.79130836
Iteration 36, loss = 0.78505626
Iteration 37, loss = 0.77545058
Iteration 38, loss = 0.78178462
Iteration 39, loss = 0.79757906
Iteration 40, loss = 0.86332888
Iteration 41, loss = 1.04965432
Iteration 42, loss = 0.73705849
Iteration 43, loss = 0.93496868
Iteration 44, loss = 1.05132899
Iteration 45, loss = 0.77935078
Iteration 46, loss = 0.92091914
Iteration 47, loss = 0.79713738
Iteration 48, loss = 0.88180470
Iteration 49, loss = 0.82639487
Iteration 50, loss = 1.01703105
Iteration 51, loss = 0.94376945
Iteration 52, loss = 0.85829884
Iteration 53, loss = 0.95498901
Iteration 54, loss = 0.80269516
Iteration 55, loss = 0.87875687
Iteration 56, loss = 1.26747812
Iteration 57, loss = 0.80013105
Iteration 58, loss = 1.24008276
Iteration 59, loss = 1.20753179
Iteration 60, loss = 0.88595809
Iteration 61, loss = 0.83957152
Iteration 62, loss = 1.07324611
Iteration 63, loss = 1.01649586
Iteration 64, loss = 0.78495849
Iteration 65, loss = 0.89583237
Iteration 66, loss = 0.94232904
Iteration 67, loss = 0.76775335
Iteration 68, loss = 0.93426169
Iteration 69, loss = 0.85886933
Iteration 70, loss = 0.76721429
Iteration 71, loss = 0.87869138
Iteration 72, loss = 0.85493759
Iteration 73, loss = 0.76190591
Iteration 74, loss = 0.82235490
Iteration 75, loss = 0.84040062
Iteration 76, loss = 0.76565234
Iteration 77, loss = 0.78441305
Iteration 78, loss = 0.85897662
Iteration 79, loss = 0.75924884
Iteration 80, loss = 0.77528458
Iteration 81, loss = 0.80456525
Iteration 82, loss = 0.74039793
Iteration 83, loss = 0.75241761
Iteration 84, loss = 0.80550167
Iteration 85, loss = 0.78903426
Iteration 86, loss = 0.75555272
Iteration 87, loss = 0.77793120
Iteration 88, loss = 0.77979175
Iteration 89, loss = 0.74900199
Iteration 90, loss = 0.76449299
Iteration 91, loss = 0.76873823
Iteration 92, loss = 0.73859990
Iteration 93, loss = 0.69376427
Iteration 94, loss = 0.77576339
Iteration 95, loss = 0.74550793
Iteration 96, loss = 0.79860727
Iteration 97, loss = 0.78920885
Iteration 98, loss = 0.75032184
Iteration 99, loss = 0.77997008
Iteration 100, loss = 0.78630315
Iteration 101, loss = 0.75016377
Iteration 102, loss = 0.76027243
Iteration 103, loss = 0.77375905
Iteration 104, loss = 0.74805154
Iteration 105, loss = 0.74710662
Iteration 106, loss = 0.76110317
Iteration 107, loss = 0.74488464
Iteration 108, loss = 0.73958376
Iteration 109, loss = 0.75193814
Iteration 110, loss = 0.74265591
Iteration 111, loss = 0.73483875
Iteration 112, loss = 0.72604283
Iteration 113, loss = 0.72913941
Iteration 114, loss = 0.73565154
Iteration 115, loss = 0.79074091
Iteration 116, loss = 0.74750774
Iteration 117, loss = 0.77230913
Iteration 118, loss = 0.78365002
Iteration 119, loss = 0.74518287
Iteration 120, loss = 0.75266374
Iteration 121, loss = 0.71449850
Iteration 122, loss = 0.77143080
Iteration 123, loss = 0.74987631
Iteration 124, loss = 0.80475463
Iteration 125, loss = 0.74809264
Iteration 126, loss = 1.06734508
Iteration 127, loss = 0.79101423
Iteration 128, loss = 0.86030880
Iteration 129, loss = 0.96700763
Iteration 130, loss = 0.73477715
Iteration 131, loss = 1.61598718
Iteration 132, loss = 1.00812713
Iteration 133, loss = 0.76066152
Iteration 134, loss = 1.00126833
Iteration 135, loss = 0.97502065
Iteration 136, loss = 0.77409985
Iteration 137, loss = 0.94087784
Iteration 138, loss = 0.91899824
Iteration 139, loss = 0.76501521
Iteration 140, loss = 0.88396218
Iteration 141, loss = 0.85929320
Iteration 142, loss = 0.74836222
Iteration 143, loss = 0.83963773
Iteration 144, loss = 0.81235103
Iteration 145, loss = 0.73753554
Iteration 146, loss = 0.73462447
Iteration 147, loss = 0.74387363
Iteration 148, loss = 0.74579945
Iteration 149, loss = 0.89128296
Iteration 150, loss = 1.06609973
Iteration 151, loss = 0.84541383
Iteration 152, loss = 0.85888980
Iteration 153, loss = 0.81442109
Iteration 154, loss = 0.85469142
Iteration 155, loss = 0.76614213
Iteration 156, loss = 0.73715794
Iteration 157, loss = 0.90117320
Iteration 158, loss = 0.77203854
Iteration 159, loss = 0.93107479
Iteration 160, loss = 0.82924035
Iteration 161, loss = 0.79643380
Iteration 162, loss = 0.88545811
Iteration 163, loss = 0.76853441
Iteration 164, loss = 0.80710237
Iteration 165, loss = 0.82210193
Iteration 166, loss = 0.75029052
Iteration 167, loss = 0.79678549
Iteration 168, loss = 0.75157407
Iteration 169, loss = 0.76057801
Iteration 170, loss = 0.77858210
Iteration 171, loss = 0.74108474
Iteration 172, loss = 0.76439956
Iteration 173, loss = 0.75583962
Iteration 174, loss = 0.76595700
Iteration 175, loss = 0.74176124
Iteration 176, loss = 0.76760009
Iteration 177, loss = 0.76536763
Iteration 178, loss = 0.75471329
Iteration 179, loss = 0.77439448
Iteration 180, loss = 0.75410143
Iteration 181, loss = 0.75292779
Iteration 182, loss = 0.75572088
Iteration 183, loss = 0.73652687
Iteration 184, loss = 0.74059009
Iteration 185, loss = 0.70294366
Iteration 186, loss = 0.79962827
Iteration 187, loss = 0.74493082
Iteration 188, loss = 0.78795584
Iteration 189, loss = 0.78490953
Iteration 190, loss = 0.74819938
Iteration 191, loss = 0.78214348
Iteration 192, loss = 0.75672473
Iteration 193, loss = 0.74055636
Iteration 194, loss = 0.73384315
Iteration 195, loss = 0.96506441
Iteration 196, loss = 0.77585426
Iteration 197, loss = 1.03211796
Iteration 198, loss = 0.83861122
Iteration 199, loss = 0.82453043
Iteration 200, loss = 0.95765263
Iteration 201, loss = 0.76677796
Iteration 202, loss = 0.84319861
Iteration 203, loss = 0.86709105
Iteration 204, loss = 0.82950705
Iteration 205, loss = 0.73057144
Iteration 206, loss = 0.74006561
Iteration 207, loss = 0.74709915
Iteration 208, loss = 0.75448643
Iteration 209, loss = 0.75282122
Iteration 210, loss = 0.75216293
Iteration 211, loss = 0.74890982
Iteration 212, loss = 0.73724435
Iteration 213, loss = 0.92781475
Iteration 214, loss = 0.87884450
Iteration 215, loss = 0.86748627
Iteration 216, loss = 0.73311357
Iteration 217, loss = 0.86289398
Iteration 218, loss = 0.73142213
Iteration 219, loss = 0.80728962
Iteration 220, loss = 1.02105553
Iteration 221, loss = 1.04397958
Iteration 222, loss = 0.75520222
Iteration 223, loss = 1.01158969
Iteration 224, loss = 0.84901857
Iteration 225, loss = 0.80899333
Iteration 226, loss = 0.93498531
Iteration 227, loss = 0.73818629
Iteration 228, loss = 0.85390880
Iteration 229, loss = 0.81852127
Iteration 230, loss = 0.88481487
Iteration 231, loss = 0.82620376
Iteration 232, loss = 0.75397186
Iteration 233, loss = 0.83640581
Iteration 234, loss = 0.86874008
Iteration 235, loss = 0.82546026
Iteration 236, loss = 1.00818481
Iteration 237, loss = 0.78423600
Iteration 238, loss = 0.87552263
Iteration 239, loss = 0.91849121
Iteration 240, loss = 0.74379785
Iteration 241, loss = 0.80427993
Iteration 242, loss = 0.77383579
Iteration 243, loss = 0.77414090
Iteration 244, loss = 0.78323912
Iteration 245, loss = 0.76156134
Iteration 246, loss = 0.78665103
Iteration 247, loss = 0.74715361
Iteration 248, loss = 0.78067910
Iteration 249, loss = 0.74525878
Iteration 250, loss = 0.76615267
Iteration 251, loss = 0.72702817
Iteration 252, loss = 0.77242253
Iteration 253, loss = 0.75304362
Iteration 254, loss = 0.75989385
Iteration 255, loss = 0.75773924
Iteration 256, loss = 0.74419884
Iteration 257, loss = 0.75489462
Iteration 258, loss = 0.73844501
Iteration 259, loss = 0.74805062
Iteration 260, loss = 0.73618788
Iteration 261, loss = 0.73167377
Iteration 262, loss = 0.74755392
Iteration 263, loss = 0.75029849
Iteration 264, loss = 0.75190058
Iteration 265, loss = 0.73033504
Iteration 266, loss = 0.77974404
Iteration 267, loss = 0.73254878
Iteration 268, loss = 0.97066132
Iteration 269, loss = 0.76202199
Iteration 270, loss = 0.93914219
Iteration 271, loss = 0.81178119
Iteration 272, loss = 0.85818587
Iteration 273, loss = 0.87382662
Iteration 274, loss = 0.77715832
Iteration 275, loss = 0.87317422
Iteration 276, loss = 0.76734973
Iteration 277, loss = 0.82524595
Iteration 278, loss = 0.79584434
Iteration 279, loss = 0.76990606
Iteration 280, loss = 0.81074967
Iteration 281, loss = 0.74776438
Iteration 282, loss = 0.79826005
Iteration 283, loss = 0.75849140
Iteration 284, loss = 0.77070758
Iteration 285, loss = 0.74048758
Iteration 286, loss = 0.76387096
Iteration 287, loss = 0.75525002
Iteration 288, loss = 0.77227505
Iteration 289, loss = 0.74139525
Iteration 290, loss = 0.86786741
Iteration 291, loss = 1.07423947
Iteration 292, loss = 0.82148908
Iteration 293, loss = 0.98926581
Iteration 294, loss = 0.94784252
Iteration 295, loss = 0.83240948
Iteration 296, loss = 0.97917383
Iteration 297, loss = 0.77488721
Iteration 298, loss = 0.92498677
Iteration 299, loss = 0.79658672
Iteration 300, loss = 0.78507338
Iteration 301, loss = 0.96569704
Iteration 302, loss = 0.79709329
Iteration 303, loss = 0.89659188
Iteration 304, loss = 0.85058435
Iteration 305, loss = 0.80716720
Iteration 306, loss = 0.86927158
Iteration 307, loss = 0.75905717
Iteration 308, loss = 0.84653068
Iteration 309, loss = 0.76526570
Iteration 310, loss = 0.80171664
Iteration 311, loss = 0.81979897
Iteration 312, loss = 0.75666186
Iteration 313, loss = 0.80377360
Iteration 314, loss = 0.75052870
Iteration 315, loss = 1.08229066
Iteration 316, loss = 0.85115431
Iteration 317, loss = 0.88580943
Iteration 318, loss = 0.77554846
Iteration 319, loss = 0.90137247
Iteration 320, loss = 0.80050847
Iteration 321, loss = 0.84880810
Iteration 322, loss = 0.85435167
Iteration 323, loss = 0.79335956
Iteration 324, loss = 0.85999556
Iteration 325, loss = 0.78465727
Iteration 326, loss = 0.82108125
Iteration 327, loss = 0.80266965
Iteration 328, loss = 0.77672395
Iteration 329, loss = 0.80732079
Iteration 330, loss = 0.75986339
Iteration 331, loss = 0.79036211
Iteration 332, loss = 0.76669588
Iteration 333, loss = 0.76612226
Iteration 334, loss = 0.77571726
Iteration 335, loss = 0.75241288
Iteration 336, loss = 0.78168800
Iteration 337, loss = 0.75219919
Iteration 338, loss = 0.76749956
Iteration 339, loss = 0.79400002
Iteration 340, loss = 0.77328542
Iteration 341, loss = 0.79223095
Iteration 342, loss = 0.77010310
Iteration 343, loss = 0.78766830
Iteration 344, loss = 0.76252384
Iteration 345, loss = 0.78077585
Iteration 346, loss = 0.75619110
Iteration 347, loss = 0.77453379
Iteration 348, loss = 0.75229362
Iteration 349, loss = 0.76918659
Iteration 350, loss = 0.75041837
Iteration 351, loss = 0.76450584
Iteration 352, loss = 0.74947614
Iteration 353, loss = 0.75964266
Iteration 354, loss = 0.74806208
Iteration 355, loss = 0.72675193
Iteration 356, loss = 0.74055567
Iteration 357, loss = 0.81628500
Iteration 358, loss = 0.77616973
Iteration 359, loss = 0.82935158
Iteration 360, loss = 0.77744382
Iteration 361, loss = 0.80992064
Iteration 362, loss = 0.77030662
Iteration 363, loss = 0.79279090
Iteration 364, loss = 0.76018533
Iteration 365, loss = 0.77572879
Iteration 366, loss = 0.75281272
Iteration 367, loss = 0.83599523
Iteration 368, loss = 0.76699898
Iteration 369, loss = 0.82227587
Iteration 370, loss = 0.77464319
Iteration 371, loss = 0.80251445
Iteration 372, loss = 0.77627640
Iteration 373, loss = 0.78205984
Iteration 374, loss = 0.77429117
Iteration 375, loss = 0.76592194
Iteration 376, loss = 0.77269133
Iteration 377, loss = 0.75555432
Iteration 378, loss = 0.76760900
Iteration 379, loss = 0.72950132
Iteration 380, loss = 0.94588339
Iteration 381, loss = 0.81136449
Iteration 382, loss = 0.89463912
Iteration 383, loss = 0.77184903
Iteration 384, loss = 0.87445733
Iteration 385, loss = 0.75474800
Iteration 386, loss = 0.84976302
Iteration 387, loss = 0.74795059
Iteration 388, loss = 0.81465255
Iteration 389, loss = 0.75281030
Iteration 390, loss = 0.78425836
Iteration 391, loss = 0.75788968
Iteration 392, loss = 0.75645695
Iteration 393, loss = 0.74776517
Iteration 394, loss = 0.67838908
Iteration 395, loss = 1.04975603
Iteration 396, loss = 1.52807880
Iteration 397, loss = 1.34014815
Iteration 398, loss = 0.90193307
Iteration 399, loss = 1.42216963
Iteration 400, loss = 0.96690703
Iteration 401, loss = 1.17543406
Iteration 402, loss = 1.25997760
Iteration 403, loss = 0.95230735
Iteration 404, loss = 1.10694668
Iteration 405, loss = 0.86462520
Iteration 406, loss = 1.04710815
Iteration 407, loss = 0.93688232
Iteration 408, loss = 0.90428875
Iteration 409, loss = 0.96965523
Iteration 410, loss = 0.80652201
Iteration 411, loss = 0.87231729
Iteration 412, loss = 1.06201567
Iteration 413, loss = 0.90458192
Iteration 414, loss = 1.17740259
Iteration 415, loss = 0.85624055
Iteration 416, loss = 0.99199657
Iteration 417, loss = 1.03366004
Iteration 418, loss = 0.78871969
Iteration 419, loss = 0.99562575
Iteration 420, loss = 0.83878608
Iteration 421, loss = 0.89135421
Iteration 422, loss = 0.84745165
Iteration 423, loss = 0.79028006
Iteration 424, loss = 0.87097811
Iteration 425, loss = 0.76942479
Iteration 426, loss = 0.85419146
Iteration 427, loss = 0.77572936
Iteration 428, loss = 0.82439776
Iteration 429, loss = 0.79212925
Iteration 430, loss = 0.79261693
Iteration 431, loss = 0.80404784
Iteration 432, loss = 0.77033318
Iteration 433, loss = 0.80481727
Iteration 434, loss = 0.76274410
Iteration 435, loss = 0.79571943
Iteration 436, loss = 0.76511759
Iteration 437, loss = 0.78081993
Iteration 438, loss = 0.76622322
Iteration 439, loss = 0.79712248
Iteration 440, loss = 0.74593338
Iteration 441, loss = 0.75022532
Iteration 442, loss = 0.76086038
Iteration 443, loss = 0.75139793
Iteration 444, loss = 0.76908148
Iteration 445, loss = 0.77753879
Iteration 446, loss = 0.77640105
Iteration 447, loss = 0.77328507
Iteration 448, loss = 0.76806618
Iteration 449, loss = 0.76065428
Iteration 450, loss = 0.75509286
Iteration 451, loss = 0.75108590
Iteration 452, loss = 0.74787365
Iteration 453, loss = 0.74355916
Iteration 454, loss = 0.73736166
Iteration 455, loss = 0.69058195
Iteration 456, loss = 0.84708632
Iteration 457, loss = 0.82682852
Iteration 458, loss = 0.84294193
Iteration 459, loss = 0.74027934
Iteration 460, loss = 0.78423923
Iteration 461, loss = 0.79964068
Iteration 462, loss = 0.78662473
Iteration 463, loss = 0.79700109
Iteration 464, loss = 0.78164099
Iteration 465, loss = 0.79046842
Iteration 466, loss = 0.77720067
Iteration 467, loss = 0.78275648
Iteration 468, loss = 0.77080966
Iteration 469, loss = 0.77450504
Iteration 470, loss = 0.76539029
Iteration 471, loss = 0.76835288
Iteration 472, loss = 0.76264538
Iteration 473, loss = 0.76545775
Iteration 474, loss = 0.76252332
Iteration 475, loss = 0.76468429
Iteration 476, loss = 0.76320164
Iteration 477, loss = 0.76420943
Iteration 478, loss = 0.76331720
Iteration 479, loss = 0.76321862
Iteration 480, loss = 0.76260315
Iteration 481, loss = 0.76174074
Iteration 482, loss = 0.76133133
Iteration 483, loss = 0.76005042
Iteration 484, loss = 0.75979974
Iteration 485, loss = 0.75834726
Iteration 486, loss = 0.75823295
Iteration 487, loss = 0.75681821
Iteration 488, loss = 0.75686423
Iteration 489, loss = 0.75563615
Iteration 490, loss = 0.75583472
Iteration 491, loss = 0.75483193
Iteration 492, loss = 0.75510754
Iteration 493, loss = 0.75426216
Iteration 494, loss = 0.75449196
Iteration 495, loss = 0.75370223
Iteration 496, loss = 0.75379628
Iteration 497, loss = 0.75300624
Iteration 498, loss = 0.75294884
Iteration 499, loss = 0.75216224
Iteration 500, loss = 0.75198989
Iteration 501, loss = 0.75123701
Iteration 502, loss = 0.75100427
Iteration 503, loss = 0.75032987
Iteration 504, loss = 0.75010001
Iteration 505, loss = 0.74953169
Iteration 506, loss = 0.74931293
Iteration 507, loss = 0.74881195
Iteration 508, loss = 0.74858285
Iteration 509, loss = 0.74813265
Iteration 510, loss = 0.74789574
Iteration 511, loss = 0.74747053
Iteration 512, loss = 0.74717518
Iteration 513, loss = 0.74656248
Iteration 514, loss = 0.74605653
Iteration 515, loss = 0.74565659
Iteration 516, loss = 0.74544524
Iteration 517, loss = 0.74484958
Iteration 518, loss = 0.74469316
Iteration 519, loss = 0.74424608
Iteration 520, loss = 0.74348252
Iteration 521, loss = 0.74221202
Iteration 522, loss = 0.74077089
Iteration 523, loss = 0.74017534
Iteration 524, loss = 0.73690737
Iteration 525, loss = 0.79447990
Iteration 526, loss = 0.90553408
Iteration 527, loss = 0.74246870
Iteration 528, loss = 0.89758921
Iteration 529, loss = 0.76954718
Iteration 530, loss = 0.89332462
Iteration 531, loss = 0.80640534
Iteration 532, loss = 0.88740520
Iteration 533, loss = 0.82413314
Iteration 534, loss = 0.85835099
Iteration 535, loss = 0.81743531
Iteration 536, loss = 0.81571990
Iteration 537, loss = 0.79141098
Iteration 538, loss = 0.77542940
Iteration 539, loss = 0.77866086
Iteration 540, loss = 0.75671168
Iteration 541, loss = 0.77054348
Iteration 542, loss = 0.74920755
Iteration 543, loss = 0.76620105
Iteration 544, loss = 0.74832113
Iteration 545, loss = 0.76265583
Iteration 546, loss = 0.74999524
Iteration 547, loss = 0.75865521
Iteration 548, loss = 0.74990648
Iteration 549, loss = 0.74979068
Iteration 550, loss = 0.72716435
Iteration 551, loss = 0.81556600
Iteration 552, loss = 0.76313406
Iteration 553, loss = 0.81434495
Iteration 554, loss = 0.75454631
Iteration 555, loss = 0.79978014
Iteration 556, loss = 0.75458735
Iteration 557, loss = 0.78078491
Iteration 558, loss = 0.76030974
Iteration 559, loss = 0.76505522
Iteration 560, loss = 0.76642754
Iteration 561, loss = 0.75467922
Iteration 562, loss = 0.76889501
Iteration 563, loss = 0.74908434
Iteration 564, loss = 0.76688667
Iteration 565, loss = 0.74717081
Iteration 566, loss = 0.76125934
Iteration 567, loss = 0.74630700
Iteration 568, loss = 0.75894033
Iteration 569, loss = 0.74549577
Iteration 570, loss = 0.74667603
Iteration 571, loss = 0.66723102
Iteration 572, loss = 0.81082298
Iteration 573, loss = 0.80821824
Iteration 574, loss = 0.78660100
Iteration 575, loss = 0.83312519
Iteration 576, loss = 0.77699063
Iteration 577, loss = 0.82461812
Iteration 578, loss = 0.77204072
Iteration 579, loss = 0.80206997
Iteration 580, loss = 0.77037018
Iteration 581, loss = 0.77991737
Iteration 582, loss = 0.77112150
Iteration 583, loss = 0.76466228
Iteration 584, loss = 0.77290999
Iteration 585, loss = 0.75752143
Iteration 586, loss = 0.77306503
Iteration 587, loss = 0.75539521
Iteration 588, loss = 0.77117402
Iteration 589, loss = 0.75624234
Iteration 590, loss = 0.76666802
Iteration 591, loss = 0.75673994
Iteration 592, loss = 0.76097221
Iteration 593, loss = 0.75692367
Iteration 594, loss = 0.75665635
Iteration 595, loss = 0.75699980
Iteration 596, loss = 0.75164118
Iteration 597, loss = 0.75541293
Iteration 598, loss = 0.75004269
Iteration 599, loss = 0.75324059
Iteration 600, loss = 0.73747207
Iteration 601, loss = 0.79801174
Iteration 602, loss = 1.07658431
Iteration 603, loss = 0.70198287
Iteration 604, loss = 1.28303538
Iteration 605, loss = 0.83491976
Iteration 606, loss = 1.21606534
Iteration 607, loss = 1.02288109
Iteration 608, loss = 1.05468251
Iteration 609, loss = 1.09090127
Iteration 610, loss = 0.81100089
Iteration 611, loss = 1.06678509
Iteration 612, loss = 0.79104362
Iteration 613, loss = 0.96171292
Iteration 614, loss = 0.87909060
Iteration 615, loss = 0.82595223
Iteration 616, loss = 0.92149442
Iteration 617, loss = 0.75996822
Iteration 618, loss = 0.90321272
Iteration 619, loss = 0.77788683
Iteration 620, loss = 0.84776580
Iteration 621, loss = 0.81730376
Iteration 622, loss = 0.78685699
Iteration 623, loss = 0.83429893
Iteration 624, loss = 0.75427831
Iteration 625, loss = 0.82421814
Iteration 626, loss = 0.75633573
Iteration 627, loss = 0.79760626
Iteration 628, loss = 0.77187103
Iteration 629, loss = 0.76828861
Iteration 630, loss = 0.78188968
Iteration 631, loss = 0.74756015
Iteration 632, loss = 0.76051537
Iteration 633, loss = 0.78360652
Iteration 634, loss = 0.82081637
Iteration 635, loss = 0.82964285
Iteration 636, loss = 0.76853122
Iteration 637, loss = 0.83495512
Iteration 638, loss = 0.75459942
Iteration 639, loss = 0.80717954
Iteration 640, loss = 0.76998631
Iteration 641, loss = 0.77112875
Iteration 642, loss = 0.78635916
Iteration 643, loss = 0.75016326
Iteration 644, loss = 0.78730328
Iteration 645, loss = 0.74986152
Iteration 646, loss = 0.77381156
Iteration 647, loss = 0.75872652
Iteration 648, loss = 0.75594647
Iteration 649, loss = 0.76376455
Iteration 650, loss = 0.74411231
Iteration 651, loss = 0.76160082
Iteration 652, loss = 0.74234809
Iteration 653, loss = 0.75320877
Iteration 654, loss = 0.74522559
Iteration 655, loss = 0.74257360
Iteration 656, loss = 0.74602371
Iteration 657, loss = 0.73611785
Iteration 658, loss = 0.74199190
Iteration 659, loss = 0.72960781
Iteration 660, loss = 0.72789047
Iteration 661, loss = 0.89967315
Iteration 662, loss = 1.01922911
Iteration 663, loss = 0.76371806
Iteration 664, loss = 1.15181699
Iteration 665, loss = 0.98434217
Iteration 666, loss = 0.91581533
Iteration 667, loss = 1.12086378
Iteration 668, loss = 0.85018284
Iteration 669, loss = 1.00064694
Iteration 670, loss = 0.97200443
Iteration 671, loss = 0.81240768
Iteration 672, loss = 0.96189043
Iteration 673, loss = 0.80359560
Iteration 674, loss = 0.84428279
Iteration 675, loss = 0.86416204
Iteration 676, loss = 0.75285509
Iteration 677, loss = 0.85439329
Iteration 678, loss = 0.77324228
Iteration 679, loss = 0.79156772
Iteration 680, loss = 0.81752863
Iteration 681, loss = 0.75143591
Iteration 682, loss = 0.81419625
Iteration 683, loss = 0.76580886
Iteration 684, loss = 0.77557643
Iteration 685, loss = 0.78885986
Iteration 686, loss = 0.74766158
Iteration 687, loss = 0.78158339
Iteration 688, loss = 0.74594650
Iteration 689, loss = 0.77807911
Iteration 690, loss = 0.76368130
Iteration 691, loss = 0.74882630
Iteration 692, loss = 0.76735835
Iteration 693, loss = 0.73749511
Iteration 694, loss = 0.75015788
Iteration 695, loss = 0.74727843
Iteration 696, loss = 0.72951155
Iteration 697, loss = 0.72656138
Iteration 698, loss = 0.94019636
Iteration 699, loss = 0.75647318
Iteration 700, loss = 0.91278027
Iteration 701, loss = 0.86815852
Iteration 702, loss = 0.76872143
Iteration 703, loss = 0.88641229
Iteration 704, loss = 0.78881495
Iteration 705, loss = 0.76423207
Iteration 706, loss = 0.76961616
Iteration 707, loss = 1.50261067
Iteration 708, loss = 0.80149112
Iteration 709, loss = 1.34555526
Iteration 710, loss = 1.32110102
Iteration 711, loss = 0.79100962
Iteration 712, loss = 1.24158587
Iteration 713, loss = 1.09996409
Iteration 714, loss = 0.80374374
Iteration 715, loss = 1.12155234
Iteration 716, loss = 0.89328325
Iteration 717, loss = 0.86276160
Iteration 718, loss = 0.97087151
Iteration 719, loss = 0.61276903
Iteration 720, loss = 1.32945579
Iteration 721, loss = 0.90543901
Iteration 722, loss = 1.03489550
Iteration 723, loss = 1.23384504
Iteration 724, loss = 0.83722994
Iteration 725, loss = 1.06000847
Iteration 726, loss = 1.08864981
Iteration 727, loss = 0.82119781
Iteration 728, loss = 0.94663011
Iteration 729, loss = 0.79418363
Iteration 730, loss = 0.91290802
Iteration 731, loss = 0.79039760
Iteration 732, loss = 0.87035011
Iteration 733, loss = 0.80046117
Iteration 734, loss = 0.82064566
Iteration 735, loss = 0.81299513
Iteration 736, loss = 0.78451940
Iteration 737, loss = 0.82147934
Iteration 738, loss = 0.76869199
Iteration 739, loss = 0.81572862
Iteration 740, loss = 0.76681141
Iteration 741, loss = 0.92893271
Iteration 742, loss = 0.80681180
Iteration 743, loss = 0.82902484
Iteration 744, loss = 0.82936770
Iteration 745, loss = 0.78839769
Iteration 746, loss = 0.80458610
Iteration 747, loss = 0.91054677
Iteration 748, loss = 0.86874003
Iteration 749, loss = 0.82243081
Iteration 750, loss = 0.89266347
Iteration 751, loss = 0.79701815
Iteration 752, loss = 0.85274958
Iteration 753, loss = 0.82848908
Iteration 754, loss = 0.79795835
Iteration 755, loss = 0.84056626
Iteration 756, loss = 0.78381529
Iteration 757, loss = 0.81684021
Iteration 758, loss = 0.80228604
Iteration 759, loss = 0.78633251
Iteration 760, loss = 0.81211274
Iteration 761, loss = 0.77882463
Iteration 762, loss = 0.79986822
Iteration 763, loss = 0.78938799
Iteration 764, loss = 0.78150081
Iteration 765, loss = 0.79531059
Iteration 766, loss = 0.77506516
Iteration 767, loss = 0.78800407
Iteration 768, loss = 0.77967707
Iteration 769, loss = 0.77639299
Iteration 770, loss = 0.78330676
Iteration 771, loss = 0.77146976
Iteration 772, loss = 0.77966730
Iteration 773, loss = 0.77335481
Iteration 774, loss = 0.77237090
Iteration 775, loss = 0.77495492
Iteration 776, loss = 0.76772494
Iteration 777, loss = 0.77236762
Iteration 778, loss = 0.76728241
Iteration 779, loss = 0.76704698
Iteration 780, loss = 0.76716186
Iteration 781, loss = 0.76221740
Iteration 782, loss = 0.76420252
Iteration 783, loss = 0.76052153
Iteration 784, loss = 0.75970690
Iteration 785, loss = 0.75722858
Iteration 786, loss = 0.75057061
Iteration 787, loss = 0.74041500
Iteration 788, loss = 0.84336414
Iteration 789, loss = 0.79054330
Iteration 790, loss = 0.82307439
Iteration 791, loss = 0.83519567
Iteration 792, loss = 0.79263184
Iteration 793, loss = 0.83626011
Iteration 794, loss = 0.79196412
Iteration 795, loss = 0.80254968
Iteration 796, loss = 0.80166799
Iteration 797, loss = 0.77341552
Iteration 798, loss = 0.79809300
Iteration 799, loss = 0.77091146
Iteration 800, loss = 0.78149764
Iteration 801, loss = 0.78097440
Iteration 802, loss = 0.76823163
Iteration 803, loss = 0.78382438
Iteration 804, loss = 0.76765936
Iteration 805, loss = 0.77590349
Iteration 806, loss = 0.77334944
Iteration 807, loss = 0.76720465
Iteration 808, loss = 0.77528625
Iteration 809, loss = 0.76501132
Iteration 810, loss = 0.77068026
Iteration 811, loss = 0.76704362
Iteration 812, loss = 0.76568990
Iteration 813, loss = 0.76668887
Iteration 814, loss = 0.76210271
Iteration 815, loss = 0.76578330
Iteration 816, loss = 0.76049003
Iteration 817, loss = 0.76294125
Iteration 818, loss = 0.76055129
Iteration 819, loss = 0.76015583
Iteration 820, loss = 0.76090208
Iteration 821, loss = 0.75844621
Iteration 822, loss = 0.76029409
Iteration 823, loss = 0.75775554
Iteration 824, loss = 0.75872267
Iteration 825, loss = 0.75750204
Iteration 826, loss = 0.75690041
Iteration 827, loss = 0.75703126
Iteration 828, loss = 0.75542831
Iteration 829, loss = 0.75590408
Iteration 830, loss = 0.75410035
Iteration 831, loss = 0.75385513
Iteration 832, loss = 0.75289404
Iteration 833, loss = 0.75232859
Iteration 834, loss = 0.75225322
Iteration 835, loss = 0.75130641
Iteration 836, loss = 0.75137918
Iteration 837, loss = 0.75042900
Iteration 838, loss = 0.75020846
Iteration 839, loss = 0.74953039
Iteration 840, loss = 0.74892084
Iteration 841, loss = 0.74853313
Iteration 842, loss = 0.74772386
Iteration 843, loss = 0.74739989
Iteration 844, loss = 0.74652559
Iteration 845, loss = 0.74582843
Iteration 846, loss = 0.74461472
Iteration 847, loss = 0.74332974
Iteration 848, loss = 0.74220736
Iteration 849, loss = 0.74076687
Iteration 850, loss = 0.73965050
Iteration 851, loss = 0.73826355
Iteration 852, loss = 0.73649075
Iteration 853, loss = 0.73279411
Iteration 854, loss = 0.72571731
Iteration 855, loss = 0.79674832
Iteration 856, loss = 0.93352915
Iteration 857, loss = 0.81522319
Iteration 858, loss = 0.81943812
Iteration 859, loss = 1.10168732
Iteration 860, loss = 0.91341009
Iteration 861, loss = 1.03718223
Iteration 862, loss = 0.82880754
Iteration 863, loss = 1.02907780
Iteration 864, loss = 0.91835563
Iteration 865, loss = 0.90186619
Iteration 866, loss = 0.97189770
Iteration 867, loss = 0.81990045
Iteration 868, loss = 0.92297996
Iteration 869, loss = 0.83962117
Iteration 870, loss = 0.83030559
Iteration 871, loss = 0.86348371
Iteration 872, loss = 0.77605692
Iteration 873, loss = 0.86000564
Iteration 874, loss = 0.78375903
Iteration 875, loss = 0.82552334
Iteration 876, loss = 0.80753441
Iteration 877, loss = 0.78971697
Iteration 878, loss = 0.81044473
Iteration 879, loss = 0.80847277
Iteration 880, loss = 0.82360372
Iteration 881, loss = 1.00024682
Iteration 882, loss = 0.78858201
Iteration 883, loss = 0.99084592
Iteration 884, loss = 0.86852549
Iteration 885, loss = 0.84826506
Iteration 886, loss = 0.93094009
Iteration 887, loss = 0.77933725
Iteration 888, loss = 0.87213150
Iteration 889, loss = 0.82672355
Iteration 890, loss = 0.78947924
Iteration 891, loss = 0.85342402
Iteration 892, loss = 0.79024552
Iteration 893, loss = 0.87912155
Iteration 894, loss = 0.83168116
Iteration 895, loss = 0.84605135
Iteration 896, loss = 0.87694771
Iteration 897, loss = 0.81960806
Iteration 898, loss = 0.84540996
Iteration 899, loss = 0.96802275
Iteration 900, loss = 0.88735106
Iteration 901, loss = 0.98225186
Iteration 902, loss = 0.79932890
Iteration 903, loss = 0.92721140
Iteration 904, loss = 0.84921843
Iteration 905, loss = 1.28284847
Iteration 906, loss = 1.18869229
Iteration 907, loss = 0.86242529
Iteration 908, loss = 1.21459561
Iteration 909, loss = 0.80111809
Iteration 910, loss = 0.75728007
Iteration 911, loss = 1.17676662
Iteration 912, loss = 0.83594213
Iteration 913, loss = 1.14012276
Iteration 914, loss = 0.95472248
Iteration 915, loss = 0.97852352
Iteration 916, loss = 1.03562341
Iteration 917, loss = 0.83267238
Iteration 918, loss = 1.00819899
Iteration 919, loss = 0.82127942
Iteration 920, loss = 0.92872630
Iteration 921, loss = 0.87340613
Iteration 922, loss = 0.83868979
Iteration 923, loss = 0.88282685
Iteration 924, loss = 0.95297744
Iteration 925, loss = 0.80855294
Iteration 926, loss = 0.93346931
Iteration 927, loss = 0.80894087
Iteration 928, loss = 0.90585968
Iteration 929, loss = 0.80269832
Iteration 930, loss = 0.88013634
Iteration 931, loss = 0.79223519
Iteration 932, loss = 0.89510617
Iteration 933, loss = 0.79507882
Iteration 934, loss = 0.87949157
Iteration 935, loss = 0.80259221
Iteration 936, loss = 0.85825085
Iteration 937, loss = 0.80881093
Iteration 938, loss = 0.83529007
Iteration 939, loss = 0.81294579
Iteration 940, loss = 0.81558800
Iteration 941, loss = 0.81579154
Iteration 942, loss = 0.80168688
Iteration 943, loss = 0.81615027
Iteration 944, loss = 0.79281257
Iteration 945, loss = 0.81369745
Iteration 946, loss = 0.78776972
Iteration 947, loss = 0.80900762
Iteration 948, loss = 0.78514122
Iteration 949, loss = 0.80305329
Iteration 950, loss = 0.78509793
Iteration 951, loss = 0.79772625
Iteration 952, loss = 0.78568242
Iteration 953, loss = 0.79230025
Iteration 954, loss = 0.78588333
Iteration 955, loss = 0.78729625
Iteration 956, loss = 0.78568225
Iteration 957, loss = 0.78364242
Iteration 958, loss = 0.78510147
Iteration 959, loss = 0.78046145
Iteration 960, loss = 0.78318597
Iteration 961, loss = 0.77947003
Iteration 962, loss = 0.78137318
Iteration 963, loss = 0.77914417
Iteration 964, loss = 0.78055294
Iteration 965, loss = 0.77647335
Iteration 966, loss = 0.77374484
Iteration 967, loss = 0.74668928
Iteration 968, loss = 0.80737292
Iteration 969, loss = 0.81597227
Iteration 970, loss = 0.81525854
Iteration 971, loss = 0.80468613
Iteration 972, loss = 0.81269598
Iteration 973, loss = 0.79019506
Iteration 974, loss = 0.80386318
Iteration 975, loss = 0.77708855
Iteration 976, loss = 0.79425926
Iteration 977, loss = 0.76864900
Iteration 978, loss = 0.78373000
Iteration 979, loss = 0.75367797
Iteration 980, loss = 0.84872175
Iteration 981, loss = 1.33032247
Iteration 982, loss = 0.98565271
Iteration 983, loss = 1.08942682
Iteration 984, loss = 1.21630163
Iteration 985, loss = 0.83380444
Iteration 986, loss = 1.17228426
Iteration 987, loss = 0.91588064
Iteration 988, loss = 0.99992639
Iteration 989, loss = 1.03017868
Iteration 990, loss = 0.82599103
Iteration 991, loss = 1.01602043
Iteration 992, loss = 0.81074944
Iteration 993, loss = 0.93258517
Iteration 994, loss = 0.87365398
Iteration 995, loss = 0.83070526
Iteration 996, loss = 0.90417871
Iteration 997, loss = 0.78215198
Iteration 998, loss = 0.88705733
Iteration 999, loss = 0.79628550
Iteration 1000, loss = 0.84180252
